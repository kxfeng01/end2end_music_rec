25/02/04 17:11:40 WARN Utils: Your hostname, Kexins-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.43 instead (on interface en0)
25/02/04 17:11:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/04 17:11:41 INFO SparkContext: Running Spark version 3.5.4
25/02/04 17:11:41 INFO SparkContext: OS info Mac OS X, 10.16, x86_64
25/02/04 17:11:41 INFO SparkContext: Java version 1.8.0_231
25/02/04 17:11:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/04 17:11:41 INFO ResourceUtils: ==============================================================
25/02/04 17:11:41 INFO ResourceUtils: No custom resources configured for spark.driver.
25/02/04 17:11:41 INFO ResourceUtils: ==============================================================
25/02/04 17:11:41 INFO SparkContext: Submitted application: ProcessData
25/02/04 17:11:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/02/04 17:11:41 INFO ResourceProfile: Limiting resource is cpu
25/02/04 17:11:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/02/04 17:11:41 INFO SecurityManager: Changing view acls to: Kexin
25/02/04 17:11:41 INFO SecurityManager: Changing modify acls to: Kexin
25/02/04 17:11:41 INFO SecurityManager: Changing view acls groups to: 
25/02/04 17:11:41 INFO SecurityManager: Changing modify acls groups to: 
25/02/04 17:11:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Kexin; groups with view permissions: EMPTY; users with modify permissions: Kexin; groups with modify permissions: EMPTY
25/02/04 17:11:42 INFO Utils: Successfully started service 'sparkDriver' on port 62418.
25/02/04 17:11:42 INFO SparkEnv: Registering MapOutputTracker
25/02/04 17:11:42 INFO SparkEnv: Registering BlockManagerMaster
25/02/04 17:11:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/02/04 17:11:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/02/04 17:11:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/02/04 17:11:42 INFO DiskBlockManager: Created local directory at /private/var/folders/fp/rrfgkk216j93ycpskxsyphnw0000gn/T/blockmgr-a7a46525-9fbd-4c80-8024-669c30059a31
25/02/04 17:11:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/02/04 17:11:42 INFO SparkEnv: Registering OutputCommitCoordinator
25/02/04 17:11:42 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/02/04 17:11:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/02/04 17:11:42 INFO Executor: Starting executor ID driver on host 10.0.0.43
25/02/04 17:11:42 INFO Executor: OS info Mac OS X, 10.16, x86_64
25/02/04 17:11:42 INFO Executor: Java version 1.8.0_231
25/02/04 17:11:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/02/04 17:11:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1ee9c375 for default.
25/02/04 17:11:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62420.
25/02/04 17:11:42 INFO NettyBlockTransferService: Server created on 10.0.0.43:62420
25/02/04 17:11:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/02/04 17:11:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.0.43, 62420, None)
25/02/04 17:11:42 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.0.43:62420 with 366.3 MiB RAM, BlockManagerId(driver, 10.0.0.43, 62420, None)
25/02/04 17:11:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.0.43, 62420, None)
25/02/04 17:11:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.0.43, 62420, None)
25/02/04 17:11:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/02/04 17:11:43 INFO SharedState: Warehouse path is 'file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/spark-warehouse'.
25/02/04 17:11:44 INFO InMemoryFileIndex: It took 56 ms to list leaf files for 1 paths.
25/02/04 17:11:44 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/02/04 17:11:47 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:11:47 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/02/04 17:11:48 INFO CodeGenerator: Code generated in 268.669167 ms
25/02/04 17:11:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.4 KiB, free 366.0 MiB)
25/02/04 17:11:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 365.9 MiB)
25/02/04 17:11:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.3 MiB)
25/02/04 17:11:49 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:11:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:11:49 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:11:49 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:11:49 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:11:49 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:11:49 INFO DAGScheduler: Missing parents: List()
25/02/04 17:11:49 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:11:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 365.9 MiB)
25/02/04 17:11:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 365.9 MiB)
25/02/04 17:11:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.0.43:62420 (size: 6.4 KiB, free: 366.3 MiB)
25/02/04 17:11:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/02/04 17:11:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:11:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/02/04 17:11:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/02/04 17:11:50 INFO CodeGenerator: Code generated in 49.555375 ms
25/02/04 17:11:50 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:11:50 INFO CodeGenerator: Code generated in 29.015333 ms
25/02/04 17:11:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1676 bytes result sent to driver
25/02/04 17:11:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 780 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:11:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/02/04 17:11:50 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.994 s
25/02/04 17:11:50 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:11:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/02/04 17:11:50 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.089623 s
25/02/04 17:11:50 INFO CodeGenerator: Code generated in 23.790917 ms
25/02/04 17:11:50 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:11:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:11:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 350.4 KiB, free 365.6 MiB)
25/02/04 17:11:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 365.5 MiB)
25/02/04 17:11:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:11:50 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:11:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:11:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:11:50 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:11:50 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:11:50 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:11:50 INFO DAGScheduler: Missing parents: List()
25/02/04 17:11:50 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:11:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.7 KiB, free 365.5 MiB)
25/02/04 17:11:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 365.5 MiB)
25/02/04 17:11:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.0.43:62420 (size: 12.7 KiB, free: 366.2 MiB)
25/02/04 17:11:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
25/02/04 17:11:50 INFO DAGScheduler: Submitting 23 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:11:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 23 tasks resource profile 0
25/02/04 17:11:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/02/04 17:11:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
25/02/04 17:11:50 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
25/02/04 17:11:50 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)
25/02/04 17:11:50 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
25/02/04 17:11:50 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
25/02/04 17:11:50 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
25/02/04 17:11:50 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)
25/02/04 17:11:50 INFO Executor: Running task 8.0 in stage 1.0 (TID 9)
25/02/04 17:11:50 INFO Executor: Running task 9.0 in stage 1.0 (TID 10)
25/02/04 17:11:51 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.0.43:62420 in memory (size: 6.4 KiB, free: 366.2 MiB)
25/02/04 17:11:51 INFO CodeGenerator: Code generated in 29.113583 ms
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:11:51 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:11:56 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1616 bytes result sent to driver
25/02/04 17:11:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)
25/02/04 17:11:56 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)
25/02/04 17:11:56 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 13) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 12.0 in stage 1.0 (TID 13)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 5695 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 5694 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 5696 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:11:56 INFO Executor: Finished task 9.0 in stage 1.0 (TID 10). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 14) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 13.0 in stage 1.0 (TID 14)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 5763 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:11:56 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO Executor: Finished task 8.0 in stage 1.0 (TID 9). 1616 bytes result sent to driver
25/02/04 17:11:56 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 15) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 14.0 in stage 1.0 (TID 15)
25/02/04 17:11:56 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 16) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 15.0 in stage 1.0 (TID 16)
25/02/04 17:11:56 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 17) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 16.0 in stage 1.0 (TID 17)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 5803 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 5806 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 5805 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:11:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1616 bytes result sent to driver
25/02/04 17:11:56 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 18) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 17.0 in stage 1.0 (TID 18)
25/02/04 17:11:56 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 19) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5866 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:11:56 INFO Executor: Running task 18.0 in stage 1.0 (TID 19)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 5862 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:11:56 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 1659 bytes result sent to driver
25/02/04 17:11:56 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 20) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:56 INFO Executor: Running task 19.0 in stage 1.0 (TID 20)
25/02/04 17:11:56 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 5907 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:11:56 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:11:59 INFO Executor: Finished task 14.0 in stage 1.0 (TID 15). 1659 bytes result sent to driver
25/02/04 17:11:59 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 21) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:11:59 INFO Executor: Running task 20.0 in stage 1.0 (TID 21)
25/02/04 17:11:59 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 15) in 3309 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:12:00 INFO Executor: Finished task 17.0 in stage 1.0 (TID 18). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 22) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:12:00 INFO Executor: Running task 21.0 in stage 1.0 (TID 22)
25/02/04 17:12:00 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 18) in 3335 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:12:00 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:12:00 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:12:00 INFO Executor: Finished task 10.0 in stage 1.0 (TID 11). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 23) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9635 bytes) 
25/02/04 17:12:00 INFO Executor: Running task 22.0 in stage 1.0 (TID 23)
25/02/04 17:12:00 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 3687 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:12:00 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:12:00 INFO Executor: Finished task 19.0 in stage 1.0 (TID 20). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 20) in 3559 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:12:00 INFO Executor: Finished task 18.0 in stage 1.0 (TID 19). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 19) in 3629 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:12:00 INFO Executor: Finished task 12.0 in stage 1.0 (TID 13). 1616 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 13) in 3893 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:12:00 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 3935 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:12:00 INFO Executor: Finished task 16.0 in stage 1.0 (TID 17). 1616 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 17) in 3768 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:12:00 INFO Executor: Finished task 15.0 in stage 1.0 (TID 16). 1616 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 16) in 3777 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:12:00 INFO Executor: Finished task 13.0 in stage 1.0 (TID 14). 1659 bytes result sent to driver
25/02/04 17:12:00 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 14) in 4020 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:12:01 INFO Executor: Finished task 22.0 in stage 1.0 (TID 23). 1659 bytes result sent to driver
25/02/04 17:12:01 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 23) in 880 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:12:02 INFO Executor: Finished task 21.0 in stage 1.0 (TID 22). 1616 bytes result sent to driver
25/02/04 17:12:02 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 22) in 2125 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:12:02 INFO Executor: Finished task 20.0 in stage 1.0 (TID 21). 1616 bytes result sent to driver
25/02/04 17:12:02 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 21) in 2276 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:12:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/02/04 17:12:02 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 11.421 s
25/02/04 17:12:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:12:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/02/04 17:12:02 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 11.444342 s
25/02/04 17:12:02 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/02/04 17:12:02 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/02/04 17:12:02 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:02 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#30, None)) > 0)
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 350.4 KiB, free 365.2 MiB)
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 365.1 MiB)
25/02/04 17:12:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:12:02 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:02 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:02 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:12:02 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:02 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:02 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KiB, free 365.1 MiB)
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 365.1 MiB)
25/02/04 17:12:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.0.43:62420 (size: 6.4 KiB, free: 366.2 MiB)
25/02/04 17:12:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:12:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/02/04 17:12:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 24) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9649 bytes) 
25/02/04 17:12:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 24)
25/02/04 17:12:02 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 0-4194304, partition values: [empty row]
25/02/04 17:12:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 24). 1609 bytes result sent to driver
25/02/04 17:12:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 24) in 38 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:12:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/02/04 17:12:02 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.060 s
25/02/04 17:12:02 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:12:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/02/04 17:12:02 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.072783 s
25/02/04 17:12:02 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:02 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 350.4 KiB, free 364.8 MiB)
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/02/04 17:12:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:02 INFO SparkContext: Created broadcast 6 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:02 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:02 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/02/04 17:12:02 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:02 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:02 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 27.6 KiB, free 364.7 MiB)
25/02/04 17:12:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 364.7 MiB)
25/02/04 17:12:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.0.43:62420 (size: 12.7 KiB, free: 366.1 MiB)
25/02/04 17:12:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/02/04 17:12:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks resource profile 0
25/02/04 17:12:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 25) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9649 bytes) 
25/02/04 17:12:02 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 26) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9649 bytes) 
25/02/04 17:12:02 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 27) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9649 bytes) 
25/02/04 17:12:02 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 28) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9649 bytes) 
25/02/04 17:12:02 INFO Executor: Running task 1.0 in stage 3.0 (TID 26)
25/02/04 17:12:02 INFO Executor: Running task 3.0 in stage 3.0 (TID 28)
25/02/04 17:12:02 INFO Executor: Running task 2.0 in stage 3.0 (TID 27)
25/02/04 17:12:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 25)
25/02/04 17:12:02 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 4194304-8388608, partition values: [empty row]
25/02/04 17:12:02 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 8388608-12582912, partition values: [empty row]
25/02/04 17:12:02 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 12582912-14644326, partition values: [empty row]
25/02/04 17:12:02 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 0-4194304, partition values: [empty row]
25/02/04 17:12:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:12:03 INFO Executor: Finished task 3.0 in stage 3.0 (TID 28). 1603 bytes result sent to driver
25/02/04 17:12:03 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 28) in 291 ms on 10.0.0.43 (executor driver) (1/4)
25/02/04 17:12:03 INFO Executor: Finished task 2.0 in stage 3.0 (TID 27). 1560 bytes result sent to driver
25/02/04 17:12:03 INFO Executor: Finished task 1.0 in stage 3.0 (TID 26). 1560 bytes result sent to driver
25/02/04 17:12:03 INFO Executor: Finished task 0.0 in stage 3.0 (TID 25). 1560 bytes result sent to driver
25/02/04 17:12:03 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 27) in 300 ms on 10.0.0.43 (executor driver) (2/4)
25/02/04 17:12:03 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 26) in 301 ms on 10.0.0.43 (executor driver) (3/4)
25/02/04 17:12:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 25) in 303 ms on 10.0.0.43 (executor driver) (4/4)
25/02/04 17:12:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/02/04 17:12:03 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.333 s
25/02/04 17:12:03 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:12:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/02/04 17:12:03 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.349736 s
25/02/04 17:12:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/02/04 17:12:03 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/02/04 17:12:03 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:03 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#56, None)) > 0)
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 350.4 KiB, free 364.7 MiB)
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/02/04 17:12:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:03 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:03 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:03 INFO DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:12:03 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:03 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:03 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.5 KiB, free 364.7 MiB)
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 364.7 MiB)
25/02/04 17:12:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.0.43:62420 (size: 6.4 KiB, free: 366.1 MiB)
25/02/04 17:12:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:12:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/02/04 17:12:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 29) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9631 bytes) 
25/02/04 17:12:03 INFO Executor: Running task 0.0 in stage 4.0 (TID 29)
25/02/04 17:12:03 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/msd_subset.csv, range: 0-1155592, partition values: [empty row]
25/02/04 17:12:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 29). 1714 bytes result sent to driver
25/02/04 17:12:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 29) in 46 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:12:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/02/04 17:12:03 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.067 s
25/02/04 17:12:03 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:12:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/02/04 17:12:03 INFO DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:0, took 0.088168 s
25/02/04 17:12:03 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 350.4 KiB, free 364.3 MiB)
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.3 MiB)
25/02/04 17:12:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:03 INFO SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:03 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/02/04 17:12:03 INFO DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:12:03 INFO DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:03 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:03 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 27.8 KiB, free 364.3 MiB)
25/02/04 17:12:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 364.3 MiB)
25/02/04 17:12:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.0.43:62420 (size: 12.8 KiB, free: 366.1 MiB)
25/02/04 17:12:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:12:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/02/04 17:12:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 30) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9631 bytes) 
25/02/04 17:12:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 30)
25/02/04 17:12:03 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/msd_subset.csv, range: 0-1155592, partition values: [empty row]
25/02/04 17:12:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 30). 1600 bytes result sent to driver
25/02/04 17:12:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 30) in 150 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:12:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/02/04 17:12:03 INFO DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.179 s
25/02/04 17:12:03 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:12:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/02/04 17:12:03 INFO DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 0.201643 s
25/02/04 17:12:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(_c0),IsNotNull(_c1)
25/02/04 17:12:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(_c0#17),isnotnull(_c1#18)
25/02/04 17:12:04 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:04 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:12:04 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:12:04 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:12:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:05 INFO CodeGenerator: Code generated in 46.574417 ms
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 350.3 KiB, free 363.9 MiB)
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 363.9 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.0 MiB)
25/02/04 17:12:05 INFO SparkContext: Created broadcast 12 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:12:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:05 INFO DAGScheduler: Registering RDD 33 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/02/04 17:12:05 INFO DAGScheduler: Got map stage job 6 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:12:05 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:05 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:05 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:05 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[33] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 18.3 KiB, free 363.9 MiB)
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 363.9 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.0.43:62420 (size: 8.8 KiB, free: 366.0 MiB)
25/02/04 17:12:05 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:05 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[33] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:12:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 23 tasks resource profile 0
25/02/04 17:12:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 31) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 32) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 33) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 34) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 35) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 36) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 37) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 38) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 8.0 in stage 6.0 (TID 39) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO TaskSetManager: Starting task 9.0 in stage 6.0 (TID 40) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:05 INFO Executor: Running task 1.0 in stage 6.0 (TID 32)
25/02/04 17:12:05 INFO Executor: Running task 0.0 in stage 6.0 (TID 31)
25/02/04 17:12:05 INFO Executor: Running task 9.0 in stage 6.0 (TID 40)
25/02/04 17:12:05 INFO Executor: Running task 2.0 in stage 6.0 (TID 33)
25/02/04 17:12:05 INFO Executor: Running task 8.0 in stage 6.0 (TID 39)
25/02/04 17:12:05 INFO Executor: Running task 3.0 in stage 6.0 (TID 34)
25/02/04 17:12:05 INFO Executor: Running task 7.0 in stage 6.0 (TID 38)
25/02/04 17:12:05 INFO Executor: Running task 4.0 in stage 6.0 (TID 35)
25/02/04 17:12:05 INFO Executor: Running task 6.0 in stage 6.0 (TID 37)
25/02/04 17:12:05 INFO Executor: Running task 5.0 in stage 6.0 (TID 36)
25/02/04 17:12:05 INFO CodeGenerator: Code generated in 66.418708 ms
25/02/04 17:12:05 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.0.43:62420 in memory (size: 12.8 KiB, free: 366.1 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.0.43:62420 in memory (size: 6.4 KiB, free: 366.1 MiB)
25/02/04 17:12:05 INFO CodeGenerator: Code generated in 132.678625 ms
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:12:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:12:05 INFO CodeGenerator: Code generated in 37.634375 ms
25/02/04 17:12:05 INFO CodeGenerator: Code generated in 757.807459 ms
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 350.3 KiB, free 364.3 MiB)
25/02/04 17:12:05 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.3 MiB)
25/02/04 17:12:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:05 INFO SparkContext: Created broadcast 14 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:12:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:06 INFO CodeGenerator: Code generated in 58.455125 ms
25/02/04 17:12:06 INFO DAGScheduler: Registering RDD 37 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/02/04 17:12:06 INFO DAGScheduler: Got map stage job 7 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:12:06 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:06 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:06 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:06 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[37] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:06 INFO CodeGenerator: Code generated in 24.8965 ms
25/02/04 17:12:06 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 37.1 KiB, free 364.3 MiB)
25/02/04 17:12:06 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 364.2 MiB)
25/02/04 17:12:06 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:12:06 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:06 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[37] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:12:06 INFO TaskSchedulerImpl: Adding task set 7.0 with 23 tasks resource profile 0
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.0.43:62420 in memory (size: 12.7 KiB, free: 366.1 MiB)
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.0.43:62420 in memory (size: 6.4 KiB, free: 366.2 MiB)
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.0.43:62420 in memory (size: 12.7 KiB, free: 366.2 MiB)
25/02/04 17:12:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:12:07 INFO CodeGenerator: Code generated in 1509.759583 ms
25/02/04 17:12:07 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 350.3 KiB, free 365.1 MiB)
25/02/04 17:12:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 365.1 MiB)
25/02/04 17:12:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:12:08 INFO SparkContext: Created broadcast 16 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:12:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:12:08 INFO DAGScheduler: Registering RDD 41 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/02/04 17:12:08 INFO DAGScheduler: Got map stage job 8 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:12:08 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:08 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:12:08 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:08 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[41] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:08 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 37.1 KiB, free 365.1 MiB)
25/02/04 17:12:08 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 365.0 MiB)
25/02/04 17:12:08 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.2 MiB)
25/02/04 17:12:08 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:08 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[41] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:12:08 INFO TaskSchedulerImpl: Adding task set 8.0 with 23 tasks resource profile 0
25/02/04 17:12:13 INFO Executor: Finished task 7.0 in stage 6.0 (TID 38). 2085 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 3.0 in stage 6.0 (TID 34). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 0.0 in stage 6.0 (TID 31). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 8.0 in stage 6.0 (TID 39). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 1.0 in stage 6.0 (TID 32). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 4.0 in stage 6.0 (TID 35). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 9.0 in stage 6.0 (TID 40). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 6.0 in stage 6.0 (TID 37). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 2.0 in stage 6.0 (TID 33). 2128 bytes result sent to driver
25/02/04 17:12:13 INFO Executor: Finished task 5.0 in stage 6.0 (TID 36). 2085 bytes result sent to driver
25/02/04 17:12:13 INFO TaskSetManager: Starting task 10.0 in stage 6.0 (TID 41) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 10.0 in stage 6.0 (TID 41)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 11.0 in stage 6.0 (TID 42) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 11.0 in stage 6.0 (TID 42)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 12.0 in stage 6.0 (TID 43) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 12.0 in stage 6.0 (TID 43)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 13.0 in stage 6.0 (TID 44) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 13.0 in stage 6.0 (TID 44)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 14.0 in stage 6.0 (TID 45) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 14.0 in stage 6.0 (TID 45)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 15.0 in stage 6.0 (TID 46) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 15.0 in stage 6.0 (TID 46)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 16.0 in stage 6.0 (TID 47) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 16.0 in stage 6.0 (TID 47)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 17.0 in stage 6.0 (TID 48) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO TaskSetManager: Starting task 18.0 in stage 6.0 (TID 49) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 17.0 in stage 6.0 (TID 48)
25/02/04 17:12:13 INFO Executor: Running task 18.0 in stage 6.0 (TID 49)
25/02/04 17:12:13 INFO TaskSetManager: Starting task 19.0 in stage 6.0 (TID 50) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:13 INFO Executor: Running task 19.0 in stage 6.0 (TID 50)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 38) in 8792 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 31) in 8820 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 8.0 in stage 6.0 (TID 39) in 8806 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 34) in 8808 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 32) in 8829 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 35) in 8822 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 37) in 8821 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 9.0 in stage 6.0 (TID 40) in 8821 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 33) in 8827 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:12:14 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 36) in 8825 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:12:14 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:12:21 INFO Executor: Finished task 13.0 in stage 6.0 (TID 44). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 17.0 in stage 6.0 (TID 48). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 12.0 in stage 6.0 (TID 43). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 11.0 in stage 6.0 (TID 42). 2085 bytes result sent to driver
25/02/04 17:12:21 INFO TaskSetManager: Starting task 20.0 in stage 6.0 (TID 51) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 20.0 in stage 6.0 (TID 51)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 21.0 in stage 6.0 (TID 52) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 21.0 in stage 6.0 (TID 52)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 22.0 in stage 6.0 (TID 53) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 22.0 in stage 6.0 (TID 53)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 54) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 54)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 13.0 in stage 6.0 (TID 44) in 7137 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 11.0 in stage 6.0 (TID 42) in 7160 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 12.0 in stage 6.0 (TID 43) in 7147 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 17.0 in stage 6.0 (TID 48) in 7140 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:12:21 INFO Executor: Finished task 16.0 in stage 6.0 (TID 47). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 14.0 in stage 6.0 (TID 45). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 10.0 in stage 6.0 (TID 41). 2128 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Finished task 19.0 in stage 6.0 (TID 50). 2085 bytes result sent to driver
25/02/04 17:12:21 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 55) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 1.0 in stage 7.0 (TID 55)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 56) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO TaskSetManager: Finished task 16.0 in stage 6.0 (TID 47) in 7292 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:12:21 INFO Executor: Running task 2.0 in stage 7.0 (TID 56)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 57) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 3.0 in stage 7.0 (TID 57)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 58) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Finished task 15.0 in stage 6.0 (TID 46). 2085 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Running task 4.0 in stage 7.0 (TID 58)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 59) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Finished task 18.0 in stage 6.0 (TID 49). 2085 bytes result sent to driver
25/02/04 17:12:21 INFO Executor: Running task 5.0 in stage 7.0 (TID 59)
25/02/04 17:12:21 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 60) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:21 INFO Executor: Running task 6.0 in stage 7.0 (TID 60)
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:12:21 INFO TaskSetManager: Finished task 19.0 in stage 6.0 (TID 50) in 7557 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 14.0 in stage 6.0 (TID 45) in 7559 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 10.0 in stage 6.0 (TID 41) in 7598 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 15.0 in stage 6.0 (TID 46) in 7560 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:12:21 INFO TaskSetManager: Finished task 18.0 in stage 6.0 (TID 49) in 7566 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:12:21 INFO CodeGenerator: Code generated in 567.314417 ms
25/02/04 17:12:21 INFO CodeGenerator: Code generated in 47.017708 ms
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:12:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:12:23 INFO Executor: Finished task 22.0 in stage 6.0 (TID 53). 2128 bytes result sent to driver
25/02/04 17:12:23 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 61) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:23 INFO Executor: Running task 7.0 in stage 7.0 (TID 61)
25/02/04 17:12:23 INFO TaskSetManager: Finished task 22.0 in stage 6.0 (TID 53) in 2867 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:12:24 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:12:27 INFO Executor: Finished task 21.0 in stage 6.0 (TID 52). 2128 bytes result sent to driver
25/02/04 17:12:27 INFO TaskSetManager: Finished task 21.0 in stage 6.0 (TID 52) in 6665 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:12:27 INFO Executor: Finished task 20.0 in stage 6.0 (TID 51). 2085 bytes result sent to driver
25/02/04 17:12:27 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 62) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:27 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 63) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:27 INFO Executor: Running task 8.0 in stage 7.0 (TID 62)
25/02/04 17:12:27 INFO Executor: Running task 9.0 in stage 7.0 (TID 63)
25/02/04 17:12:27 INFO TaskSetManager: Finished task 20.0 in stage 6.0 (TID 51) in 6765 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/02/04 17:12:27 INFO DAGScheduler: ShuffleMapStage 6 (parquet at NativeMethodAccessorImpl.java:0) finished in 22.733 s
25/02/04 17:12:27 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:27 INFO DAGScheduler: running: Set(ShuffleMapStage 7, ShuffleMapStage 8)
25/02/04 17:12:27 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:27 INFO DAGScheduler: failed: Set()
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:12:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 54). 2805 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 1.0 in stage 7.0 (TID 55). 2805 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 6.0 in stage 7.0 (TID 60). 2805 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 4.0 in stage 7.0 (TID 58). 2805 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 2.0 in stage 7.0 (TID 56). 2805 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 5.0 in stage 7.0 (TID 59). 2762 bytes result sent to driver
25/02/04 17:12:28 INFO Executor: Finished task 3.0 in stage 7.0 (TID 57). 2762 bytes result sent to driver
25/02/04 17:12:28 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 64) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 10.0 in stage 7.0 (TID 64)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 65) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 11.0 in stage 7.0 (TID 65)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 66) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 12.0 in stage 7.0 (TID 66)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 67) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 13.0 in stage 7.0 (TID 67)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 68) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 14.0 in stage 7.0 (TID 68)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 69) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 15.0 in stage 7.0 (TID 69)
25/02/04 17:12:28 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 70) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO Executor: Running task 16.0 in stage 7.0 (TID 70)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 56) in 7417 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 55) in 7440 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 60) in 7392 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 54) in 7582 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 59) in 7395 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 58) in 7409 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:12:28 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 57) in 7412 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:12:28 INFO Executor: Finished task 7.0 in stage 7.0 (TID 61). 2762 bytes result sent to driver
25/02/04 17:12:28 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 71) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:28 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 61) in 4791 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:12:28 INFO Executor: Running task 17.0 in stage 7.0 (TID 71)
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:12:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:12:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:32 INFO Executor: Finished task 9.0 in stage 7.0 (TID 63). 2805 bytes result sent to driver
25/02/04 17:12:32 INFO Executor: Finished task 8.0 in stage 7.0 (TID 62). 2805 bytes result sent to driver
25/02/04 17:12:32 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 72) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:32 INFO Executor: Running task 18.0 in stage 7.0 (TID 72)
25/02/04 17:12:32 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 73) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:32 INFO Executor: Running task 19.0 in stage 7.0 (TID 73)
25/02/04 17:12:32 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 62) in 5003 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:12:32 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 63) in 4998 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:12:32 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:12:32 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:12:33 INFO Executor: Finished task 11.0 in stage 7.0 (TID 65). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 74) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 65) in 4447 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:12:33 INFO Executor: Running task 20.0 in stage 7.0 (TID 74)
25/02/04 17:12:33 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:12:33 INFO Executor: Finished task 17.0 in stage 7.0 (TID 71). 2805 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 75) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 21.0 in stage 7.0 (TID 75)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 71) in 4612 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:12:33 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:12:33 INFO Executor: Finished task 14.0 in stage 7.0 (TID 68). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 76) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 22.0 in stage 7.0 (TID 76)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 68) in 4797 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:12:33 INFO Executor: Finished task 13.0 in stage 7.0 (TID 67). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 77) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 0.0 in stage 8.0 (TID 77)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 67) in 4813 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:12:33 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:12:33 INFO Executor: Finished task 10.0 in stage 7.0 (TID 64). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 78) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 1.0 in stage 8.0 (TID 78)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 64) in 4889 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:12:33 INFO Executor: Finished task 12.0 in stage 7.0 (TID 66). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 79) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 2.0 in stage 8.0 (TID 79)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 66) in 5044 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:12:33 INFO Executor: Finished task 15.0 in stage 7.0 (TID 69). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO Executor: Finished task 16.0 in stage 7.0 (TID 70). 2762 bytes result sent to driver
25/02/04 17:12:33 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 80) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 69) in 5093 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:12:33 INFO Executor: Running task 3.0 in stage 8.0 (TID 80)
25/02/04 17:12:33 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 81) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:33 INFO Executor: Running task 4.0 in stage 8.0 (TID 81)
25/02/04 17:12:33 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 70) in 5093 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:12:33 INFO CodeGenerator: Code generated in 462.2995 ms
25/02/04 17:12:34 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:12:34 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:12:34 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:12:34 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:12:34 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:12:35 INFO Executor: Finished task 22.0 in stage 7.0 (TID 76). 2805 bytes result sent to driver
25/02/04 17:12:35 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 82) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:35 INFO Executor: Running task 5.0 in stage 8.0 (TID 82)
25/02/04 17:12:35 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 76) in 1559 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:12:35 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:12:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.0.43:62420 in memory (size: 8.8 KiB, free: 366.2 MiB)
25/02/04 17:12:37 INFO Executor: Finished task 18.0 in stage 7.0 (TID 72). 2805 bytes result sent to driver
25/02/04 17:12:37 INFO Executor: Finished task 19.0 in stage 7.0 (TID 73). 2762 bytes result sent to driver
25/02/04 17:12:37 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 83) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:37 INFO Executor: Running task 6.0 in stage 8.0 (TID 83)
25/02/04 17:12:37 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 84) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:37 INFO Executor: Running task 7.0 in stage 8.0 (TID 84)
25/02/04 17:12:37 INFO Executor: Finished task 20.0 in stage 7.0 (TID 74). 2805 bytes result sent to driver
25/02/04 17:12:37 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 85) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:37 INFO Executor: Running task 8.0 in stage 8.0 (TID 85)
25/02/04 17:12:37 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 72) in 4763 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:12:37 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 73) in 4550 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:12:37 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 74) in 4278 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:12:37 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:12:37 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:12:37 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:12:37 INFO Executor: Finished task 21.0 in stage 7.0 (TID 75). 2805 bytes result sent to driver
25/02/04 17:12:37 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 86) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:37 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 75) in 4245 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:12:37 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/02/04 17:12:37 INFO Executor: Running task 9.0 in stage 8.0 (TID 86)
25/02/04 17:12:37 INFO DAGScheduler: ShuffleMapStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 31.467 s
25/02/04 17:12:37 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:37 INFO DAGScheduler: running: Set(ShuffleMapStage 8)
25/02/04 17:12:37 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:37 INFO DAGScheduler: failed: Set()
25/02/04 17:12:37 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:12:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:37 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 4576237, minimum partition size: 1048576
25/02/04 17:12:38 INFO CodeGenerator: Code generated in 253.067541 ms
25/02/04 17:12:38 INFO DAGScheduler: Registering RDD 44 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/02/04 17:12:38 INFO DAGScheduler: Got map stage job 9 (parquet at NativeMethodAccessorImpl.java:0) with 10 output partitions
25/02/04 17:12:38 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/02/04 17:12:38 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:38 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[44] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:38 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 43.4 KiB, free 217.0 MiB)
25/02/04 17:12:38 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 217.0 MiB)
25/02/04 17:12:38 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.1 MiB)
25/02/04 17:12:38 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[44] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/02/04 17:12:38 INFO TaskSchedulerImpl: Adding task set 10.0 with 10 tasks resource profile 0
25/02/04 17:12:39 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.0.43:62420 in memory (size: 17.4 KiB, free: 366.2 MiB)
25/02/04 17:12:39 INFO Executor: Finished task 2.0 in stage 8.0 (TID 79). 2805 bytes result sent to driver
25/02/04 17:12:39 INFO Executor: Finished task 3.0 in stage 8.0 (TID 80). 2762 bytes result sent to driver
25/02/04 17:12:39 INFO Executor: Finished task 4.0 in stage 8.0 (TID 81). 2762 bytes result sent to driver
25/02/04 17:12:39 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 87) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:39 INFO Executor: Running task 10.0 in stage 8.0 (TID 87)
25/02/04 17:12:39 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 79) in 6163 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:12:39 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 88) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:39 INFO Executor: Running task 11.0 in stage 8.0 (TID 88)
25/02/04 17:12:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 77). 2762 bytes result sent to driver
25/02/04 17:12:39 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 89) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:39 INFO Executor: Running task 12.0 in stage 8.0 (TID 89)
25/02/04 17:12:39 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 90) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:39 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 80) in 6141 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:12:39 INFO Executor: Running task 13.0 in stage 8.0 (TID 90)
25/02/04 17:12:39 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 81) in 6140 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:12:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 77) in 6428 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:12:39 INFO Executor: Finished task 1.0 in stage 8.0 (TID 78). 2762 bytes result sent to driver
25/02/04 17:12:39 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 91) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:39 INFO Executor: Running task 14.0 in stage 8.0 (TID 91)
25/02/04 17:12:39 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 78) in 6429 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:12:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:12:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:12:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:12:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:12:40 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:12:40 INFO Executor: Finished task 5.0 in stage 8.0 (TID 82). 2762 bytes result sent to driver
25/02/04 17:12:40 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 92) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:40 INFO Executor: Running task 15.0 in stage 8.0 (TID 92)
25/02/04 17:12:40 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 82) in 5007 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:12:40 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:12:42 INFO Executor: Finished task 7.0 in stage 8.0 (TID 84). 2805 bytes result sent to driver
25/02/04 17:12:42 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 93) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:42 INFO Executor: Running task 16.0 in stage 8.0 (TID 93)
25/02/04 17:12:42 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 84) in 4945 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:12:42 INFO Executor: Finished task 9.0 in stage 8.0 (TID 86). 2805 bytes result sent to driver
25/02/04 17:12:42 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 94) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:42 INFO Executor: Running task 17.0 in stage 8.0 (TID 94)
25/02/04 17:12:42 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 86) in 4840 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:12:42 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:12:42 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:12:42 INFO Executor: Finished task 8.0 in stage 8.0 (TID 85). 2762 bytes result sent to driver
25/02/04 17:12:42 INFO Executor: Finished task 6.0 in stage 8.0 (TID 83). 2805 bytes result sent to driver
25/02/04 17:12:42 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 95) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:42 INFO Executor: Running task 18.0 in stage 8.0 (TID 95)
25/02/04 17:12:42 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 96) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:42 INFO Executor: Running task 19.0 in stage 8.0 (TID 96)
25/02/04 17:12:42 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 83) in 5178 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:12:42 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 85) in 5153 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:12:42 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:12:42 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:12:44 INFO Executor: Finished task 12.0 in stage 8.0 (TID 89). 2805 bytes result sent to driver
25/02/04 17:12:44 INFO Executor: Finished task 15.0 in stage 8.0 (TID 92). 2762 bytes result sent to driver
25/02/04 17:12:44 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 97) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:44 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 89) in 4815 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:12:44 INFO Executor: Running task 20.0 in stage 8.0 (TID 97)
25/02/04 17:12:44 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 98) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:44 INFO Executor: Running task 21.0 in stage 8.0 (TID 98)
25/02/04 17:12:44 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 92) in 4710 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:12:44 INFO Executor: Finished task 14.0 in stage 8.0 (TID 91). 2805 bytes result sent to driver
25/02/04 17:12:44 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 99) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:12:44 INFO Executor: Running task 22.0 in stage 8.0 (TID 99)
25/02/04 17:12:44 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 91) in 4769 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:12:44 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:12:44 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:12:44 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:12:44 INFO Executor: Finished task 13.0 in stage 8.0 (TID 90). 2762 bytes result sent to driver
25/02/04 17:12:44 INFO Executor: Finished task 10.0 in stage 8.0 (TID 87). 2762 bytes result sent to driver
25/02/04 17:12:44 INFO Executor: Finished task 11.0 in stage 8.0 (TID 88). 2762 bytes result sent to driver
25/02/04 17:12:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 100) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 100)
25/02/04 17:12:44 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 101) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:44 INFO Executor: Running task 1.0 in stage 10.0 (TID 101)
25/02/04 17:12:44 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 102) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:44 INFO Executor: Running task 2.0 in stage 10.0 (TID 102)
25/02/04 17:12:44 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 90) in 5021 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:12:44 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 87) in 5081 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:12:44 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 88) in 5052 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Getting 23 (4.3 MiB) non-empty blocks including 23 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 163 ms
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 164 ms
25/02/04 17:12:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 161 ms
25/02/04 17:12:45 INFO CodeGenerator: Code generated in 239.785458 ms
25/02/04 17:12:46 INFO Executor: Finished task 1.0 in stage 10.0 (TID 101). 5342 bytes result sent to driver
25/02/04 17:12:46 INFO Executor: Finished task 2.0 in stage 10.0 (TID 102). 5342 bytes result sent to driver
25/02/04 17:12:46 INFO Executor: Finished task 0.0 in stage 10.0 (TID 100). 5342 bytes result sent to driver
25/02/04 17:12:46 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 103) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:46 INFO Executor: Running task 3.0 in stage 10.0 (TID 103)
25/02/04 17:12:46 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 104) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:46 INFO Executor: Running task 4.0 in stage 10.0 (TID 104)
25/02/04 17:12:46 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 105) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:46 INFO Executor: Running task 5.0 in stage 10.0 (TID 105)
25/02/04 17:12:46 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 100) in 1651 ms on 10.0.0.43 (executor driver) (1/10)
25/02/04 17:12:46 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 102) in 1594 ms on 10.0.0.43 (executor driver) (2/10)
25/02/04 17:12:46 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 101) in 1600 ms on 10.0.0.43 (executor driver) (3/10)
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:12:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:12:47 INFO Executor: Finished task 22.0 in stage 8.0 (TID 99). 2805 bytes result sent to driver
25/02/04 17:12:47 INFO Executor: Finished task 4.0 in stage 10.0 (TID 104). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO Executor: Finished task 3.0 in stage 10.0 (TID 103). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO Executor: Finished task 5.0 in stage 10.0 (TID 105). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 106) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:47 INFO Executor: Running task 6.0 in stage 10.0 (TID 106)
25/02/04 17:12:47 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 107) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:47 INFO Executor: Running task 7.0 in stage 10.0 (TID 107)
25/02/04 17:12:47 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 108) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:47 INFO Executor: Running task 8.0 in stage 10.0 (TID 108)
25/02/04 17:12:47 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 109) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:47 INFO Executor: Running task 9.0 in stage 10.0 (TID 109)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 99) in 2391 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 103) in 662 ms on 10.0.0.43 (executor driver) (4/10)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 105) in 652 ms on 10.0.0.43 (executor driver) (5/10)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 104) in 652 ms on 10.0.0.43 (executor driver) (6/10)
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 23 (4.3 MiB) non-empty blocks including 23 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 23 (5.2 MiB) non-empty blocks including 23 (5.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 29 ms
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 37 ms
25/02/04 17:12:47 INFO Executor: Finished task 16.0 in stage 8.0 (TID 93). 2805 bytes result sent to driver
25/02/04 17:12:47 INFO Executor: Finished task 17.0 in stage 8.0 (TID 94). 2805 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 93) in 5140 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 94) in 5049 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:12:47 INFO Executor: Finished task 18.0 in stage 8.0 (TID 95). 2762 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 95) in 5013 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:12:47 INFO Executor: Finished task 7.0 in stage 10.0 (TID 107). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 107) in 446 ms on 10.0.0.43 (executor driver) (7/10)
25/02/04 17:12:47 INFO Executor: Finished task 8.0 in stage 10.0 (TID 108). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO Executor: Finished task 6.0 in stage 10.0 (TID 106). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 106) in 481 ms on 10.0.0.43 (executor driver) (8/10)
25/02/04 17:12:47 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 108) in 449 ms on 10.0.0.43 (executor driver) (9/10)
25/02/04 17:12:47 INFO Executor: Finished task 9.0 in stage 10.0 (TID 109). 5299 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 109) in 449 ms on 10.0.0.43 (executor driver) (10/10)
25/02/04 17:12:47 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/02/04 17:12:47 INFO Executor: Finished task 19.0 in stage 8.0 (TID 96). 2762 bytes result sent to driver
25/02/04 17:12:47 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 96) in 5044 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:12:47 INFO DAGScheduler: ShuffleMapStage 10 (parquet at NativeMethodAccessorImpl.java:0) finished in 9.039 s
25/02/04 17:12:47 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:47 INFO DAGScheduler: running: Set(ShuffleMapStage 8)
25/02/04 17:12:47 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:47 INFO DAGScheduler: failed: Set()
25/02/04 17:12:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:47 INFO CodeGenerator: Code generated in 81.421917 ms
25/02/04 17:12:47 INFO CodeGenerator: Code generated in 51.659291 ms
25/02/04 17:12:48 INFO DAGScheduler: Registering RDD 49 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/02/04 17:12:48 INFO DAGScheduler: Got map stage job 10 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:12:48 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/02/04 17:12:48 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:48 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:48 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 46.2 KiB, free 329.0 MiB)
25/02/04 17:12:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 329.0 MiB)
25/02/04 17:12:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.0.43:62420 (size: 21.4 KiB, free: 366.1 MiB)
25/02/04 17:12:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:12:48 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/02/04 17:12:48 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 110) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:48 INFO Executor: Running task 0.0 in stage 13.0 (TID 110)
25/02/04 17:12:48 INFO ShuffleBlockFetcherIterator: Getting 10 (42.9 MiB) non-empty blocks including 10 (42.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:12:48 INFO CodeGenerator: Code generated in 17.565042 ms
25/02/04 17:12:48 INFO CodeGenerator: Code generated in 37.073583 ms
25/02/04 17:12:48 INFO CodeGenerator: Code generated in 21.817875 ms
25/02/04 17:12:48 INFO CodeGenerator: Code generated in 14.136875 ms
25/02/04 17:12:49 INFO Executor: Finished task 20.0 in stage 8.0 (TID 97). 2762 bytes result sent to driver
25/02/04 17:12:49 INFO Executor: Finished task 21.0 in stage 8.0 (TID 98). 2762 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 97) in 4360 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:12:49 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 98) in 4336 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:12:49 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/02/04 17:12:49 INFO DAGScheduler: ShuffleMapStage 8 (parquet at NativeMethodAccessorImpl.java:0) finished in 40.688 s
25/02/04 17:12:49 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:49 INFO DAGScheduler: running: Set(ShuffleMapStage 13)
25/02/04 17:12:49 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:49 INFO DAGScheduler: failed: Set()
25/02/04 17:12:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:49 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 7453208, minimum partition size: 1048576
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 113.059125 ms
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 30.478417 ms
25/02/04 17:12:49 INFO DAGScheduler: Registering RDD 52 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 5
25/02/04 17:12:49 INFO DAGScheduler: Got map stage job 11 (parquet at NativeMethodAccessorImpl.java:0) with 11 output partitions
25/02/04 17:12:49 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/02/04 17:12:49 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:49 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[52] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 16.995584 ms
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 5.677583 ms
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 13.199125 ms
25/02/04 17:12:49 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 43.5 KiB, free 272.9 MiB)
25/02/04 17:12:49 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 272.9 MiB)
25/02/04 17:12:49 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.1 MiB)
25/02/04 17:12:49 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:49 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[52] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/02/04 17:12:49 INFO TaskSchedulerImpl: Adding task set 15.0 with 11 tasks resource profile 0
25/02/04 17:12:49 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 111) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 112) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 113) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 114) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 115) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 116) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 117) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 118) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 119) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO Executor: Running task 0.0 in stage 15.0 (TID 111)
25/02/04 17:12:49 INFO Executor: Running task 1.0 in stage 15.0 (TID 112)
25/02/04 17:12:49 INFO Executor: Running task 4.0 in stage 15.0 (TID 115)
25/02/04 17:12:49 INFO Executor: Running task 3.0 in stage 15.0 (TID 114)
25/02/04 17:12:49 INFO Executor: Running task 6.0 in stage 15.0 (TID 117)
25/02/04 17:12:49 INFO Executor: Running task 7.0 in stage 15.0 (TID 118)
25/02/04 17:12:49 INFO Executor: Running task 8.0 in stage 15.0 (TID 119)
25/02/04 17:12:49 INFO Executor: Running task 5.0 in stage 15.0 (TID 116)
25/02/04 17:12:49 INFO Executor: Running task 2.0 in stage 15.0 (TID 113)
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (7.1 MiB) non-empty blocks including 23 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (7.1 MiB) non-empty blocks including 23 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (7.1 MiB) non-empty blocks including 23 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:12:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:12:49 INFO CodeGenerator: Code generated in 79.295125 ms
25/02/04 17:12:49 INFO Executor: Finished task 1.0 in stage 15.0 (TID 112). 5299 bytes result sent to driver
25/02/04 17:12:49 INFO Executor: Finished task 2.0 in stage 15.0 (TID 113). 5299 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 120) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 112) in 537 ms on 10.0.0.43 (executor driver) (1/11)
25/02/04 17:12:49 INFO Executor: Running task 9.0 in stage 15.0 (TID 120)
25/02/04 17:12:49 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 121) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:49 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 113) in 542 ms on 10.0.0.43 (executor driver) (2/11)
25/02/04 17:12:49 INFO Executor: Running task 10.0 in stage 15.0 (TID 121)
25/02/04 17:12:49 INFO Executor: Finished task 8.0 in stage 15.0 (TID 119). 5299 bytes result sent to driver
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:12:49 INFO Executor: Finished task 0.0 in stage 15.0 (TID 111). 5342 bytes result sent to driver
25/02/04 17:12:49 INFO Executor: Finished task 6.0 in stage 15.0 (TID 117). 5342 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 119) in 576 ms on 10.0.0.43 (executor driver) (3/11)
25/02/04 17:12:49 INFO Executor: Finished task 7.0 in stage 15.0 (TID 118). 5342 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 111) in 580 ms on 10.0.0.43 (executor driver) (4/11)
25/02/04 17:12:49 INFO Executor: Finished task 5.0 in stage 15.0 (TID 116). 5342 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 117) in 578 ms on 10.0.0.43 (executor driver) (5/11)
25/02/04 17:12:49 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 118) in 579 ms on 10.0.0.43 (executor driver) (6/11)
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Getting 23 (2.1 MiB) non-empty blocks including 23 (2.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:49 INFO Executor: Finished task 3.0 in stage 15.0 (TID 114). 5342 bytes result sent to driver
25/02/04 17:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:12:49 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 114) in 580 ms on 10.0.0.43 (executor driver) (7/11)
25/02/04 17:12:49 INFO Executor: Finished task 4.0 in stage 15.0 (TID 115). 5299 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 116) in 580 ms on 10.0.0.43 (executor driver) (8/11)
25/02/04 17:12:49 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 115) in 580 ms on 10.0.0.43 (executor driver) (9/11)
25/02/04 17:12:49 INFO Executor: Finished task 10.0 in stage 15.0 (TID 121). 5299 bytes result sent to driver
25/02/04 17:12:49 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 121) in 142 ms on 10.0.0.43 (executor driver) (10/11)
25/02/04 17:12:50 INFO Executor: Finished task 9.0 in stage 15.0 (TID 120). 5299 bytes result sent to driver
25/02/04 17:12:50 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 120) in 257 ms on 10.0.0.43 (executor driver) (11/11)
25/02/04 17:12:50 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/02/04 17:12:50 INFO DAGScheduler: ShuffleMapStage 15 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.805 s
25/02/04 17:12:50 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:50 INFO DAGScheduler: running: Set(ShuffleMapStage 13)
25/02/04 17:12:50 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:50 INFO DAGScheduler: failed: Set()
25/02/04 17:12:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:12:50 INFO CodeGenerator: Code generated in 68.81475 ms
25/02/04 17:12:50 INFO CodeGenerator: Code generated in 73.390917 ms
25/02/04 17:12:50 INFO DAGScheduler: Registering RDD 57 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 6
25/02/04 17:12:50 INFO DAGScheduler: Got map stage job 12 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:12:50 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
25/02/04 17:12:50 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:50 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[57] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 46.3 KiB, free 272.9 MiB)
25/02/04 17:12:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 272.9 MiB)
25/02/04 17:12:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.0.43:62420 (size: 21.4 KiB, free: 366.1 MiB)
25/02/04 17:12:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[57] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:12:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
25/02/04 17:12:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 122) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:12:50 INFO Executor: Running task 0.0 in stage 18.0 (TID 122)
25/02/04 17:12:50 INFO ShuffleBlockFetcherIterator: Getting 11 (6.0 MiB) non-empty blocks including 11 (6.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:12:50 INFO CodeGenerator: Code generated in 19.25825 ms
25/02/04 17:12:50 INFO CodeGenerator: Code generated in 10.507125 ms
25/02/04 17:12:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:12:50 INFO Executor: Finished task 0.0 in stage 13.0 (TID 110). 7267 bytes result sent to driver
25/02/04 17:12:50 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 110) in 2734 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:12:50 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/02/04 17:12:50 INFO DAGScheduler: ShuffleMapStage 13 (parquet at NativeMethodAccessorImpl.java:0) finished in 2.772 s
25/02/04 17:12:50 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:50 INFO DAGScheduler: running: Set(ShuffleMapStage 18)
25/02/04 17:12:50 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:50 INFO DAGScheduler: failed: Set()
25/02/04 17:12:50 INFO ShufflePartitionsUtil: For shuffle(0, 4), advisory target size: 67108864, actual target size 67108864, minimum partition size: 1048576
25/02/04 17:12:50 INFO Executor: Finished task 0.0 in stage 18.0 (TID 122). 7138 bytes result sent to driver
25/02/04 17:12:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 122) in 578 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:12:51 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/02/04 17:12:51 INFO DAGScheduler: ShuffleMapStage 18 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.607 s
25/02/04 17:12:51 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:12:51 INFO DAGScheduler: running: Set()
25/02/04 17:12:51 INFO DAGScheduler: waiting: Set()
25/02/04 17:12:51 INFO DAGScheduler: failed: Set()
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 57.188542 ms
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 36.361916 ms
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 22.196792 ms
25/02/04 17:12:51 INFO DAGScheduler: Registering RDD 64 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 7
25/02/04 17:12:51 INFO DAGScheduler: Got map stage job 13 (parquet at NativeMethodAccessorImpl.java:0) with 17 output partitions
25/02/04 17:12:51 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:12:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21, ShuffleMapStage 22)
25/02/04 17:12:51 INFO DAGScheduler: Missing parents: List()
25/02/04 17:12:51 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[64] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:12:51 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 64.5 KiB, free 364.8 MiB)
25/02/04 17:12:51 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 364.8 MiB)
25/02/04 17:12:51 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.0.43:62420 (size: 28.8 KiB, free: 366.1 MiB)
25/02/04 17:12:51 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
25/02/04 17:12:51 INFO DAGScheduler: Submitting 17 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[64] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:12:51 INFO TaskSchedulerImpl: Adding task set 23.0 with 17 tasks resource profile 0
25/02/04 17:12:51 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 123) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 124) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 125) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 126) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 4.0 in stage 23.0 (TID 127) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 5.0 in stage 23.0 (TID 128) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 6.0 in stage 23.0 (TID 129) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 7.0 in stage 23.0 (TID 130) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 8.0 in stage 23.0 (TID 131) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO TaskSetManager: Starting task 9.0 in stage 23.0 (TID 132) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 9270 bytes) 
25/02/04 17:12:51 INFO Executor: Running task 1.0 in stage 23.0 (TID 124)
25/02/04 17:12:51 INFO Executor: Running task 7.0 in stage 23.0 (TID 130)
25/02/04 17:12:51 INFO Executor: Running task 5.0 in stage 23.0 (TID 128)
25/02/04 17:12:51 INFO Executor: Running task 8.0 in stage 23.0 (TID 131)
25/02/04 17:12:51 INFO Executor: Running task 2.0 in stage 23.0 (TID 125)
25/02/04 17:12:51 INFO Executor: Running task 4.0 in stage 23.0 (TID 127)
25/02/04 17:12:51 INFO Executor: Running task 9.0 in stage 23.0 (TID 132)
25/02/04 17:12:51 INFO Executor: Running task 3.0 in stage 23.0 (TID 126)
25/02/04 17:12:51 INFO Executor: Running task 6.0 in stage 23.0 (TID 129)
25/02/04 17:12:51 INFO Executor: Running task 0.0 in stage 23.0 (TID 123)
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.8 MiB) non-empty blocks including 23 (59.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (60.5 MiB) non-empty blocks including 23 (60.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.0 MiB) non-empty blocks including 23 (59.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.7 MiB) non-empty blocks including 23 (59.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.3 MiB) non-empty blocks including 23 (59.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.3 MiB) non-empty blocks including 23 (59.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.5 MiB) non-empty blocks including 23 (59.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (60.0 MiB) non-empty blocks including 23 (60.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.2 MiB) non-empty blocks including 23 (59.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 23 (59.4 MiB) non-empty blocks including 23 (59.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 29.597792 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 MiB) non-empty blocks including 1 (2.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 MiB) non-empty blocks including 1 (2.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:12:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 13.351584 ms
25/02/04 17:12:51 INFO CodeGenerator: Code generated in 47.092167 ms
25/02/04 17:12:51 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.0.43:62420 in memory (size: 21.4 KiB, free: 366.1 MiB)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:51 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (0  time so far)
25/02/04 17:12:52 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.0.43:62420 in memory (size: 21.4 KiB, free: 366.1 MiB)
25/02/04 17:12:52 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.0.43:62420 in memory (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:12:52 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:12:52 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:52 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (1  time so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (2  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (3  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (4  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (5  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (6  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:53 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (7  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 36.0 MiB to disk (8  times so far)
25/02/04 17:12:54 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 36.0 MiB to disk (9  times so far)
25/02/04 17:13:04 INFO Executor: Finished task 4.0 in stage 23.0 (TID 127). 10683 bytes result sent to driver
25/02/04 17:13:04 INFO Executor: Finished task 3.0 in stage 23.0 (TID 126). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO TaskSetManager: Starting task 10.0 in stage 23.0 (TID 133) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO Executor: Running task 10.0 in stage 23.0 (TID 133)
25/02/04 17:13:04 INFO TaskSetManager: Starting task 11.0 in stage 23.0 (TID 134) (10.0.0.43, executor driver, partition 11, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO TaskSetManager: Finished task 4.0 in stage 23.0 (TID 127) in 13156 ms on 10.0.0.43 (executor driver) (1/17)
25/02/04 17:13:04 INFO Executor: Running task 11.0 in stage 23.0 (TID 134)
25/02/04 17:13:04 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 126) in 13159 ms on 10.0.0.43 (executor driver) (2/17)
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.8 MiB) non-empty blocks including 23 (59.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.6 MiB) non-empty blocks including 23 (59.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 MiB) non-empty blocks including 1 (2.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:13:04 INFO Executor: Finished task 9.0 in stage 23.0 (TID 132). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO TaskSetManager: Starting task 12.0 in stage 23.0 (TID 135) (10.0.0.43, executor driver, partition 12, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO TaskSetManager: Finished task 9.0 in stage 23.0 (TID 132) in 13423 ms on 10.0.0.43 (executor driver) (3/17)
25/02/04 17:13:04 INFO Executor: Running task 12.0 in stage 23.0 (TID 135)
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.7 MiB) non-empty blocks including 23 (59.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:04 INFO Executor: Finished task 5.0 in stage 23.0 (TID 128). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO TaskSetManager: Starting task 13.0 in stage 23.0 (TID 136) (10.0.0.43, executor driver, partition 13, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO Executor: Running task 13.0 in stage 23.0 (TID 136)
25/02/04 17:13:04 INFO TaskSetManager: Finished task 5.0 in stage 23.0 (TID 128) in 13439 ms on 10.0.0.43 (executor driver) (4/17)
25/02/04 17:13:04 INFO Executor: Finished task 7.0 in stage 23.0 (TID 130). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO Executor: Finished task 8.0 in stage 23.0 (TID 131). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO TaskSetManager: Starting task 14.0 in stage 23.0 (TID 137) (10.0.0.43, executor driver, partition 14, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO Executor: Running task 14.0 in stage 23.0 (TID 137)
25/02/04 17:13:04 INFO TaskSetManager: Finished task 7.0 in stage 23.0 (TID 130) in 13445 ms on 10.0.0.43 (executor driver) (5/17)
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO TaskSetManager: Starting task 15.0 in stage 23.0 (TID 138) (10.0.0.43, executor driver, partition 15, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:13:04 INFO Executor: Running task 15.0 in stage 23.0 (TID 138)
25/02/04 17:13:04 INFO TaskSetManager: Finished task 8.0 in stage 23.0 (TID 131) in 13451 ms on 10.0.0.43 (executor driver) (6/17)
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.0 MiB) non-empty blocks including 23 (59.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.3 MiB) non-empty blocks including 23 (59.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (59.7 MiB) non-empty blocks including 23 (59.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 MiB) non-empty blocks including 1 (2.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 MiB) non-empty blocks including 1 (2.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:04 INFO Executor: Finished task 1.0 in stage 23.0 (TID 124). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO TaskSetManager: Starting task 16.0 in stage 23.0 (TID 139) (10.0.0.43, executor driver, partition 16, NODE_LOCAL, 9270 bytes) 
25/02/04 17:13:04 INFO Executor: Running task 16.0 in stage 23.0 (TID 139)
25/02/04 17:13:04 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 124) in 13522 ms on 10.0.0.43 (executor driver) (7/17)
25/02/04 17:13:04 INFO Executor: Finished task 6.0 in stage 23.0 (TID 129). 10640 bytes result sent to driver
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 23 (39.4 MiB) non-empty blocks including 23 (39.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:04 INFO TaskSetManager: Finished task 6.0 in stage 23.0 (TID 129) in 13530 ms on 10.0.0.43 (executor driver) (8/17)
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Getting 1 (1878.6 KiB) non-empty blocks including 1 (1878.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:04 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 54.0 MiB to disk (0  time so far)
25/02/04 17:13:04 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 52.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO Executor: Finished task 2.0 in stage 23.0 (TID 125). 10683 bytes result sent to driver
25/02/04 17:13:05 INFO Executor: Finished task 0.0 in stage 23.0 (TID 123). 10640 bytes result sent to driver
25/02/04 17:13:05 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 125) in 13915 ms on 10.0.0.43 (executor driver) (9/17)
25/02/04 17:13:05 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 123) in 13932 ms on 10.0.0.43 (executor driver) (10/17)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 42.0 MiB to disk (0  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 42.0 MiB to disk (1  time so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 42.0 MiB to disk (2  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 42.0 MiB to disk (3  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 42.0 MiB to disk (4  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (5  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (6  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:06 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 42.0 MiB to disk (7  times so far)
25/02/04 17:13:07 INFO Executor: Finished task 16.0 in stage 23.0 (TID 139). 10683 bytes result sent to driver
25/02/04 17:13:07 INFO TaskSetManager: Finished task 16.0 in stage 23.0 (TID 139) in 3099 ms on 10.0.0.43 (executor driver) (11/17)
25/02/04 17:13:08 INFO Executor: Finished task 10.0 in stage 23.0 (TID 133). 10683 bytes result sent to driver
25/02/04 17:13:08 INFO TaskSetManager: Finished task 10.0 in stage 23.0 (TID 133) in 4299 ms on 10.0.0.43 (executor driver) (12/17)
25/02/04 17:13:08 INFO Executor: Finished task 15.0 in stage 23.0 (TID 138). 10640 bytes result sent to driver
25/02/04 17:13:08 INFO Executor: Finished task 11.0 in stage 23.0 (TID 134). 10640 bytes result sent to driver
25/02/04 17:13:08 INFO TaskSetManager: Finished task 15.0 in stage 23.0 (TID 138) in 3994 ms on 10.0.0.43 (executor driver) (13/17)
25/02/04 17:13:08 INFO TaskSetManager: Finished task 11.0 in stage 23.0 (TID 134) in 4289 ms on 10.0.0.43 (executor driver) (14/17)
25/02/04 17:13:08 INFO Executor: Finished task 13.0 in stage 23.0 (TID 136). 10640 bytes result sent to driver
25/02/04 17:13:08 INFO Executor: Finished task 12.0 in stage 23.0 (TID 135). 10640 bytes result sent to driver
25/02/04 17:13:08 INFO TaskSetManager: Finished task 13.0 in stage 23.0 (TID 136) in 4042 ms on 10.0.0.43 (executor driver) (15/17)
25/02/04 17:13:08 INFO TaskSetManager: Finished task 12.0 in stage 23.0 (TID 135) in 4058 ms on 10.0.0.43 (executor driver) (16/17)
25/02/04 17:13:08 INFO Executor: Finished task 14.0 in stage 23.0 (TID 137). 10640 bytes result sent to driver
25/02/04 17:13:08 INFO TaskSetManager: Finished task 14.0 in stage 23.0 (TID 137) in 4070 ms on 10.0.0.43 (executor driver) (17/17)
25/02/04 17:13:08 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
25/02/04 17:13:08 INFO DAGScheduler: ShuffleMapStage 23 (parquet at NativeMethodAccessorImpl.java:0) finished in 17.572 s
25/02/04 17:13:08 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:13:08 INFO DAGScheduler: running: Set()
25/02/04 17:13:08 INFO DAGScheduler: waiting: Set()
25/02/04 17:13:08 INFO DAGScheduler: failed: Set()
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 133.015958 ms
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 79.986708 ms
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 21.416542 ms
25/02/04 17:13:09 INFO DAGScheduler: Got job 14 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
25/02/04 17:13:09 INFO DAGScheduler: Final stage: ResultStage 32 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:13:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 28)
25/02/04 17:13:09 INFO DAGScheduler: Missing parents: List()
25/02/04 17:13:09 INFO DAGScheduler: Submitting ResultStage 32 (AdaptiveSparkPlan isFinalPlan=false
+- Project [new_userId#116, new_songId#122, Plays#25]
   +- SortMergeJoin [songId#24], [songId#141], Inner
      :- Sort [songId#24 ASC NULLS FIRST], false, 0
      :  +- Exchange hashpartitioning(songId#24, 200), ENSURE_REQUIREMENTS, [plan_id=157]
      :     +- Project [songId#24, Plays#25, new_userId#116]
      :        +- SortMergeJoin [userId#23], [userId#129], Inner
      :           :- Sort [userId#23 ASC NULLS FIRST], false, 0
      :           :  +- Exchange hashpartitioning(userId#23, 200), ENSURE_REQUIREMENTS, [plan_id=141]
      :           :     +- Project [_c0#17 AS userId#23, _c1#18 AS songId#24, _c2#19 AS Plays#25]
      :           :        +- Filter (isnotnull(_c0#17) AND isnotnull(_c1#18))
      :           :           +- FileScan csv [_c0#17,_c1#18,_c2#19] Batched: false, DataFilters: [isnotnull(_c0#17), isnotnull(_c1#18)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt], Parti... MapPartitionsRDD[72] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:13:09 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 92.3 KiB, free 365.0 MiB)
25/02/04 17:13:09 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 40.5 KiB, free 365.0 MiB)
25/02/04 17:13:09 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.0.43:62420 (size: 40.5 KiB, free: 366.1 MiB)
25/02/04 17:13:09 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
25/02/04 17:13:09 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 32 (AdaptiveSparkPlan isFinalPlan=false
+- Project [new_userId#116, new_songId#122, Plays#25]
   +- SortMergeJoin [songId#24], [songId#141], Inner
      :- Sort [songId#24 ASC NULLS FIRST], false, 0
      :  +- Exchange hashpartitioning(songId#24, 200), ENSURE_REQUIREMENTS, [plan_id=157]
      :     +- Project [songId#24, Plays#25, new_userId#116]
      :        +- SortMergeJoin [userId#23], [userId#129], Inner
      :           :- Sort [userId#23 ASC NULLS FIRST], false, 0
      :           :  +- Exchange hashpartitioning(userId#23, 200), ENSURE_REQUIREMENTS, [plan_id=141]
      :           :     +- Project [_c0#17 AS userId#23, _c1#18 AS songId#24, _c2#19 AS Plays#25]
      :           :        +- Filter (isnotnull(_c0#17) AND isnotnull(_c1#18))
      :           :           +- FileScan csv [_c0#17,_c1#18,_c2#19] Batched: false, DataFilters: [isnotnull(_c0#17), isnotnull(_c1#18)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt], Parti... MapPartitionsRDD[72] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:13:09 INFO TaskSchedulerImpl: Adding task set 32.0 with 200 tasks resource profile 0
25/02/04 17:13:09 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 140) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 141) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 142) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 143) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 144) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 145) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 146) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 7.0 in stage 32.0 (TID 147) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 8.0 in stage 32.0 (TID 148) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO TaskSetManager: Starting task 9.0 in stage 32.0 (TID 149) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:09 INFO Executor: Running task 2.0 in stage 32.0 (TID 142)
25/02/04 17:13:09 INFO Executor: Running task 7.0 in stage 32.0 (TID 147)
25/02/04 17:13:09 INFO Executor: Running task 0.0 in stage 32.0 (TID 140)
25/02/04 17:13:09 INFO Executor: Running task 5.0 in stage 32.0 (TID 145)
25/02/04 17:13:09 INFO Executor: Running task 8.0 in stage 32.0 (TID 148)
25/02/04 17:13:09 INFO Executor: Running task 3.0 in stage 32.0 (TID 143)
25/02/04 17:13:09 INFO Executor: Running task 4.0 in stage 32.0 (TID 144)
25/02/04 17:13:09 INFO Executor: Running task 9.0 in stage 32.0 (TID 149)
25/02/04 17:13:09 INFO Executor: Running task 1.0 in stage 32.0 (TID 141)
25/02/04 17:13:09 INFO Executor: Running task 6.0 in stage 32.0 (TID 146)
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.1 MiB) non-empty blocks including 17 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 65.602625 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 12.976291 ms
25/02/04 17:13:09 INFO CodeGenerator: Code generated in 30.604333 ms
25/02/04 17:13:10 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.0.43:62420 in memory (size: 28.8 KiB, free: 366.2 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_5 stored as values in memory (estimated size 1094.6 KiB, free 184.6 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_7 stored as values in memory (estimated size 950.4 KiB, free 184.6 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_5 in memory on 10.0.0.43:62420 (size: 1094.6 KiB, free: 365.1 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_6 stored as values in memory (estimated size 1246.8 KiB, free 209.5 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_2 stored as values in memory (estimated size 1178.9 KiB, free 230.4 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_7 in memory on 10.0.0.43:62420 (size: 950.4 KiB, free: 364.2 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_6 in memory on 10.0.0.43:62420 (size: 1246.8 KiB, free: 362.9 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_2 in memory on 10.0.0.43:62420 (size: 1178.9 KiB, free: 361.8 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_3 stored as values in memory (estimated size 1048.3 KiB, free 253.4 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_0 stored as values in memory (estimated size 1104.4 KiB, free 252.3 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_3 in memory on 10.0.0.43:62420 (size: 1048.3 KiB, free: 360.8 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_0 in memory on 10.0.0.43:62420 (size: 1104.4 KiB, free: 359.7 MiB)
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 0.0 in stage 32.0 (TID 140)
[rdd_72_0]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 2.0 in stage 32.0 (TID 142)
[rdd_72_2]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 5.0 in stage 32.0 (TID 145)
[rdd_72_5]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 3.0 in stage 32.0 (TID 143)
[rdd_72_3]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 7.0 in stage 32.0 (TID 147)
[rdd_72_7]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 6.0 in stage 32.0 (TID 146)
[rdd_72_6]
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_9 stored as values in memory (estimated size 1150.5 KiB, free 275.3 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_9 in memory on 10.0.0.43:62420 (size: 1150.5 KiB, free: 358.6 MiB)
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 9.0 in stage 32.0 (TID 149)
[rdd_72_9]
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_4 stored as values in memory (estimated size 1252.8 KiB, free 326.2 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_4 in memory on 10.0.0.43:62420 (size: 1252.8 KiB, free: 357.3 MiB)
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_8 stored as values in memory (estimated size 1311.0 KiB, free 324.9 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_8 in memory on 10.0.0.43:62420 (size: 1311.0 KiB, free: 356.1 MiB)
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 4.0 in stage 32.0 (TID 144)
[rdd_72_4]
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 8.0 in stage 32.0 (TID 148)
[rdd_72_8]
25/02/04 17:13:12 INFO Executor: Finished task 9.0 in stage 32.0 (TID 149). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 2.0 in stage 32.0 (TID 142). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 5.0 in stage 32.0 (TID 145). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 4.0 in stage 32.0 (TID 144). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 3.0 in stage 32.0 (TID 143). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 8.0 in stage 32.0 (TID 148). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 0.0 in stage 32.0 (TID 140). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 7.0 in stage 32.0 (TID 147). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO Executor: Finished task 6.0 in stage 32.0 (TID 146). 17052 bytes result sent to driver
25/02/04 17:13:12 INFO TaskSetManager: Starting task 10.0 in stage 32.0 (TID 150) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 10.0 in stage 32.0 (TID 150)
25/02/04 17:13:12 INFO TaskSetManager: Starting task 11.0 in stage 32.0 (TID 151) (10.0.0.43, executor driver, partition 11, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 11.0 in stage 32.0 (TID 151)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 9.0 in stage 32.0 (TID 149) in 2914 ms on 10.0.0.43 (executor driver) (1/200)
25/02/04 17:13:12 INFO TaskSetManager: Starting task 12.0 in stage 32.0 (TID 152) (10.0.0.43, executor driver, partition 12, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 140) in 2941 ms on 10.0.0.43 (executor driver) (2/200)
25/02/04 17:13:12 INFO Executor: Running task 12.0 in stage 32.0 (TID 152)
25/02/04 17:13:12 INFO TaskSetManager: Starting task 13.0 in stage 32.0 (TID 153) (10.0.0.43, executor driver, partition 13, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 13.0 in stage 32.0 (TID 153)
25/02/04 17:13:12 INFO TaskSetManager: Starting task 14.0 in stage 32.0 (TID 154) (10.0.0.43, executor driver, partition 14, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO TaskSetManager: Starting task 15.0 in stage 32.0 (TID 155) (10.0.0.43, executor driver, partition 15, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 14.0 in stage 32.0 (TID 154)
25/02/04 17:13:12 INFO Executor: Running task 15.0 in stage 32.0 (TID 155)
25/02/04 17:13:12 INFO TaskSetManager: Starting task 16.0 in stage 32.0 (TID 156) (10.0.0.43, executor driver, partition 16, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO TaskSetManager: Starting task 17.0 in stage 32.0 (TID 157) (10.0.0.43, executor driver, partition 17, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO TaskSetManager: Starting task 18.0 in stage 32.0 (TID 158) (10.0.0.43, executor driver, partition 18, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 17.0 in stage 32.0 (TID 157)
25/02/04 17:13:12 INFO Executor: Running task 16.0 in stage 32.0 (TID 156)
25/02/04 17:13:12 INFO Executor: Running task 18.0 in stage 32.0 (TID 158)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 8.0 in stage 32.0 (TID 148) in 2953 ms on 10.0.0.43 (executor driver) (3/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 145) in 2962 ms on 10.0.0.43 (executor driver) (4/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 144) in 2963 ms on 10.0.0.43 (executor driver) (5/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 142) in 2964 ms on 10.0.0.43 (executor driver) (6/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 7.0 in stage 32.0 (TID 147) in 2965 ms on 10.0.0.43 (executor driver) (7/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 146) in 2965 ms on 10.0.0.43 (executor driver) (8/200)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 143) in 2970 ms on 10.0.0.43 (executor driver) (9/200)
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (5.6 MiB) non-empty blocks including 17 (5.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 37 ms
25/02/04 17:13:12 INFO MemoryStore: Block rdd_72_1 stored as values in memory (estimated size 1576.2 KiB, free 353.4 MiB)
25/02/04 17:13:12 INFO BlockManagerInfo: Added rdd_72_1 in memory on 10.0.0.43:62420 (size: 1576.2 KiB, free: 354.5 MiB)
25/02/04 17:13:12 INFO Executor: 1 block locks were not released by task 1.0 in stage 32.0 (TID 141)
[rdd_72_1]
25/02/04 17:13:12 INFO Executor: Finished task 1.0 in stage 32.0 (TID 141). 17009 bytes result sent to driver
25/02/04 17:13:12 INFO TaskSetManager: Starting task 19.0 in stage 32.0 (TID 159) (10.0.0.43, executor driver, partition 19, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:12 INFO Executor: Running task 19.0 in stage 32.0 (TID 159)
25/02/04 17:13:12 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 141) in 3219 ms on 10.0.0.43 (executor driver) (10/200)
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 17 (4.3 MiB) non-empty blocks including 17 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:12 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 30.0 MiB to disk (0  time so far)
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_10 stored as values in memory (estimated size 1160.4 KiB, free 163.8 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_10 in memory on 10.0.0.43:62420 (size: 1160.4 KiB, free: 353.4 MiB)
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_18 stored as values in memory (estimated size 974.0 KiB, free 162.8 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_18 in memory on 10.0.0.43:62420 (size: 974.0 KiB, free: 352.4 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 18.0 in stage 32.0 (TID 158)
[rdd_72_18]
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 10.0 in stage 32.0 (TID 150)
[rdd_72_10]
25/02/04 17:13:13 INFO Executor: Finished task 18.0 in stage 32.0 (TID 158). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO Executor: Finished task 10.0 in stage 32.0 (TID 150). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_16 stored as values in memory (estimated size 1175.6 KiB, free 185.7 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_16 in memory on 10.0.0.43:62420 (size: 1175.6 KiB, free: 351.3 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 16.0 in stage 32.0 (TID 156)
[rdd_72_16]
25/02/04 17:13:13 INFO Executor: Finished task 16.0 in stage 32.0 (TID 156). 17009 bytes result sent to driver
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_12 stored as values in memory (estimated size 1209.2 KiB, free 208.6 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_12 in memory on 10.0.0.43:62420 (size: 1209.2 KiB, free: 350.1 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 12.0 in stage 32.0 (TID 152)
[rdd_72_12]
25/02/04 17:13:13 INFO TaskSetManager: Starting task 20.0 in stage 32.0 (TID 160) (10.0.0.43, executor driver, partition 20, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_15 stored as values in memory (estimated size 1319.8 KiB, free 233.4 MiB)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 10.0 in stage 32.0 (TID 150) in 1314 ms on 10.0.0.43 (executor driver) (11/200)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_15 in memory on 10.0.0.43:62420 (size: 1319.8 KiB, free: 348.8 MiB)
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_11 stored as values in memory (estimated size 1153.5 KiB, free 256.3 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 15.0 in stage 32.0 (TID 155)
[rdd_72_15]
25/02/04 17:13:13 INFO Executor: Running task 20.0 in stage 32.0 (TID 160)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_11 in memory on 10.0.0.43:62420 (size: 1153.5 KiB, free: 347.7 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 11.0 in stage 32.0 (TID 151)
[rdd_72_11]
25/02/04 17:13:13 INFO TaskSetManager: Starting task 21.0 in stage 32.0 (TID 161) (10.0.0.43, executor driver, partition 21, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 21.0 in stage 32.0 (TID 161)
25/02/04 17:13:13 INFO TaskSetManager: Starting task 22.0 in stage 32.0 (TID 162) (10.0.0.43, executor driver, partition 22, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 22.0 in stage 32.0 (TID 162)
25/02/04 17:13:13 INFO Executor: Finished task 12.0 in stage 32.0 (TID 152). 17009 bytes result sent to driver
25/02/04 17:13:13 INFO TaskSetManager: Starting task 23.0 in stage 32.0 (TID 163) (10.0.0.43, executor driver, partition 23, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO TaskSetManager: Finished task 18.0 in stage 32.0 (TID 158) in 1169 ms on 10.0.0.43 (executor driver) (12/200)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 12.0 in stage 32.0 (TID 152) in 1182 ms on 10.0.0.43 (executor driver) (13/200)
25/02/04 17:13:13 INFO Executor: Running task 23.0 in stage 32.0 (TID 163)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 16.0 in stage 32.0 (TID 156) in 1173 ms on 10.0.0.43 (executor driver) (14/200)
25/02/04 17:13:13 INFO Executor: Finished task 11.0 in stage 32.0 (TID 151). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_13 stored as values in memory (estimated size 1448.0 KiB, free 283.0 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_13 in memory on 10.0.0.43:62420 (size: 1448.0 KiB, free: 346.3 MiB)
25/02/04 17:13:13 INFO TaskSetManager: Starting task 24.0 in stage 32.0 (TID 164) (10.0.0.43, executor driver, partition 24, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 13.0 in stage 32.0 (TID 153)
[rdd_72_13]
25/02/04 17:13:13 INFO Executor: Running task 24.0 in stage 32.0 (TID 164)
25/02/04 17:13:13 INFO Executor: Finished task 15.0 in stage 32.0 (TID 155). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO Executor: Finished task 13.0 in stage 32.0 (TID 153). 17009 bytes result sent to driver
25/02/04 17:13:13 INFO TaskSetManager: Finished task 11.0 in stage 32.0 (TID 151) in 1245 ms on 10.0.0.43 (executor driver) (15/200)
25/02/04 17:13:13 INFO TaskSetManager: Starting task 25.0 in stage 32.0 (TID 165) (10.0.0.43, executor driver, partition 25, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO TaskSetManager: Starting task 26.0 in stage 32.0 (TID 166) (10.0.0.43, executor driver, partition 26, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 25.0 in stage 32.0 (TID 165)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 15.0 in stage 32.0 (TID 155) in 1182 ms on 10.0.0.43 (executor driver) (16/200)
25/02/04 17:13:13 INFO Executor: Running task 26.0 in stage 32.0 (TID 166)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 13.0 in stage 32.0 (TID 153) in 1185 ms on 10.0.0.43 (executor driver) (17/200)
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_19 stored as values in memory (estimated size 1392.1 KiB, free 307.7 MiB)
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.1 MiB) non-empty blocks including 17 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_19 in memory on 10.0.0.43:62420 (size: 1392.1 KiB, free: 344.9 MiB)
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 19.0 in stage 32.0 (TID 159)
[rdd_72_19]
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_17 stored as values in memory (estimated size 1538.4 KiB, free 333.7 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_17 in memory on 10.0.0.43:62420 (size: 1538.4 KiB, free: 343.4 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 17.0 in stage 32.0 (TID 157)
[rdd_72_17]
25/02/04 17:13:13 INFO Executor: Finished task 17.0 in stage 32.0 (TID 157). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO Executor: Finished task 19.0 in stage 32.0 (TID 159). 17052 bytes result sent to driver
25/02/04 17:13:13 INFO TaskSetManager: Starting task 27.0 in stage 32.0 (TID 167) (10.0.0.43, executor driver, partition 27, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 27.0 in stage 32.0 (TID 167)
25/02/04 17:13:13 INFO TaskSetManager: Starting task 28.0 in stage 32.0 (TID 168) (10.0.0.43, executor driver, partition 28, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 28.0 in stage 32.0 (TID 168)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 17.0 in stage 32.0 (TID 157) in 1263 ms on 10.0.0.43 (executor driver) (18/200)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 19.0 in stage 32.0 (TID 159) in 1021 ms on 10.0.0.43 (executor driver) (19/200)
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (2.9 MiB) non-empty blocks including 17 (2.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO MemoryStore: Block rdd_72_14 stored as values in memory (estimated size 1929.1 KiB, free 135.9 MiB)
25/02/04 17:13:13 INFO BlockManagerInfo: Added rdd_72_14 in memory on 10.0.0.43:62420 (size: 1929.1 KiB, free: 341.5 MiB)
25/02/04 17:13:13 INFO Executor: 1 block locks were not released by task 14.0 in stage 32.0 (TID 154)
[rdd_72_14]
25/02/04 17:13:13 INFO Executor: Finished task 14.0 in stage 32.0 (TID 154). 17095 bytes result sent to driver
25/02/04 17:13:13 INFO TaskSetManager: Starting task 29.0 in stage 32.0 (TID 169) (10.0.0.43, executor driver, partition 29, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:13 INFO Executor: Running task 29.0 in stage 32.0 (TID 169)
25/02/04 17:13:13 INFO TaskSetManager: Finished task 14.0 in stage 32.0 (TID 154) in 1449 ms on 10.0.0.43 (executor driver) (20/200)
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_27 stored as values in memory (estimated size 866.2 KiB, free 123.0 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_27 in memory on 10.0.0.43:62420 (size: 866.2 KiB, free: 340.7 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 27.0 in stage 32.0 (TID 167)
[rdd_72_27]
25/02/04 17:13:14 INFO Executor: Finished task 27.0 in stage 32.0 (TID 167). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_25 stored as values in memory (estimated size 985.1 KiB, free 144.1 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_25 in memory on 10.0.0.43:62420 (size: 985.1 KiB, free: 339.7 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 25.0 in stage 32.0 (TID 165)
[rdd_72_25]
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_20 stored as values in memory (estimated size 1143.9 KiB, free 167.1 MiB)
25/02/04 17:13:14 INFO Executor: Finished task 25.0 in stage 32.0 (TID 165). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_20 in memory on 10.0.0.43:62420 (size: 1143.9 KiB, free: 338.6 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 20.0 in stage 32.0 (TID 160)
[rdd_72_20]
25/02/04 17:13:14 INFO TaskSetManager: Starting task 30.0 in stage 32.0 (TID 170) (10.0.0.43, executor driver, partition 30, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 27.0 in stage 32.0 (TID 167) in 506 ms on 10.0.0.43 (executor driver) (21/200)
25/02/04 17:13:14 INFO Executor: Running task 30.0 in stage 32.0 (TID 170)
25/02/04 17:13:14 INFO Executor: Finished task 20.0 in stage 32.0 (TID 160). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 31.0 in stage 32.0 (TID 171) (10.0.0.43, executor driver, partition 31, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Starting task 32.0 in stage 32.0 (TID 172) (10.0.0.43, executor driver, partition 32, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 31.0 in stage 32.0 (TID 171)
25/02/04 17:13:14 INFO Executor: Running task 32.0 in stage 32.0 (TID 172)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_21 stored as values in memory (estimated size 968.7 KiB, free 188.2 MiB)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 20.0 in stage 32.0 (TID 160) in 623 ms on 10.0.0.43 (executor driver) (22/200)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 25.0 in stage 32.0 (TID 165) in 594 ms on 10.0.0.43 (executor driver) (23/200)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_21 in memory on 10.0.0.43:62420 (size: 968.7 KiB, free: 337.7 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 21.0 in stage 32.0 (TID 161)
[rdd_72_21]
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_23 stored as values in memory (estimated size 1151.9 KiB, free 211.1 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_23 in memory on 10.0.0.43:62420 (size: 1151.9 KiB, free: 336.5 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 23.0 in stage 32.0 (TID 163)
[rdd_72_23]
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_24 stored as values in memory (estimated size 1092.3 KiB, free 234.1 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_24 in memory on 10.0.0.43:62420 (size: 1092.3 KiB, free: 335.5 MiB)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 24.0 in stage 32.0 (TID 164)
[rdd_72_24]
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO Executor: Finished task 21.0 in stage 32.0 (TID 161). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 33.0 in stage 32.0 (TID 173) (10.0.0.43, executor driver, partition 33, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 33.0 in stage 32.0 (TID 173)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 21.0 in stage 32.0 (TID 161) in 618 ms on 10.0.0.43 (executor driver) (24/200)
25/02/04 17:13:14 INFO Executor: Finished task 23.0 in stage 32.0 (TID 163). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO Executor: Finished task 24.0 in stage 32.0 (TID 164). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 34.0 in stage 32.0 (TID 174) (10.0.0.43, executor driver, partition 34, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 34.0 in stage 32.0 (TID 174)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 35.0 in stage 32.0 (TID 175) (10.0.0.43, executor driver, partition 35, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 24.0 in stage 32.0 (TID 164) in 607 ms on 10.0.0.43 (executor driver) (25/200)
25/02/04 17:13:14 INFO Executor: Running task 35.0 in stage 32.0 (TID 175)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 23.0 in stage 32.0 (TID 163) in 615 ms on 10.0.0.43 (executor driver) (26/200)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_28 stored as values in memory (estimated size 1076.3 KiB, free 238.9 MiB)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_28 in memory on 10.0.0.43:62420 (size: 1076.3 KiB, free: 334.4 MiB)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 28.0 in stage 32.0 (TID 168)
[rdd_72_28]
25/02/04 17:13:14 INFO Executor: Finished task 28.0 in stage 32.0 (TID 168). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_26 stored as values in memory (estimated size 1254.6 KiB, free 238.6 MiB)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 36.0 in stage 32.0 (TID 176) (10.0.0.43, executor driver, partition 36, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:13:14 INFO Executor: Running task 36.0 in stage 32.0 (TID 176)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 28.0 in stage 32.0 (TID 168) in 557 ms on 10.0.0.43 (executor driver) (27/200)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_26 in memory on 10.0.0.43:62420 (size: 1254.6 KiB, free: 333.2 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 26.0 in stage 32.0 (TID 166)
[rdd_72_26]
25/02/04 17:13:14 INFO Executor: Finished task 26.0 in stage 32.0 (TID 166). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
25/02/04 17:13:14 INFO TaskSetManager: Starting task 37.0 in stage 32.0 (TID 177) (10.0.0.43, executor driver, partition 37, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 37.0 in stage 32.0 (TID 177)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 26.0 in stage 32.0 (TID 166) in 646 ms on 10.0.0.43 (executor driver) (28/200)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_22 stored as values in memory (estimated size 1279.5 KiB, free 214.8 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_22 in memory on 10.0.0.43:62420 (size: 1279.5 KiB, free: 331.9 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 22.0 in stage 32.0 (TID 162)
[rdd_72_22]
25/02/04 17:13:14 INFO Executor: Finished task 22.0 in stage 32.0 (TID 162). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 38.0 in stage 32.0 (TID 178) (10.0.0.43, executor driver, partition 38, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 22.0 in stage 32.0 (TID 162) in 679 ms on 10.0.0.43 (executor driver) (29/200)
25/02/04 17:13:14 INFO Executor: Running task 38.0 in stage 32.0 (TID 178)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_29 stored as values in memory (estimated size 1378.9 KiB, free 104.9 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_29 in memory on 10.0.0.43:62420 (size: 1378.9 KiB, free: 330.6 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 29.0 in stage 32.0 (TID 169)
[rdd_72_29]
25/02/04 17:13:14 INFO Executor: Finished task 29.0 in stage 32.0 (TID 169). 17052 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 39.0 in stage 32.0 (TID 179) (10.0.0.43, executor driver, partition 39, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 29.0 in stage 32.0 (TID 169) in 782 ms on 10.0.0.43 (executor driver) (30/200)
25/02/04 17:13:14 INFO Executor: Running task 39.0 in stage 32.0 (TID 179)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_33 stored as values in memory (estimated size 1063.3 KiB, free 127.9 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_33 in memory on 10.0.0.43:62420 (size: 1063.3 KiB, free: 329.6 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 33.0 in stage 32.0 (TID 173)
[rdd_72_33]
25/02/04 17:13:14 INFO Executor: Finished task 33.0 in stage 32.0 (TID 173). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 40.0 in stage 32.0 (TID 180) (10.0.0.43, executor driver, partition 40, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 33.0 in stage 32.0 (TID 173) in 481 ms on 10.0.0.43 (executor driver) (31/200)
25/02/04 17:13:14 INFO Executor: Running task 40.0 in stage 32.0 (TID 180)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_31 stored as values in memory (estimated size 1222.2 KiB, free 152.8 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_31 in memory on 10.0.0.43:62420 (size: 1222.2 KiB, free: 328.4 MiB)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 83 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 82 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_30 stored as values in memory (estimated size 1339.9 KiB, free 299.9 MiB)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_37 stored as values in memory (estimated size 1228.3 KiB, free 297.6 MiB)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_38 stored as values in memory (estimated size 1115.5 KiB, free 296.5 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 31.0 in stage 32.0 (TID 171)
[rdd_72_31]
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_35 stored as values in memory (estimated size 1098.4 KiB, free 295.4 MiB)
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_34 stored as values in memory (estimated size 1134.6 KiB, free 295.4 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_30 in memory on 10.0.0.43:62420 (size: 1339.9 KiB, free: 327.1 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_37 in memory on 10.0.0.43:62420 (size: 1228.3 KiB, free: 325.9 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_38 in memory on 10.0.0.43:62420 (size: 1115.5 KiB, free: 324.8 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_35 in memory on 10.0.0.43:62420 (size: 1098.4 KiB, free: 323.7 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_34 in memory on 10.0.0.43:62420 (size: 1134.6 KiB, free: 322.6 MiB)
25/02/04 17:13:14 INFO Executor: Finished task 31.0 in stage 32.0 (TID 171). 17052 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 41.0 in stage 32.0 (TID 181) (10.0.0.43, executor driver, partition 41, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 41.0 in stage 32.0 (TID 181)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 31.0 in stage 32.0 (TID 171) in 620 ms on 10.0.0.43 (executor driver) (32/200)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 34.0 in stage 32.0 (TID 174)
[rdd_72_34]
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 37.0 in stage 32.0 (TID 177)
[rdd_72_37]
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 35.0 in stage 32.0 (TID 175)
[rdd_72_35]
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 38.0 in stage 32.0 (TID 178)
[rdd_72_38]
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 30.0 in stage 32.0 (TID 170)
[rdd_72_30]
25/02/04 17:13:14 INFO Executor: Finished task 37.0 in stage 32.0 (TID 177). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO Executor: Finished task 35.0 in stage 32.0 (TID 175). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO Executor: Finished task 30.0 in stage 32.0 (TID 170). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO Executor: Finished task 34.0 in stage 32.0 (TID 174). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 42.0 in stage 32.0 (TID 182) (10.0.0.43, executor driver, partition 42, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Finished task 38.0 in stage 32.0 (TID 178). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO Executor: Running task 42.0 in stage 32.0 (TID 182)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 43.0 in stage 32.0 (TID 183) (10.0.0.43, executor driver, partition 43, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 35.0 in stage 32.0 (TID 175) in 612 ms on 10.0.0.43 (executor driver) (33/200)
25/02/04 17:13:14 INFO Executor: Running task 43.0 in stage 32.0 (TID 183)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 44.0 in stage 32.0 (TID 184) (10.0.0.43, executor driver, partition 44, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO TaskSetManager: Finished task 30.0 in stage 32.0 (TID 170) in 635 ms on 10.0.0.43 (executor driver) (34/200)
25/02/04 17:13:14 INFO Executor: Running task 44.0 in stage 32.0 (TID 184)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 45.0 in stage 32.0 (TID 185) (10.0.0.43, executor driver, partition 45, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 45.0 in stage 32.0 (TID 185)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_36 stored as values in memory (estimated size 1064.4 KiB, free 290.1 MiB)
25/02/04 17:13:14 INFO TaskSetManager: Starting task 46.0 in stage 32.0 (TID 186) (10.0.0.43, executor driver, partition 46, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_36 in memory on 10.0.0.43:62420 (size: 1064.4 KiB, free: 321.6 MiB)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 34.0 in stage 32.0 (TID 174) in 614 ms on 10.0.0.43 (executor driver) (35/200)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 37.0 in stage 32.0 (TID 177) in 573 ms on 10.0.0.43 (executor driver) (36/200)
25/02/04 17:13:14 INFO Executor: Running task 46.0 in stage 32.0 (TID 186)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 38.0 in stage 32.0 (TID 178) in 555 ms on 10.0.0.43 (executor driver) (37/200)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 36.0 in stage 32.0 (TID 176)
[rdd_72_36]
25/02/04 17:13:14 INFO Executor: Finished task 36.0 in stage 32.0 (TID 176). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 47.0 in stage 32.0 (TID 187) (10.0.0.43, executor driver, partition 47, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 47.0 in stage 32.0 (TID 187)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 36.0 in stage 32.0 (TID 176) in 580 ms on 10.0.0.43 (executor driver) (38/200)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:14 INFO MemoryStore: Block rdd_72_32 stored as values in memory (estimated size 1297.1 KiB, free 279.1 MiB)
25/02/04 17:13:14 INFO BlockManagerInfo: Added rdd_72_32 in memory on 10.0.0.43:62420 (size: 1297.1 KiB, free: 320.3 MiB)
25/02/04 17:13:14 INFO Executor: 1 block locks were not released by task 32.0 in stage 32.0 (TID 172)
[rdd_72_32]
25/02/04 17:13:14 INFO Executor: Finished task 32.0 in stage 32.0 (TID 172). 17009 bytes result sent to driver
25/02/04 17:13:14 INFO TaskSetManager: Starting task 48.0 in stage 32.0 (TID 188) (10.0.0.43, executor driver, partition 48, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:14 INFO Executor: Running task 48.0 in stage 32.0 (TID 188)
25/02/04 17:13:14 INFO TaskSetManager: Finished task 32.0 in stage 32.0 (TID 172) in 663 ms on 10.0.0.43 (executor driver) (39/200)
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_40 stored as values in memory (estimated size 1050.1 KiB, free 81.6 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_40 in memory on 10.0.0.43:62420 (size: 1050.1 KiB, free: 319.3 MiB)
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_39 stored as values in memory (estimated size 1282.7 KiB, free 106.4 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_39 in memory on 10.0.0.43:62420 (size: 1282.7 KiB, free: 318.0 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 40.0 in stage 32.0 (TID 180)
[rdd_72_40]
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 39.0 in stage 32.0 (TID 179)
[rdd_72_39]
25/02/04 17:13:15 INFO Executor: Finished task 39.0 in stage 32.0 (TID 179). 17009 bytes result sent to driver
25/02/04 17:13:15 INFO Executor: Finished task 40.0 in stage 32.0 (TID 180). 17052 bytes result sent to driver
25/02/04 17:13:15 INFO TaskSetManager: Starting task 49.0 in stage 32.0 (TID 189) (10.0.0.43, executor driver, partition 49, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_47 stored as values in memory (estimated size 1176.4 KiB, free 129.3 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_47 in memory on 10.0.0.43:62420 (size: 1176.4 KiB, free: 316.9 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 47.0 in stage 32.0 (TID 187)
[rdd_72_47]
25/02/04 17:13:15 INFO TaskSetManager: Finished task 40.0 in stage 32.0 (TID 180) in 649 ms on 10.0.0.43 (executor driver) (40/200)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 50.0 in stage 32.0 (TID 190) (10.0.0.43, executor driver, partition 50, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO Executor: Running task 49.0 in stage 32.0 (TID 189)
25/02/04 17:13:15 INFO Executor: Running task 50.0 in stage 32.0 (TID 190)
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_41 stored as values in memory (estimated size 1231.3 KiB, free 154.2 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_41 in memory on 10.0.0.43:62420 (size: 1231.3 KiB, free: 315.7 MiB)
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_43 stored as values in memory (estimated size 1258.3 KiB, free 179.0 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 41.0 in stage 32.0 (TID 181)
[rdd_72_41]
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_43 in memory on 10.0.0.43:62420 (size: 1258.3 KiB, free: 314.4 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 43.0 in stage 32.0 (TID 183)
[rdd_72_43]
25/02/04 17:13:15 INFO Executor: Finished task 47.0 in stage 32.0 (TID 187). 17052 bytes result sent to driver
25/02/04 17:13:15 INFO TaskSetManager: Finished task 39.0 in stage 32.0 (TID 179) in 706 ms on 10.0.0.43 (executor driver) (41/200)
25/02/04 17:13:15 INFO Executor: Finished task 43.0 in stage 32.0 (TID 183). 17052 bytes result sent to driver
25/02/04 17:13:15 INFO Executor: Finished task 41.0 in stage 32.0 (TID 181). 17052 bytes result sent to driver
25/02/04 17:13:15 INFO TaskSetManager: Starting task 51.0 in stage 32.0 (TID 191) (10.0.0.43, executor driver, partition 51, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO TaskSetManager: Finished task 47.0 in stage 32.0 (TID 187) in 528 ms on 10.0.0.43 (executor driver) (42/200)
25/02/04 17:13:15 INFO Executor: Running task 51.0 in stage 32.0 (TID 191)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 52.0 in stage 32.0 (TID 192) (10.0.0.43, executor driver, partition 52, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO TaskSetManager: Finished task 43.0 in stage 32.0 (TID 183) in 534 ms on 10.0.0.43 (executor driver) (43/200)
25/02/04 17:13:15 INFO Executor: Running task 52.0 in stage 32.0 (TID 192)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 53.0 in stage 32.0 (TID 193) (10.0.0.43, executor driver, partition 53, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO Executor: Running task 53.0 in stage 32.0 (TID 193)
25/02/04 17:13:15 INFO TaskSetManager: Finished task 41.0 in stage 32.0 (TID 181) in 545 ms on 10.0.0.43 (executor driver) (44/200)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_45 stored as values in memory (estimated size 1353.6 KiB, free 205.7 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_45 in memory on 10.0.0.43:62420 (size: 1353.6 KiB, free: 313.1 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 45.0 in stage 32.0 (TID 185)
[rdd_72_45]
25/02/04 17:13:15 INFO Executor: Finished task 45.0 in stage 32.0 (TID 185). 17009 bytes result sent to driver
25/02/04 17:13:15 INFO TaskSetManager: Starting task 54.0 in stage 32.0 (TID 194) (10.0.0.43, executor driver, partition 54, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO TaskSetManager: Finished task 45.0 in stage 32.0 (TID 185) in 571 ms on 10.0.0.43 (executor driver) (45/200)
25/02/04 17:13:15 INFO Executor: Running task 54.0 in stage 32.0 (TID 194)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_48 stored as values in memory (estimated size 1275.9 KiB, free 222.7 MiB)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_48 in memory on 10.0.0.43:62420 (size: 1275.9 KiB, free: 311.9 MiB)
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_44 stored as values in memory (estimated size 1177.9 KiB, free 244.2 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 48.0 in stage 32.0 (TID 188)
[rdd_72_48]
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_44 in memory on 10.0.0.43:62420 (size: 1177.9 KiB, free: 310.7 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 44.0 in stage 32.0 (TID 184)
[rdd_72_44]
25/02/04 17:13:15 INFO Executor: Finished task 44.0 in stage 32.0 (TID 184). 17009 bytes result sent to driver
25/02/04 17:13:15 INFO Executor: Finished task 48.0 in stage 32.0 (TID 188). 17052 bytes result sent to driver
25/02/04 17:13:15 INFO TaskSetManager: Starting task 55.0 in stage 32.0 (TID 195) (10.0.0.43, executor driver, partition 55, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO Executor: Running task 55.0 in stage 32.0 (TID 195)
25/02/04 17:13:15 INFO TaskSetManager: Finished task 44.0 in stage 32.0 (TID 184) in 619 ms on 10.0.0.43 (executor driver) (46/200)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 56.0 in stage 32.0 (TID 196) (10.0.0.43, executor driver, partition 56, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO Executor: Running task 56.0 in stage 32.0 (TID 196)
25/02/04 17:13:15 INFO TaskSetManager: Finished task 48.0 in stage 32.0 (TID 188) in 594 ms on 10.0.0.43 (executor driver) (47/200)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_46 stored as values in memory (estimated size 1512.7 KiB, free 219.7 MiB)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_46 in memory on 10.0.0.43:62420 (size: 1512.7 KiB, free: 309.2 MiB)
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 46.0 in stage 32.0 (TID 186)
[rdd_72_46]
25/02/04 17:13:15 INFO Executor: Finished task 46.0 in stage 32.0 (TID 186). 17009 bytes result sent to driver
25/02/04 17:13:15 INFO MemoryStore: Block rdd_72_42 stored as values in memory (estimated size 1541.0 KiB, free 218.2 MiB)
25/02/04 17:13:15 INFO BlockManagerInfo: Added rdd_72_42 in memory on 10.0.0.43:62420 (size: 1541.0 KiB, free: 307.7 MiB)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 57.0 in stage 32.0 (TID 197) (10.0.0.43, executor driver, partition 57, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO Executor: 1 block locks were not released by task 42.0 in stage 32.0 (TID 182)
[rdd_72_42]
25/02/04 17:13:15 INFO TaskSetManager: Finished task 46.0 in stage 32.0 (TID 186) in 647 ms on 10.0.0.43 (executor driver) (48/200)
25/02/04 17:13:15 INFO Executor: Finished task 42.0 in stage 32.0 (TID 182). 17009 bytes result sent to driver
25/02/04 17:13:15 INFO Executor: Running task 57.0 in stage 32.0 (TID 197)
25/02/04 17:13:15 INFO TaskSetManager: Starting task 58.0 in stage 32.0 (TID 198) (10.0.0.43, executor driver, partition 58, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:15 INFO TaskSetManager: Finished task 42.0 in stage 32.0 (TID 182) in 653 ms on 10.0.0.43 (executor driver) (49/200)
25/02/04 17:13:15 INFO Executor: Running task 58.0 in stage 32.0 (TID 198)
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 17 (4.1 MiB) non-empty blocks including 17 (4.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_49 stored as values in memory (estimated size 1056.0 KiB, free 85.0 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_49 in memory on 10.0.0.43:62420 (size: 1056.0 KiB, free: 306.7 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_53 stored as values in memory (estimated size 1058.2 KiB, free 108.0 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_53 in memory on 10.0.0.43:62420 (size: 1058.2 KiB, free: 305.7 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 49.0 in stage 32.0 (TID 189)
[rdd_72_49]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 53.0 in stage 32.0 (TID 193)
[rdd_72_53]
25/02/04 17:13:16 INFO Executor: Finished task 49.0 in stage 32.0 (TID 189). 17052 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: Finished task 53.0 in stage 32.0 (TID 193). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 59.0 in stage 32.0 (TID 199) (10.0.0.43, executor driver, partition 59, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 49.0 in stage 32.0 (TID 189) in 767 ms on 10.0.0.43 (executor driver) (50/200)
25/02/04 17:13:16 INFO Executor: Running task 59.0 in stage 32.0 (TID 199)
25/02/04 17:13:16 INFO TaskSetManager: Starting task 60.0 in stage 32.0 (TID 200) (10.0.0.43, executor driver, partition 60, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 53.0 in stage 32.0 (TID 193) in 726 ms on 10.0.0.43 (executor driver) (51/200)
25/02/04 17:13:16 INFO Executor: Running task 60.0 in stage 32.0 (TID 200)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_51 stored as values in memory (estimated size 1019.7 KiB, free 129.1 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_51 in memory on 10.0.0.43:62420 (size: 1019.7 KiB, free: 304.7 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 51.0 in stage 32.0 (TID 191)
[rdd_72_51]
25/02/04 17:13:16 INFO Executor: Finished task 51.0 in stage 32.0 (TID 191). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:16 INFO TaskSetManager: Starting task 61.0 in stage 32.0 (TID 201) (10.0.0.43, executor driver, partition 61, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 51.0 in stage 32.0 (TID 191) in 765 ms on 10.0.0.43 (executor driver) (52/200)
25/02/04 17:13:16 INFO Executor: Running task 61.0 in stage 32.0 (TID 201)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_58 stored as values in memory (estimated size 960.6 KiB, free 150.1 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_54 stored as values in memory (estimated size 1153.3 KiB, free 172.8 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_58 in memory on 10.0.0.43:62420 (size: 960.6 KiB, free: 303.7 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_54 in memory on 10.0.0.43:62420 (size: 1153.3 KiB, free: 302.6 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 58.0 in stage 32.0 (TID 198)
[rdd_72_58]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 54.0 in stage 32.0 (TID 194)
[rdd_72_54]
25/02/04 17:13:16 INFO Executor: Finished task 54.0 in stage 32.0 (TID 194). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: Finished task 58.0 in stage 32.0 (TID 198). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 62.0 in stage 32.0 (TID 202) (10.0.0.43, executor driver, partition 62, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO Executor: Running task 62.0 in stage 32.0 (TID 202)
25/02/04 17:13:16 INFO TaskSetManager: Starting task 63.0 in stage 32.0 (TID 203) (10.0.0.43, executor driver, partition 63, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 54.0 in stage 32.0 (TID 194) in 784 ms on 10.0.0.43 (executor driver) (53/200)
25/02/04 17:13:16 INFO Executor: Running task 63.0 in stage 32.0 (TID 203)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 58.0 in stage 32.0 (TID 198) in 707 ms on 10.0.0.43 (executor driver) (54/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_56 stored as values in memory (estimated size 1129.4 KiB, free 180.6 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_52 stored as values in memory (estimated size 1374.8 KiB, free 178.8 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_56 in memory on 10.0.0.43:62420 (size: 1129.4 KiB, free: 301.5 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_52 in memory on 10.0.0.43:62420 (size: 1374.8 KiB, free: 300.2 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 52.0 in stage 32.0 (TID 192)
[rdd_72_52]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 56.0 in stage 32.0 (TID 196)
[rdd_72_56]
25/02/04 17:13:16 INFO Executor: Finished task 56.0 in stage 32.0 (TID 196). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: Finished task 52.0 in stage 32.0 (TID 192). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 64.0 in stage 32.0 (TID 204) (10.0.0.43, executor driver, partition 64, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO Executor: Running task 64.0 in stage 32.0 (TID 204)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO TaskSetManager: Starting task 65.0 in stage 32.0 (TID 205) (10.0.0.43, executor driver, partition 65, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 52.0 in stage 32.0 (TID 192) in 860 ms on 10.0.0.43 (executor driver) (55/200)
25/02/04 17:13:16 INFO Executor: Running task 65.0 in stage 32.0 (TID 205)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 56.0 in stage 32.0 (TID 196) in 769 ms on 10.0.0.43 (executor driver) (56/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (4.3 MiB) non-empty blocks including 17 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_50 stored as values in memory (estimated size 1555.2 KiB, free 130.5 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_50 in memory on 10.0.0.43:62420 (size: 1555.2 KiB, free: 298.6 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 50.0 in stage 32.0 (TID 190)
[rdd_72_50]
25/02/04 17:13:16 INFO Executor: Finished task 50.0 in stage 32.0 (TID 190). 17052 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 66.0 in stage 32.0 (TID 206) (10.0.0.43, executor driver, partition 66, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 50.0 in stage 32.0 (TID 190) in 921 ms on 10.0.0.43 (executor driver) (57/200)
25/02/04 17:13:16 INFO Executor: Running task 66.0 in stage 32.0 (TID 206)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_55 stored as values in memory (estimated size 1096.5 KiB, free 94.9 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_55 in memory on 10.0.0.43:62420 (size: 1096.5 KiB, free: 297.6 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 55.0 in stage 32.0 (TID 195)
[rdd_72_55]
25/02/04 17:13:16 INFO Executor: Finished task 55.0 in stage 32.0 (TID 195). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 67.0 in stage 32.0 (TID 207) (10.0.0.43, executor driver, partition 67, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 55.0 in stage 32.0 (TID 195) in 907 ms on 10.0.0.43 (executor driver) (58/200)
25/02/04 17:13:16 INFO Executor: Running task 67.0 in stage 32.0 (TID 207)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_57 stored as values in memory (estimated size 1342.1 KiB, free 78.6 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_57 in memory on 10.0.0.43:62420 (size: 1342.1 KiB, free: 296.3 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 57.0 in stage 32.0 (TID 197)
[rdd_72_57]
25/02/04 17:13:16 INFO Executor: Finished task 57.0 in stage 32.0 (TID 197). 17052 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 68.0 in stage 32.0 (TID 208) (10.0.0.43, executor driver, partition 68, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO Executor: Running task 68.0 in stage 32.0 (TID 208)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 57.0 in stage 32.0 (TID 197) in 970 ms on 10.0.0.43 (executor driver) (59/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_62 stored as values in memory (estimated size 1097.7 KiB, free 61.5 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_62 in memory on 10.0.0.43:62420 (size: 1097.7 KiB, free: 295.2 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_63 stored as values in memory (estimated size 1263.8 KiB, free 84.3 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 62.0 in stage 32.0 (TID 202)
[rdd_72_62]
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_63 in memory on 10.0.0.43:62420 (size: 1263.8 KiB, free: 294.0 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_61 stored as values in memory (estimated size 1250.6 KiB, free 109.2 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_59 stored as values in memory (estimated size 1403.8 KiB, free 135.9 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_61 in memory on 10.0.0.43:62420 (size: 1250.6 KiB, free: 292.7 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_59 in memory on 10.0.0.43:62420 (size: 1403.8 KiB, free: 291.4 MiB)
25/02/04 17:13:16 INFO Executor: Finished task 62.0 in stage 32.0 (TID 202). 17052 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 59.0 in stage 32.0 (TID 199)
[rdd_72_59]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 61.0 in stage 32.0 (TID 201)
[rdd_72_61]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 63.0 in stage 32.0 (TID 203)
[rdd_72_63]
25/02/04 17:13:16 INFO Executor: Finished task 59.0 in stage 32.0 (TID 199). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 69.0 in stage 32.0 (TID 209) (10.0.0.43, executor driver, partition 69, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Starting task 70.0 in stage 32.0 (TID 210) (10.0.0.43, executor driver, partition 70, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 62.0 in stage 32.0 (TID 202) in 545 ms on 10.0.0.43 (executor driver) (60/200)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 59.0 in stage 32.0 (TID 199) in 651 ms on 10.0.0.43 (executor driver) (61/200)
25/02/04 17:13:16 INFO Executor: Running task 69.0 in stage 32.0 (TID 209)
25/02/04 17:13:16 INFO Executor: Running task 70.0 in stage 32.0 (TID 210)
25/02/04 17:13:16 INFO Executor: Finished task 61.0 in stage 32.0 (TID 201). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: Finished task 63.0 in stage 32.0 (TID 203). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 71.0 in stage 32.0 (TID 211) (10.0.0.43, executor driver, partition 71, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 61.0 in stage 32.0 (TID 201) in 619 ms on 10.0.0.43 (executor driver) (62/200)
25/02/04 17:13:16 INFO Executor: Running task 71.0 in stage 32.0 (TID 211)
25/02/04 17:13:16 INFO TaskSetManager: Starting task 72.0 in stage 32.0 (TID 212) (10.0.0.43, executor driver, partition 72, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO Executor: Running task 72.0 in stage 32.0 (TID 212)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 63.0 in stage 32.0 (TID 203) in 562 ms on 10.0.0.43 (executor driver) (63/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_60 stored as values in memory (estimated size 1426.3 KiB, free 212.4 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_64 stored as values in memory (estimated size 1254.2 KiB, free 210.1 MiB)
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_66 stored as values in memory (estimated size 1069.9 KiB, free 210.1 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_60 in memory on 10.0.0.43:62420 (size: 1426.3 KiB, free: 290.0 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 60.0 in stage 32.0 (TID 200)
[rdd_72_60]
25/02/04 17:13:16 INFO Executor: Finished task 60.0 in stage 32.0 (TID 200). 17052 bytes result sent to driver
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_64 in memory on 10.0.0.43:62420 (size: 1254.2 KiB, free: 288.7 MiB)
25/02/04 17:13:16 INFO TaskSetManager: Starting task 73.0 in stage 32.0 (TID 213) (10.0.0.43, executor driver, partition 73, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_66 in memory on 10.0.0.43:62420 (size: 1069.9 KiB, free: 287.7 MiB)
25/02/04 17:13:16 INFO Executor: Running task 73.0 in stage 32.0 (TID 213)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 64.0 in stage 32.0 (TID 204)
[rdd_72_64]
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 66.0 in stage 32.0 (TID 206)
[rdd_72_66]
25/02/04 17:13:16 INFO TaskSetManager: Finished task 60.0 in stage 32.0 (TID 200) in 725 ms on 10.0.0.43 (executor driver) (64/200)
25/02/04 17:13:16 INFO Executor: Finished task 66.0 in stage 32.0 (TID 206). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO Executor: Finished task 64.0 in stage 32.0 (TID 204). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 74.0 in stage 32.0 (TID 214) (10.0.0.43, executor driver, partition 74, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Starting task 75.0 in stage 32.0 (TID 215) (10.0.0.43, executor driver, partition 75, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 66.0 in stage 32.0 (TID 206) in 544 ms on 10.0.0.43 (executor driver) (65/200)
25/02/04 17:13:16 INFO Executor: Running task 74.0 in stage 32.0 (TID 214)
25/02/04 17:13:16 INFO Executor: Running task 75.0 in stage 32.0 (TID 215)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO TaskSetManager: Finished task 64.0 in stage 32.0 (TID 204) in 609 ms on 10.0.0.43 (executor driver) (66/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_67 stored as values in memory (estimated size 1146.0 KiB, free 221.1 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_67 in memory on 10.0.0.43:62420 (size: 1146.0 KiB, free: 286.6 MiB)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 67.0 in stage 32.0 (TID 207)
[rdd_72_67]
25/02/04 17:13:16 INFO Executor: Finished task 67.0 in stage 32.0 (TID 207). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 76.0 in stage 32.0 (TID 216) (10.0.0.43, executor driver, partition 76, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO Executor: Running task 76.0 in stage 32.0 (TID 216)
25/02/04 17:13:16 INFO TaskSetManager: Finished task 67.0 in stage 32.0 (TID 207) in 485 ms on 10.0.0.43 (executor driver) (67/200)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_65 stored as values in memory (estimated size 1448.7 KiB, free 163.5 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_65 in memory on 10.0.0.43:62420 (size: 1448.7 KiB, free: 285.2 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 65.0 in stage 32.0 (TID 205)
[rdd_72_65]
25/02/04 17:13:16 INFO Executor: Finished task 65.0 in stage 32.0 (TID 205). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 77.0 in stage 32.0 (TID 217) (10.0.0.43, executor driver, partition 77, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 65.0 in stage 32.0 (TID 205) in 661 ms on 10.0.0.43 (executor driver) (68/200)
25/02/04 17:13:16 INFO Executor: Running task 77.0 in stage 32.0 (TID 217)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.0 MiB) non-empty blocks including 17 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:16 INFO MemoryStore: Block rdd_72_68 stored as values in memory (estimated size 1124.1 KiB, free 102.4 MiB)
25/02/04 17:13:16 INFO BlockManagerInfo: Added rdd_72_68 in memory on 10.0.0.43:62420 (size: 1124.1 KiB, free: 284.1 MiB)
25/02/04 17:13:16 INFO Executor: 1 block locks were not released by task 68.0 in stage 32.0 (TID 208)
[rdd_72_68]
25/02/04 17:13:16 INFO Executor: Finished task 68.0 in stage 32.0 (TID 208). 17009 bytes result sent to driver
25/02/04 17:13:16 INFO TaskSetManager: Starting task 78.0 in stage 32.0 (TID 218) (10.0.0.43, executor driver, partition 78, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:16 INFO TaskSetManager: Finished task 68.0 in stage 32.0 (TID 208) in 484 ms on 10.0.0.43 (executor driver) (69/200)
25/02/04 17:13:16 INFO Executor: Running task 78.0 in stage 32.0 (TID 218)
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_69 stored as values in memory (estimated size 981.1 KiB, free 61.4 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_69 in memory on 10.0.0.43:62420 (size: 981.1 KiB, free: 283.1 MiB)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_70 stored as values in memory (estimated size 1056.1 KiB, free 84.5 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 69.0 in stage 32.0 (TID 209)
[rdd_72_69]
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_70 in memory on 10.0.0.43:62420 (size: 1056.1 KiB, free: 282.1 MiB)
25/02/04 17:13:17 INFO Executor: Finished task 69.0 in stage 32.0 (TID 209). 17052 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 79.0 in stage 32.0 (TID 219) (10.0.0.43, executor driver, partition 79, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_71 stored as values in memory (estimated size 1153.0 KiB, free 153.5 MiB)
25/02/04 17:13:17 INFO Executor: Running task 79.0 in stage 32.0 (TID 219)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 69.0 in stage 32.0 (TID 209) in 669 ms on 10.0.0.43 (executor driver) (70/200)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_77 stored as values in memory (estimated size 934.4 KiB, free 152.6 MiB)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_75 stored as values in memory (estimated size 1068.8 KiB, free 151.6 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 70.0 in stage 32.0 (TID 210)
[rdd_72_70]
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_71 in memory on 10.0.0.43:62420 (size: 1153.0 KiB, free: 280.9 MiB)
25/02/04 17:13:17 INFO Executor: Finished task 70.0 in stage 32.0 (TID 210). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 71.0 in stage 32.0 (TID 211)
[rdd_72_71]
25/02/04 17:13:17 INFO Executor: Finished task 71.0 in stage 32.0 (TID 211). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_77 in memory on 10.0.0.43:62420 (size: 934.4 KiB, free: 280.0 MiB)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_74 stored as values in memory (estimated size 1337.1 KiB, free 200.4 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 77.0 in stage 32.0 (TID 217)
[rdd_72_77]
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_76 stored as values in memory (estimated size 1148.0 KiB, free 199.3 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_75 in memory on 10.0.0.43:62420 (size: 1068.8 KiB, free: 279.0 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_74 in memory on 10.0.0.43:62420 (size: 1337.1 KiB, free: 277.7 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 75.0 in stage 32.0 (TID 215)
[rdd_72_75]
25/02/04 17:13:17 INFO Executor: Finished task 77.0 in stage 32.0 (TID 217). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 74.0 in stage 32.0 (TID 214)
[rdd_72_74]
25/02/04 17:13:17 INFO Executor: Finished task 75.0 in stage 32.0 (TID 215). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_76 in memory on 10.0.0.43:62420 (size: 1148.0 KiB, free: 276.6 MiB)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 80.0 in stage 32.0 (TID 220) (10.0.0.43, executor driver, partition 80, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Finished task 74.0 in stage 32.0 (TID 214). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Finished task 70.0 in stage 32.0 (TID 210) in 685 ms on 10.0.0.43 (executor driver) (71/200)
25/02/04 17:13:17 INFO Executor: Running task 80.0 in stage 32.0 (TID 220)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 76.0 in stage 32.0 (TID 216)
[rdd_72_76]
25/02/04 17:13:17 INFO Executor: Finished task 76.0 in stage 32.0 (TID 216). 17052 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 81.0 in stage 32.0 (TID 221) (10.0.0.43, executor driver, partition 81, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 81.0 in stage 32.0 (TID 221)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 82.0 in stage 32.0 (TID 222) (10.0.0.43, executor driver, partition 82, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO TaskSetManager: Finished task 71.0 in stage 32.0 (TID 211) in 677 ms on 10.0.0.43 (executor driver) (72/200)
25/02/04 17:13:17 INFO Executor: Running task 82.0 in stage 32.0 (TID 222)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:17 INFO TaskSetManager: Starting task 83.0 in stage 32.0 (TID 223) (10.0.0.43, executor driver, partition 83, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO TaskSetManager: Finished task 77.0 in stage 32.0 (TID 217) in 549 ms on 10.0.0.43 (executor driver) (73/200)
25/02/04 17:13:17 INFO Executor: Running task 83.0 in stage 32.0 (TID 223)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 84.0 in stage 32.0 (TID 224) (10.0.0.43, executor driver, partition 84, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO TaskSetManager: Finished task 75.0 in stage 32.0 (TID 215) in 608 ms on 10.0.0.43 (executor driver) (74/200)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 74.0 in stage 32.0 (TID 214) in 609 ms on 10.0.0.43 (executor driver) (75/200)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO Executor: Running task 84.0 in stage 32.0 (TID 224)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 85.0 in stage 32.0 (TID 225) (10.0.0.43, executor driver, partition 85, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 85.0 in stage 32.0 (TID 225)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 76.0 in stage 32.0 (TID 216) in 593 ms on 10.0.0.43 (executor driver) (76/200)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_73 stored as values in memory (estimated size 1243.1 KiB, free 224.1 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_73 in memory on 10.0.0.43:62420 (size: 1243.1 KiB, free: 275.4 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 73.0 in stage 32.0 (TID 213)
[rdd_72_73]
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO Executor: Finished task 73.0 in stage 32.0 (TID 213). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 86.0 in stage 32.0 (TID 226) (10.0.0.43, executor driver, partition 86, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 86.0 in stage 32.0 (TID 226)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 73.0 in stage 32.0 (TID 213) in 625 ms on 10.0.0.43 (executor driver) (77/200)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_78 stored as values in memory (estimated size 1105.7 KiB, free 240.4 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_78 in memory on 10.0.0.43:62420 (size: 1105.7 KiB, free: 274.3 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 78.0 in stage 32.0 (TID 218)
[rdd_72_78]
25/02/04 17:13:17 INFO Executor: Finished task 78.0 in stage 32.0 (TID 218). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO TaskSetManager: Starting task 87.0 in stage 32.0 (TID 227) (10.0.0.43, executor driver, partition 87, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 87.0 in stage 32.0 (TID 227)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 78.0 in stage 32.0 (TID 218) in 528 ms on 10.0.0.43 (executor driver) (78/200)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_72 stored as values in memory (estimated size 1253.6 KiB, free 167.4 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_72 in memory on 10.0.0.43:62420 (size: 1253.6 KiB, free: 273.0 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 72.0 in stage 32.0 (TID 212)
[rdd_72_72]
25/02/04 17:13:17 INFO Executor: Finished task 72.0 in stage 32.0 (TID 212). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 88.0 in stage 32.0 (TID 228) (10.0.0.43, executor driver, partition 88, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO TaskSetManager: Finished task 72.0 in stage 32.0 (TID 212) in 760 ms on 10.0.0.43 (executor driver) (79/200)
25/02/04 17:13:17 INFO Executor: Running task 88.0 in stage 32.0 (TID 228)
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_79 stored as values in memory (estimated size 1046.6 KiB, free 52.3 MiB)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_83 stored as values in memory (estimated size 1017.8 KiB, free 73.4 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_79 in memory on 10.0.0.43:62420 (size: 1046.6 KiB, free: 272.0 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_83 in memory on 10.0.0.43:62420 (size: 1017.8 KiB, free: 271.0 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 79.0 in stage 32.0 (TID 219)
[rdd_72_79]
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 83.0 in stage 32.0 (TID 223)
[rdd_72_83]
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_85 stored as values in memory (estimated size 1035.6 KiB, free 94.5 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_85 in memory on 10.0.0.43:62420 (size: 1035.6 KiB, free: 270.0 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 85.0 in stage 32.0 (TID 225)
[rdd_72_85]
25/02/04 17:13:17 INFO Executor: Finished task 83.0 in stage 32.0 (TID 223). 17052 bytes result sent to driver
25/02/04 17:13:17 INFO Executor: Finished task 79.0 in stage 32.0 (TID 219). 17052 bytes result sent to driver
25/02/04 17:13:17 INFO Executor: Finished task 85.0 in stage 32.0 (TID 225). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_80 stored as values in memory (estimated size 1093.8 KiB, free 117.5 MiB)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_80 in memory on 10.0.0.43:62420 (size: 1093.8 KiB, free: 269.0 MiB)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 80.0 in stage 32.0 (TID 220)
[rdd_72_80]
25/02/04 17:13:17 INFO Executor: Finished task 80.0 in stage 32.0 (TID 220). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 89.0 in stage 32.0 (TID 229) (10.0.0.43, executor driver, partition 89, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 89.0 in stage 32.0 (TID 229)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 90.0 in stage 32.0 (TID 230) (10.0.0.43, executor driver, partition 90, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 90.0 in stage 32.0 (TID 230)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_84 stored as values in memory (estimated size 1123.3 KiB, free 140.4 MiB)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 83.0 in stage 32.0 (TID 223) in 563 ms on 10.0.0.43 (executor driver) (80/200)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 91.0 in stage 32.0 (TID 231) (10.0.0.43, executor driver, partition 91, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 91.0 in stage 32.0 (TID 231)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_84 in memory on 10.0.0.43:62420 (size: 1123.3 KiB, free: 267.9 MiB)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 92.0 in stage 32.0 (TID 232) (10.0.0.43, executor driver, partition 92, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 92.0 in stage 32.0 (TID 232)
25/02/04 17:13:17 INFO MemoryStore: Block rdd_72_87 stored as values in memory (estimated size 1050.2 KiB, free 163.5 MiB)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 85.0 in stage 32.0 (TID 225) in 564 ms on 10.0.0.43 (executor driver) (81/200)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 79.0 in stage 32.0 (TID 219) in 629 ms on 10.0.0.43 (executor driver) (82/200)
25/02/04 17:13:17 INFO BlockManagerInfo: Added rdd_72_87 in memory on 10.0.0.43:62420 (size: 1050.2 KiB, free: 266.8 MiB)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 80.0 in stage 32.0 (TID 220) in 587 ms on 10.0.0.43 (executor driver) (83/200)
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 84.0 in stage 32.0 (TID 224)
[rdd_72_84]
25/02/04 17:13:17 INFO Executor: 1 block locks were not released by task 87.0 in stage 32.0 (TID 227)
[rdd_72_87]
25/02/04 17:13:17 INFO Executor: Finished task 84.0 in stage 32.0 (TID 224). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO Executor: Finished task 87.0 in stage 32.0 (TID 227). 17009 bytes result sent to driver
25/02/04 17:13:17 INFO TaskSetManager: Starting task 93.0 in stage 32.0 (TID 233) (10.0.0.43, executor driver, partition 93, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO Executor: Running task 93.0 in stage 32.0 (TID 233)
25/02/04 17:13:17 INFO TaskSetManager: Starting task 94.0 in stage 32.0 (TID 234) (10.0.0.43, executor driver, partition 94, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:17 INFO TaskSetManager: Finished task 84.0 in stage 32.0 (TID 224) in 574 ms on 10.0.0.43 (executor driver) (84/200)
25/02/04 17:13:17 INFO Executor: Running task 94.0 in stage 32.0 (TID 234)
25/02/04 17:13:17 INFO TaskSetManager: Finished task 87.0 in stage 32.0 (TID 227) in 539 ms on 10.0.0.43 (executor driver) (85/200)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.3 MiB) non-empty blocks including 17 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_82 stored as values in memory (estimated size 1281.3 KiB, free 188.3 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_82 in memory on 10.0.0.43:62420 (size: 1281.3 KiB, free: 265.6 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 82.0 in stage 32.0 (TID 222)
[rdd_72_82]
25/02/04 17:13:18 INFO Executor: Finished task 82.0 in stage 32.0 (TID 222). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_86 stored as values in memory (estimated size 1128.6 KiB, free 211.2 MiB)
25/02/04 17:13:18 INFO TaskSetManager: Starting task 95.0 in stage 32.0 (TID 235) (10.0.0.43, executor driver, partition 95, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_86 in memory on 10.0.0.43:62420 (size: 1128.6 KiB, free: 264.5 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 86.0 in stage 32.0 (TID 226)
[rdd_72_86]
25/02/04 17:13:18 INFO TaskSetManager: Finished task 82.0 in stage 32.0 (TID 222) in 619 ms on 10.0.0.43 (executor driver) (86/200)
25/02/04 17:13:18 INFO Executor: Finished task 86.0 in stage 32.0 (TID 226). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO Executor: Running task 95.0 in stage 32.0 (TID 235)
25/02/04 17:13:18 INFO TaskSetManager: Starting task 96.0 in stage 32.0 (TID 236) (10.0.0.43, executor driver, partition 96, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO Executor: Running task 96.0 in stage 32.0 (TID 236)
25/02/04 17:13:18 INFO TaskSetManager: Finished task 86.0 in stage 32.0 (TID 226) in 604 ms on 10.0.0.43 (executor driver) (87/200)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_81 stored as values in memory (estimated size 1309.1 KiB, free 236.0 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_81 in memory on 10.0.0.43:62420 (size: 1309.1 KiB, free: 263.2 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 81.0 in stage 32.0 (TID 221)
[rdd_72_81]
25/02/04 17:13:18 INFO Executor: Finished task 81.0 in stage 32.0 (TID 221). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 97.0 in stage 32.0 (TID 237) (10.0.0.43, executor driver, partition 97, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO Executor: Running task 97.0 in stage 32.0 (TID 237)
25/02/04 17:13:18 INFO TaskSetManager: Finished task 81.0 in stage 32.0 (TID 221) in 640 ms on 10.0.0.43 (executor driver) (88/200)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 24.0 MiB to disk (0  time so far)
25/02/04 17:13:18 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 24.0 MiB to disk (0  time so far)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_88 stored as values in memory (estimated size 1331.9 KiB, free 59.9 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_88 in memory on 10.0.0.43:62420 (size: 1331.9 KiB, free: 261.9 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 88.0 in stage 32.0 (TID 228)
[rdd_72_88]
25/02/04 17:13:18 INFO Executor: Finished task 88.0 in stage 32.0 (TID 228). 17052 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 98.0 in stage 32.0 (TID 238) (10.0.0.43, executor driver, partition 98, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 88.0 in stage 32.0 (TID 228) in 783 ms on 10.0.0.43 (executor driver) (89/200)
25/02/04 17:13:18 INFO Executor: Running task 98.0 in stage 32.0 (TID 238)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_95 stored as values in memory (estimated size 998.9 KiB, free 108.8 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_95 in memory on 10.0.0.43:62420 (size: 998.9 KiB, free: 260.9 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 95.0 in stage 32.0 (TID 235)
[rdd_72_95]
25/02/04 17:13:18 INFO Executor: Finished task 95.0 in stage 32.0 (TID 235). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 99.0 in stage 32.0 (TID 239) (10.0.0.43, executor driver, partition 99, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 95.0 in stage 32.0 (TID 235) in 477 ms on 10.0.0.43 (executor driver) (90/200)
25/02/04 17:13:18 INFO Executor: Running task 99.0 in stage 32.0 (TID 239)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_90 stored as values in memory (estimated size 1025.4 KiB, free 129.8 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_90 in memory on 10.0.0.43:62420 (size: 1025.4 KiB, free: 259.9 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 90.0 in stage 32.0 (TID 230)
[rdd_72_90]
25/02/04 17:13:18 INFO Executor: Finished task 90.0 in stage 32.0 (TID 230). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 100.0 in stage 32.0 (TID 240) (10.0.0.43, executor driver, partition 100, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 90.0 in stage 32.0 (TID 230) in 554 ms on 10.0.0.43 (executor driver) (91/200)
25/02/04 17:13:18 INFO Executor: Running task 100.0 in stage 32.0 (TID 240)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_96 stored as values in memory (estimated size 1038.0 KiB, free 147.9 MiB)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_92 stored as values in memory (estimated size 1066.1 KiB, free 170.9 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_96 in memory on 10.0.0.43:62420 (size: 1038.0 KiB, free: 258.9 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_92 in memory on 10.0.0.43:62420 (size: 1066.1 KiB, free: 257.9 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 96.0 in stage 32.0 (TID 236)
[rdd_72_96]
25/02/04 17:13:18 INFO Executor: Finished task 96.0 in stage 32.0 (TID 236). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.1 MiB) non-empty blocks including 17 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO TaskSetManager: Starting task 101.0 in stage 32.0 (TID 241) (10.0.0.43, executor driver, partition 101, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 96.0 in stage 32.0 (TID 236) in 515 ms on 10.0.0.43 (executor driver) (92/200)
25/02/04 17:13:18 INFO Executor: Running task 101.0 in stage 32.0 (TID 241)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 92.0 in stage 32.0 (TID 232)
[rdd_72_92]
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.1 MiB) non-empty blocks including 17 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO Executor: Finished task 92.0 in stage 32.0 (TID 232). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 102.0 in stage 32.0 (TID 242) (10.0.0.43, executor driver, partition 102, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO TaskSetManager: Finished task 92.0 in stage 32.0 (TID 232) in 615 ms on 10.0.0.43 (executor driver) (93/200)
25/02/04 17:13:18 INFO Executor: Running task 102.0 in stage 32.0 (TID 242)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_93 stored as values in memory (estimated size 1206.0 KiB, free 116.6 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_93 in memory on 10.0.0.43:62420 (size: 1206.0 KiB, free: 256.7 MiB)
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_91 stored as values in memory (estimated size 1209.1 KiB, free 133.5 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_91 in memory on 10.0.0.43:62420 (size: 1209.1 KiB, free: 255.5 MiB)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 93.0 in stage 32.0 (TID 233)
[rdd_72_93]
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 91.0 in stage 32.0 (TID 231)
[rdd_72_91]
25/02/04 17:13:18 INFO Executor: Finished task 93.0 in stage 32.0 (TID 233). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO Executor: Finished task 91.0 in stage 32.0 (TID 231). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 103.0 in stage 32.0 (TID 243) (10.0.0.43, executor driver, partition 103, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 93.0 in stage 32.0 (TID 233) in 675 ms on 10.0.0.43 (executor driver) (94/200)
25/02/04 17:13:18 INFO Executor: Running task 103.0 in stage 32.0 (TID 243)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:18 INFO TaskSetManager: Starting task 104.0 in stage 32.0 (TID 244) (10.0.0.43, executor driver, partition 104, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO Executor: Running task 104.0 in stage 32.0 (TID 244)
25/02/04 17:13:18 INFO TaskSetManager: Finished task 91.0 in stage 32.0 (TID 231) in 688 ms on 10.0.0.43 (executor driver) (95/200)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_97 stored as values in memory (estimated size 1377.5 KiB, free 148.0 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_97 in memory on 10.0.0.43:62420 (size: 1377.5 KiB, free: 254.2 MiB)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 97.0 in stage 32.0 (TID 237)
[rdd_72_97]
25/02/04 17:13:18 INFO Executor: Finished task 97.0 in stage 32.0 (TID 237). 17009 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 105.0 in stage 32.0 (TID 245) (10.0.0.43, executor driver, partition 105, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 97.0 in stage 32.0 (TID 237) in 648 ms on 10.0.0.43 (executor driver) (96/200)
25/02/04 17:13:18 INFO Executor: Running task 105.0 in stage 32.0 (TID 245)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_94 stored as values in memory (estimated size 1436.0 KiB, free 62.8 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_94 in memory on 10.0.0.43:62420 (size: 1436.0 KiB, free: 252.8 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 94.0 in stage 32.0 (TID 234)
[rdd_72_94]
25/02/04 17:13:18 INFO Executor: Finished task 94.0 in stage 32.0 (TID 234). 17095 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 106.0 in stage 32.0 (TID 246) (10.0.0.43, executor driver, partition 106, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO TaskSetManager: Finished task 94.0 in stage 32.0 (TID 234) in 852 ms on 10.0.0.43 (executor driver) (97/200)
25/02/04 17:13:18 INFO Executor: Running task 106.0 in stage 32.0 (TID 246)
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
25/02/04 17:13:18 INFO MemoryStore: Block rdd_72_89 stored as values in memory (estimated size 1436.1 KiB, free 58.7 MiB)
25/02/04 17:13:18 INFO BlockManagerInfo: Added rdd_72_89 in memory on 10.0.0.43:62420 (size: 1436.1 KiB, free: 251.4 MiB)
25/02/04 17:13:18 INFO Executor: 1 block locks were not released by task 89.0 in stage 32.0 (TID 229)
[rdd_72_89]
25/02/04 17:13:18 INFO Executor: Finished task 89.0 in stage 32.0 (TID 229). 17095 bytes result sent to driver
25/02/04 17:13:18 INFO TaskSetManager: Starting task 107.0 in stage 32.0 (TID 247) (10.0.0.43, executor driver, partition 107, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:18 INFO Executor: Running task 107.0 in stage 32.0 (TID 247)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 89.0 in stage 32.0 (TID 229) in 1058 ms on 10.0.0.43 (executor driver) (98/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_99 stored as values in memory (estimated size 934.9 KiB, free 70.8 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_99 in memory on 10.0.0.43:62420 (size: 934.9 KiB, free: 250.4 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 99.0 in stage 32.0 (TID 239)
[rdd_72_99]
25/02/04 17:13:19 INFO Executor: Finished task 99.0 in stage 32.0 (TID 239). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_101 stored as values in memory (estimated size 956.2 KiB, free 87.3 MiB)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 108.0 in stage 32.0 (TID 248) (10.0.0.43, executor driver, partition 108, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_101 in memory on 10.0.0.43:62420 (size: 956.2 KiB, free: 249.5 MiB)
25/02/04 17:13:19 INFO Executor: Running task 108.0 in stage 32.0 (TID 248)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 101.0 in stage 32.0 (TID 241)
[rdd_72_101]
25/02/04 17:13:19 INFO Executor: Finished task 101.0 in stage 32.0 (TID 241). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 109.0 in stage 32.0 (TID 249) (10.0.0.43, executor driver, partition 109, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO Executor: Running task 109.0 in stage 32.0 (TID 249)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 101.0 in stage 32.0 (TID 241) in 617 ms on 10.0.0.43 (executor driver) (99/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 38 ms
25/02/04 17:13:19 INFO TaskSetManager: Finished task 99.0 in stage 32.0 (TID 239) in 659 ms on 10.0.0.43 (executor driver) (100/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.3 MiB) non-empty blocks including 17 (3.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_100 stored as values in memory (estimated size 1207.1 KiB, free 90.1 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_100 in memory on 10.0.0.43:62420 (size: 1207.1 KiB, free: 248.3 MiB)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 100.0 in stage 32.0 (TID 240)
[rdd_72_100]
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_103 stored as values in memory (estimated size 1066.7 KiB, free 131.7 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_103 in memory on 10.0.0.43:62420 (size: 1066.7 KiB, free: 247.3 MiB)
25/02/04 17:13:19 INFO Executor: Finished task 100.0 in stage 32.0 (TID 240). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 103.0 in stage 32.0 (TID 243)
[rdd_72_103]
25/02/04 17:13:19 INFO Executor: Finished task 103.0 in stage 32.0 (TID 243). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 110.0 in stage 32.0 (TID 250) (10.0.0.43, executor driver, partition 110, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 100.0 in stage 32.0 (TID 240) in 713 ms on 10.0.0.43 (executor driver) (101/200)
25/02/04 17:13:19 INFO Executor: Running task 110.0 in stage 32.0 (TID 250)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 103.0 in stage 32.0 (TID 243) in 583 ms on 10.0.0.43 (executor driver) (102/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:19 INFO TaskSetManager: Starting task 111.0 in stage 32.0 (TID 251) (10.0.0.43, executor driver, partition 111, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO Executor: Running task 111.0 in stage 32.0 (TID 251)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_104 stored as values in memory (estimated size 1184.6 KiB, free 148.6 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_104 in memory on 10.0.0.43:62420 (size: 1184.6 KiB, free: 246.1 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 104.0 in stage 32.0 (TID 244)
[rdd_72_104]
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_102 stored as values in memory (estimated size 1372.4 KiB, free 171.2 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_102 in memory on 10.0.0.43:62420 (size: 1372.4 KiB, free: 244.8 MiB)
25/02/04 17:13:19 INFO Executor: Finished task 104.0 in stage 32.0 (TID 244). 17052 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 112.0 in stage 32.0 (TID 252) (10.0.0.43, executor driver, partition 112, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 104.0 in stage 32.0 (TID 244) in 675 ms on 10.0.0.43 (executor driver) (103/200)
25/02/04 17:13:19 INFO Executor: Running task 112.0 in stage 32.0 (TID 252)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 102.0 in stage 32.0 (TID 242)
[rdd_72_102]
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_105 stored as values in memory (estimated size 1205.0 KiB, free 170.1 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_105 in memory on 10.0.0.43:62420 (size: 1205.0 KiB, free: 243.6 MiB)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 105.0 in stage 32.0 (TID 245)
[rdd_72_105]
25/02/04 17:13:19 INFO Executor: Finished task 102.0 in stage 32.0 (TID 242). 17052 bytes result sent to driver
25/02/04 17:13:19 INFO Executor: Finished task 105.0 in stage 32.0 (TID 245). 17052 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 113.0 in stage 32.0 (TID 253) (10.0.0.43, executor driver, partition 113, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Starting task 114.0 in stage 32.0 (TID 254) (10.0.0.43, executor driver, partition 114, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 102.0 in stage 32.0 (TID 242) in 797 ms on 10.0.0.43 (executor driver) (104/200)
25/02/04 17:13:19 INFO Executor: Running task 113.0 in stage 32.0 (TID 253)
25/02/04 17:13:19 INFO Executor: Running task 114.0 in stage 32.0 (TID 254)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 105.0 in stage 32.0 (TID 245) in 687 ms on 10.0.0.43 (executor driver) (105/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_98 stored as values in memory (estimated size 1466.2 KiB, free 59.2 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_98 in memory on 10.0.0.43:62420 (size: 1466.2 KiB, free: 242.2 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 98.0 in stage 32.0 (TID 238)
[rdd_72_98]
25/02/04 17:13:19 INFO Executor: Finished task 98.0 in stage 32.0 (TID 238). 17095 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Finished task 98.0 in stage 32.0 (TID 238) in 1214 ms on 10.0.0.43 (executor driver) (106/200)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 115.0 in stage 32.0 (TID 255) (10.0.0.43, executor driver, partition 115, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_107 stored as values in memory (estimated size 1226.5 KiB, free 97.4 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_107 in memory on 10.0.0.43:62420 (size: 1226.5 KiB, free: 241.0 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 107.0 in stage 32.0 (TID 247)
[rdd_72_107]
25/02/04 17:13:19 INFO Executor: Finished task 107.0 in stage 32.0 (TID 247). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO Executor: Running task 115.0 in stage 32.0 (TID 255)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 116.0 in stage 32.0 (TID 256) (10.0.0.43, executor driver, partition 116, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_108 stored as values in memory (estimated size 1017.1 KiB, free 138.6 MiB)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_106 stored as values in memory (estimated size 1425.5 KiB, free 136.2 MiB)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_109 stored as values in memory (estimated size 1040.2 KiB, free 137.5 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_108 in memory on 10.0.0.43:62420 (size: 1017.1 KiB, free: 240.0 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 108.0 in stage 32.0 (TID 248)
[rdd_72_108]
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_106 in memory on 10.0.0.43:62420 (size: 1425.5 KiB, free: 238.6 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_109 in memory on 10.0.0.43:62420 (size: 1040.2 KiB, free: 237.6 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 106.0 in stage 32.0 (TID 246)
[rdd_72_106]
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 109.0 in stage 32.0 (TID 249)
[rdd_72_109]
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (2.9 MiB) non-empty blocks including 17 (2.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO Executor: Finished task 109.0 in stage 32.0 (TID 249). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO Executor: Finished task 106.0 in stage 32.0 (TID 246). 17095 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Finished task 107.0 in stage 32.0 (TID 247) in 693 ms on 10.0.0.43 (executor driver) (107/200)
25/02/04 17:13:19 INFO Executor: Finished task 108.0 in stage 32.0 (TID 248). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 117.0 in stage 32.0 (TID 257) (10.0.0.43, executor driver, partition 117, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 109.0 in stage 32.0 (TID 249) in 526 ms on 10.0.0.43 (executor driver) (108/200)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 118.0 in stage 32.0 (TID 258) (10.0.0.43, executor driver, partition 118, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO Executor: Running task 116.0 in stage 32.0 (TID 256)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 106.0 in stage 32.0 (TID 246) in 803 ms on 10.0.0.43 (executor driver) (109/200)
25/02/04 17:13:19 INFO Executor: Running task 118.0 in stage 32.0 (TID 258)
25/02/04 17:13:19 INFO Executor: Running task 117.0 in stage 32.0 (TID 257)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 119.0 in stage 32.0 (TID 259) (10.0.0.43, executor driver, partition 119, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 108.0 in stage 32.0 (TID 248) in 535 ms on 10.0.0.43 (executor driver) (110/200)
25/02/04 17:13:19 INFO Executor: Running task 119.0 in stage 32.0 (TID 259)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (4.1 MiB) non-empty blocks including 17 (4.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (4.7 MiB) non-empty blocks including 17 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_110 stored as values in memory (estimated size 975.1 KiB, free 64.1 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_110 in memory on 10.0.0.43:62420 (size: 975.1 KiB, free: 236.6 MiB)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_111 stored as values in memory (estimated size 1035.3 KiB, free 63.1 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_111 in memory on 10.0.0.43:62420 (size: 1035.3 KiB, free: 235.6 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 110.0 in stage 32.0 (TID 250)
[rdd_72_110]
25/02/04 17:13:19 INFO Executor: Finished task 110.0 in stage 32.0 (TID 250). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 111.0 in stage 32.0 (TID 251)
[rdd_72_111]
25/02/04 17:13:19 INFO Executor: Finished task 111.0 in stage 32.0 (TID 251). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 120.0 in stage 32.0 (TID 260) (10.0.0.43, executor driver, partition 120, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 110.0 in stage 32.0 (TID 250) in 595 ms on 10.0.0.43 (executor driver) (111/200)
25/02/04 17:13:19 INFO Executor: Running task 120.0 in stage 32.0 (TID 260)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 111.0 in stage 32.0 (TID 251) in 582 ms on 10.0.0.43 (executor driver) (112/200)
25/02/04 17:13:19 INFO TaskSetManager: Starting task 121.0 in stage 32.0 (TID 261) (10.0.0.43, executor driver, partition 121, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO Executor: Running task 121.0 in stage 32.0 (TID 261)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_113 stored as values in memory (estimated size 1203.2 KiB, free 161.8 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_113 in memory on 10.0.0.43:62420 (size: 1203.2 KiB, free: 234.4 MiB)
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 113.0 in stage 32.0 (TID 253)
[rdd_72_113]
25/02/04 17:13:19 INFO Executor: Finished task 113.0 in stage 32.0 (TID 253). 17009 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 122.0 in stage 32.0 (TID 262) (10.0.0.43, executor driver, partition 122, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO Executor: Running task 122.0 in stage 32.0 (TID 262)
25/02/04 17:13:19 INFO TaskSetManager: Finished task 113.0 in stage 32.0 (TID 253) in 539 ms on 10.0.0.43 (executor driver) (113/200)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_112 stored as values in memory (estimated size 1125.1 KiB, free 156.7 MiB)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_112 in memory on 10.0.0.43:62420 (size: 1125.1 KiB, free: 233.3 MiB)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO Executor: 1 block locks were not released by task 112.0 in stage 32.0 (TID 252)
[rdd_72_112]
25/02/04 17:13:19 INFO Executor: Finished task 112.0 in stage 32.0 (TID 252). 17095 bytes result sent to driver
25/02/04 17:13:19 INFO TaskSetManager: Starting task 123.0 in stage 32.0 (TID 263) (10.0.0.43, executor driver, partition 123, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:19 INFO TaskSetManager: Finished task 112.0 in stage 32.0 (TID 252) in 611 ms on 10.0.0.43 (executor driver) (114/200)
25/02/04 17:13:19 INFO Executor: Running task 123.0 in stage 32.0 (TID 263)
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:19 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:19 INFO MemoryStore: Block rdd_72_114 stored as values in memory (estimated size 1391.4 KiB, free 115.1 MiB)
25/02/04 17:13:19 INFO BlockManagerInfo: Added rdd_72_114 in memory on 10.0.0.43:62420 (size: 1391.4 KiB, free: 232.0 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 114.0 in stage 32.0 (TID 254)
[rdd_72_114]
25/02/04 17:13:20 INFO Executor: Finished task 114.0 in stage 32.0 (TID 254). 17009 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 124.0 in stage 32.0 (TID 264) (10.0.0.43, executor driver, partition 124, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 124.0 in stage 32.0 (TID 264)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 114.0 in stage 32.0 (TID 254) in 649 ms on 10.0.0.43 (executor driver) (115/200)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_115 stored as values in memory (estimated size 879.4 KiB, free 87.4 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_115 in memory on 10.0.0.43:62420 (size: 879.4 KiB, free: 231.1 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 115.0 in stage 32.0 (TID 255)
[rdd_72_115]
25/02/04 17:13:20 INFO Executor: Finished task 115.0 in stage 32.0 (TID 255). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 125.0 in stage 32.0 (TID 265) (10.0.0.43, executor driver, partition 125, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 115.0 in stage 32.0 (TID 255) in 670 ms on 10.0.0.43 (executor driver) (116/200)
25/02/04 17:13:20 INFO Executor: Running task 125.0 in stage 32.0 (TID 265)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_119 stored as values in memory (estimated size 1062.9 KiB, free 113.4 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_119 in memory on 10.0.0.43:62420 (size: 1062.9 KiB, free: 230.1 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 119.0 in stage 32.0 (TID 259)
[rdd_72_119]
25/02/04 17:13:20 INFO Executor: Finished task 119.0 in stage 32.0 (TID 259). 17138 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 126.0 in stage 32.0 (TID 266) (10.0.0.43, executor driver, partition 126, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 119.0 in stage 32.0 (TID 259) in 647 ms on 10.0.0.43 (executor driver) (117/200)
25/02/04 17:13:20 INFO Executor: Running task 126.0 in stage 32.0 (TID 266)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.3 MiB) non-empty blocks including 17 (3.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_118 stored as values in memory (estimated size 1312.1 KiB, free 128.2 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_118 in memory on 10.0.0.43:62420 (size: 1312.1 KiB, free: 228.8 MiB)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_116 stored as values in memory (estimated size 1543.8 KiB, free 135.7 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 118.0 in stage 32.0 (TID 258)
[rdd_72_118]
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_116 in memory on 10.0.0.43:62420 (size: 1543.8 KiB, free: 227.3 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 116.0 in stage 32.0 (TID 256)
[rdd_72_116]
25/02/04 17:13:20 INFO Executor: Finished task 116.0 in stage 32.0 (TID 256). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 127.0 in stage 32.0 (TID 267) (10.0.0.43, executor driver, partition 127, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 116.0 in stage 32.0 (TID 256) in 760 ms on 10.0.0.43 (executor driver) (118/200)
25/02/04 17:13:20 INFO Executor: Running task 127.0 in stage 32.0 (TID 267)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (5.1 MiB) non-empty blocks including 17 (5.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_121 stored as values in memory (estimated size 1182.1 KiB, free 126.5 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_121 in memory on 10.0.0.43:62420 (size: 1182.1 KiB, free: 226.1 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 121.0 in stage 32.0 (TID 261)
[rdd_72_121]
25/02/04 17:13:20 INFO Executor: Finished task 118.0 in stage 32.0 (TID 258). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_117 stored as values in memory (estimated size 1560.3 KiB, free 133.1 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_117 in memory on 10.0.0.43:62420 (size: 1560.3 KiB, free: 224.6 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 117.0 in stage 32.0 (TID 257)
[rdd_72_117]
25/02/04 17:13:20 INFO TaskSetManager: Starting task 128.0 in stage 32.0 (TID 268) (10.0.0.43, executor driver, partition 128, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 128.0 in stage 32.0 (TID 268)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 118.0 in stage 32.0 (TID 258) in 895 ms on 10.0.0.43 (executor driver) (119/200)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_120 stored as values in memory (estimated size 1129.3 KiB, free 128.0 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_120 in memory on 10.0.0.43:62420 (size: 1129.3 KiB, free: 223.5 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 120.0 in stage 32.0 (TID 260)
[rdd_72_120]
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:20 INFO Executor: Finished task 120.0 in stage 32.0 (TID 260). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO Executor: Finished task 117.0 in stage 32.0 (TID 257). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO Executor: Finished task 121.0 in stage 32.0 (TID 261). 17009 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 129.0 in stage 32.0 (TID 269) (10.0.0.43, executor driver, partition 129, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 129.0 in stage 32.0 (TID 269)
25/02/04 17:13:20 INFO TaskSetManager: Starting task 130.0 in stage 32.0 (TID 270) (10.0.0.43, executor driver, partition 130, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Starting task 131.0 in stage 32.0 (TID 271) (10.0.0.43, executor driver, partition 131, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 130.0 in stage 32.0 (TID 270)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO TaskSetManager: Finished task 121.0 in stage 32.0 (TID 261) in 802 ms on 10.0.0.43 (executor driver) (120/200)
25/02/04 17:13:20 INFO Executor: Running task 131.0 in stage 32.0 (TID 271)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 120.0 in stage 32.0 (TID 260) in 820 ms on 10.0.0.43 (executor driver) (121/200)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 117.0 in stage 32.0 (TID 257) in 1015 ms on 10.0.0.43 (executor driver) (122/200)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (4.3 MiB) non-empty blocks including 17 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_123 stored as values in memory (estimated size 1264.0 KiB, free 104.5 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_123 in memory on 10.0.0.43:62420 (size: 1264.0 KiB, free: 222.3 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 123.0 in stage 32.0 (TID 263)
[rdd_72_123]
25/02/04 17:13:20 INFO Executor: Finished task 123.0 in stage 32.0 (TID 263). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 132.0 in stage 32.0 (TID 272) (10.0.0.43, executor driver, partition 132, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 123.0 in stage 32.0 (TID 263) in 752 ms on 10.0.0.43 (executor driver) (123/200)
25/02/04 17:13:20 INFO Executor: Running task 132.0 in stage 32.0 (TID 272)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_122 stored as values in memory (estimated size 1375.8 KiB, free 62.6 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_122 in memory on 10.0.0.43:62420 (size: 1375.8 KiB, free: 220.9 MiB)
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 122.0 in stage 32.0 (TID 262)
[rdd_72_122]
25/02/04 17:13:20 INFO Executor: Finished task 122.0 in stage 32.0 (TID 262). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 133.0 in stage 32.0 (TID 273) (10.0.0.43, executor driver, partition 133, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 133.0 in stage 32.0 (TID 273)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 122.0 in stage 32.0 (TID 262) in 813 ms on 10.0.0.43 (executor driver) (124/200)
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_124 stored as values in memory (estimated size 1178.8 KiB, free 43.2 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_124 in memory on 10.0.0.43:62420 (size: 1178.8 KiB, free: 219.8 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 124.0 in stage 32.0 (TID 264)
[rdd_72_124]
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.0 MiB) non-empty blocks including 17 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO Executor: Finished task 124.0 in stage 32.0 (TID 264). 17095 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 134.0 in stage 32.0 (TID 274) (10.0.0.43, executor driver, partition 134, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO Executor: Running task 134.0 in stage 32.0 (TID 274)
25/02/04 17:13:20 INFO TaskSetManager: Finished task 124.0 in stage 32.0 (TID 264) in 721 ms on 10.0.0.43 (executor driver) (125/200)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 8.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO ExecutionMemoryPool: TID 273 waiting for at least 1/2N of on-heap execution pool to be free
25/02/04 17:13:20 INFO ExecutionMemoryPool: TID 273 waiting for at least 1/2N of on-heap execution pool to be free
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_125 stored as values in memory (estimated size 1204.4 KiB, free 69.0 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_125 in memory on 10.0.0.43:62420 (size: 1204.4 KiB, free: 218.6 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 125.0 in stage 32.0 (TID 265)
[rdd_72_125]
25/02/04 17:13:20 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:20 INFO Executor: Finished task 125.0 in stage 32.0 (TID 265). 17052 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 135.0 in stage 32.0 (TID 275) (10.0.0.43, executor driver, partition 135, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 125.0 in stage 32.0 (TID 265) in 760 ms on 10.0.0.43 (executor driver) (126/200)
25/02/04 17:13:20 INFO Executor: Running task 135.0 in stage 32.0 (TID 275)
25/02/04 17:13:20 INFO MemoryStore: Block rdd_72_126 stored as values in memory (estimated size 1073.8 KiB, free 126.8 MiB)
25/02/04 17:13:20 INFO BlockManagerInfo: Added rdd_72_126 in memory on 10.0.0.43:62420 (size: 1073.8 KiB, free: 217.6 MiB)
25/02/04 17:13:20 INFO Executor: 1 block locks were not released by task 126.0 in stage 32.0 (TID 266)
[rdd_72_126]
25/02/04 17:13:20 INFO Executor: Finished task 126.0 in stage 32.0 (TID 266). 17009 bytes result sent to driver
25/02/04 17:13:20 INFO TaskSetManager: Starting task 136.0 in stage 32.0 (TID 276) (10.0.0.43, executor driver, partition 136, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:20 INFO TaskSetManager: Finished task 126.0 in stage 32.0 (TID 266) in 687 ms on 10.0.0.43 (executor driver) (127/200)
25/02/04 17:13:20 INFO Executor: Running task 136.0 in stage 32.0 (TID 276)
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Getting 17 (3.3 MiB) non-empty blocks including 17 (3.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_133 stored as values in memory (estimated size 919.7 KiB, free 134.1 MiB)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_130 stored as values in memory (estimated size 1167.7 KiB, free 138.9 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_130 in memory on 10.0.0.43:62420 (size: 1167.7 KiB, free: 216.4 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_133 in memory on 10.0.0.43:62420 (size: 919.7 KiB, free: 215.5 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 133.0 in stage 32.0 (TID 273)
[rdd_72_133]
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_128 stored as values in memory (estimated size 1177.6 KiB, free 141.8 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_128 in memory on 10.0.0.43:62420 (size: 1177.6 KiB, free: 214.4 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 128.0 in stage 32.0 (TID 268)
[rdd_72_128]
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 130.0 in stage 32.0 (TID 270)
[rdd_72_130]
25/02/04 17:13:21 INFO Executor: Finished task 128.0 in stage 32.0 (TID 268). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: Finished task 130.0 in stage 32.0 (TID 270). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: Finished task 133.0 in stage 32.0 (TID 273). 17138 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 137.0 in stage 32.0 (TID 277) (10.0.0.43, executor driver, partition 137, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Finished task 128.0 in stage 32.0 (TID 268) in 795 ms on 10.0.0.43 (executor driver) (128/200)
25/02/04 17:13:21 INFO Executor: Running task 137.0 in stage 32.0 (TID 277)
25/02/04 17:13:21 INFO TaskSetManager: Starting task 138.0 in stage 32.0 (TID 278) (10.0.0.43, executor driver, partition 138, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 138.0 in stage 32.0 (TID 278)
25/02/04 17:13:21 INFO TaskSetManager: Starting task 139.0 in stage 32.0 (TID 279) (10.0.0.43, executor driver, partition 139, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 139.0 in stage 32.0 (TID 279)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 130.0 in stage 32.0 (TID 270) in 701 ms on 10.0.0.43 (executor driver) (129/200)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_134 stored as values in memory (estimated size 1147.5 KiB, free 158.8 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_134 in memory on 10.0.0.43:62420 (size: 1147.5 KiB, free: 213.3 MiB)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_132 stored as values in memory (estimated size 1234.5 KiB, free 165.6 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_132 in memory on 10.0.0.43:62420 (size: 1234.5 KiB, free: 212.1 MiB)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 133.0 in stage 32.0 (TID 273) in 623 ms on 10.0.0.43 (executor driver) (130/200)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_131 stored as values in memory (estimated size 1353.8 KiB, free 174.4 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_131 in memory on 10.0.0.43:62420 (size: 1353.8 KiB, free: 210.7 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 131.0 in stage 32.0 (TID 271)
[rdd_72_131]
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_127 stored as values in memory (estimated size 1660.8 KiB, free 174.8 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_127 in memory on 10.0.0.43:62420 (size: 1660.8 KiB, free: 209.1 MiB)
25/02/04 17:13:21 INFO Executor: Finished task 131.0 in stage 32.0 (TID 271). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 140.0 in stage 32.0 (TID 280) (10.0.0.43, executor driver, partition 140, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Finished task 131.0 in stage 32.0 (TID 271) in 725 ms on 10.0.0.43 (executor driver) (131/200)
25/02/04 17:13:21 INFO Executor: Running task 140.0 in stage 32.0 (TID 280)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 134.0 in stage 32.0 (TID 274)
[rdd_72_134]
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 127.0 in stage 32.0 (TID 267)
[rdd_72_127]
25/02/04 17:13:21 INFO Executor: Finished task 127.0 in stage 32.0 (TID 267). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: Finished task 134.0 in stage 32.0 (TID 274). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 141.0 in stage 32.0 (TID 281) (10.0.0.43, executor driver, partition 141, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Starting task 142.0 in stage 32.0 (TID 282) (10.0.0.43, executor driver, partition 142, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 142.0 in stage 32.0 (TID 282)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 127.0 in stage 32.0 (TID 267) in 1008 ms on 10.0.0.43 (executor driver) (132/200)
25/02/04 17:13:21 INFO Executor: Running task 141.0 in stage 32.0 (TID 281)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 134.0 in stage 32.0 (TID 274) in 630 ms on 10.0.0.43 (executor driver) (133/200)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.3 MiB) non-empty blocks including 17 (3.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_129 stored as values in memory (estimated size 1408.3 KiB, free 187.5 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_129 in memory on 10.0.0.43:62420 (size: 1408.3 KiB, free: 207.7 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 132.0 in stage 32.0 (TID 272)
[rdd_72_132]
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 129.0 in stage 32.0 (TID 269)
[rdd_72_129]
25/02/04 17:13:21 INFO Executor: Finished task 129.0 in stage 32.0 (TID 269). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: Finished task 132.0 in stage 32.0 (TID 272). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 143.0 in stage 32.0 (TID 283) (10.0.0.43, executor driver, partition 143, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 143.0 in stage 32.0 (TID 283)
25/02/04 17:13:21 INFO TaskSetManager: Starting task 144.0 in stage 32.0 (TID 284) (10.0.0.43, executor driver, partition 144, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 144.0 in stage 32.0 (TID 284)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 132.0 in stage 32.0 (TID 272) in 689 ms on 10.0.0.43 (executor driver) (134/200)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 129.0 in stage 32.0 (TID 269) in 750 ms on 10.0.0.43 (executor driver) (135/200)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_135 stored as values in memory (estimated size 1025.8 KiB, free 34.3 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_135 in memory on 10.0.0.43:62420 (size: 1025.8 KiB, free: 206.7 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 135.0 in stage 32.0 (TID 275)
[rdd_72_135]
25/02/04 17:13:21 INFO Executor: Finished task 135.0 in stage 32.0 (TID 275). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 145.0 in stage 32.0 (TID 285) (10.0.0.43, executor driver, partition 145, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 145.0 in stage 32.0 (TID 285)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 135.0 in stage 32.0 (TID 275) in 627 ms on 10.0.0.43 (executor driver) (136/200)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_136 stored as values in memory (estimated size 1429.3 KiB, free 124.2 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_136 in memory on 10.0.0.43:62420 (size: 1429.3 KiB, free: 205.3 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 136.0 in stage 32.0 (TID 276)
[rdd_72_136]
25/02/04 17:13:21 INFO Executor: Finished task 136.0 in stage 32.0 (TID 276). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 146.0 in stage 32.0 (TID 286) (10.0.0.43, executor driver, partition 146, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Finished task 136.0 in stage 32.0 (TID 276) in 822 ms on 10.0.0.43 (executor driver) (137/200)
25/02/04 17:13:21 INFO Executor: Running task 146.0 in stage 32.0 (TID 286)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_137 stored as values in memory (estimated size 1027.9 KiB, free 116.3 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_137 in memory on 10.0.0.43:62420 (size: 1027.9 KiB, free: 204.3 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 137.0 in stage 32.0 (TID 277)
[rdd_72_137]
25/02/04 17:13:21 INFO Executor: Finished task 137.0 in stage 32.0 (TID 277). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Finished task 137.0 in stage 32.0 (TID 277) in 583 ms on 10.0.0.43 (executor driver) (138/200)
25/02/04 17:13:21 INFO TaskSetManager: Starting task 147.0 in stage 32.0 (TID 287) (10.0.0.43, executor driver, partition 147, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 147.0 in stage 32.0 (TID 287)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_144 stored as values in memory (estimated size 1027.6 KiB, free 137.3 MiB)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_138 stored as values in memory (estimated size 1174.8 KiB, free 136.1 MiB)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_142 stored as values in memory (estimated size 1171.1 KiB, free 138.3 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_144 in memory on 10.0.0.43:62420 (size: 1027.6 KiB, free: 203.3 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_138 in memory on 10.0.0.43:62420 (size: 1174.8 KiB, free: 202.2 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 138.0 in stage 32.0 (TID 278)
[rdd_72_138]
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_142 in memory on 10.0.0.43:62420 (size: 1171.1 KiB, free: 201.0 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 144.0 in stage 32.0 (TID 284)
[rdd_72_144]
25/02/04 17:13:21 INFO Executor: Finished task 138.0 in stage 32.0 (TID 278). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: Finished task 144.0 in stage 32.0 (TID 284). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 142.0 in stage 32.0 (TID 282)
[rdd_72_142]
25/02/04 17:13:21 INFO Executor: Finished task 142.0 in stage 32.0 (TID 282). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 148.0 in stage 32.0 (TID 288) (10.0.0.43, executor driver, partition 148, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Starting task 149.0 in stage 32.0 (TID 289) (10.0.0.43, executor driver, partition 149, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 148.0 in stage 32.0 (TID 288)
25/02/04 17:13:21 INFO Executor: Running task 149.0 in stage 32.0 (TID 289)
25/02/04 17:13:21 INFO TaskSetManager: Starting task 150.0 in stage 32.0 (TID 290) (10.0.0.43, executor driver, partition 150, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Finished task 138.0 in stage 32.0 (TID 278) in 635 ms on 10.0.0.43 (executor driver) (139/200)
25/02/04 17:13:21 INFO Executor: Running task 150.0 in stage 32.0 (TID 290)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 144.0 in stage 32.0 (TID 284) in 567 ms on 10.0.0.43 (executor driver) (140/200)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 142.0 in stage 32.0 (TID 282) in 581 ms on 10.0.0.43 (executor driver) (141/200)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_140 stored as values in memory (estimated size 1202.8 KiB, free 135.0 MiB)
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_140 in memory on 10.0.0.43:62420 (size: 1202.8 KiB, free: 199.9 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 140.0 in stage 32.0 (TID 280)
[rdd_72_140]
25/02/04 17:13:21 INFO Executor: Finished task 140.0 in stage 32.0 (TID 280). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 151.0 in stage 32.0 (TID 291) (10.0.0.43, executor driver, partition 151, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO Executor: Running task 151.0 in stage 32.0 (TID 291)
25/02/04 17:13:21 INFO TaskSetManager: Finished task 140.0 in stage 32.0 (TID 280) in 598 ms on 10.0.0.43 (executor driver) (142/200)
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_143 stored as values in memory (estimated size 1200.3 KiB, free 139.9 MiB)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_143 in memory on 10.0.0.43:62420 (size: 1200.3 KiB, free: 198.7 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 143.0 in stage 32.0 (TID 283)
[rdd_72_143]
25/02/04 17:13:21 INFO Executor: Finished task 143.0 in stage 32.0 (TID 283). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO TaskSetManager: Starting task 152.0 in stage 32.0 (TID 292) (10.0.0.43, executor driver, partition 152, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO TaskSetManager: Finished task 143.0 in stage 32.0 (TID 283) in 586 ms on 10.0.0.43 (executor driver) (143/200)
25/02/04 17:13:21 INFO Executor: Running task 152.0 in stage 32.0 (TID 292)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO MemoryStore: Block rdd_72_139 stored as values in memory (estimated size 1149.9 KiB, free 142.7 MiB)
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:21 INFO BlockManagerInfo: Added rdd_72_139 in memory on 10.0.0.43:62420 (size: 1149.9 KiB, free: 197.6 MiB)
25/02/04 17:13:21 INFO Executor: 1 block locks were not released by task 139.0 in stage 32.0 (TID 279)
[rdd_72_139]
25/02/04 17:13:21 INFO Executor: Finished task 139.0 in stage 32.0 (TID 279). 17095 bytes result sent to driver
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO TaskSetManager: Starting task 153.0 in stage 32.0 (TID 293) (10.0.0.43, executor driver, partition 153, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:21 INFO TaskSetManager: Finished task 139.0 in stage 32.0 (TID 279) in 666 ms on 10.0.0.43 (executor driver) (144/200)
25/02/04 17:13:21 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO Executor: Running task 153.0 in stage 32.0 (TID 293)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_141 stored as values in memory (estimated size 1268.3 KiB, free 76.3 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_141 in memory on 10.0.0.43:62420 (size: 1268.3 KiB, free: 196.3 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 141.0 in stage 32.0 (TID 281)
[rdd_72_141]
25/02/04 17:13:22 INFO Executor: Finished task 141.0 in stage 32.0 (TID 281). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 154.0 in stage 32.0 (TID 294) (10.0.0.43, executor driver, partition 154, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 141.0 in stage 32.0 (TID 281) in 675 ms on 10.0.0.43 (executor driver) (145/200)
25/02/04 17:13:22 INFO Executor: Running task 154.0 in stage 32.0 (TID 294)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_145 stored as values in memory (estimated size 1331.0 KiB, free 98.0 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_145 in memory on 10.0.0.43:62420 (size: 1331.0 KiB, free: 195.0 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 145.0 in stage 32.0 (TID 285)
[rdd_72_145]
25/02/04 17:13:22 INFO Executor: Finished task 145.0 in stage 32.0 (TID 285). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 155.0 in stage 32.0 (TID 295) (10.0.0.43, executor driver, partition 155, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 145.0 in stage 32.0 (TID 285) in 817 ms on 10.0.0.43 (executor driver) (146/200)
25/02/04 17:13:22 INFO Executor: Running task 155.0 in stage 32.0 (TID 295)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_146 stored as values in memory (estimated size 1225.4 KiB, free 103.8 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_146 in memory on 10.0.0.43:62420 (size: 1225.4 KiB, free: 193.8 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 146.0 in stage 32.0 (TID 286)
[rdd_72_146]
25/02/04 17:13:22 INFO Executor: Finished task 146.0 in stage 32.0 (TID 286). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 156.0 in stage 32.0 (TID 296) (10.0.0.43, executor driver, partition 156, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 146.0 in stage 32.0 (TID 286) in 618 ms on 10.0.0.43 (executor driver) (147/200)
25/02/04 17:13:22 INFO Executor: Running task 156.0 in stage 32.0 (TID 296)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_147 stored as values in memory (estimated size 1105.9 KiB, free 122.5 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_147 in memory on 10.0.0.43:62420 (size: 1105.9 KiB, free: 192.8 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 147.0 in stage 32.0 (TID 287)
[rdd_72_147]
25/02/04 17:13:22 INFO Executor: Finished task 147.0 in stage 32.0 (TID 287). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 157.0 in stage 32.0 (TID 297) (10.0.0.43, executor driver, partition 157, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 147.0 in stage 32.0 (TID 287) in 622 ms on 10.0.0.43 (executor driver) (148/200)
25/02/04 17:13:22 INFO Executor: Running task 157.0 in stage 32.0 (TID 297)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_149 stored as values in memory (estimated size 1166.6 KiB, free 107.4 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_149 in memory on 10.0.0.43:62420 (size: 1166.6 KiB, free: 191.6 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 149.0 in stage 32.0 (TID 289)
[rdd_72_149]
25/02/04 17:13:22 INFO Executor: Finished task 149.0 in stage 32.0 (TID 289). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 158.0 in stage 32.0 (TID 298) (10.0.0.43, executor driver, partition 158, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 149.0 in stage 32.0 (TID 289) in 718 ms on 10.0.0.43 (executor driver) (149/200)
25/02/04 17:13:22 INFO Executor: Running task 158.0 in stage 32.0 (TID 298)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_148 stored as values in memory (estimated size 1260.4 KiB, free 114.3 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_148 in memory on 10.0.0.43:62420 (size: 1260.4 KiB, free: 190.4 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 148.0 in stage 32.0 (TID 288)
[rdd_72_148]
25/02/04 17:13:22 INFO Executor: Finished task 148.0 in stage 32.0 (TID 288). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 159.0 in stage 32.0 (TID 299) (10.0.0.43, executor driver, partition 159, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO Executor: Running task 159.0 in stage 32.0 (TID 299)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_151 stored as values in memory (estimated size 1217.8 KiB, free 117.2 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_151 in memory on 10.0.0.43:62420 (size: 1217.8 KiB, free: 189.2 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 151.0 in stage 32.0 (TID 291)
[rdd_72_151]
25/02/04 17:13:22 INFO Executor: Finished task 151.0 in stage 32.0 (TID 291). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO TaskSetManager: Starting task 160.0 in stage 32.0 (TID 300) (10.0.0.43, executor driver, partition 160, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO TaskSetManager: Finished task 148.0 in stage 32.0 (TID 288) in 740 ms on 10.0.0.43 (executor driver) (150/200)
25/02/04 17:13:22 INFO Executor: Running task 160.0 in stage 32.0 (TID 300)
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_150 stored as values in memory (estimated size 1152.4 KiB, free 116.1 MiB)
25/02/04 17:13:22 INFO TaskSetManager: Finished task 151.0 in stage 32.0 (TID 291) in 728 ms on 10.0.0.43 (executor driver) (151/200)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_150 in memory on 10.0.0.43:62420 (size: 1152.4 KiB, free: 188.1 MiB)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 150.0 in stage 32.0 (TID 290)
[rdd_72_150]
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
25/02/04 17:13:22 INFO Executor: Finished task 150.0 in stage 32.0 (TID 290). 17138 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 161.0 in stage 32.0 (TID 301) (10.0.0.43, executor driver, partition 161, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 150.0 in stage 32.0 (TID 290) in 785 ms on 10.0.0.43 (executor driver) (152/200)
25/02/04 17:13:22 INFO Executor: Running task 161.0 in stage 32.0 (TID 301)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_153 stored as values in memory (estimated size 994.4 KiB, free 86.7 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_153 in memory on 10.0.0.43:62420 (size: 994.4 KiB, free: 187.1 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 153.0 in stage 32.0 (TID 293)
[rdd_72_153]
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO Executor: Finished task 153.0 in stage 32.0 (TID 293). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 162.0 in stage 32.0 (TID 302) (10.0.0.43, executor driver, partition 162, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO TaskSetManager: Finished task 153.0 in stage 32.0 (TID 293) in 812 ms on 10.0.0.43 (executor driver) (153/200)
25/02/04 17:13:22 INFO Executor: Running task 162.0 in stage 32.0 (TID 302)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO MemoryStore: Block rdd_72_154 stored as values in memory (estimated size 1069.8 KiB, free 74.5 MiB)
25/02/04 17:13:22 INFO BlockManagerInfo: Added rdd_72_154 in memory on 10.0.0.43:62420 (size: 1069.8 KiB, free: 186.1 MiB)
25/02/04 17:13:22 INFO Executor: 1 block locks were not released by task 154.0 in stage 32.0 (TID 294)
[rdd_72_154]
25/02/04 17:13:22 INFO Executor: Finished task 154.0 in stage 32.0 (TID 294). 17095 bytes result sent to driver
25/02/04 17:13:22 INFO TaskSetManager: Starting task 163.0 in stage 32.0 (TID 303) (10.0.0.43, executor driver, partition 163, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:22 INFO Executor: Running task 163.0 in stage 32.0 (TID 303)
25/02/04 17:13:22 INFO TaskSetManager: Finished task 154.0 in stage 32.0 (TID 294) in 776 ms on 10.0.0.43 (executor driver) (154/200)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 17 (4.1 MiB) non-empty blocks including 17 (4.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:22 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_152 stored as values in memory (estimated size 1410.1 KiB, free 86.6 MiB)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_155 stored as values in memory (estimated size 1139.9 KiB, free 105.4 MiB)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_156 stored as values in memory (estimated size 1061.6 KiB, free 111.0 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_152 in memory on 10.0.0.43:62420 (size: 1410.1 KiB, free: 184.7 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_155 in memory on 10.0.0.43:62420 (size: 1139.9 KiB, free: 183.6 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_156 in memory on 10.0.0.43:62420 (size: 1061.6 KiB, free: 182.5 MiB)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 152.0 in stage 32.0 (TID 292)
[rdd_72_152]
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 156.0 in stage 32.0 (TID 296)
[rdd_72_156]
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 155.0 in stage 32.0 (TID 295)
[rdd_72_155]
25/02/04 17:13:23 INFO Executor: Finished task 152.0 in stage 32.0 (TID 292). 17138 bytes result sent to driver
25/02/04 17:13:23 INFO Executor: Finished task 156.0 in stage 32.0 (TID 296). 17138 bytes result sent to driver
25/02/04 17:13:23 INFO Executor: Finished task 155.0 in stage 32.0 (TID 295). 17138 bytes result sent to driver
25/02/04 17:13:23 INFO TaskSetManager: Starting task 164.0 in stage 32.0 (TID 304) (10.0.0.43, executor driver, partition 164, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Starting task 165.0 in stage 32.0 (TID 305) (10.0.0.43, executor driver, partition 165, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Finished task 156.0 in stage 32.0 (TID 296) in 942 ms on 10.0.0.43 (executor driver) (155/200)
25/02/04 17:13:23 INFO TaskSetManager: Starting task 166.0 in stage 32.0 (TID 306) (10.0.0.43, executor driver, partition 166, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Finished task 152.0 in stage 32.0 (TID 292) in 1362 ms on 10.0.0.43 (executor driver) (156/200)
25/02/04 17:13:23 INFO TaskSetManager: Finished task 155.0 in stage 32.0 (TID 295) in 979 ms on 10.0.0.43 (executor driver) (157/200)
25/02/04 17:13:23 INFO Executor: Running task 166.0 in stage 32.0 (TID 306)
25/02/04 17:13:23 INFO Executor: Running task 165.0 in stage 32.0 (TID 305)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_157 stored as values in memory (estimated size 1199.3 KiB, free 113.9 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_157 in memory on 10.0.0.43:62420 (size: 1199.3 KiB, free: 181.4 MiB)
25/02/04 17:13:23 INFO Executor: Running task 164.0 in stage 32.0 (TID 304)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 157.0 in stage 32.0 (TID 297)
[rdd_72_157]
25/02/04 17:13:23 INFO Executor: Finished task 157.0 in stage 32.0 (TID 297). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (4.6 MiB) non-empty blocks including 17 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:13:23 INFO TaskSetManager: Starting task 167.0 in stage 32.0 (TID 307) (10.0.0.43, executor driver, partition 167, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Finished task 157.0 in stage 32.0 (TID 297) in 953 ms on 10.0.0.43 (executor driver) (158/200)
25/02/04 17:13:23 INFO Executor: Running task 167.0 in stage 32.0 (TID 307)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_160 stored as values in memory (estimated size 1206.5 KiB, free 120.7 MiB)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_158 stored as values in memory (estimated size 1398.2 KiB, free 133.4 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_160 in memory on 10.0.0.43:62420 (size: 1206.5 KiB, free: 180.2 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_158 in memory on 10.0.0.43:62420 (size: 1398.2 KiB, free: 178.8 MiB)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 160.0 in stage 32.0 (TID 300)
[rdd_72_160]
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 158.0 in stage 32.0 (TID 298)
[rdd_72_158]
25/02/04 17:13:23 INFO Executor: Finished task 160.0 in stage 32.0 (TID 300). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO Executor: Finished task 158.0 in stage 32.0 (TID 298). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO TaskSetManager: Starting task 168.0 in stage 32.0 (TID 308) (10.0.0.43, executor driver, partition 168, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO Executor: Running task 168.0 in stage 32.0 (TID 308)
25/02/04 17:13:23 INFO TaskSetManager: Starting task 169.0 in stage 32.0 (TID 309) (10.0.0.43, executor driver, partition 169, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO Executor: Running task 169.0 in stage 32.0 (TID 309)
25/02/04 17:13:23 INFO TaskSetManager: Finished task 158.0 in stage 32.0 (TID 298) in 851 ms on 10.0.0.43 (executor driver) (159/200)
25/02/04 17:13:23 INFO TaskSetManager: Finished task 160.0 in stage 32.0 (TID 300) in 827 ms on 10.0.0.43 (executor driver) (160/200)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_161 stored as values in memory (estimated size 1138.7 KiB, free 140.2 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_161 in memory on 10.0.0.43:62420 (size: 1138.7 KiB, free: 177.7 MiB)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 161.0 in stage 32.0 (TID 301)
[rdd_72_161]
25/02/04 17:13:23 INFO Executor: Finished task 161.0 in stage 32.0 (TID 301). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO TaskSetManager: Starting task 170.0 in stage 32.0 (TID 310) (10.0.0.43, executor driver, partition 170, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO Executor: Running task 170.0 in stage 32.0 (TID 310)
25/02/04 17:13:23 INFO TaskSetManager: Finished task 161.0 in stage 32.0 (TID 301) in 845 ms on 10.0.0.43 (executor driver) (161/200)
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_162 stored as values in memory (estimated size 1247.5 KiB, free 149.1 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_162 in memory on 10.0.0.43:62420 (size: 1247.5 KiB, free: 176.5 MiB)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 162.0 in stage 32.0 (TID 302)
[rdd_72_162]
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_159 stored as values in memory (estimated size 1537.9 KiB, free 161.6 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_159 in memory on 10.0.0.43:62420 (size: 1537.9 KiB, free: 175.0 MiB)
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 159.0 in stage 32.0 (TID 299)
[rdd_72_159]
25/02/04 17:13:23 INFO Executor: Finished task 162.0 in stage 32.0 (TID 302). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO Executor: Finished task 159.0 in stage 32.0 (TID 299). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO TaskSetManager: Starting task 171.0 in stage 32.0 (TID 311) (10.0.0.43, executor driver, partition 171, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO TaskSetManager: Finished task 162.0 in stage 32.0 (TID 302) in 820 ms on 10.0.0.43 (executor driver) (162/200)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 35 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 36 ms
25/02/04 17:13:23 INFO TaskSetManager: Starting task 172.0 in stage 32.0 (TID 312) (10.0.0.43, executor driver, partition 172, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Finished task 159.0 in stage 32.0 (TID 299) in 936 ms on 10.0.0.43 (executor driver) (163/200)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 35 ms
25/02/04 17:13:23 INFO Executor: Running task 171.0 in stage 32.0 (TID 311)
25/02/04 17:13:23 INFO Executor: Running task 172.0 in stage 32.0 (TID 312)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 37 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.0 MiB) non-empty blocks including 17 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:23 INFO MemoryStore: Block rdd_72_163 stored as values in memory (estimated size 1328.4 KiB, free 171.9 MiB)
25/02/04 17:13:23 INFO BlockManagerInfo: Added rdd_72_163 in memory on 10.0.0.43:62420 (size: 1328.4 KiB, free: 173.7 MiB)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:13:23 INFO Executor: 1 block locks were not released by task 163.0 in stage 32.0 (TID 303)
[rdd_72_163]
25/02/04 17:13:23 INFO Executor: Finished task 163.0 in stage 32.0 (TID 303). 17095 bytes result sent to driver
25/02/04 17:13:23 INFO TaskSetManager: Starting task 173.0 in stage 32.0 (TID 313) (10.0.0.43, executor driver, partition 173, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:23 INFO TaskSetManager: Finished task 163.0 in stage 32.0 (TID 303) in 976 ms on 10.0.0.43 (executor driver) (164/200)
25/02/04 17:13:23 INFO Executor: Running task 173.0 in stage 32.0 (TID 313)
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO MemoryStore: 4 blocks selected for dropping (453.2 KiB bytes)
25/02/04 17:13:23 INFO BlockManager: Dropping block broadcast_12_piece0 from memory
25/02/04 17:13:23 INFO BlockManager: Writing block broadcast_12_piece0 to disk
25/02/04 17:13:23 INFO BlockManagerInfo: Updated broadcast_12_piece0 on disk on 10.0.0.43:62420 (current size: 34.3 KiB, original size: 0.0 B)
25/02/04 17:13:23 INFO BlockManager: Dropping block broadcast_12 from memory
25/02/04 17:13:23 INFO BlockManager: Writing block broadcast_12 to disk
25/02/04 17:13:23 INFO BlockManager: Dropping block broadcast_14_piece0 from memory
25/02/04 17:13:23 INFO BlockManager: Writing block broadcast_14_piece0 to disk
25/02/04 17:13:23 INFO BlockManagerInfo: Updated broadcast_14_piece0 on disk on 10.0.0.43:62420 (current size: 34.3 KiB, original size: 0.0 B)
25/02/04 17:13:23 INFO BlockManager: Dropping block broadcast_16_piece0 from memory
25/02/04 17:13:23 INFO BlockManager: Writing block broadcast_16_piece0 to disk
25/02/04 17:13:23 INFO BlockManagerInfo: Updated broadcast_16_piece0 on disk on 10.0.0.43:62420 (current size: 34.3 KiB, original size: 0.0 B)
25/02/04 17:13:23 INFO MemoryStore: After dropping 4 blocks, free memory is 17.0 MiB
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:23 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_172 stored as values in memory (estimated size 936.9 KiB, free 83.3 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_172 in memory on 10.0.0.43:62420 (size: 936.9 KiB, free: 172.9 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 172.0 in stage 32.0 (TID 312)
[rdd_72_172]
25/02/04 17:13:24 INFO Executor: Finished task 172.0 in stage 32.0 (TID 312). 17138 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 174.0 in stage 32.0 (TID 314) (10.0.0.43, executor driver, partition 174, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO TaskSetManager: Finished task 172.0 in stage 32.0 (TID 312) in 709 ms on 10.0.0.43 (executor driver) (165/200)
25/02/04 17:13:24 INFO Executor: Running task 174.0 in stage 32.0 (TID 314)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_165 stored as values in memory (estimated size 1185.7 KiB, free 84.1 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_165 in memory on 10.0.0.43:62420 (size: 1185.7 KiB, free: 171.7 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 165.0 in stage 32.0 (TID 305)
[rdd_72_165]
25/02/04 17:13:24 INFO Executor: Finished task 165.0 in stage 32.0 (TID 305). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 175.0 in stage 32.0 (TID 315) (10.0.0.43, executor driver, partition 175, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO TaskSetManager: Finished task 165.0 in stage 32.0 (TID 305) in 1074 ms on 10.0.0.43 (executor driver) (166/200)
25/02/04 17:13:24 INFO Executor: Running task 175.0 in stage 32.0 (TID 315)
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_171 stored as values in memory (estimated size 1299.1 KiB, free 70.6 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_171 in memory on 10.0.0.43:62420 (size: 1299.1 KiB, free: 170.4 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 171.0 in stage 32.0 (TID 311)
[rdd_72_171]
25/02/04 17:13:24 INFO Executor: Finished task 171.0 in stage 32.0 (TID 311). 17138 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 176.0 in stage 32.0 (TID 316) (10.0.0.43, executor driver, partition 176, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO TaskSetManager: Finished task 171.0 in stage 32.0 (TID 311) in 847 ms on 10.0.0.43 (executor driver) (167/200)
25/02/04 17:13:24 INFO Executor: Running task 176.0 in stage 32.0 (TID 316)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_164 stored as values in memory (estimated size 1434.8 KiB, free 83.3 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_164 in memory on 10.0.0.43:62420 (size: 1434.8 KiB, free: 169.0 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 164.0 in stage 32.0 (TID 304)
[rdd_72_164]
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO Executor: Finished task 164.0 in stage 32.0 (TID 304). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 177.0 in stage 32.0 (TID 317) (10.0.0.43, executor driver, partition 177, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO Executor: Running task 177.0 in stage 32.0 (TID 317)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 164.0 in stage 32.0 (TID 304) in 1153 ms on 10.0.0.43 (executor driver) (168/200)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_166 stored as values in memory (estimated size 1547.2 KiB, free 67.6 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_166 in memory on 10.0.0.43:62420 (size: 1547.2 KiB, free: 167.5 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 166.0 in stage 32.0 (TID 306)
[rdd_72_166]
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_167 stored as values in memory (estimated size 1054.2 KiB, free 67.7 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_167 in memory on 10.0.0.43:62420 (size: 1054.2 KiB, free: 166.5 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 167.0 in stage 32.0 (TID 307)
[rdd_72_167]
25/02/04 17:13:24 INFO Executor: Finished task 166.0 in stage 32.0 (TID 306). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO Executor: Finished task 167.0 in stage 32.0 (TID 307). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO TaskSetManager: Starting task 178.0 in stage 32.0 (TID 318) (10.0.0.43, executor driver, partition 178, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO TaskSetManager: Starting task 179.0 in stage 32.0 (TID 319) (10.0.0.43, executor driver, partition 179, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO Executor: Running task 178.0 in stage 32.0 (TID 318)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 166.0 in stage 32.0 (TID 306) in 1294 ms on 10.0.0.43 (executor driver) (169/200)
25/02/04 17:13:24 INFO Executor: Running task 179.0 in stage 32.0 (TID 319)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 167.0 in stage 32.0 (TID 307) in 1228 ms on 10.0.0.43 (executor driver) (170/200)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_169 stored as values in memory (estimated size 1113.0 KiB, free 54.7 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_169 in memory on 10.0.0.43:62420 (size: 1113.0 KiB, free: 165.4 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 169.0 in stage 32.0 (TID 309)
[rdd_72_169]
25/02/04 17:13:24 INFO Executor: Finished task 169.0 in stage 32.0 (TID 309). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 180.0 in stage 32.0 (TID 320) (10.0.0.43, executor driver, partition 180, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO Executor: Running task 180.0 in stage 32.0 (TID 320)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 169.0 in stage 32.0 (TID 309) in 1219 ms on 10.0.0.43 (executor driver) (171/200)
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_170 stored as values in memory (estimated size 1245.6 KiB, free 79.6 MiB)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_170 in memory on 10.0.0.43:62420 (size: 1245.6 KiB, free: 164.2 MiB)
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 170.0 in stage 32.0 (TID 310)
[rdd_72_170]
25/02/04 17:13:24 INFO Executor: Finished task 170.0 in stage 32.0 (TID 310). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 181.0 in stage 32.0 (TID 321) (10.0.0.43, executor driver, partition 181, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO MemoryStore: Block rdd_72_168 stored as values in memory (estimated size 1077.6 KiB, free 90.2 MiB)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 170.0 in stage 32.0 (TID 310) in 1289 ms on 10.0.0.43 (executor driver) (172/200)
25/02/04 17:13:24 INFO BlockManagerInfo: Added rdd_72_168 in memory on 10.0.0.43:62420 (size: 1077.6 KiB, free: 163.1 MiB)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms
25/02/04 17:13:24 INFO Executor: 1 block locks were not released by task 168.0 in stage 32.0 (TID 308)
[rdd_72_168]
25/02/04 17:13:24 INFO Executor: Running task 181.0 in stage 32.0 (TID 321)
25/02/04 17:13:24 INFO Executor: Finished task 168.0 in stage 32.0 (TID 308). 17095 bytes result sent to driver
25/02/04 17:13:24 INFO TaskSetManager: Starting task 182.0 in stage 32.0 (TID 322) (10.0.0.43, executor driver, partition 182, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:24 INFO Executor: Running task 182.0 in stage 32.0 (TID 322)
25/02/04 17:13:24 INFO TaskSetManager: Finished task 168.0 in stage 32.0 (TID 308) in 1389 ms on 10.0.0.43 (executor driver) (173/200)
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 17 (3.7 MiB) non-empty blocks including 17 (3.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:24 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_176 stored as values in memory (estimated size 1020.3 KiB, free 68.6 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_176 in memory on 10.0.0.43:62420 (size: 1020.3 KiB, free: 162.1 MiB)
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_173 stored as values in memory (estimated size 1103.4 KiB, free 83.8 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_173 in memory on 10.0.0.43:62420 (size: 1103.4 KiB, free: 161.1 MiB)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 176.0 in stage 32.0 (TID 316)
[rdd_72_176]
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_174 stored as values in memory (estimated size 1313.1 KiB, free 93.6 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_174 in memory on 10.0.0.43:62420 (size: 1313.1 KiB, free: 159.8 MiB)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 174.0 in stage 32.0 (TID 314)
[rdd_72_174]
25/02/04 17:13:25 INFO Executor: Finished task 176.0 in stage 32.0 (TID 316). 17138 bytes result sent to driver
25/02/04 17:13:25 INFO Executor: Finished task 174.0 in stage 32.0 (TID 314). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_175 stored as values in memory (estimated size 1094.3 KiB, free 98.6 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_175 in memory on 10.0.0.43:62420 (size: 1094.3 KiB, free: 158.7 MiB)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 175.0 in stage 32.0 (TID 315)
[rdd_72_175]
25/02/04 17:13:25 INFO Executor: Finished task 175.0 in stage 32.0 (TID 315). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 173.0 in stage 32.0 (TID 313)
[rdd_72_173]
25/02/04 17:13:25 INFO Executor: Finished task 173.0 in stage 32.0 (TID 313). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO TaskSetManager: Starting task 183.0 in stage 32.0 (TID 323) (10.0.0.43, executor driver, partition 183, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO Executor: Running task 183.0 in stage 32.0 (TID 323)
25/02/04 17:13:25 INFO TaskSetManager: Starting task 184.0 in stage 32.0 (TID 324) (10.0.0.43, executor driver, partition 184, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO TaskSetManager: Starting task 185.0 in stage 32.0 (TID 325) (10.0.0.43, executor driver, partition 185, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO TaskSetManager: Starting task 186.0 in stage 32.0 (TID 326) (10.0.0.43, executor driver, partition 186, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO Executor: Running task 186.0 in stage 32.0 (TID 326)
25/02/04 17:13:25 INFO Executor: Running task 184.0 in stage 32.0 (TID 324)
25/02/04 17:13:25 INFO Executor: Running task 185.0 in stage 32.0 (TID 325)
25/02/04 17:13:25 INFO TaskSetManager: Finished task 174.0 in stage 32.0 (TID 314) in 988 ms on 10.0.0.43 (executor driver) (174/200)
25/02/04 17:13:25 INFO TaskSetManager: Finished task 173.0 in stage 32.0 (TID 313) in 1514 ms on 10.0.0.43 (executor driver) (175/200)
25/02/04 17:13:25 INFO TaskSetManager: Finished task 176.0 in stage 32.0 (TID 316) in 863 ms on 10.0.0.43 (executor driver) (176/200)
25/02/04 17:13:25 INFO TaskSetManager: Finished task 175.0 in stage 32.0 (TID 315) in 931 ms on 10.0.0.43 (executor driver) (177/200)
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (3.5 MiB) non-empty blocks including 17 (3.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 29 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_177 stored as values in memory (estimated size 1384.6 KiB, free 55.0 MiB)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_177 in memory on 10.0.0.43:62420 (size: 1384.6 KiB, free: 157.4 MiB)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 177.0 in stage 32.0 (TID 317)
[rdd_72_177]
25/02/04 17:13:25 INFO Executor: Finished task 177.0 in stage 32.0 (TID 317). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO TaskSetManager: Starting task 187.0 in stage 32.0 (TID 327) (10.0.0.43, executor driver, partition 187, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO TaskSetManager: Finished task 177.0 in stage 32.0 (TID 317) in 1069 ms on 10.0.0.43 (executor driver) (178/200)
25/02/04 17:13:25 INFO Executor: Running task 187.0 in stage 32.0 (TID 327)
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (5.1 MiB) non-empty blocks including 17 (5.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_178 stored as values in memory (estimated size 1351.0 KiB, free 24.6 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_178 in memory on 10.0.0.43:62420 (size: 1351.0 KiB, free: 156.0 MiB)
25/02/04 17:13:25 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:25 INFO MemoryStore: Block rdd_72_180 stored as values in memory (estimated size 1080.7 KiB, free 22.3 MiB)
25/02/04 17:13:25 INFO BlockManagerInfo: Added rdd_72_180 in memory on 10.0.0.43:62420 (size: 1080.7 KiB, free: 155.0 MiB)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 178.0 in stage 32.0 (TID 318)
[rdd_72_178]
25/02/04 17:13:25 INFO Executor: Finished task 178.0 in stage 32.0 (TID 318). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO TaskSetManager: Starting task 188.0 in stage 32.0 (TID 328) (10.0.0.43, executor driver, partition 188, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO TaskSetManager: Finished task 178.0 in stage 32.0 (TID 318) in 983 ms on 10.0.0.43 (executor driver) (179/200)
25/02/04 17:13:25 INFO Executor: Running task 188.0 in stage 32.0 (TID 328)
25/02/04 17:13:25 INFO Executor: 1 block locks were not released by task 180.0 in stage 32.0 (TID 320)
[rdd_72_180]
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO Executor: Finished task 180.0 in stage 32.0 (TID 320). 17095 bytes result sent to driver
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO TaskSetManager: Starting task 189.0 in stage 32.0 (TID 329) (10.0.0.43, executor driver, partition 189, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:25 INFO TaskSetManager: Finished task 180.0 in stage 32.0 (TID 320) in 877 ms on 10.0.0.43 (executor driver) (180/200)
25/02/04 17:13:25 INFO Executor: Running task 189.0 in stage 32.0 (TID 329)
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 17 (4.5 MiB) non-empty blocks including 17 (4.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:25 INFO MemoryStore: 6 blocks selected for dropping (3.1 MiB bytes)
25/02/04 17:13:25 INFO BlockManager: Dropping block broadcast_14 from memory
25/02/04 17:13:25 INFO BlockManager: Writing block broadcast_14 to disk
25/02/04 17:13:25 INFO BlockManager: Dropping block broadcast_16 from memory
25/02/04 17:13:25 INFO BlockManager: Writing block broadcast_16 to disk
25/02/04 17:13:25 INFO BlockManager: Dropping block broadcast_23_piece0 from memory
25/02/04 17:13:25 INFO BlockManager: Writing block broadcast_23_piece0 to disk
25/02/04 17:13:25 INFO BlockManagerInfo: Updated broadcast_23_piece0 on disk on 10.0.0.43:62420 (current size: 40.5 KiB, original size: 0.0 B)
25/02/04 17:13:25 INFO BlockManager: Dropping block broadcast_23 from memory
25/02/04 17:13:25 INFO BlockManager: Writing block broadcast_23 to disk
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_6 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_6 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_6 on disk on 10.0.0.43:62420 (current size: 1175.2 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_3 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_3 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_3 on disk on 10.0.0.43:62420 (current size: 987.2 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 6 blocks, free memory is 14.2 MiB
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_182 stored as values in memory (estimated size 1175.7 KiB, free 115.7 MiB)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_181 stored as values in memory (estimated size 1168.3 KiB, free 97.1 MiB)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_179 stored as values in memory (estimated size 1459.9 KiB, free 97.1 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_179 in memory on 10.0.0.43:62420 (size: 1459.9 KiB, free: 155.8 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_182 in memory on 10.0.0.43:62420 (size: 1175.7 KiB, free: 154.7 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 179.0 in stage 32.0 (TID 319)
[rdd_72_179]
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 182.0 in stage 32.0 (TID 322)
[rdd_72_182]
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_181 in memory on 10.0.0.43:62420 (size: 1168.3 KiB, free: 153.6 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 181.0 in stage 32.0 (TID 321)
[rdd_72_181]
25/02/04 17:13:26 INFO Executor: Finished task 179.0 in stage 32.0 (TID 319). 17138 bytes result sent to driver
25/02/04 17:13:26 INFO Executor: Finished task 181.0 in stage 32.0 (TID 321). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO Executor: Finished task 182.0 in stage 32.0 (TID 322). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO TaskSetManager: Starting task 190.0 in stage 32.0 (TID 330) (10.0.0.43, executor driver, partition 190, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 190.0 in stage 32.0 (TID 330)
25/02/04 17:13:26 INFO TaskSetManager: Starting task 191.0 in stage 32.0 (TID 331) (10.0.0.43, executor driver, partition 191, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 191.0 in stage 32.0 (TID 331)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 179.0 in stage 32.0 (TID 319) in 1600 ms on 10.0.0.43 (executor driver) (181/200)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 182.0 in stage 32.0 (TID 322) in 1326 ms on 10.0.0.43 (executor driver) (182/200)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 181.0 in stage 32.0 (TID 321) in 1432 ms on 10.0.0.43 (executor driver) (183/200)
25/02/04 17:13:26 INFO TaskSetManager: Starting task 192.0 in stage 32.0 (TID 332) (10.0.0.43, executor driver, partition 192, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 192.0 in stage 32.0 (TID 332)
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (4.0 MiB) non-empty blocks including 17 (4.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.4 MiB) non-empty blocks including 17 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (4.2 MiB) non-empty blocks including 17 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_2 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_2 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_2 on disk on 10.0.0.43:62420 (current size: 1110.3 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_7 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_7 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_7 on disk on 10.0.0.43:62420 (current size: 895.3 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 18.9 MiB
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_183 stored as values in memory (estimated size 1091.3 KiB, free 44.9 MiB)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_184 stored as values in memory (estimated size 1023.9 KiB, free 44.9 MiB)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_186 stored as values in memory (estimated size 1115.1 KiB, free 43.8 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_183 in memory on 10.0.0.43:62420 (size: 1091.3 KiB, free: 154.6 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_186 in memory on 10.0.0.43:62420 (size: 1115.1 KiB, free: 153.5 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_184 in memory on 10.0.0.43:62420 (size: 1023.9 KiB, free: 152.5 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 184.0 in stage 32.0 (TID 324)
[rdd_72_184]
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 186.0 in stage 32.0 (TID 326)
[rdd_72_186]
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 183.0 in stage 32.0 (TID 323)
[rdd_72_183]
25/02/04 17:13:26 INFO Executor: Finished task 183.0 in stage 32.0 (TID 323). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO Executor: Finished task 184.0 in stage 32.0 (TID 324). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO Executor: Finished task 186.0 in stage 32.0 (TID 326). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO TaskSetManager: Starting task 193.0 in stage 32.0 (TID 333) (10.0.0.43, executor driver, partition 193, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 193.0 in stage 32.0 (TID 333)
25/02/04 17:13:26 INFO TaskSetManager: Starting task 194.0 in stage 32.0 (TID 334) (10.0.0.43, executor driver, partition 194, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 194.0 in stage 32.0 (TID 334)
25/02/04 17:13:26 INFO TaskSetManager: Starting task 195.0 in stage 32.0 (TID 335) (10.0.0.43, executor driver, partition 195, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO TaskSetManager: Finished task 184.0 in stage 32.0 (TID 324) in 1263 ms on 10.0.0.43 (executor driver) (184/200)
25/02/04 17:13:26 INFO Executor: Running task 195.0 in stage 32.0 (TID 335)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 183.0 in stage 32.0 (TID 323) in 1269 ms on 10.0.0.43 (executor driver) (185/200)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 186.0 in stage 32.0 (TID 326) in 1264 ms on 10.0.0.43 (executor driver) (186/200)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_185 stored as values in memory (estimated size 1151.8 KiB, free 38.7 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_185 in memory on 10.0.0.43:62420 (size: 1151.8 KiB, free: 151.4 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 185.0 in stage 32.0 (TID 325)
[rdd_72_185]
25/02/04 17:13:26 INFO Executor: Finished task 185.0 in stage 32.0 (TID 325). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO TaskSetManager: Starting task 196.0 in stage 32.0 (TID 336) (10.0.0.43, executor driver, partition 196, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO TaskSetManager: Finished task 185.0 in stage 32.0 (TID 325) in 1295 ms on 10.0.0.43 (executor driver) (187/200)
25/02/04 17:13:26 INFO Executor: Running task 196.0 in stage 32.0 (TID 336)
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (5.1 MiB) non-empty blocks including 17 (5.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.9 MiB) non-empty blocks including 17 (3.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_188 stored as values in memory (estimated size 1209.4 KiB, free 59.6 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_188 in memory on 10.0.0.43:62420 (size: 1209.4 KiB, free: 150.2 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 188.0 in stage 32.0 (TID 328)
[rdd_72_188]
25/02/04 17:13:26 INFO Executor: Finished task 188.0 in stage 32.0 (TID 328). 17009 bytes result sent to driver
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO TaskSetManager: Starting task 197.0 in stage 32.0 (TID 337) (10.0.0.43, executor driver, partition 197, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 197.0 in stage 32.0 (TID 337)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 188.0 in stage 32.0 (TID 328) in 1054 ms on 10.0.0.43 (executor driver) (188/200)
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.6 MiB) non-empty blocks including 17 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO MemoryStore: 1 blocks selected for dropping (1094.6 KiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_5 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_5 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_5 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 1 blocks, free memory is 12.6 MiB
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_0 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_0 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_0 on disk on 10.0.0.43:62420 (current size: 1043.3 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_9 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_9 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_9 on disk on 10.0.0.43:62420 (current size: 1084.9 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 12.8 MiB
25/02/04 17:13:26 INFO MemoryStore: 1 blocks selected for dropping (1252.8 KiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_4 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_4 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_4 on disk on 10.0.0.43:62420 (current size: 1183.4 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 1 blocks, free memory is 12.0 MiB
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.8 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_8 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_8 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_8 on disk on 10.0.0.43:62420 (current size: 1237.7 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_1 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_1 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_1 on disk on 10.0.0.43:62420 (current size: 1494.1 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 12.9 MiB
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_10 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_10 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_10 on disk on 10.0.0.43:62420 (current size: 1093.3 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_18 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_18 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_18 on disk on 10.0.0.43:62420 (current size: 918.0 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 13.0 MiB
25/02/04 17:13:26 INFO MemoryStore: 1 blocks selected for dropping (1175.6 KiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_16 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_16 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_16 on disk on 10.0.0.43:62420 (current size: 1109.4 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 1 blocks, free memory is 12.1 MiB
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.5 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_12 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_12 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_12 on disk on 10.0.0.43:62420 (current size: 1138.3 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_15 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_15 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_15 on disk on 10.0.0.43:62420 (current size: 1246.0 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 12.6 MiB
25/02/04 17:13:26 INFO MemoryStore: 2 blocks selected for dropping (2.5 MiB bytes)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_11 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_11 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_11 on disk on 10.0.0.43:62420 (current size: 1090.0 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO BlockManager: Dropping block rdd_72_13 from memory
25/02/04 17:13:26 INFO BlockManager: Writing block rdd_72_13 to disk
25/02/04 17:13:26 INFO BlockManagerInfo: Updated rdd_72_13 on disk on 10.0.0.43:62420 (current size: 1373.4 KiB, original size: 0.0 B)
25/02/04 17:13:26 INFO MemoryStore: After dropping 2 blocks, free memory is 13.1 MiB
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_189 stored as values in memory (estimated size 1483.9 KiB, free 34.5 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_189 in memory on 10.0.0.43:62420 (size: 1483.9 KiB, free: 164.3 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 189.0 in stage 32.0 (TID 329)
[rdd_72_189]
25/02/04 17:13:26 INFO MemoryStore: Block rdd_72_187 stored as values in memory (estimated size 1826.0 KiB, free 54.7 MiB)
25/02/04 17:13:26 INFO BlockManagerInfo: Added rdd_72_187 in memory on 10.0.0.43:62420 (size: 1826.0 KiB, free: 162.5 MiB)
25/02/04 17:13:26 INFO Executor: 1 block locks were not released by task 187.0 in stage 32.0 (TID 327)
[rdd_72_187]
25/02/04 17:13:26 INFO Executor: Finished task 187.0 in stage 32.0 (TID 327). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO Executor: Finished task 189.0 in stage 32.0 (TID 329). 17095 bytes result sent to driver
25/02/04 17:13:26 INFO TaskSetManager: Starting task 198.0 in stage 32.0 (TID 338) (10.0.0.43, executor driver, partition 198, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 198.0 in stage 32.0 (TID 338)
25/02/04 17:13:26 INFO TaskSetManager: Starting task 199.0 in stage 32.0 (TID 339) (10.0.0.43, executor driver, partition 199, NODE_LOCAL, 9281 bytes) 
25/02/04 17:13:26 INFO Executor: Running task 199.0 in stage 32.0 (TID 339)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 187.0 in stage 32.0 (TID 327) in 1389 ms on 10.0.0.43 (executor driver) (189/200)
25/02/04 17:13:26 INFO TaskSetManager: Finished task 189.0 in stage 32.0 (TID 329) in 1322 ms on 10.0.0.43 (executor driver) (190/200)
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.2 MiB) non-empty blocks including 17 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Getting 17 (3.8 MiB) non-empty blocks including 17 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:27 INFO ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:13:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:13:27 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:27 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 16.0 MiB to disk (0  time so far)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_192 stored as values in memory (estimated size 1074.5 KiB, free 92.4 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_192 in memory on 10.0.0.43:62420 (size: 1074.5 KiB, free: 161.5 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 192.0 in stage 32.0 (TID 332)
[rdd_72_192]
25/02/04 17:13:27 INFO Executor: Finished task 192.0 in stage 32.0 (TID 332). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 192.0 in stage 32.0 (TID 332) in 1115 ms on 10.0.0.43 (executor driver) (191/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_191 stored as values in memory (estimated size 1429.8 KiB, free 89.1 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_191 in memory on 10.0.0.43:62420 (size: 1429.8 KiB, free: 160.1 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 191.0 in stage 32.0 (TID 331)
[rdd_72_191]
25/02/04 17:13:27 INFO Executor: Finished task 191.0 in stage 32.0 (TID 331). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_190 stored as values in memory (estimated size 1326.0 KiB, free 99.8 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_190 in memory on 10.0.0.43:62420 (size: 1326.0 KiB, free: 158.8 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 190.0 in stage 32.0 (TID 330)
[rdd_72_190]
25/02/04 17:13:27 INFO TaskSetManager: Finished task 191.0 in stage 32.0 (TID 331) in 1135 ms on 10.0.0.43 (executor driver) (192/200)
25/02/04 17:13:27 INFO Executor: Finished task 190.0 in stage 32.0 (TID 330). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 190.0 in stage 32.0 (TID 330) in 1156 ms on 10.0.0.43 (executor driver) (193/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_194 stored as values in memory (estimated size 1006.5 KiB, free 103.9 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_194 in memory on 10.0.0.43:62420 (size: 1006.5 KiB, free: 157.8 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 194.0 in stage 32.0 (TID 334)
[rdd_72_194]
25/02/04 17:13:27 INFO Executor: Finished task 194.0 in stage 32.0 (TID 334). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 194.0 in stage 32.0 (TID 334) in 860 ms on 10.0.0.43 (executor driver) (194/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_195 stored as values in memory (estimated size 968.9 KiB, free 107.5 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_195 in memory on 10.0.0.43:62420 (size: 968.9 KiB, free: 156.8 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 195.0 in stage 32.0 (TID 335)
[rdd_72_195]
25/02/04 17:13:27 INFO Executor: Finished task 195.0 in stage 32.0 (TID 335). 17138 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 195.0 in stage 32.0 (TID 335) in 874 ms on 10.0.0.43 (executor driver) (195/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_197 stored as values in memory (estimated size 1149.1 KiB, free 114.5 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_197 in memory on 10.0.0.43:62420 (size: 1149.1 KiB, free: 155.7 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 197.0 in stage 32.0 (TID 337)
[rdd_72_197]
25/02/04 17:13:27 INFO Executor: Finished task 197.0 in stage 32.0 (TID 337). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_198 stored as values in memory (estimated size 1005.0 KiB, free 118.5 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_198 in memory on 10.0.0.43:62420 (size: 1005.0 KiB, free: 154.7 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 198.0 in stage 32.0 (TID 338)
[rdd_72_198]
25/02/04 17:13:27 INFO Executor: Finished task 198.0 in stage 32.0 (TID 338). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 197.0 in stage 32.0 (TID 337) in 867 ms on 10.0.0.43 (executor driver) (196/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_193 stored as values in memory (estimated size 1261.6 KiB, free 127.4 MiB)
25/02/04 17:13:27 INFO TaskSetManager: Finished task 198.0 in stage 32.0 (TID 338) in 575 ms on 10.0.0.43 (executor driver) (197/200)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_193 in memory on 10.0.0.43:62420 (size: 1261.6 KiB, free: 153.5 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 193.0 in stage 32.0 (TID 333)
[rdd_72_193]
25/02/04 17:13:27 INFO Executor: Finished task 193.0 in stage 32.0 (TID 333). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 193.0 in stage 32.0 (TID 333) in 946 ms on 10.0.0.43 (executor driver) (198/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_199 stored as values in memory (estimated size 1240.6 KiB, free 136.2 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_199 in memory on 10.0.0.43:62420 (size: 1240.6 KiB, free: 152.3 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 199.0 in stage 32.0 (TID 339)
[rdd_72_199]
25/02/04 17:13:27 INFO Executor: Finished task 199.0 in stage 32.0 (TID 339). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 199.0 in stage 32.0 (TID 339) in 664 ms on 10.0.0.43 (executor driver) (199/200)
25/02/04 17:13:27 INFO MemoryStore: Block rdd_72_196 stored as values in memory (estimated size 1663.1 KiB, free 150.7 MiB)
25/02/04 17:13:27 INFO BlockManagerInfo: Added rdd_72_196 in memory on 10.0.0.43:62420 (size: 1663.1 KiB, free: 150.7 MiB)
25/02/04 17:13:27 INFO Executor: 1 block locks were not released by task 196.0 in stage 32.0 (TID 336)
[rdd_72_196]
25/02/04 17:13:27 INFO Executor: Finished task 196.0 in stage 32.0 (TID 336). 17095 bytes result sent to driver
25/02/04 17:13:27 INFO TaskSetManager: Finished task 196.0 in stage 32.0 (TID 336) in 1018 ms on 10.0.0.43 (executor driver) (200/200)
25/02/04 17:13:27 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
25/02/04 17:13:27 INFO DAGScheduler: ResultStage 32 (parquet at NativeMethodAccessorImpl.java:0) finished in 18.186 s
25/02/04 17:13:27 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:13:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
25/02/04 17:13:27 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:28 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:13:28 INFO DAGScheduler: Got job 15 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
25/02/04 17:13:28 INFO DAGScheduler: Final stage: ResultStage 41 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:13:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 40)
25/02/04 17:13:28 INFO DAGScheduler: Missing parents: List()
25/02/04 17:13:28 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[76] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:13:28 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 295.3 KiB, free 150.4 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 112.1 KiB, free 150.3 MiB)
25/02/04 17:13:28 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.0.43:62420 (size: 112.1 KiB, free: 150.6 MiB)
25/02/04 17:13:28 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
25/02/04 17:13:28 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 41 (MapPartitionsRDD[76] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:13:28 INFO TaskSchedulerImpl: Adding task set 41.0 with 200 tasks resource profile 0
25/02/04 17:13:28 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 340) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 341) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 342) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 343) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 344) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 345) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 6.0 in stage 41.0 (TID 346) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 7.0 in stage 41.0 (TID 347) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 8.0 in stage 41.0 (TID 348) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO TaskSetManager: Starting task 9.0 in stage 41.0 (TID 349) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:28 INFO Executor: Running task 5.0 in stage 41.0 (TID 345)
25/02/04 17:13:28 INFO Executor: Running task 8.0 in stage 41.0 (TID 348)
25/02/04 17:13:28 INFO Executor: Running task 0.0 in stage 41.0 (TID 340)
25/02/04 17:13:28 INFO Executor: Running task 4.0 in stage 41.0 (TID 344)
25/02/04 17:13:28 INFO Executor: Running task 1.0 in stage 41.0 (TID 341)
25/02/04 17:13:28 INFO Executor: Running task 9.0 in stage 41.0 (TID 349)
25/02/04 17:13:28 INFO Executor: Running task 3.0 in stage 41.0 (TID 343)
25/02/04 17:13:28 INFO Executor: Running task 7.0 in stage 41.0 (TID 347)
25/02/04 17:13:28 INFO Executor: Running task 6.0 in stage 41.0 (TID 346)
25/02/04 17:13:28 INFO Executor: Running task 2.0 in stage 41.0 (TID 342)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_9 stored as values in memory (estimated size 1150.5 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_0 stored as values in memory (estimated size 1104.4 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_1 stored as values in memory (estimated size 1576.2 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_6 stored as values in memory (estimated size 1246.8 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_7 stored as values in memory (estimated size 950.4 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_4 stored as values in memory (estimated size 1252.8 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_3 stored as values in memory (estimated size 1048.3 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_2 stored as values in memory (estimated size 1178.9 KiB, free 141.0 MiB)
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_7 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_4 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_9 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_6 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_3 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_1 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_2 locally
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_0 locally
25/02/04 17:13:28 INFO MemoryStore: Block rdd_72_8 stored as values in memory (estimated size 1311.0 KiB, free 139.7 MiB)
25/02/04 17:13:28 INFO BlockManager: Found block rdd_72_8 locally
25/02/04 17:13:29 INFO MemoryStore: Block rdd_72_5 stored as values in memory (estimated size 1094.6 KiB, free 138.6 MiB)
25/02/04 17:13:29 INFO BlockManager: Found block rdd_72_5 locally
25/02/04 17:13:29 INFO CodeGenerator: Code generated in 180.781709 ms
25/02/04 17:13:29 INFO CodeGenerator: Code generated in 117.306625 ms
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 INFO CodecPool: Got brand-new compressor [.snappy]
25/02/04 17:13:30 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:30 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:30 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:33 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:33 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000005_345' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000005
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000008_348' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000008
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000001_341' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000001
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000009_349' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000009
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000004_344' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000004
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000007_347' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000007
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000000_340' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000000
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000003_343' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000003
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000006_346' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000006
25/02/04 17:13:33 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000002_342' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000002
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000009_349: Committed. Elapsed time: 4 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000008_348: Committed. Elapsed time: 3 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000001_341: Committed. Elapsed time: 3 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000000_340: Committed. Elapsed time: 3 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000002_342: Committed. Elapsed time: 11 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000006_346: Committed. Elapsed time: 8 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000004_344: Committed. Elapsed time: 2 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000007_347: Committed. Elapsed time: 4 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000005_345: Committed. Elapsed time: 1 ms.
25/02/04 17:13:33 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000003_343: Committed. Elapsed time: 10 ms.
25/02/04 17:13:33 INFO Executor: Finished task 9.0 in stage 41.0 (TID 349). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 1.0 in stage 41.0 (TID 341). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 4.0 in stage 41.0 (TID 344). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 6.0 in stage 41.0 (TID 346). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 0.0 in stage 41.0 (TID 340). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 3.0 in stage 41.0 (TID 343). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 8.0 in stage 41.0 (TID 348). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 2.0 in stage 41.0 (TID 342). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 7.0 in stage 41.0 (TID 347). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO Executor: Finished task 5.0 in stage 41.0 (TID 345). 17674 bytes result sent to driver
25/02/04 17:13:33 INFO TaskSetManager: Starting task 10.0 in stage 41.0 (TID 350) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 10.0 in stage 41.0 (TID 350)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 11.0 in stage 41.0 (TID 351) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 11.0 in stage 41.0 (TID 351)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 12.0 in stage 41.0 (TID 352) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 12.0 in stage 41.0 (TID 352)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 13.0 in stage 41.0 (TID 353) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 13.0 in stage 41.0 (TID 353)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 14.0 in stage 41.0 (TID 354) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 14.0 in stage 41.0 (TID 354)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 344) in 5278 ms on 10.0.0.43 (executor driver) (1/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 9.0 in stage 41.0 (TID 349) in 5277 ms on 10.0.0.43 (executor driver) (2/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 341) in 5281 ms on 10.0.0.43 (executor driver) (3/200)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 15.0 in stage 41.0 (TID 355) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 15.0 in stage 41.0 (TID 355)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 16.0 in stage 41.0 (TID 356) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO TaskSetManager: Finished task 6.0 in stage 41.0 (TID 346) in 5284 ms on 10.0.0.43 (executor driver) (4/200)
25/02/04 17:13:33 INFO Executor: Running task 16.0 in stage 41.0 (TID 356)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 17.0 in stage 41.0 (TID 357) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 17.0 in stage 41.0 (TID 357)
25/02/04 17:13:33 INFO TaskSetManager: Starting task 18.0 in stage 41.0 (TID 358) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO TaskSetManager: Starting task 19.0 in stage 41.0 (TID 359) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:33 INFO Executor: Running task 19.0 in stage 41.0 (TID 359)
25/02/04 17:13:33 INFO Executor: Running task 18.0 in stage 41.0 (TID 358)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 340) in 5311 ms on 10.0.0.43 (executor driver) (5/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 343) in 5302 ms on 10.0.0.43 (executor driver) (6/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 342) in 5304 ms on 10.0.0.43 (executor driver) (7/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 8.0 in stage 41.0 (TID 348) in 5303 ms on 10.0.0.43 (executor driver) (8/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 345) in 5305 ms on 10.0.0.43 (executor driver) (9/200)
25/02/04 17:13:33 INFO TaskSetManager: Finished task 7.0 in stage 41.0 (TID 347) in 5310 ms on 10.0.0.43 (executor driver) (10/200)
25/02/04 17:13:33 INFO BlockManager: Found block rdd_72_19 locally
25/02/04 17:13:33 INFO BlockManager: Found block rdd_72_17 locally
25/02/04 17:13:33 INFO BlockManager: Found block rdd_72_14 locally
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_18 stored as values in memory (estimated size 974.0 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_15 stored as values in memory (estimated size 1319.8 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_12 stored as values in memory (estimated size 1209.2 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_11 stored as values in memory (estimated size 1153.5 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_13 stored as values in memory (estimated size 1448.0 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_16 stored as values in memory (estimated size 1175.6 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO MemoryStore: Block rdd_72_10 stored as values in memory (estimated size 1160.4 KiB, free 130.4 MiB)
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_12 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_15 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_10 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_16 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_11 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_13 locally
25/02/04 17:13:34 INFO BlockManager: Found block rdd_72_18 locally
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:34 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:34 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:34 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:34 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:34 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000015_355' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000015
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000010_350' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000010
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000019_359' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000019
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000016_356' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000016
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000017_357' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000017
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000012_352' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000012
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000014_354' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000014
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000011_351' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000011
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000013_353' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000013
25/02/04 17:13:34 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000018_358' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000018
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000019_359: Committed. Elapsed time: 3 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000018_358: Committed. Elapsed time: 4 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000011_351: Committed. Elapsed time: 2 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000013_353: Committed. Elapsed time: 3 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000014_354: Committed. Elapsed time: 2 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000012_352: Committed. Elapsed time: 4 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000015_355: Committed. Elapsed time: 1 ms.
25/02/04 17:13:34 INFO Executor: Finished task 12.0 in stage 41.0 (TID 352). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 11.0 in stage 41.0 (TID 351). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 13.0 in stage 41.0 (TID 353). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 18.0 in stage 41.0 (TID 358). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 15.0 in stage 41.0 (TID 355). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 14.0 in stage 41.0 (TID 354). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 19.0 in stage 41.0 (TID 359). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000016_356: Committed. Elapsed time: 1 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000010_350: Committed. Elapsed time: 2 ms.
25/02/04 17:13:34 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000017_357: Committed. Elapsed time: 1 ms.
25/02/04 17:13:34 INFO Executor: Finished task 10.0 in stage 41.0 (TID 350). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 16.0 in stage 41.0 (TID 356). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO Executor: Finished task 17.0 in stage 41.0 (TID 357). 17674 bytes result sent to driver
25/02/04 17:13:34 INFO TaskSetManager: Starting task 20.0 in stage 41.0 (TID 360) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:34 INFO Executor: Running task 20.0 in stage 41.0 (TID 360)
25/02/04 17:13:34 INFO TaskSetManager: Starting task 21.0 in stage 41.0 (TID 361) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:34 INFO Executor: Running task 21.0 in stage 41.0 (TID 361)
25/02/04 17:13:34 INFO TaskSetManager: Finished task 12.0 in stage 41.0 (TID 352) in 1419 ms on 10.0.0.43 (executor driver) (11/200)
25/02/04 17:13:34 INFO TaskSetManager: Starting task 22.0 in stage 41.0 (TID 362) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:34 INFO Executor: Running task 22.0 in stage 41.0 (TID 362)
25/02/04 17:13:34 INFO TaskSetManager: Finished task 15.0 in stage 41.0 (TID 355) in 1406 ms on 10.0.0.43 (executor driver) (12/200)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 23.0 in stage 41.0 (TID 363) (10.0.0.43, executor driver, partition 23, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO Executor: Running task 23.0 in stage 41.0 (TID 363)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 24.0 in stage 41.0 (TID 364) (10.0.0.43, executor driver, partition 24, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO Executor: Running task 24.0 in stage 41.0 (TID 364)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 25.0 in stage 41.0 (TID 365) (10.0.0.43, executor driver, partition 25, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO Executor: Running task 25.0 in stage 41.0 (TID 365)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 18.0 in stage 41.0 (TID 358) in 1403 ms on 10.0.0.43 (executor driver) (13/200)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 11.0 in stage 41.0 (TID 351) in 1432 ms on 10.0.0.43 (executor driver) (14/200)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 26.0 in stage 41.0 (TID 366) (10.0.0.43, executor driver, partition 26, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO TaskSetManager: Finished task 13.0 in stage 41.0 (TID 353) in 1418 ms on 10.0.0.43 (executor driver) (15/200)
25/02/04 17:13:35 INFO Executor: Running task 26.0 in stage 41.0 (TID 366)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 27.0 in stage 41.0 (TID 367) (10.0.0.43, executor driver, partition 27, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO Executor: Running task 27.0 in stage 41.0 (TID 367)
25/02/04 17:13:35 INFO TaskSetManager: Starting task 28.0 in stage 41.0 (TID 368) (10.0.0.43, executor driver, partition 28, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO TaskSetManager: Starting task 29.0 in stage 41.0 (TID 369) (10.0.0.43, executor driver, partition 29, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:35 INFO TaskSetManager: Finished task 14.0 in stage 41.0 (TID 354) in 1417 ms on 10.0.0.43 (executor driver) (16/200)
25/02/04 17:13:35 INFO Executor: Running task 28.0 in stage 41.0 (TID 368)
25/02/04 17:13:35 INFO Executor: Running task 29.0 in stage 41.0 (TID 369)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 19.0 in stage 41.0 (TID 359) in 1415 ms on 10.0.0.43 (executor driver) (17/200)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 17.0 in stage 41.0 (TID 357) in 1423 ms on 10.0.0.43 (executor driver) (18/200)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 16.0 in stage 41.0 (TID 356) in 1424 ms on 10.0.0.43 (executor driver) (19/200)
25/02/04 17:13:35 INFO TaskSetManager: Finished task 10.0 in stage 41.0 (TID 350) in 1484 ms on 10.0.0.43 (executor driver) (20/200)
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_28 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_29 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_25 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_20 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_26 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_27 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_22 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_24 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_23 locally
25/02/04 17:13:35 INFO BlockManager: Found block rdd_72_21 locally
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:35 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:35 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:35 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:36 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.0.43:62420 on disk (size: 40.5 KiB)
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000024_364' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000024
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000023_363' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000023
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000026_366' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000026
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000023_363: Committed. Elapsed time: 3 ms.
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000026_366: Committed. Elapsed time: 5 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000021_361' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000021
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000021_361: Committed. Elapsed time: 2 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000029_369' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000029
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000029_369: Committed. Elapsed time: 5 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000027_367' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000027
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000027_367: Committed. Elapsed time: 5 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000025_365' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000025
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000025_365: Committed. Elapsed time: 5 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000020_360' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000020
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000020_360: Committed. Elapsed time: 3 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000028_368' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000028
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000028_368: Committed. Elapsed time: 3 ms.
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000024_364: Committed. Elapsed time: 2 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000022_362' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000022
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000022_362: Committed. Elapsed time: 5 ms.
25/02/04 17:13:36 INFO Executor: Finished task 23.0 in stage 41.0 (TID 363). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 20.0 in stage 41.0 (TID 360). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 21.0 in stage 41.0 (TID 361). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 22.0 in stage 41.0 (TID 362). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 29.0 in stage 41.0 (TID 369). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 26.0 in stage 41.0 (TID 366). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 28.0 in stage 41.0 (TID 368). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 27.0 in stage 41.0 (TID 367). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 25.0 in stage 41.0 (TID 365). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 24.0 in stage 41.0 (TID 364). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO TaskSetManager: Starting task 30.0 in stage 41.0 (TID 370) (10.0.0.43, executor driver, partition 30, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 30.0 in stage 41.0 (TID 370)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 31.0 in stage 41.0 (TID 371) (10.0.0.43, executor driver, partition 31, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 31.0 in stage 41.0 (TID 371)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 32.0 in stage 41.0 (TID 372) (10.0.0.43, executor driver, partition 32, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 32.0 in stage 41.0 (TID 372)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 33.0 in stage 41.0 (TID 373) (10.0.0.43, executor driver, partition 33, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 33.0 in stage 41.0 (TID 373)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 34.0 in stage 41.0 (TID 374) (10.0.0.43, executor driver, partition 34, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 34.0 in stage 41.0 (TID 374)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 35.0 in stage 41.0 (TID 375) (10.0.0.43, executor driver, partition 35, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 35.0 in stage 41.0 (TID 375)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 36.0 in stage 41.0 (TID 376) (10.0.0.43, executor driver, partition 36, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 36.0 in stage 41.0 (TID 376)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 37.0 in stage 41.0 (TID 377) (10.0.0.43, executor driver, partition 37, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 37.0 in stage 41.0 (TID 377)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 38.0 in stage 41.0 (TID 378) (10.0.0.43, executor driver, partition 38, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO TaskSetManager: Starting task 39.0 in stage 41.0 (TID 379) (10.0.0.43, executor driver, partition 39, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 39.0 in stage 41.0 (TID 379)
25/02/04 17:13:36 INFO Executor: Running task 38.0 in stage 41.0 (TID 378)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 23.0 in stage 41.0 (TID 363) in 1430 ms on 10.0.0.43 (executor driver) (21/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 27.0 in stage 41.0 (TID 367) in 1430 ms on 10.0.0.43 (executor driver) (22/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 25.0 in stage 41.0 (TID 365) in 1432 ms on 10.0.0.43 (executor driver) (23/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 20.0 in stage 41.0 (TID 360) in 1450 ms on 10.0.0.43 (executor driver) (24/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 29.0 in stage 41.0 (TID 369) in 1431 ms on 10.0.0.43 (executor driver) (25/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 22.0 in stage 41.0 (TID 362) in 1438 ms on 10.0.0.43 (executor driver) (26/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 24.0 in stage 41.0 (TID 364) in 1438 ms on 10.0.0.43 (executor driver) (27/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 26.0 in stage 41.0 (TID 366) in 1446 ms on 10.0.0.43 (executor driver) (28/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 21.0 in stage 41.0 (TID 361) in 1454 ms on 10.0.0.43 (executor driver) (29/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 28.0 in stage 41.0 (TID 368) in 1446 ms on 10.0.0.43 (executor driver) (30/200)
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_30 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_35 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_37 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_39 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_31 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_36 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_38 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_33 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_34 locally
25/02/04 17:13:36 INFO BlockManager: Found block rdd_72_32 locally
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000033_373' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000033
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000036_376' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000036
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000033_373: Committed. Elapsed time: 1 ms.
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000036_376: Committed. Elapsed time: 0 ms.
25/02/04 17:13:36 INFO Executor: Finished task 36.0 in stage 41.0 (TID 376). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 33.0 in stage 41.0 (TID 373). 17674 bytes result sent to driver
25/02/04 17:13:36 INFO TaskSetManager: Starting task 40.0 in stage 41.0 (TID 380) (10.0.0.43, executor driver, partition 40, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000032_372' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000032
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000032_372: Committed. Elapsed time: 1 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000038_378' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000038
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000038_378: Committed. Elapsed time: 0 ms.
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000037_377' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000037
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000037_377: Committed. Elapsed time: 0 ms.
25/02/04 17:13:36 INFO Executor: Finished task 32.0 in stage 41.0 (TID 372). 17631 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 37.0 in stage 41.0 (TID 377). 17631 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Finished task 38.0 in stage 41.0 (TID 378). 17631 bytes result sent to driver
25/02/04 17:13:36 INFO TaskSetManager: Starting task 41.0 in stage 41.0 (TID 381) (10.0.0.43, executor driver, partition 41, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 40.0 in stage 41.0 (TID 380)
25/02/04 17:13:36 INFO Executor: Running task 41.0 in stage 41.0 (TID 381)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 42.0 in stage 41.0 (TID 382) (10.0.0.43, executor driver, partition 42, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO Executor: Running task 42.0 in stage 41.0 (TID 382)
25/02/04 17:13:36 INFO TaskSetManager: Starting task 43.0 in stage 41.0 (TID 383) (10.0.0.43, executor driver, partition 43, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:36 INFO TaskSetManager: Finished task 32.0 in stage 41.0 (TID 372) in 659 ms on 10.0.0.43 (executor driver) (31/200)
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000035_375' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000035
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000035_375: Committed. Elapsed time: 0 ms.
25/02/04 17:13:36 INFO TaskSetManager: Finished task 37.0 in stage 41.0 (TID 377) in 647 ms on 10.0.0.43 (executor driver) (32/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 36.0 in stage 41.0 (TID 376) in 649 ms on 10.0.0.43 (executor driver) (33/200)
25/02/04 17:13:36 INFO TaskSetManager: Finished task 33.0 in stage 41.0 (TID 373) in 655 ms on 10.0.0.43 (executor driver) (34/200)
25/02/04 17:13:36 INFO Executor: Finished task 35.0 in stage 41.0 (TID 375). 17631 bytes result sent to driver
25/02/04 17:13:36 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000031_371' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000031
25/02/04 17:13:36 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000031_371: Committed. Elapsed time: 0 ms.
25/02/04 17:13:36 INFO Executor: Finished task 31.0 in stage 41.0 (TID 371). 17631 bytes result sent to driver
25/02/04 17:13:36 INFO Executor: Running task 43.0 in stage 41.0 (TID 383)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 44.0 in stage 41.0 (TID 384) (10.0.0.43, executor driver, partition 44, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 44.0 in stage 41.0 (TID 384)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 45.0 in stage 41.0 (TID 385) (10.0.0.43, executor driver, partition 45, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Finished task 38.0 in stage 41.0 (TID 378) in 673 ms on 10.0.0.43 (executor driver) (35/200)
25/02/04 17:13:37 INFO Executor: Running task 45.0 in stage 41.0 (TID 385)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 46.0 in stage 41.0 (TID 386) (10.0.0.43, executor driver, partition 46, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 46.0 in stage 41.0 (TID 386)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 35.0 in stage 41.0 (TID 375) in 680 ms on 10.0.0.43 (executor driver) (36/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 31.0 in stage 41.0 (TID 371) in 696 ms on 10.0.0.43 (executor driver) (37/200)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000039_379' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000039
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000039_379: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000034_374' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000034
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000034_374: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 39.0 in stage 41.0 (TID 379). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Finished task 34.0 in stage 41.0 (TID 374). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 47.0 in stage 41.0 (TID 387) (10.0.0.43, executor driver, partition 47, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Starting task 48.0 in stage 41.0 (TID 388) (10.0.0.43, executor driver, partition 48, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 48.0 in stage 41.0 (TID 388)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_40 locally
25/02/04 17:13:37 INFO TaskSetManager: Finished task 34.0 in stage 41.0 (TID 374) in 698 ms on 10.0.0.43 (executor driver) (38/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_45 locally
25/02/04 17:13:37 INFO TaskSetManager: Finished task 39.0 in stage 41.0 (TID 379) in 692 ms on 10.0.0.43 (executor driver) (39/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_43 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_44 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_42 locally
25/02/04 17:13:37 INFO Executor: Running task 47.0 in stage 41.0 (TID 387)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_46 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_41 locally
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000030_370' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000030
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000030_370: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 30.0 in stage 41.0 (TID 370). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO TaskSetManager: Starting task 49.0 in stage 41.0 (TID 389) (10.0.0.43, executor driver, partition 49, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO Executor: Running task 49.0 in stage 41.0 (TID 389)
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO TaskSetManager: Finished task 30.0 in stage 41.0 (TID 370) in 766 ms on 10.0.0.43 (executor driver) (40/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_47 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_48 locally
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_49 locally
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000044_384' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000044
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000044_384: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000040_380' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000040
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000040_380: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 44.0 in stage 41.0 (TID 384). 17674 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Finished task 40.0 in stage 41.0 (TID 380). 17674 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 50.0 in stage 41.0 (TID 390) (10.0.0.43, executor driver, partition 50, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 50.0 in stage 41.0 (TID 390)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 51.0 in stage 41.0 (TID 391) (10.0.0.43, executor driver, partition 51, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 51.0 in stage 41.0 (TID 391)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 44.0 in stage 41.0 (TID 384) in 283 ms on 10.0.0.43 (executor driver) (41/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 40.0 in stage 41.0 (TID 380) in 303 ms on 10.0.0.43 (executor driver) (42/200)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000042_382' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000042
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000042_382: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000046_386' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000046
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000046_386: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000043_383' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000043
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000043_383: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 42.0 in stage 41.0 (TID 382). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Finished task 43.0 in stage 41.0 (TID 383). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 52.0 in stage 41.0 (TID 392) (10.0.0.43, executor driver, partition 52, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Starting task 53.0 in stage 41.0 (TID 393) (10.0.0.43, executor driver, partition 53, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 52.0 in stage 41.0 (TID 392)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 42.0 in stage 41.0 (TID 382) in 307 ms on 10.0.0.43 (executor driver) (43/200)
25/02/04 17:13:37 INFO Executor: Running task 53.0 in stage 41.0 (TID 393)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 43.0 in stage 41.0 (TID 383) in 306 ms on 10.0.0.43 (executor driver) (44/200)
25/02/04 17:13:37 INFO Executor: Finished task 46.0 in stage 41.0 (TID 386). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 54.0 in stage 41.0 (TID 394) (10.0.0.43, executor driver, partition 54, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 54.0 in stage 41.0 (TID 394)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 46.0 in stage 41.0 (TID 386) in 277 ms on 10.0.0.43 (executor driver) (45/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_51 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_53 locally
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000041_381' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000041
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000041_381: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_52 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_54 locally
25/02/04 17:13:37 INFO Executor: Finished task 41.0 in stage 41.0 (TID 381). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 55.0 in stage 41.0 (TID 395) (10.0.0.43, executor driver, partition 55, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 55.0 in stage 41.0 (TID 395)
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_50 locally
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_55 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000045_385' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000045
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000045_385: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000048_388' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000048
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000048_388: Committed. Elapsed time: 3 ms.
25/02/04 17:13:37 INFO Executor: Finished task 48.0 in stage 41.0 (TID 388). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Finished task 45.0 in stage 41.0 (TID 385). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 56.0 in stage 41.0 (TID 396) (10.0.0.43, executor driver, partition 56, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 56.0 in stage 41.0 (TID 396)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 57.0 in stage 41.0 (TID 397) (10.0.0.43, executor driver, partition 57, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 57.0 in stage 41.0 (TID 397)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000049_389' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000049
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000049_389: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 49.0 in stage 41.0 (TID 389). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 58.0 in stage 41.0 (TID 398) (10.0.0.43, executor driver, partition 58, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 58.0 in stage 41.0 (TID 398)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_57 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_58 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000047_387' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000047
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000047_387: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO Executor: Finished task 47.0 in stage 41.0 (TID 387). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO TaskSetManager: Starting task 59.0 in stage 41.0 (TID 399) (10.0.0.43, executor driver, partition 59, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 59.0 in stage 41.0 (TID 399)
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO TaskSetManager: Finished task 45.0 in stage 41.0 (TID 385) in 391 ms on 10.0.0.43 (executor driver) (46/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 48.0 in stage 41.0 (TID 388) in 373 ms on 10.0.0.43 (executor driver) (47/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 41.0 in stage 41.0 (TID 381) in 424 ms on 10.0.0.43 (executor driver) (48/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 49.0 in stage 41.0 (TID 389) in 348 ms on 10.0.0.43 (executor driver) (49/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 47.0 in stage 41.0 (TID 387) in 381 ms on 10.0.0.43 (executor driver) (50/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_56 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_59 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000053_393' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000053
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000053_393: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 53.0 in stage 41.0 (TID 393). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 60.0 in stage 41.0 (TID 400) (10.0.0.43, executor driver, partition 60, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 60.0 in stage 41.0 (TID 400)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 53.0 in stage 41.0 (TID 393) in 224 ms on 10.0.0.43 (executor driver) (51/200)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000051_391' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000051
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000051_391: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000054_394' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000054
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000054_394: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 51.0 in stage 41.0 (TID 391). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Finished task 54.0 in stage 41.0 (TID 394). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 61.0 in stage 41.0 (TID 401) (10.0.0.43, executor driver, partition 61, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Starting task 62.0 in stage 41.0 (TID 402) (10.0.0.43, executor driver, partition 62, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Finished task 51.0 in stage 41.0 (TID 391) in 243 ms on 10.0.0.43 (executor driver) (52/200)
25/02/04 17:13:37 INFO Executor: Running task 61.0 in stage 41.0 (TID 401)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 54.0 in stage 41.0 (TID 394) in 227 ms on 10.0.0.43 (executor driver) (53/200)
25/02/04 17:13:37 INFO Executor: Running task 62.0 in stage 41.0 (TID 402)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_60 locally
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000055_395' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000055
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000055_395: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 55.0 in stage 41.0 (TID 395). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 63.0 in stage 41.0 (TID 403) (10.0.0.43, executor driver, partition 63, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO TaskSetManager: Finished task 55.0 in stage 41.0 (TID 395) in 224 ms on 10.0.0.43 (executor driver) (54/200)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000052_392' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000052
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000052_392: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO Executor: Finished task 52.0 in stage 41.0 (TID 392). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO Executor: Running task 63.0 in stage 41.0 (TID 403)
25/02/04 17:13:37 INFO TaskSetManager: Starting task 64.0 in stage 41.0 (TID 404) (10.0.0.43, executor driver, partition 64, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Finished task 52.0 in stage 41.0 (TID 392) in 242 ms on 10.0.0.43 (executor driver) (55/200)
25/02/04 17:13:37 INFO Executor: Running task 64.0 in stage 41.0 (TID 404)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000050_390' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000050
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000050_390: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 50.0 in stage 41.0 (TID 390). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 65.0 in stage 41.0 (TID 405) (10.0.0.43, executor driver, partition 65, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 65.0 in stage 41.0 (TID 405)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 50.0 in stage 41.0 (TID 390) in 266 ms on 10.0.0.43 (executor driver) (56/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_62 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_64 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_63 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_61 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_65 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000058_398' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000058
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000058_398: Committed. Elapsed time: 2 ms.
25/02/04 17:13:37 INFO Executor: Finished task 58.0 in stage 41.0 (TID 398). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 66.0 in stage 41.0 (TID 406) (10.0.0.43, executor driver, partition 66, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 66.0 in stage 41.0 (TID 406)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000057_397' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000057
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000057_397: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 57.0 in stage 41.0 (TID 397). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 67.0 in stage 41.0 (TID 407) (10.0.0.43, executor driver, partition 67, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 67.0 in stage 41.0 (TID 407)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000056_396' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000056
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000056_396: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 56.0 in stage 41.0 (TID 396). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 68.0 in stage 41.0 (TID 408) (10.0.0.43, executor driver, partition 68, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 68.0 in stage 41.0 (TID 408)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000059_399' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000059
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000059_399: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO Executor: Finished task 59.0 in stage 41.0 (TID 399). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 69.0 in stage 41.0 (TID 409) (10.0.0.43, executor driver, partition 69, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 69.0 in stage 41.0 (TID 409)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000062_402' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000062
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000062_402: Committed. Elapsed time: 20 ms.
25/02/04 17:13:37 INFO Executor: Finished task 62.0 in stage 41.0 (TID 402). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 70.0 in stage 41.0 (TID 410) (10.0.0.43, executor driver, partition 70, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 70.0 in stage 41.0 (TID 410)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_66 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_69 locally
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_70 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_68 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_67 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO TaskSetManager: Finished task 59.0 in stage 41.0 (TID 399) in 381 ms on 10.0.0.43 (executor driver) (57/200)
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO TaskSetManager: Finished task 58.0 in stage 41.0 (TID 398) in 403 ms on 10.0.0.43 (executor driver) (58/200)
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000063_403' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000063
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000064_404' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000064
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000064_404: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000063_403: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 64.0 in stage 41.0 (TID 404). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 71.0 in stage 41.0 (TID 411) (10.0.0.43, executor driver, partition 71, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 71.0 in stage 41.0 (TID 411)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 62.0 in stage 41.0 (TID 402) in 270 ms on 10.0.0.43 (executor driver) (59/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 56.0 in stage 41.0 (TID 396) in 424 ms on 10.0.0.43 (executor driver) (60/200)
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO Executor: Finished task 63.0 in stage 41.0 (TID 403). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 72.0 in stage 41.0 (TID 412) (10.0.0.43, executor driver, partition 72, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 72.0 in stage 41.0 (TID 412)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 63.0 in stage 41.0 (TID 403) in 262 ms on 10.0.0.43 (executor driver) (61/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 64.0 in stage 41.0 (TID 404) in 260 ms on 10.0.0.43 (executor driver) (62/200)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 57.0 in stage 41.0 (TID 397) in 417 ms on 10.0.0.43 (executor driver) (63/200)
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000061_401' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000061
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000060_400' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000060
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000060_400: Committed. Elapsed time: 2 ms.
25/02/04 17:13:37 INFO Executor: Finished task 60.0 in stage 41.0 (TID 400). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_71 locally
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000061_401: Committed. Elapsed time: 1 ms.
25/02/04 17:13:37 INFO Executor: Finished task 61.0 in stage 41.0 (TID 401). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 73.0 in stage 41.0 (TID 413) (10.0.0.43, executor driver, partition 73, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO TaskSetManager: Starting task 74.0 in stage 41.0 (TID 414) (10.0.0.43, executor driver, partition 74, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO Executor: Running task 73.0 in stage 41.0 (TID 413)
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO Executor: Running task 74.0 in stage 41.0 (TID 414)
25/02/04 17:13:37 INFO TaskSetManager: Finished task 60.0 in stage 41.0 (TID 400) in 310 ms on 10.0.0.43 (executor driver) (64/200)
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO TaskSetManager: Finished task 61.0 in stage 41.0 (TID 401) in 284 ms on 10.0.0.43 (executor driver) (65/200)
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_72 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_73 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000065_405' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000065
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000065_405: Committed. Elapsed time: 0 ms.
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO Executor: Finished task 65.0 in stage 41.0 (TID 405). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_74 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO TaskSetManager: Starting task 75.0 in stage 41.0 (TID 415) (10.0.0.43, executor driver, partition 75, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO Executor: Running task 75.0 in stage 41.0 (TID 415)
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 INFO TaskSetManager: Finished task 65.0 in stage 41.0 (TID 405) in 284 ms on 10.0.0.43 (executor driver) (66/200)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_75 locally
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000068_408' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000068
25/02/04 17:13:37 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000068_408: Committed. Elapsed time: 3 ms.
25/02/04 17:13:37 INFO Executor: Finished task 68.0 in stage 41.0 (TID 408). 17631 bytes result sent to driver
25/02/04 17:13:37 INFO TaskSetManager: Starting task 76.0 in stage 41.0 (TID 416) (10.0.0.43, executor driver, partition 76, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:37 INFO TaskSetManager: Finished task 68.0 in stage 41.0 (TID 408) in 285 ms on 10.0.0.43 (executor driver) (67/200)
25/02/04 17:13:37 INFO Executor: Running task 76.0 in stage 41.0 (TID 416)
25/02/04 17:13:37 INFO BlockManager: Found block rdd_72_76 locally
25/02/04 17:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000066_406' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000066
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000066_406: Committed. Elapsed time: 1 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000069_409' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000069
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000069_409: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 66.0 in stage 41.0 (TID 406). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 77.0 in stage 41.0 (TID 417) (10.0.0.43, executor driver, partition 77, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000070_410' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000070
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000070_410: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 70.0 in stage 41.0 (TID 410). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Running task 77.0 in stage 41.0 (TID 417)
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000067_407' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000067
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000067_407: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 67.0 in stage 41.0 (TID 407). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 78.0 in stage 41.0 (TID 418) (10.0.0.43, executor driver, partition 78, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 78.0 in stage 41.0 (TID 418)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 79.0 in stage 41.0 (TID 419) (10.0.0.43, executor driver, partition 79, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000072_412' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000072
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000072_412: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 72.0 in stage 41.0 (TID 412). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 80.0 in stage 41.0 (TID 420) (10.0.0.43, executor driver, partition 80, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 79.0 in stage 41.0 (TID 419)
25/02/04 17:13:38 INFO Executor: Finished task 69.0 in stage 41.0 (TID 409). 17674 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Running task 80.0 in stage 41.0 (TID 420)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 81.0 in stage 41.0 (TID 421) (10.0.0.43, executor driver, partition 81, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 66.0 in stage 41.0 (TID 406) in 410 ms on 10.0.0.43 (executor driver) (68/200)
25/02/04 17:13:38 INFO Executor: Running task 81.0 in stage 41.0 (TID 421)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 70.0 in stage 41.0 (TID 410) in 302 ms on 10.0.0.43 (executor driver) (69/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 67.0 in stage 41.0 (TID 407) in 418 ms on 10.0.0.43 (executor driver) (70/200)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_77 locally
25/02/04 17:13:38 INFO TaskSetManager: Finished task 72.0 in stage 41.0 (TID 412) in 266 ms on 10.0.0.43 (executor driver) (71/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 69.0 in stage 41.0 (TID 409) in 354 ms on 10.0.0.43 (executor driver) (72/200)
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_78 locally
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000075_415' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000075
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000075_415: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 75.0 in stage 41.0 (TID 415). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_79 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO TaskSetManager: Starting task 82.0 in stage 41.0 (TID 422) (10.0.0.43, executor driver, partition 82, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO TaskSetManager: Finished task 75.0 in stage 41.0 (TID 415) in 247 ms on 10.0.0.43 (executor driver) (73/200)
25/02/04 17:13:38 INFO Executor: Running task 82.0 in stage 41.0 (TID 422)
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_81 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_80 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000074_414' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000074
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000074_414: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO Executor: Finished task 74.0 in stage 41.0 (TID 414). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO TaskSetManager: Starting task 83.0 in stage 41.0 (TID 423) (10.0.0.43, executor driver, partition 83, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO TaskSetManager: Finished task 74.0 in stage 41.0 (TID 414) in 271 ms on 10.0.0.43 (executor driver) (74/200)
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000073_413' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000073
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000073_413: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Running task 83.0 in stage 41.0 (TID 423)
25/02/04 17:13:38 INFO Executor: Finished task 73.0 in stage 41.0 (TID 413). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO TaskSetManager: Starting task 84.0 in stage 41.0 (TID 424) (10.0.0.43, executor driver, partition 84, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO Executor: Running task 84.0 in stage 41.0 (TID 424)
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO TaskSetManager: Finished task 73.0 in stage 41.0 (TID 413) in 275 ms on 10.0.0.43 (executor driver) (75/200)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_82 locally
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000071_411' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000071
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000071_411: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO Executor: Finished task 71.0 in stage 41.0 (TID 411). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO TaskSetManager: Starting task 85.0 in stage 41.0 (TID 425) (10.0.0.43, executor driver, partition 85, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 85.0 in stage 41.0 (TID 425)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 71.0 in stage 41.0 (TID 411) in 293 ms on 10.0.0.43 (executor driver) (76/200)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_83 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_84 locally
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_85 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:38 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:38 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:38 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000076_416' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000076
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000076_416: Committed. Elapsed time: 2 ms.
25/02/04 17:13:38 INFO Executor: Finished task 76.0 in stage 41.0 (TID 416). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 86.0 in stage 41.0 (TID 426) (10.0.0.43, executor driver, partition 86, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 76.0 in stage 41.0 (TID 416) in 435 ms on 10.0.0.43 (executor driver) (77/200)
25/02/04 17:13:38 INFO Executor: Running task 86.0 in stage 41.0 (TID 426)
25/02/04 17:13:38 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000084_424' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000084
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000084_424: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000077_417' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000077
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000077_417: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 77.0 in stage 41.0 (TID 417). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 84.0 in stage 41.0 (TID 424). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_86 locally
25/02/04 17:13:38 INFO TaskSetManager: Starting task 87.0 in stage 41.0 (TID 427) (10.0.0.43, executor driver, partition 87, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 87.0 in stage 41.0 (TID 427)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 88.0 in stage 41.0 (TID 428) (10.0.0.43, executor driver, partition 88, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 77.0 in stage 41.0 (TID 417) in 526 ms on 10.0.0.43 (executor driver) (78/200)
25/02/04 17:13:38 INFO Executor: Running task 88.0 in stage 41.0 (TID 428)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 84.0 in stage 41.0 (TID 424) in 465 ms on 10.0.0.43 (executor driver) (79/200)
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_87 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_88 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000081_421' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000081
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000081_421: Committed. Elapsed time: 1 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000082_422' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000082
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000082_422: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000085_425' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000085
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000085_425: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO Executor: Finished task 82.0 in stage 41.0 (TID 422). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 81.0 in stage 41.0 (TID 421). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 85.0 in stage 41.0 (TID 425). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 89.0 in stage 41.0 (TID 429) (10.0.0.43, executor driver, partition 89, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 89.0 in stage 41.0 (TID 429)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 90.0 in stage 41.0 (TID 430) (10.0.0.43, executor driver, partition 90, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 90.0 in stage 41.0 (TID 430)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 91.0 in stage 41.0 (TID 431) (10.0.0.43, executor driver, partition 91, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 82.0 in stage 41.0 (TID 422) in 531 ms on 10.0.0.43 (executor driver) (80/200)
25/02/04 17:13:38 INFO Executor: Running task 91.0 in stage 41.0 (TID 431)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 81.0 in stage 41.0 (TID 421) in 574 ms on 10.0.0.43 (executor driver) (81/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 85.0 in stage 41.0 (TID 425) in 519 ms on 10.0.0.43 (executor driver) (82/200)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_90 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_91 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_89 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000079_419' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000079
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000083_423' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000083
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000083_423: Committed. Elapsed time: 10 ms.
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000079_419: Committed. Elapsed time: 10 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000080_420' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000080
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000080_420: Committed. Elapsed time: 12 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000078_418' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000078
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000078_418: Committed. Elapsed time: 12 ms.
25/02/04 17:13:38 INFO Executor: Finished task 83.0 in stage 41.0 (TID 423). 17674 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 79.0 in stage 41.0 (TID 419). 17674 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 78.0 in stage 41.0 (TID 418). 17674 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 92.0 in stage 41.0 (TID 432) (10.0.0.43, executor driver, partition 92, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 83.0 in stage 41.0 (TID 423) in 658 ms on 10.0.0.43 (executor driver) (83/200)
25/02/04 17:13:38 INFO Executor: Finished task 80.0 in stage 41.0 (TID 420). 17674 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Running task 92.0 in stage 41.0 (TID 432)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 93.0 in stage 41.0 (TID 433) (10.0.0.43, executor driver, partition 93, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 93.0 in stage 41.0 (TID 433)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 94.0 in stage 41.0 (TID 434) (10.0.0.43, executor driver, partition 94, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 94.0 in stage 41.0 (TID 434)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 95.0 in stage 41.0 (TID 435) (10.0.0.43, executor driver, partition 95, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 79.0 in stage 41.0 (TID 419) in 750 ms on 10.0.0.43 (executor driver) (84/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 78.0 in stage 41.0 (TID 418) in 761 ms on 10.0.0.43 (executor driver) (85/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 80.0 in stage 41.0 (TID 420) in 759 ms on 10.0.0.43 (executor driver) (86/200)
25/02/04 17:13:38 INFO Executor: Running task 95.0 in stage 41.0 (TID 435)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_94 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_93 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_95 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_92 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000087_427' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000087
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000087_427: Committed. Elapsed time: 1 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000086_426' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000086
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000086_426: Committed. Elapsed time: 0 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000090_430' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000090
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000090_430: Committed. Elapsed time: 1 ms.
25/02/04 17:13:38 INFO Executor: Finished task 87.0 in stage 41.0 (TID 427). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 86.0 in stage 41.0 (TID 426). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Finished task 90.0 in stage 41.0 (TID 430). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO TaskSetManager: Starting task 96.0 in stage 41.0 (TID 436) (10.0.0.43, executor driver, partition 96, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Running task 96.0 in stage 41.0 (TID 436)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 97.0 in stage 41.0 (TID 437) (10.0.0.43, executor driver, partition 97, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Starting task 98.0 in stage 41.0 (TID 438) (10.0.0.43, executor driver, partition 98, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 87.0 in stage 41.0 (TID 427) in 332 ms on 10.0.0.43 (executor driver) (87/200)
25/02/04 17:13:38 INFO Executor: Running task 97.0 in stage 41.0 (TID 437)
25/02/04 17:13:38 INFO Executor: Running task 98.0 in stage 41.0 (TID 438)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 86.0 in stage 41.0 (TID 426) in 481 ms on 10.0.0.43 (executor driver) (88/200)
25/02/04 17:13:38 INFO TaskSetManager: Finished task 90.0 in stage 41.0 (TID 430) in 271 ms on 10.0.0.43 (executor driver) (89/200)
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000088_428' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000088
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000088_428: Committed. Elapsed time: 11 ms.
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000089_429' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000089
25/02/04 17:13:38 INFO Executor: Finished task 88.0 in stage 41.0 (TID 428). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000089_429: Committed. Elapsed time: 11 ms.
25/02/04 17:13:38 INFO TaskSetManager: Starting task 99.0 in stage 41.0 (TID 439) (10.0.0.43, executor driver, partition 99, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO Executor: Finished task 89.0 in stage 41.0 (TID 429). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO Executor: Running task 99.0 in stage 41.0 (TID 439)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 100.0 in stage 41.0 (TID 440) (10.0.0.43, executor driver, partition 100, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000091_431' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000091
25/02/04 17:13:38 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000091_431: Committed. Elapsed time: 14 ms.
25/02/04 17:13:38 INFO Executor: Finished task 91.0 in stage 41.0 (TID 431). 17631 bytes result sent to driver
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_96 locally
25/02/04 17:13:38 INFO TaskSetManager: Finished task 88.0 in stage 41.0 (TID 428) in 342 ms on 10.0.0.43 (executor driver) (90/200)
25/02/04 17:13:38 INFO Executor: Running task 100.0 in stage 41.0 (TID 440)
25/02/04 17:13:38 INFO TaskSetManager: Starting task 101.0 in stage 41.0 (TID 441) (10.0.0.43, executor driver, partition 101, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:38 INFO TaskSetManager: Finished task 89.0 in stage 41.0 (TID 429) in 285 ms on 10.0.0.43 (executor driver) (91/200)
25/02/04 17:13:38 INFO Executor: Running task 101.0 in stage 41.0 (TID 441)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_97 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_98 locally
25/02/04 17:13:38 INFO TaskSetManager: Finished task 91.0 in stage 41.0 (TID 431) in 286 ms on 10.0.0.43 (executor driver) (92/200)
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_99 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_100 locally
25/02/04 17:13:38 INFO BlockManager: Found block rdd_72_101 locally
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000092_432' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000092
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000092_432: Committed. Elapsed time: 4 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000095_435' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000095
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000095_435: Committed. Elapsed time: 4 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000093_433' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000093
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000093_433: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 92.0 in stage 41.0 (TID 432). 17674 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 95.0 in stage 41.0 (TID 435). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 93.0 in stage 41.0 (TID 433). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 102.0 in stage 41.0 (TID 442) (10.0.0.43, executor driver, partition 102, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 102.0 in stage 41.0 (TID 442)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 92.0 in stage 41.0 (TID 432) in 302 ms on 10.0.0.43 (executor driver) (93/200)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 103.0 in stage 41.0 (TID 443) (10.0.0.43, executor driver, partition 103, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 103.0 in stage 41.0 (TID 443)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000094_434' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000094
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000094_434: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 94.0 in stage 41.0 (TID 434). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 104.0 in stage 41.0 (TID 444) (10.0.0.43, executor driver, partition 104, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 104.0 in stage 41.0 (TID 444)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 95.0 in stage 41.0 (TID 435) in 293 ms on 10.0.0.43 (executor driver) (94/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 93.0 in stage 41.0 (TID 433) in 314 ms on 10.0.0.43 (executor driver) (95/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_103 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_102 locally
25/02/04 17:13:39 INFO TaskSetManager: Starting task 105.0 in stage 41.0 (TID 445) (10.0.0.43, executor driver, partition 105, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 105.0 in stage 41.0 (TID 445)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 94.0 in stage 41.0 (TID 434) in 313 ms on 10.0.0.43 (executor driver) (96/200)
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_104 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_105 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000101_441' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000101
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000101_441: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000096_436' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000096
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000096_436: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 101.0 in stage 41.0 (TID 441). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000100_440' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000100
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000100_440: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 96.0 in stage 41.0 (TID 436). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000099_439' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000099
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000099_439: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 99.0 in stage 41.0 (TID 439). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 100.0 in stage 41.0 (TID 440). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 106.0 in stage 41.0 (TID 446) (10.0.0.43, executor driver, partition 106, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 101.0 in stage 41.0 (TID 441) in 265 ms on 10.0.0.43 (executor driver) (97/200)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000097_437' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000097
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000097_437: Committed. Elapsed time: 2 ms.
25/02/04 17:13:39 INFO Executor: Running task 106.0 in stage 41.0 (TID 446)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 107.0 in stage 41.0 (TID 447) (10.0.0.43, executor driver, partition 107, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 107.0 in stage 41.0 (TID 447)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 108.0 in stage 41.0 (TID 448) (10.0.0.43, executor driver, partition 108, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Starting task 109.0 in stage 41.0 (TID 449) (10.0.0.43, executor driver, partition 109, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 100.0 in stage 41.0 (TID 440) in 276 ms on 10.0.0.43 (executor driver) (98/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 96.0 in stage 41.0 (TID 436) in 289 ms on 10.0.0.43 (executor driver) (99/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 99.0 in stage 41.0 (TID 439) in 279 ms on 10.0.0.43 (executor driver) (100/200)
25/02/04 17:13:39 INFO Executor: Running task 109.0 in stage 41.0 (TID 449)
25/02/04 17:13:39 INFO Executor: Running task 108.0 in stage 41.0 (TID 448)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000098_438' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000098
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000098_438: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 97.0 in stage 41.0 (TID 437). 17674 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 110.0 in stage 41.0 (TID 450) (10.0.0.43, executor driver, partition 110, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 110.0 in stage 41.0 (TID 450)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 97.0 in stage 41.0 (TID 437) in 291 ms on 10.0.0.43 (executor driver) (101/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_107 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_108 locally
25/02/04 17:13:39 INFO Executor: Finished task 98.0 in stage 41.0 (TID 438). 17674 bytes result sent to driver
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_109 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO TaskSetManager: Starting task 111.0 in stage 41.0 (TID 451) (10.0.0.43, executor driver, partition 111, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO TaskSetManager: Finished task 98.0 in stage 41.0 (TID 438) in 317 ms on 10.0.0.43 (executor driver) (102/200)
25/02/04 17:13:39 INFO Executor: Running task 111.0 in stage 41.0 (TID 451)
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_106 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_110 locally
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_111 locally
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000103_443' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000103
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000103_443: Committed. Elapsed time: 4 ms.
25/02/04 17:13:39 INFO Executor: Finished task 103.0 in stage 41.0 (TID 443). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 112.0 in stage 41.0 (TID 452) (10.0.0.43, executor driver, partition 112, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 103.0 in stage 41.0 (TID 443) in 255 ms on 10.0.0.43 (executor driver) (103/200)
25/02/04 17:13:39 INFO Executor: Running task 112.0 in stage 41.0 (TID 452)
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_112 locally
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000105_445' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000105
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000105_445: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000102_442' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000102
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000102_442: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 105.0 in stage 41.0 (TID 445). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO Executor: Finished task 102.0 in stage 41.0 (TID 442). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000104_444' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000104
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000104_444: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000111_451' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000111
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000111_451: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 104.0 in stage 41.0 (TID 444). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000110_450' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000110
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000110_450: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 111.0 in stage 41.0 (TID 451). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 110.0 in stage 41.0 (TID 450). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Finished task 105.0 in stage 41.0 (TID 445) in 288 ms on 10.0.0.43 (executor driver) (104/200)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 113.0 in stage 41.0 (TID 453) (10.0.0.43, executor driver, partition 113, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 113.0 in stage 41.0 (TID 453)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 102.0 in stage 41.0 (TID 442) in 358 ms on 10.0.0.43 (executor driver) (105/200)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 114.0 in stage 41.0 (TID 454) (10.0.0.43, executor driver, partition 114, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 114.0 in stage 41.0 (TID 454)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 115.0 in stage 41.0 (TID 455) (10.0.0.43, executor driver, partition 115, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Starting task 116.0 in stage 41.0 (TID 456) (10.0.0.43, executor driver, partition 116, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 115.0 in stage 41.0 (TID 455)
25/02/04 17:13:39 INFO Executor: Running task 116.0 in stage 41.0 (TID 456)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 117.0 in stage 41.0 (TID 457) (10.0.0.43, executor driver, partition 117, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 117.0 in stage 41.0 (TID 457)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 104.0 in stage 41.0 (TID 444) in 352 ms on 10.0.0.43 (executor driver) (106/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 110.0 in stage 41.0 (TID 450) in 242 ms on 10.0.0.43 (executor driver) (107/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 111.0 in stage 41.0 (TID 451) in 217 ms on 10.0.0.43 (executor driver) (108/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_113 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_117 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_114 locally
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000109_449' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000109
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000109_449: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_115 locally
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000106_446' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000106
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000107_447' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000107
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000107_447: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000106_446: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000108_448' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000108
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000108_448: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_116 locally
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO Executor: Finished task 108.0 in stage 41.0 (TID 448). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 107.0 in stage 41.0 (TID 447). 17674 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 106.0 in stage 41.0 (TID 446). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 109.0 in stage 41.0 (TID 449). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 118.0 in stage 41.0 (TID 458) (10.0.0.43, executor driver, partition 118, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 118.0 in stage 41.0 (TID 458)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 119.0 in stage 41.0 (TID 459) (10.0.0.43, executor driver, partition 119, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 119.0 in stage 41.0 (TID 459)
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO TaskSetManager: Starting task 120.0 in stage 41.0 (TID 460) (10.0.0.43, executor driver, partition 120, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO TaskSetManager: Starting task 121.0 in stage 41.0 (TID 461) (10.0.0.43, executor driver, partition 121, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 120.0 in stage 41.0 (TID 460)
25/02/04 17:13:39 INFO Executor: Running task 121.0 in stage 41.0 (TID 461)
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_121 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_119 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_120 locally
25/02/04 17:13:39 INFO TaskSetManager: Finished task 107.0 in stage 41.0 (TID 447) in 288 ms on 10.0.0.43 (executor driver) (109/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 108.0 in stage 41.0 (TID 448) in 298 ms on 10.0.0.43 (executor driver) (110/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 106.0 in stage 41.0 (TID 446) in 305 ms on 10.0.0.43 (executor driver) (111/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 109.0 in stage 41.0 (TID 449) in 299 ms on 10.0.0.43 (executor driver) (112/200)
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_118 locally
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000112_452' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000112
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000112_452: Committed. Elapsed time: 5 ms.
25/02/04 17:13:39 INFO Executor: Finished task 112.0 in stage 41.0 (TID 452). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 122.0 in stage 41.0 (TID 462) (10.0.0.43, executor driver, partition 122, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 122.0 in stage 41.0 (TID 462)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 112.0 in stage 41.0 (TID 452) in 218 ms on 10.0.0.43 (executor driver) (113/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_122 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000115_455' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000115
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000115_455: Committed. Elapsed time: 3 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000119_459' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000119
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000119_459: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 115.0 in stage 41.0 (TID 455). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000114_454' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000114
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000114_454: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO TaskSetManager: Starting task 123.0 in stage 41.0 (TID 463) (10.0.0.43, executor driver, partition 123, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 115.0 in stage 41.0 (TID 455) in 222 ms on 10.0.0.43 (executor driver) (114/200)
25/02/04 17:13:39 INFO Executor: Running task 123.0 in stage 41.0 (TID 463)
25/02/04 17:13:39 INFO Executor: Finished task 119.0 in stage 41.0 (TID 459). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 114.0 in stage 41.0 (TID 454). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000117_457' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000117
25/02/04 17:13:39 INFO TaskSetManager: Starting task 124.0 in stage 41.0 (TID 464) (10.0.0.43, executor driver, partition 124, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_123 locally
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000120_460' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000120
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000117_457: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO TaskSetManager: Starting task 125.0 in stage 41.0 (TID 465) (10.0.0.43, executor driver, partition 125, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 125.0 in stage 41.0 (TID 465)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 119.0 in stage 41.0 (TID 459) in 203 ms on 10.0.0.43 (executor driver) (115/200)
25/02/04 17:13:39 INFO Executor: Running task 124.0 in stage 41.0 (TID 464)
25/02/04 17:13:39 INFO Executor: Finished task 117.0 in stage 41.0 (TID 457). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Finished task 114.0 in stage 41.0 (TID 454) in 239 ms on 10.0.0.43 (executor driver) (116/200)
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO TaskSetManager: Starting task 126.0 in stage 41.0 (TID 466) (10.0.0.43, executor driver, partition 126, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 117.0 in stage 41.0 (TID 457) in 239 ms on 10.0.0.43 (executor driver) (117/200)
25/02/04 17:13:39 INFO Executor: Running task 126.0 in stage 41.0 (TID 466)
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000120_460: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 120.0 in stage 41.0 (TID 460). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 127.0 in stage 41.0 (TID 467) (10.0.0.43, executor driver, partition 127, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 120.0 in stage 41.0 (TID 460) in 208 ms on 10.0.0.43 (executor driver) (118/200)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000116_456' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000116
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000116_456: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 116.0 in stage 41.0 (TID 456). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO TaskSetManager: Starting task 128.0 in stage 41.0 (TID 468) (10.0.0.43, executor driver, partition 128, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 128.0 in stage 41.0 (TID 468)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 116.0 in stage 41.0 (TID 456) in 246 ms on 10.0.0.43 (executor driver) (119/200)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000113_453' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000113
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000113_453: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Running task 127.0 in stage 41.0 (TID 467)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000121_461' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000121
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000121_461: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Finished task 113.0 in stage 41.0 (TID 453). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_125 locally
25/02/04 17:13:39 INFO TaskSetManager: Starting task 129.0 in stage 41.0 (TID 469) (10.0.0.43, executor driver, partition 129, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 129.0 in stage 41.0 (TID 469)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 113.0 in stage 41.0 (TID 453) in 260 ms on 10.0.0.43 (executor driver) (120/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_126 locally
25/02/04 17:13:39 INFO Executor: Finished task 121.0 in stage 41.0 (TID 461). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_124 locally
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO TaskSetManager: Starting task 130.0 in stage 41.0 (TID 470) (10.0.0.43, executor driver, partition 130, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 121.0 in stage 41.0 (TID 461) in 213 ms on 10.0.0.43 (executor driver) (121/200)
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO Executor: Running task 130.0 in stage 41.0 (TID 470)
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_128 locally
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_129 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_130 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_127 locally
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000118_458' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000118
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000118_458: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO Executor: Finished task 118.0 in stage 41.0 (TID 458). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO TaskSetManager: Starting task 131.0 in stage 41.0 (TID 471) (10.0.0.43, executor driver, partition 131, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 131.0 in stage 41.0 (TID 471)
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO TaskSetManager: Finished task 118.0 in stage 41.0 (TID 458) in 253 ms on 10.0.0.43 (executor driver) (122/200)
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_131 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000122_462' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000122
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000122_462: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 122.0 in stage 41.0 (TID 462). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 132.0 in stage 41.0 (TID 472) (10.0.0.43, executor driver, partition 132, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000126_466' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000126
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000126_466: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO Executor: Running task 132.0 in stage 41.0 (TID 472)
25/02/04 17:13:39 INFO Executor: Finished task 126.0 in stage 41.0 (TID 466). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO TaskSetManager: Starting task 133.0 in stage 41.0 (TID 473) (10.0.0.43, executor driver, partition 133, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Finished task 122.0 in stage 41.0 (TID 462) in 291 ms on 10.0.0.43 (executor driver) (123/200)
25/02/04 17:13:39 INFO Executor: Running task 133.0 in stage 41.0 (TID 473)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 126.0 in stage 41.0 (TID 466) in 164 ms on 10.0.0.43 (executor driver) (124/200)
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000125_465' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000125
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000125_465: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 125.0 in stage 41.0 (TID 465). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_132 locally
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_133 locally
25/02/04 17:13:39 INFO TaskSetManager: Starting task 134.0 in stage 41.0 (TID 474) (10.0.0.43, executor driver, partition 134, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 134.0 in stage 41.0 (TID 474)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 125.0 in stage 41.0 (TID 465) in 176 ms on 10.0.0.43 (executor driver) (125/200)
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_134 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000129_469' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000129
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000129_469: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000123_463' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000123
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000123_463: Committed. Elapsed time: 1 ms.
25/02/04 17:13:39 INFO Executor: Finished task 129.0 in stage 41.0 (TID 469). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Finished task 123.0 in stage 41.0 (TID 463). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000130_470' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000130
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000130_470: Committed. Elapsed time: 0 ms.
25/02/04 17:13:39 INFO TaskSetManager: Starting task 135.0 in stage 41.0 (TID 475) (10.0.0.43, executor driver, partition 135, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Finished task 130.0 in stage 41.0 (TID 470). 17631 bytes result sent to driver
25/02/04 17:13:39 INFO Executor: Running task 135.0 in stage 41.0 (TID 475)
25/02/04 17:13:39 INFO TaskSetManager: Starting task 136.0 in stage 41.0 (TID 476) (10.0.0.43, executor driver, partition 136, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO TaskSetManager: Starting task 137.0 in stage 41.0 (TID 477) (10.0.0.43, executor driver, partition 137, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:39 INFO Executor: Running task 136.0 in stage 41.0 (TID 476)
25/02/04 17:13:39 INFO Executor: Running task 137.0 in stage 41.0 (TID 477)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 123.0 in stage 41.0 (TID 463) in 276 ms on 10.0.0.43 (executor driver) (126/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 129.0 in stage 41.0 (TID 469) in 250 ms on 10.0.0.43 (executor driver) (127/200)
25/02/04 17:13:39 INFO TaskSetManager: Finished task 130.0 in stage 41.0 (TID 470) in 250 ms on 10.0.0.43 (executor driver) (128/200)
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_136 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_135 locally
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO BlockManager: Found block rdd_72_137 locally
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:39 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:39 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000132_472' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000132
25/02/04 17:13:39 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000132_472: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000128_468' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000128
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000128_468: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Finished task 128.0 in stage 41.0 (TID 468). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 132.0 in stage 41.0 (TID 472). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 138.0 in stage 41.0 (TID 478) (10.0.0.43, executor driver, partition 138, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 139.0 in stage 41.0 (TID 479) (10.0.0.43, executor driver, partition 139, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 138.0 in stage 41.0 (TID 478)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 128.0 in stage 41.0 (TID 468) in 363 ms on 10.0.0.43 (executor driver) (129/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 132.0 in stage 41.0 (TID 472) in 213 ms on 10.0.0.43 (executor driver) (130/200)
25/02/04 17:13:40 INFO Executor: Running task 139.0 in stage 41.0 (TID 479)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_138 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_139 locally
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000127_467' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000127
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000127_467: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000137_477' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000137
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000137_477: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000124_464' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000124
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000124_464: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000133_473' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000133
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000133_473: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 137.0 in stage 41.0 (TID 477). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000134_474' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000134
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000134_474: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Finished task 127.0 in stage 41.0 (TID 467). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 124.0 in stage 41.0 (TID 464). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 133.0 in stage 41.0 (TID 473). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 134.0 in stage 41.0 (TID 474). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000135_475' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000135
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000135_475: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000131_471' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000131
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000131_471: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 131.0 in stage 41.0 (TID 471). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 135.0 in stage 41.0 (TID 475). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 140.0 in stage 41.0 (TID 480) (10.0.0.43, executor driver, partition 140, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 140.0 in stage 41.0 (TID 480)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 141.0 in stage 41.0 (TID 481) (10.0.0.43, executor driver, partition 141, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 142.0 in stage 41.0 (TID 482) (10.0.0.43, executor driver, partition 142, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 141.0 in stage 41.0 (TID 481)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 143.0 in stage 41.0 (TID 483) (10.0.0.43, executor driver, partition 143, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 144.0 in stage 41.0 (TID 484) (10.0.0.43, executor driver, partition 144, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 145.0 in stage 41.0 (TID 485) (10.0.0.43, executor driver, partition 145, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 146.0 in stage 41.0 (TID 486) (10.0.0.43, executor driver, partition 146, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO TaskSetManager: Finished task 124.0 in stage 41.0 (TID 464) in 403 ms on 10.0.0.43 (executor driver) (131/200)
25/02/04 17:13:40 INFO Executor: Running task 142.0 in stage 41.0 (TID 482)
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO TaskSetManager: Finished task 127.0 in stage 41.0 (TID 467) in 393 ms on 10.0.0.43 (executor driver) (132/200)
25/02/04 17:13:40 INFO Executor: Running task 143.0 in stage 41.0 (TID 483)
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO Executor: Running task 144.0 in stage 41.0 (TID 484)
25/02/04 17:13:40 INFO Executor: Running task 145.0 in stage 41.0 (TID 485)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 137.0 in stage 41.0 (TID 477) in 146 ms on 10.0.0.43 (executor driver) (133/200)
25/02/04 17:13:40 INFO Executor: Running task 146.0 in stage 41.0 (TID 486)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 131.0 in stage 41.0 (TID 471) in 354 ms on 10.0.0.43 (executor driver) (134/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 134.0 in stage 41.0 (TID 474) in 228 ms on 10.0.0.43 (executor driver) (135/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 135.0 in stage 41.0 (TID 475) in 151 ms on 10.0.0.43 (executor driver) (136/200)
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO TaskSetManager: Finished task 133.0 in stage 41.0 (TID 473) in 239 ms on 10.0.0.43 (executor driver) (137/200)
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_143 locally
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_144 locally
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_142 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_140 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_146 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_145 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_141 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000136_476' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000136
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000136_476: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Finished task 136.0 in stage 41.0 (TID 476). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 147.0 in stage 41.0 (TID 487) (10.0.0.43, executor driver, partition 147, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 147.0 in stage 41.0 (TID 487)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 136.0 in stage 41.0 (TID 476) in 274 ms on 10.0.0.43 (executor driver) (138/200)
25/02/04 17:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_147 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000138_478' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000138
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000138_478: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 138.0 in stage 41.0 (TID 478). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 148.0 in stage 41.0 (TID 488) (10.0.0.43, executor driver, partition 148, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 148.0 in stage 41.0 (TID 488)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 138.0 in stage 41.0 (TID 478) in 249 ms on 10.0.0.43 (executor driver) (139/200)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_148 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000139_479' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000139
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000139_479: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000142_482' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000142
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000142_482: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 142.0 in stage 41.0 (TID 482). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 139.0 in stage 41.0 (TID 479). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 149.0 in stage 41.0 (TID 489) (10.0.0.43, executor driver, partition 149, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000144_484' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000144
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000141_481' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000141
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000144_484: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000146_486' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000146
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000143_483' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000143
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000140_480' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000140
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000140_480: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000143_483: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000141_481: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000146_486: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Running task 149.0 in stage 41.0 (TID 489)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 150.0 in stage 41.0 (TID 490) (10.0.0.43, executor driver, partition 150, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 150.0 in stage 41.0 (TID 490)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 142.0 in stage 41.0 (TID 482) in 291 ms on 10.0.0.43 (executor driver) (140/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 139.0 in stage 41.0 (TID 479) in 318 ms on 10.0.0.43 (executor driver) (141/200)
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000145_485' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000145
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000145_485: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Finished task 145.0 in stage 41.0 (TID 485). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 141.0 in stage 41.0 (TID 481). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 143.0 in stage 41.0 (TID 483). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 146.0 in stage 41.0 (TID 486). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 140.0 in stage 41.0 (TID 480). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 144.0 in stage 41.0 (TID 484). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_150 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_149 locally
25/02/04 17:13:40 INFO TaskSetManager: Starting task 151.0 in stage 41.0 (TID 491) (10.0.0.43, executor driver, partition 151, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 152.0 in stage 41.0 (TID 492) (10.0.0.43, executor driver, partition 152, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 151.0 in stage 41.0 (TID 491)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 153.0 in stage 41.0 (TID 493) (10.0.0.43, executor driver, partition 153, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 154.0 in stage 41.0 (TID 494) (10.0.0.43, executor driver, partition 154, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 155.0 in stage 41.0 (TID 495) (10.0.0.43, executor driver, partition 155, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 156.0 in stage 41.0 (TID 496) (10.0.0.43, executor driver, partition 156, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 153.0 in stage 41.0 (TID 493)
25/02/04 17:13:40 INFO Executor: Running task 155.0 in stage 41.0 (TID 495)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 143.0 in stage 41.0 (TID 483) in 312 ms on 10.0.0.43 (executor driver) (142/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 146.0 in stage 41.0 (TID 486) in 312 ms on 10.0.0.43 (executor driver) (143/200)
25/02/04 17:13:40 INFO Executor: Running task 152.0 in stage 41.0 (TID 492)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 140.0 in stage 41.0 (TID 480) in 317 ms on 10.0.0.43 (executor driver) (144/200)
25/02/04 17:13:40 INFO Executor: Running task 156.0 in stage 41.0 (TID 496)
25/02/04 17:13:40 INFO Executor: Running task 154.0 in stage 41.0 (TID 494)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 145.0 in stage 41.0 (TID 485) in 315 ms on 10.0.0.43 (executor driver) (145/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 144.0 in stage 41.0 (TID 484) in 316 ms on 10.0.0.43 (executor driver) (146/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 141.0 in stage 41.0 (TID 481) in 321 ms on 10.0.0.43 (executor driver) (147/200)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_154 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_155 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_151 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_152 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_153 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_156 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000147_487' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000147
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000147_487: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO Executor: Finished task 147.0 in stage 41.0 (TID 487). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 157.0 in stage 41.0 (TID 497) (10.0.0.43, executor driver, partition 157, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Finished task 147.0 in stage 41.0 (TID 487) in 250 ms on 10.0.0.43 (executor driver) (148/200)
25/02/04 17:13:40 INFO Executor: Running task 157.0 in stage 41.0 (TID 497)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_157 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000148_488' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000148
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000148_488: Committed. Elapsed time: 5 ms.
25/02/04 17:13:40 INFO Executor: Finished task 148.0 in stage 41.0 (TID 488). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO TaskSetManager: Starting task 158.0 in stage 41.0 (TID 498) (10.0.0.43, executor driver, partition 158, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 158.0 in stage 41.0 (TID 498)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 148.0 in stage 41.0 (TID 488) in 269 ms on 10.0.0.43 (executor driver) (149/200)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_158 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000155_495' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000155
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000155_495: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000156_496' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000156
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000156_496: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000149_489' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000149
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000149_489: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 156.0 in stage 41.0 (TID 496). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 155.0 in stage 41.0 (TID 495). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000154_494' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000154
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000154_494: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 149.0 in stage 41.0 (TID 489). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 154.0 in stage 41.0 (TID 494). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 159.0 in stage 41.0 (TID 499) (10.0.0.43, executor driver, partition 159, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 159.0 in stage 41.0 (TID 499)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 160.0 in stage 41.0 (TID 500) (10.0.0.43, executor driver, partition 160, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 161.0 in stage 41.0 (TID 501) (10.0.0.43, executor driver, partition 161, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Finished task 156.0 in stage 41.0 (TID 496) in 234 ms on 10.0.0.43 (executor driver) (150/200)
25/02/04 17:13:40 INFO Executor: Running task 160.0 in stage 41.0 (TID 500)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 155.0 in stage 41.0 (TID 495) in 235 ms on 10.0.0.43 (executor driver) (151/200)
25/02/04 17:13:40 INFO Executor: Running task 161.0 in stage 41.0 (TID 501)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 149.0 in stage 41.0 (TID 489) in 280 ms on 10.0.0.43 (executor driver) (152/200)
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000150_490' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000150
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000150_490: Committed. Elapsed time: 2 ms.
25/02/04 17:13:40 INFO Executor: Finished task 150.0 in stage 41.0 (TID 490). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 162.0 in stage 41.0 (TID 502) (10.0.0.43, executor driver, partition 162, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 163.0 in stage 41.0 (TID 503) (10.0.0.43, executor driver, partition 163, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 162.0 in stage 41.0 (TID 502)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 150.0 in stage 41.0 (TID 490) in 261 ms on 10.0.0.43 (executor driver) (153/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 154.0 in stage 41.0 (TID 494) in 239 ms on 10.0.0.43 (executor driver) (154/200)
25/02/04 17:13:40 INFO Executor: Running task 163.0 in stage 41.0 (TID 503)
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000151_491' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000151
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000151_491: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000153_493' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000153
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000153_493: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_161 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_162 locally
25/02/04 17:13:40 INFO Executor: Finished task 151.0 in stage 41.0 (TID 491). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO TaskSetManager: Starting task 164.0 in stage 41.0 (TID 504) (10.0.0.43, executor driver, partition 164, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO Executor: Finished task 153.0 in stage 41.0 (TID 493). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Running task 164.0 in stage 41.0 (TID 504)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 165.0 in stage 41.0 (TID 505) (10.0.0.43, executor driver, partition 165, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Finished task 153.0 in stage 41.0 (TID 493) in 265 ms on 10.0.0.43 (executor driver) (155/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 151.0 in stage 41.0 (TID 491) in 266 ms on 10.0.0.43 (executor driver) (156/200)
25/02/04 17:13:40 INFO Executor: Running task 165.0 in stage 41.0 (TID 505)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_159 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_163 locally
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000152_492' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000152
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000152_492: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO Executor: Finished task 152.0 in stage 41.0 (TID 492). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_160 locally
25/02/04 17:13:40 INFO TaskSetManager: Starting task 166.0 in stage 41.0 (TID 506) (10.0.0.43, executor driver, partition 166, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 166.0 in stage 41.0 (TID 506)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 152.0 in stage 41.0 (TID 492) in 269 ms on 10.0.0.43 (executor driver) (157/200)
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_164 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_165 locally
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_166 locally
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000157_497' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000157
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000157_497: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000158_498' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000158
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000158_498: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO Executor: Finished task 157.0 in stage 41.0 (TID 497). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 158.0 in stage 41.0 (TID 498). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000161_501' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000161
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000161_501: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO TaskSetManager: Finished task 157.0 in stage 41.0 (TID 497) in 362 ms on 10.0.0.43 (executor driver) (158/200)
25/02/04 17:13:40 INFO Executor: Finished task 161.0 in stage 41.0 (TID 501). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000163_503' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000163
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000163_503: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO TaskSetManager: Starting task 167.0 in stage 41.0 (TID 507) (10.0.0.43, executor driver, partition 167, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 167.0 in stage 41.0 (TID 507)
25/02/04 17:13:40 INFO Executor: Finished task 163.0 in stage 41.0 (TID 503). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_167 locally
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000159_499' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000159
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000162_502' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000162
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000164_504' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000164
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000164_504: Committed. Elapsed time: 0 ms.
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000162_502: Committed. Elapsed time: 6 ms.
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000159_499: Committed. Elapsed time: 6 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000166_506' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000166
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000166_506: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO TaskSetManager: Starting task 168.0 in stage 41.0 (TID 508) (10.0.0.43, executor driver, partition 168, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO Executor: Finished task 162.0 in stage 41.0 (TID 502). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 166.0 in stage 41.0 (TID 506). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO Executor: Finished task 164.0 in stage 41.0 (TID 504). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO Executor: Running task 168.0 in stage 41.0 (TID 508)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 158.0 in stage 41.0 (TID 498) in 323 ms on 10.0.0.43 (executor driver) (159/200)
25/02/04 17:13:40 INFO Executor: Finished task 159.0 in stage 41.0 (TID 499). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000160_500' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000160
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000160_500: Committed. Elapsed time: 2 ms.
25/02/04 17:13:40 INFO TaskSetManager: Starting task 169.0 in stage 41.0 (TID 509) (10.0.0.43, executor driver, partition 169, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 170.0 in stage 41.0 (TID 510) (10.0.0.43, executor driver, partition 170, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Finished task 161.0 in stage 41.0 (TID 501) in 261 ms on 10.0.0.43 (executor driver) (160/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 163.0 in stage 41.0 (TID 503) in 258 ms on 10.0.0.43 (executor driver) (161/200)
25/02/04 17:13:40 INFO Executor: Running task 169.0 in stage 41.0 (TID 509)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 171.0 in stage 41.0 (TID 511) (10.0.0.43, executor driver, partition 171, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Finished task 160.0 in stage 41.0 (TID 500). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Finished task 162.0 in stage 41.0 (TID 502) in 260 ms on 10.0.0.43 (executor driver) (162/200)
25/02/04 17:13:40 INFO TaskSetManager: Starting task 172.0 in stage 41.0 (TID 512) (10.0.0.43, executor driver, partition 172, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 173.0 in stage 41.0 (TID 513) (10.0.0.43, executor driver, partition 173, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 174.0 in stage 41.0 (TID 514) (10.0.0.43, executor driver, partition 174, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Starting task 175.0 in stage 41.0 (TID 515) (10.0.0.43, executor driver, partition 175, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO TaskSetManager: Finished task 159.0 in stage 41.0 (TID 499) in 265 ms on 10.0.0.43 (executor driver) (163/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 166.0 in stage 41.0 (TID 506) in 231 ms on 10.0.0.43 (executor driver) (164/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 160.0 in stage 41.0 (TID 500) in 264 ms on 10.0.0.43 (executor driver) (165/200)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 164.0 in stage 41.0 (TID 504) in 237 ms on 10.0.0.43 (executor driver) (166/200)
25/02/04 17:13:40 INFO Executor: Running task 170.0 in stage 41.0 (TID 510)
25/02/04 17:13:40 INFO Executor: Running task 175.0 in stage 41.0 (TID 515)
25/02/04 17:13:40 INFO Executor: Running task 171.0 in stage 41.0 (TID 511)
25/02/04 17:13:40 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000165_505' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000165
25/02/04 17:13:40 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000165_505: Committed. Elapsed time: 1 ms.
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_168 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_169 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO Executor: Running task 174.0 in stage 41.0 (TID 514)
25/02/04 17:13:40 INFO Executor: Running task 173.0 in stage 41.0 (TID 513)
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO Executor: Running task 172.0 in stage 41.0 (TID 512)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_170 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_175 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_172 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_171 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_173 locally
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_174 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:40 INFO Executor: Finished task 165.0 in stage 41.0 (TID 505). 17631 bytes result sent to driver
25/02/04 17:13:40 INFO TaskSetManager: Starting task 176.0 in stage 41.0 (TID 516) (10.0.0.43, executor driver, partition 176, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:40 INFO Executor: Running task 176.0 in stage 41.0 (TID 516)
25/02/04 17:13:40 INFO TaskSetManager: Finished task 165.0 in stage 41.0 (TID 505) in 289 ms on 10.0.0.43 (executor driver) (167/200)
25/02/04 17:13:40 INFO BlockManager: Found block rdd_72_176 locally
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000175_515' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000175
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000175_515: Committed. Elapsed time: 0 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000167_507' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000167
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000167_507: Committed. Elapsed time: 3 ms.
25/02/04 17:13:41 INFO Executor: Finished task 167.0 in stage 41.0 (TID 507). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 175.0 in stage 41.0 (TID 515). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 177.0 in stage 41.0 (TID 517) (10.0.0.43, executor driver, partition 177, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000169_509' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000169
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000169_509: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000173_513' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000173
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000173_513: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000168_508' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000168
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000168_508: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000174_514' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000174
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000174_514: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO Executor: Running task 177.0 in stage 41.0 (TID 517)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 175.0 in stage 41.0 (TID 515) in 387 ms on 10.0.0.43 (executor driver) (168/200)
25/02/04 17:13:41 INFO Executor: Finished task 174.0 in stage 41.0 (TID 514). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 169.0 in stage 41.0 (TID 509). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 168.0 in stage 41.0 (TID 508). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000171_511' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000171
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000171_511: Committed. Elapsed time: 2 ms.
25/02/04 17:13:41 INFO Executor: Finished task 173.0 in stage 41.0 (TID 513). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000176_516' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000176
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000176_516: Committed. Elapsed time: 4 ms.
25/02/04 17:13:41 INFO Executor: Finished task 171.0 in stage 41.0 (TID 511). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 178.0 in stage 41.0 (TID 518) (10.0.0.43, executor driver, partition 178, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 178.0 in stage 41.0 (TID 518)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 179.0 in stage 41.0 (TID 519) (10.0.0.43, executor driver, partition 179, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Starting task 180.0 in stage 41.0 (TID 520) (10.0.0.43, executor driver, partition 180, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 179.0 in stage 41.0 (TID 519)
25/02/04 17:13:41 INFO Executor: Running task 180.0 in stage 41.0 (TID 520)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 181.0 in stage 41.0 (TID 521) (10.0.0.43, executor driver, partition 181, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Finished task 176.0 in stage 41.0 (TID 516). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Finished task 167.0 in stage 41.0 (TID 507) in 483 ms on 10.0.0.43 (executor driver) (169/200)
25/02/04 17:13:41 INFO Executor: Running task 181.0 in stage 41.0 (TID 521)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 174.0 in stage 41.0 (TID 514) in 391 ms on 10.0.0.43 (executor driver) (170/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 168.0 in stage 41.0 (TID 508) in 406 ms on 10.0.0.43 (executor driver) (171/200)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 182.0 in stage 41.0 (TID 522) (10.0.0.43, executor driver, partition 182, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Finished task 169.0 in stage 41.0 (TID 509) in 398 ms on 10.0.0.43 (executor driver) (172/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 173.0 in stage 41.0 (TID 513) in 393 ms on 10.0.0.43 (executor driver) (173/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 171.0 in stage 41.0 (TID 511) in 394 ms on 10.0.0.43 (executor driver) (174/200)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 183.0 in stage 41.0 (TID 523) (10.0.0.43, executor driver, partition 183, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Starting task 184.0 in stage 41.0 (TID 524) (10.0.0.43, executor driver, partition 184, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 183.0 in stage 41.0 (TID 523)
25/02/04 17:13:41 INFO Executor: Running task 184.0 in stage 41.0 (TID 524)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 176.0 in stage 41.0 (TID 516) in 341 ms on 10.0.0.43 (executor driver) (175/200)
25/02/04 17:13:41 INFO Executor: Running task 182.0 in stage 41.0 (TID 522)
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000170_510' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000170
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000170_510: Committed. Elapsed time: 0 ms.
25/02/04 17:13:41 INFO Executor: Finished task 170.0 in stage 41.0 (TID 510). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 185.0 in stage 41.0 (TID 525) (10.0.0.43, executor driver, partition 185, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 185.0 in stage 41.0 (TID 525)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 170.0 in stage 41.0 (TID 510) in 403 ms on 10.0.0.43 (executor driver) (176/200)
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_180 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_179 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_178 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_183 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_181 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_177 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_184 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_182 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_185 locally
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000172_512' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000172
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000172_512: Committed. Elapsed time: 0 ms.
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO Executor: Finished task 172.0 in stage 41.0 (TID 512). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 186.0 in stage 41.0 (TID 526) (10.0.0.43, executor driver, partition 186, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 186.0 in stage 41.0 (TID 526)
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO TaskSetManager: Finished task 172.0 in stage 41.0 (TID 512) in 441 ms on 10.0.0.43 (executor driver) (177/200)
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_186 locally
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000182_522' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000182
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000184_524' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000184
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000182_522: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000184_524: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000181_521' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000181
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000181_521: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO Executor: Finished task 181.0 in stage 41.0 (TID 521). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 182.0 in stage 41.0 (TID 522). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 184.0 in stage 41.0 (TID 524). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 187.0 in stage 41.0 (TID 527) (10.0.0.43, executor driver, partition 187, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 187.0 in stage 41.0 (TID 527)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 188.0 in stage 41.0 (TID 528) (10.0.0.43, executor driver, partition 188, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 188.0 in stage 41.0 (TID 528)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 189.0 in stage 41.0 (TID 529) (10.0.0.43, executor driver, partition 189, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 189.0 in stage 41.0 (TID 529)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 181.0 in stage 41.0 (TID 521) in 280 ms on 10.0.0.43 (executor driver) (178/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 184.0 in stage 41.0 (TID 524) in 277 ms on 10.0.0.43 (executor driver) (179/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 182.0 in stage 41.0 (TID 522) in 279 ms on 10.0.0.43 (executor driver) (180/200)
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000179_519' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000179
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000179_519: Committed. Elapsed time: 0 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000186_526' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000186
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000186_526: Committed. Elapsed time: 0 ms.
25/02/04 17:13:41 INFO Executor: Finished task 179.0 in stage 41.0 (TID 519). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 186.0 in stage 41.0 (TID 526). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 190.0 in stage 41.0 (TID 530) (10.0.0.43, executor driver, partition 190, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 190.0 in stage 41.0 (TID 530)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 191.0 in stage 41.0 (TID 531) (10.0.0.43, executor driver, partition 191, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Finished task 179.0 in stage 41.0 (TID 519) in 291 ms on 10.0.0.43 (executor driver) (181/200)
25/02/04 17:13:41 INFO Executor: Running task 191.0 in stage 41.0 (TID 531)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 186.0 in stage 41.0 (TID 526) in 243 ms on 10.0.0.43 (executor driver) (182/200)
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_187 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_189 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_188 locally
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000178_518' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000178
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000177_517' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000177
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000185_525' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000185
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000177_517: Committed. Elapsed time: 5 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000183_523' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000183
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000185_525: Committed. Elapsed time: 6 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000183_523: Committed. Elapsed time: 7 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000180_520' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000180
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000180_520: Committed. Elapsed time: 8 ms.
25/02/04 17:13:41 INFO Executor: Finished task 183.0 in stage 41.0 (TID 523). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 185.0 in stage 41.0 (TID 525). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 177.0 in stage 41.0 (TID 517). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 180.0 in stage 41.0 (TID 520). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 192.0 in stage 41.0 (TID 532) (10.0.0.43, executor driver, partition 192, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 192.0 in stage 41.0 (TID 532)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 193.0 in stage 41.0 (TID 533) (10.0.0.43, executor driver, partition 193, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Finished task 183.0 in stage 41.0 (TID 523) in 300 ms on 10.0.0.43 (executor driver) (183/200)
25/02/04 17:13:41 INFO Executor: Running task 193.0 in stage 41.0 (TID 533)
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_190 locally
25/02/04 17:13:41 INFO TaskSetManager: Starting task 194.0 in stage 41.0 (TID 534) (10.0.0.43, executor driver, partition 194, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO TaskSetManager: Finished task 185.0 in stage 41.0 (TID 525) in 293 ms on 10.0.0.43 (executor driver) (184/200)
25/02/04 17:13:41 INFO Executor: Running task 194.0 in stage 41.0 (TID 534)
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_191 locally
25/02/04 17:13:41 INFO TaskSetManager: Starting task 195.0 in stage 41.0 (TID 535) (10.0.0.43, executor driver, partition 195, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 195.0 in stage 41.0 (TID 535)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 177.0 in stage 41.0 (TID 517) in 321 ms on 10.0.0.43 (executor driver) (185/200)
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000178_518: Committed. Elapsed time: 5 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO Executor: Finished task 178.0 in stage 41.0 (TID 518). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO TaskSetManager: Finished task 180.0 in stage 41.0 (TID 520) in 306 ms on 10.0.0.43 (executor driver) (186/200)
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO TaskSetManager: Starting task 196.0 in stage 41.0 (TID 536) (10.0.0.43, executor driver, partition 196, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 196.0 in stage 41.0 (TID 536)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 178.0 in stage 41.0 (TID 518) in 310 ms on 10.0.0.43 (executor driver) (187/200)
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_192 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_196 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_193 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_194 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_195 locally
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:41 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000195_535' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000195
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000190_530' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000190
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000191_531' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000191
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000195_535: Committed. Elapsed time: 3 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000193_533' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000193
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000193_533: Committed. Elapsed time: 4 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000190_530: Committed. Elapsed time: 3 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000191_531: Committed. Elapsed time: 5 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000194_534' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000194
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000194_534: Committed. Elapsed time: 7 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000188_528' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000188
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000188_528: Committed. Elapsed time: 7 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000192_532' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000192
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000192_532: Committed. Elapsed time: 8 ms.
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000187_527' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000187
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000187_527: Committed. Elapsed time: 8 ms.
25/02/04 17:13:41 INFO Executor: Finished task 190.0 in stage 41.0 (TID 530). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 195.0 in stage 41.0 (TID 535). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 191.0 in stage 41.0 (TID 531). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 193.0 in stage 41.0 (TID 533). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Starting task 197.0 in stage 41.0 (TID 537) (10.0.0.43, executor driver, partition 197, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Finished task 188.0 in stage 41.0 (TID 528). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 192.0 in stage 41.0 (TID 532). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 194.0 in stage 41.0 (TID 534). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Finished task 190.0 in stage 41.0 (TID 530) in 248 ms on 10.0.0.43 (executor driver) (188/200)
25/02/04 17:13:41 INFO Executor: Running task 197.0 in stage 41.0 (TID 537)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 198.0 in stage 41.0 (TID 538) (10.0.0.43, executor driver, partition 198, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 198.0 in stage 41.0 (TID 538)
25/02/04 17:13:41 INFO TaskSetManager: Starting task 199.0 in stage 41.0 (TID 539) (10.0.0.43, executor driver, partition 199, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:41 INFO Executor: Running task 199.0 in stage 41.0 (TID 539)
25/02/04 17:13:41 INFO Executor: Finished task 187.0 in stage 41.0 (TID 527). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000196_536' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000196
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000189_529' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000189
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000189_529: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000196_536: Committed. Elapsed time: 1 ms.
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_198 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_197 locally
25/02/04 17:13:41 INFO BlockManager: Found block rdd_72_199 locally
25/02/04 17:13:41 INFO Executor: Finished task 196.0 in stage 41.0 (TID 536). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 189.0 in stage 41.0 (TID 529). 17631 bytes result sent to driver
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:41 INFO TaskSetManager: Finished task 195.0 in stage 41.0 (TID 535) in 281 ms on 10.0.0.43 (executor driver) (189/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 191.0 in stage 41.0 (TID 531) in 295 ms on 10.0.0.43 (executor driver) (190/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 193.0 in stage 41.0 (TID 533) in 283 ms on 10.0.0.43 (executor driver) (191/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 188.0 in stage 41.0 (TID 528) in 307 ms on 10.0.0.43 (executor driver) (192/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 192.0 in stage 41.0 (TID 532) in 285 ms on 10.0.0.43 (executor driver) (193/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 187.0 in stage 41.0 (TID 527) in 312 ms on 10.0.0.43 (executor driver) (194/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 196.0 in stage 41.0 (TID 536) in 280 ms on 10.0.0.43 (executor driver) (195/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 189.0 in stage 41.0 (TID 529) in 307 ms on 10.0.0.43 (executor driver) (196/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 194.0 in stage 41.0 (TID 534) in 284 ms on 10.0.0.43 (executor driver) (197/200)
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000197_537' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000197
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000199_539' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000199
25/02/04 17:13:41 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713288687490367440466800_0041_m_000198_538' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/interactions_full/_temporary/0/task_202502041713288687490367440466800_0041_m_000198
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000199_539: Committed. Elapsed time: 4 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000198_538: Committed. Elapsed time: 4 ms.
25/02/04 17:13:41 INFO SparkHadoopMapRedUtil: attempt_202502041713288687490367440466800_0041_m_000197_537: Committed. Elapsed time: 4 ms.
25/02/04 17:13:41 INFO Executor: Finished task 198.0 in stage 41.0 (TID 538). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 199.0 in stage 41.0 (TID 539). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO Executor: Finished task 197.0 in stage 41.0 (TID 537). 17674 bytes result sent to driver
25/02/04 17:13:41 INFO TaskSetManager: Finished task 199.0 in stage 41.0 (TID 539) in 188 ms on 10.0.0.43 (executor driver) (198/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 197.0 in stage 41.0 (TID 537) in 194 ms on 10.0.0.43 (executor driver) (199/200)
25/02/04 17:13:41 INFO TaskSetManager: Finished task 198.0 in stage 41.0 (TID 538) in 191 ms on 10.0.0.43 (executor driver) (200/200)
25/02/04 17:13:41 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
25/02/04 17:13:41 INFO DAGScheduler: ResultStage 41 (parquet at NativeMethodAccessorImpl.java:0) finished in 13.830 s
25/02/04 17:13:41 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:13:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
25/02/04 17:13:41 INFO DAGScheduler: Job 15 finished: parquet at NativeMethodAccessorImpl.java:0, took 13.883547 s
25/02/04 17:13:41 INFO FileFormatWriter: Start to commit write Job cb1a2842-38df-40a7-a8b8-a3b473a48cdd.
25/02/04 17:13:42 INFO FileFormatWriter: Write Job cb1a2842-38df-40a7-a8b8-a3b473a48cdd committed. Elapsed time: 260 ms.
25/02/04 17:13:42 INFO FileFormatWriter: Finished processing stats for write job cb1a2842-38df-40a7-a8b8-a3b473a48cdd.
25/02/04 17:13:42 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:42 INFO CodeGenerator: Code generated in 132.1955 ms
25/02/04 17:13:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:13:42 INFO DAGScheduler: Got job 16 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
25/02/04 17:13:42 INFO DAGScheduler: Final stage: ResultStage 50 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:13:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49, ShuffleMapStage 46)
25/02/04 17:13:42 INFO DAGScheduler: Missing parents: List()
25/02/04 17:13:42 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[81] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:13:43 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 299.8 KiB, free 130.1 MiB)
25/02/04 17:13:43 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 113.3 KiB, free 130.0 MiB)
25/02/04 17:13:43 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.0.43:62420 (size: 113.3 KiB, free: 150.4 MiB)
25/02/04 17:13:43 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
25/02/04 17:13:43 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 50 (MapPartitionsRDD[81] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:13:43 INFO TaskSchedulerImpl: Adding task set 50.0 with 200 tasks resource profile 0
25/02/04 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 540) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 541) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 542) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 543) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 544) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 5.0 in stage 50.0 (TID 545) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 6.0 in stage 50.0 (TID 546) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 7.0 in stage 50.0 (TID 547) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 8.0 in stage 50.0 (TID 548) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO TaskSetManager: Starting task 9.0 in stage 50.0 (TID 549) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:43 INFO Executor: Running task 9.0 in stage 50.0 (TID 549)
25/02/04 17:13:43 INFO Executor: Running task 0.0 in stage 50.0 (TID 540)
25/02/04 17:13:43 INFO Executor: Running task 8.0 in stage 50.0 (TID 548)
25/02/04 17:13:43 INFO Executor: Running task 6.0 in stage 50.0 (TID 546)
25/02/04 17:13:43 INFO Executor: Running task 7.0 in stage 50.0 (TID 547)
25/02/04 17:13:43 INFO Executor: Running task 5.0 in stage 50.0 (TID 545)
25/02/04 17:13:43 INFO Executor: Running task 3.0 in stage 50.0 (TID 543)
25/02/04 17:13:43 INFO Executor: Running task 1.0 in stage 50.0 (TID 541)
25/02/04 17:13:43 INFO Executor: Running task 2.0 in stage 50.0 (TID 542)
25/02/04 17:13:43 INFO Executor: Running task 4.0 in stage 50.0 (TID 544)
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_3 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_4 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_1 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_2 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_7 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_6 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_8 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_5 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_9 locally
25/02/04 17:13:43 INFO BlockManager: Found block rdd_72_0 locally
25/02/04 17:13:43 INFO CodeGenerator: Code generated in 25.349875 ms
25/02/04 17:13:43 INFO CodeGenerator: Code generated in 16.796083 ms
25/02/04 17:13:43 INFO CodeGenerator: Code generated in 16.456708 ms
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:43 INFO MemoryStore: 4 blocks selected for dropping (3.3 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block broadcast_24_piece0 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block broadcast_24_piece0 to disk
25/02/04 17:13:43 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:43 INFO BlockManagerInfo: Updated broadcast_24_piece0 on disk on 10.0.0.43:62420 (current size: 112.1 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block broadcast_24 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block broadcast_24 to disk
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_19 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_19 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_19 on disk on 10.0.0.43:62420 (current size: 1310.5 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_17 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_17 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_17 on disk on 10.0.0.43:62420 (current size: 1455.6 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 4 blocks, free memory is 8.9 MiB
25/02/04 17:13:43 INFO MemoryStore: 1 blocks selected for dropping (1929.1 KiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_14 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_14 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_14 on disk on 10.0.0.43:62420 (current size: 1827.2 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 1 blocks, free memory is 2.7 MiB
25/02/04 17:13:43 INFO MemoryStore: 6 blocks selected for dropping (7.3 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_12 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_12 on disk on 10.0.0.43:62420 (current size: 1138.3 KiB, original size: 1138.3 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_15 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_15 on disk on 10.0.0.43:62420 (current size: 1246.0 KiB, original size: 1246.0 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_13 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_13 on disk on 10.0.0.43:62420 (current size: 1373.4 KiB, original size: 1373.4 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_16 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_16 on disk on 10.0.0.43:62420 (current size: 1109.4 KiB, original size: 1109.4 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_10 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_10 on disk on 10.0.0.43:62420 (current size: 1093.3 KiB, original size: 1093.3 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_11 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_11 on disk on 10.0.0.43:62420 (current size: 1090.0 KiB, original size: 1090.0 KiB)
25/02/04 17:13:43 INFO MemoryStore: After dropping 6 blocks, free memory is 8.0 MiB
25/02/04 17:13:43 INFO MemoryStore: 8 blocks selected for dropping (8.7 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_18 from memory
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_18 on disk on 10.0.0.43:62420 (current size: 918.0 KiB, original size: 918.0 KiB)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_28 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_28 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_28 on disk on 10.0.0.43:62420 (current size: 1014.4 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_29 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_29 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_29 on disk on 10.0.0.43:62420 (current size: 1303.4 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_25 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_25 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_25 on disk on 10.0.0.43:62420 (current size: 930.4 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_20 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_20 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_20 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_26 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_26 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_26 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_27 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_27 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_27 on disk on 10.0.0.43:62420 (current size: 811.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_22 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_22 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_22 on disk on 10.0.0.43:62420 (current size: 1206.1 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 8 blocks, free memory is 8.8 MiB
25/02/04 17:13:43 INFO MemoryStore: 7 blocks selected for dropping (8.0 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_24 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_24 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_24 on disk on 10.0.0.43:62420 (current size: 1032.1 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_23 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_23 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_23 on disk on 10.0.0.43:62420 (current size: 1091.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_21 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_21 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_21 on disk on 10.0.0.43:62420 (current size: 911.0 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_37 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_37 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_37 on disk on 10.0.0.43:62420 (current size: 1156.5 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_30 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_30 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_30 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_32 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_32 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_32 on disk on 10.0.0.43:62420 (current size: 1224.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_34 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_34 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_34 on disk on 10.0.0.43:62420 (current size: 1065.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 7 blocks, free memory is 8.8 MiB
25/02/04 17:13:43 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_35 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_35 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_35 on disk on 10.0.0.43:62420 (current size: 1036.4 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_31 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_31 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_31 on disk on 10.0.0.43:62420 (current size: 1153.2 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 2 blocks, free memory is 3.1 MiB
25/02/04 17:13:43 INFO MemoryStore: 3 blocks selected for dropping (3.2 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_36 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_36 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_36 on disk on 10.0.0.43:62420 (current size: 1002.0 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_33 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_33 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_33 on disk on 10.0.0.43:62420 (current size: 1002.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_38 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_38 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_38 on disk on 10.0.0.43:62420 (current size: 1049.2 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 3 blocks, free memory is 4.3 MiB
25/02/04 17:13:43 INFO MemoryStore: 7 blocks selected for dropping (9.0 MiB bytes)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_39 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_39 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_39 on disk on 10.0.0.43:62420 (current size: 1210.6 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_45 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_45 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_45 on disk on 10.0.0.43:62420 (current size: 1289.8 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_40 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_40 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_40 on disk on 10.0.0.43:62420 (current size: 989.0 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_43 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_43 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_43 on disk on 10.0.0.43:62420 (current size: 1189.7 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_44 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_44 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_44 on disk on 10.0.0.43:62420 (current size: 1113.5 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_42 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_42 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_42 on disk on 10.0.0.43:62420 (current size: 1453.8 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO BlockManager: Dropping block rdd_72_46 from memory
25/02/04 17:13:43 INFO BlockManager: Writing block rdd_72_46 to disk
25/02/04 17:13:43 INFO BlockManagerInfo: Updated rdd_72_46 on disk on 10.0.0.43:62420 (current size: 1433.6 KiB, original size: 0.0 B)
25/02/04 17:13:43 INFO MemoryStore: After dropping 7 blocks, free memory is 9.3 MiB
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:44 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:44 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:44 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:44 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:44 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000009_549' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000009
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000009_549: Committed. Elapsed time: 11 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000007_547' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000007
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000007_547: Committed. Elapsed time: 13 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000000_540' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000000
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000000_540: Committed. Elapsed time: 9 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000003_543' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000003
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000003_543: Committed. Elapsed time: 10 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000005_545' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000005
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000005_545: Committed. Elapsed time: 10 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000002_542' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000002
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000002_542: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 0.0 in stage 50.0 (TID 540). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 7.0 in stage 50.0 (TID 547). 17997 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 9.0 in stage 50.0 (TID 549). 17997 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 2.0 in stage 50.0 (TID 542). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 5.0 in stage 50.0 (TID 545). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 3.0 in stage 50.0 (TID 543). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000006_546' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000006
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000006_546: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 6.0 in stage 50.0 (TID 546). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 10.0 in stage 50.0 (TID 550) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 10.0 in stage 50.0 (TID 550)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 540) in 1997 ms on 10.0.0.43 (executor driver) (1/200)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 11.0 in stage 50.0 (TID 551) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 11.0 in stage 50.0 (TID 551)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 7.0 in stage 50.0 (TID 547) in 1996 ms on 10.0.0.43 (executor driver) (2/200)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 12.0 in stage 50.0 (TID 552) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 12.0 in stage 50.0 (TID 552)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 13.0 in stage 50.0 (TID 553) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Starting task 14.0 in stage 50.0 (TID 554) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 13.0 in stage 50.0 (TID 553)
25/02/04 17:13:45 INFO Executor: Running task 14.0 in stage 50.0 (TID 554)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 15.0 in stage 50.0 (TID 555) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Finished task 5.0 in stage 50.0 (TID 545) in 1999 ms on 10.0.0.43 (executor driver) (3/200)
25/02/04 17:13:45 INFO Executor: Running task 15.0 in stage 50.0 (TID 555)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 9.0 in stage 50.0 (TID 549) in 1999 ms on 10.0.0.43 (executor driver) (4/200)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 16.0 in stage 50.0 (TID 556) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 16.0 in stage 50.0 (TID 556)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 542) in 2001 ms on 10.0.0.43 (executor driver) (5/200)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 6.0 in stage 50.0 (TID 546) in 2000 ms on 10.0.0.43 (executor driver) (6/200)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 543) in 2000 ms on 10.0.0.43 (executor driver) (7/200)
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000008_548' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000008
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000008_548: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000004_544' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000004
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000004_544: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 8.0 in stage 50.0 (TID 548). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 4.0 in stage 50.0 (TID 544). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 17.0 in stage 50.0 (TID 557) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 17.0 in stage 50.0 (TID 557)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 18.0 in stage 50.0 (TID 558) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 18.0 in stage 50.0 (TID 558)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 8.0 in stage 50.0 (TID 548) in 2055 ms on 10.0.0.43 (executor driver) (8/200)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 544) in 2056 ms on 10.0.0.43 (executor driver) (9/200)
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000001_541' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000001
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000001_541: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 1.0 in stage 50.0 (TID 541). 18040 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 19.0 in stage 50.0 (TID 559) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 19.0 in stage 50.0 (TID 559)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 541) in 2080 ms on 10.0.0.43 (executor driver) (10/200)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_11 stored as values in memory (estimated size 1153.5 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_16 stored as values in memory (estimated size 1175.6 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_13 stored as values in memory (estimated size 1448.0 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_10 stored as values in memory (estimated size 1160.4 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_17 stored as values in memory (estimated size 1538.4 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_12 stored as values in memory (estimated size 1209.2 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_14 stored as values in memory (estimated size 1929.1 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_19 stored as values in memory (estimated size 1392.1 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_15 stored as values in memory (estimated size 1319.8 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_18 stored as values in memory (estimated size 974.0 KiB, free 160.6 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_11 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_13 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_10 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_18 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_17 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_12 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_16 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_14 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_19 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_15 locally
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:45 INFO MemoryStore: 6 blocks selected for dropping (6.7 MiB bytes)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_41 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_41 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_41 on disk on 10.0.0.43:62420 (current size: 1165.3 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_47 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_47 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_47 on disk on 10.0.0.43:62420 (current size: 1107.8 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_48 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_48 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_48 on disk on 10.0.0.43:62420 (current size: 1205.2 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_49 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_49 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_49 on disk on 10.0.0.43:62420 (current size: 990.4 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_51 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_51 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_51 on disk on 10.0.0.43:62420 (current size: 958.4 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_53 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_53 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_53 on disk on 10.0.0.43:62420 (current size: 997.8 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO MemoryStore: After dropping 6 blocks, free memory is 8.9 MiB
25/02/04 17:13:45 INFO MemoryStore: 1 blocks selected for dropping (1374.8 KiB bytes)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_52 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_52 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_52 on disk on 10.0.0.43:62420 (current size: 1301.8 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:13:45 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:45 INFO MemoryStore: 6 blocks selected for dropping (7.1 MiB bytes)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_54 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_54 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_54 on disk on 10.0.0.43:62420 (current size: 1092.8 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_50 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_50 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_50 on disk on 10.0.0.43:62420 (current size: 1473.5 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_55 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_55 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_55 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_58 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_58 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_58 on disk on 10.0.0.43:62420 (current size: 901.1 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_57 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_57 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_57 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_56 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_56 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_56 on disk on 10.0.0.43:62420 (current size: 1068.0 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO MemoryStore: After dropping 6 blocks, free memory is 9.0 MiB
25/02/04 17:13:45 INFO MemoryStore: 1 blocks selected for dropping (1403.8 KiB bytes)
25/02/04 17:13:45 INFO BlockManager: Dropping block rdd_72_59 from memory
25/02/04 17:13:45 INFO BlockManager: Writing block rdd_72_59 to disk
25/02/04 17:13:45 INFO BlockManagerInfo: Updated rdd_72_59 on disk on 10.0.0.43:62420 (current size: 1326.4 KiB, original size: 0.0 B)
25/02/04 17:13:45 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:13:45 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:45 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:45 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000018_558' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000018
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000018_558: Committed. Elapsed time: 1 ms.
25/02/04 17:13:45 INFO Executor: Finished task 18.0 in stage 50.0 (TID 558). 17997 bytes result sent to driver
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000011_551' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000011
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000011_551: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000012_552' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000012
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000012_552: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 11.0 in stage 50.0 (TID 551). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Finished task 12.0 in stage 50.0 (TID 552). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 20.0 in stage 50.0 (TID 560) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000010_550' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000010
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000010_550: Committed. Elapsed time: 1 ms.
25/02/04 17:13:45 INFO Executor: Finished task 10.0 in stage 50.0 (TID 550). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Running task 20.0 in stage 50.0 (TID 560)
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000015_555' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000015
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000019_559' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000019
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000019_559: Committed. Elapsed time: 13 ms.
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000015_555: Committed. Elapsed time: 13 ms.
25/02/04 17:13:45 INFO TaskSetManager: Starting task 21.0 in stage 50.0 (TID 561) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Finished task 15.0 in stage 50.0 (TID 555). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000016_556' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000016
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000016_556: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO Executor: Finished task 16.0 in stage 50.0 (TID 556). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO Executor: Running task 21.0 in stage 50.0 (TID 561)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 18.0 in stage 50.0 (TID 558) in 606 ms on 10.0.0.43 (executor driver) (11/200)
25/02/04 17:13:45 INFO Executor: Finished task 19.0 in stage 50.0 (TID 559). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Finished task 11.0 in stage 50.0 (TID 551) in 669 ms on 10.0.0.43 (executor driver) (12/200)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 22.0 in stage 50.0 (TID 562) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 22.0 in stage 50.0 (TID 562)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 23.0 in stage 50.0 (TID 563) (10.0.0.43, executor driver, partition 23, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Starting task 24.0 in stage 50.0 (TID 564) (10.0.0.43, executor driver, partition 24, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Starting task 25.0 in stage 50.0 (TID 565) (10.0.0.43, executor driver, partition 25, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Finished task 12.0 in stage 50.0 (TID 552) in 668 ms on 10.0.0.43 (executor driver) (13/200)
25/02/04 17:13:45 INFO Executor: Running task 23.0 in stage 50.0 (TID 563)
25/02/04 17:13:45 INFO Executor: Running task 24.0 in stage 50.0 (TID 564)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 10.0 in stage 50.0 (TID 550) in 689 ms on 10.0.0.43 (executor driver) (14/200)
25/02/04 17:13:45 INFO Executor: Running task 25.0 in stage 50.0 (TID 565)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 16.0 in stage 50.0 (TID 556) in 666 ms on 10.0.0.43 (executor driver) (15/200)
25/02/04 17:13:45 INFO TaskSetManager: Starting task 26.0 in stage 50.0 (TID 566) (10.0.0.43, executor driver, partition 26, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 26.0 in stage 50.0 (TID 566)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 19.0 in stage 50.0 (TID 559) in 589 ms on 10.0.0.43 (executor driver) (16/200)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 15.0 in stage 50.0 (TID 555) in 669 ms on 10.0.0.43 (executor driver) (17/200)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_21 stored as values in memory (estimated size 968.7 KiB, free 159.9 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_26 stored as values in memory (estimated size 1254.6 KiB, free 159.9 MiB)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_22 stored as values in memory (estimated size 1279.5 KiB, free 159.9 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_22 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_26 locally
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_20 stored as values in memory (estimated size 1143.9 KiB, free 163.4 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_20 locally
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_21 locally
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_25 stored as values in memory (estimated size 985.1 KiB, free 159.0 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_25 locally
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_24 stored as values in memory (estimated size 1092.3 KiB, free 157.9 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_24 locally
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_23 stored as values in memory (estimated size 1151.9 KiB, free 156.8 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_23 locally
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000013_553' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000013
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000013_553: Committed. Elapsed time: 1 ms.
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000017_557' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000017
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000017_557: Committed. Elapsed time: 1 ms.
25/02/04 17:13:45 INFO Executor: Finished task 17.0 in stage 50.0 (TID 557). 18040 bytes result sent to driver
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO TaskSetManager: Starting task 27.0 in stage 50.0 (TID 567) (10.0.0.43, executor driver, partition 27, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO TaskSetManager: Finished task 17.0 in stage 50.0 (TID 557) in 737 ms on 10.0.0.43 (executor driver) (18/200)
25/02/04 17:13:45 INFO Executor: Running task 27.0 in stage 50.0 (TID 567)
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO Executor: Finished task 13.0 in stage 50.0 (TID 553). 18040 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 28.0 in stage 50.0 (TID 568) (10.0.0.43, executor driver, partition 28, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO TaskSetManager: Finished task 13.0 in stage 50.0 (TID 553) in 806 ms on 10.0.0.43 (executor driver) (19/200)
25/02/04 17:13:45 INFO Executor: Running task 28.0 in stage 50.0 (TID 568)
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_28 stored as values in memory (estimated size 1076.3 KiB, free 44.3 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_28 locally
25/02/04 17:13:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_27 stored as values in memory (estimated size 866.2 KiB, free 43.4 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_27 locally
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000014_554' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000014
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000014_554: Committed. Elapsed time: 0 ms.
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO Executor: Finished task 14.0 in stage 50.0 (TID 554). 18040 bytes result sent to driver
25/02/04 17:13:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:45 INFO TaskSetManager: Starting task 29.0 in stage 50.0 (TID 569) (10.0.0.43, executor driver, partition 29, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 29.0 in stage 50.0 (TID 569)
25/02/04 17:13:45 INFO TaskSetManager: Finished task 14.0 in stage 50.0 (TID 554) in 851 ms on 10.0.0.43 (executor driver) (20/200)
25/02/04 17:13:45 INFO MemoryStore: Block rdd_72_29 stored as values in memory (estimated size 1378.9 KiB, free 50.1 MiB)
25/02/04 17:13:45 INFO BlockManager: Found block rdd_72_29 locally
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:45 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000020_560' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000020
25/02/04 17:13:45 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000020_560: Committed. Elapsed time: 1 ms.
25/02/04 17:13:45 INFO Executor: Finished task 20.0 in stage 50.0 (TID 560). 17954 bytes result sent to driver
25/02/04 17:13:45 INFO TaskSetManager: Starting task 30.0 in stage 50.0 (TID 570) (10.0.0.43, executor driver, partition 30, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:45 INFO Executor: Running task 30.0 in stage 50.0 (TID 570)
25/02/04 17:13:46 INFO TaskSetManager: Finished task 20.0 in stage 50.0 (TID 560) in 298 ms on 10.0.0.43 (executor driver) (21/200)
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000021_561' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000021
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000021_561: Committed. Elapsed time: 0 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000025_565' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000025
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000025_565: Committed. Elapsed time: 0 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000023_563' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000023
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000023_563: Committed. Elapsed time: 0 ms.
25/02/04 17:13:46 INFO Executor: Finished task 23.0 in stage 50.0 (TID 563). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO Executor: Finished task 25.0 in stage 50.0 (TID 565). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_30 stored as values in memory (estimated size 1339.9 KiB, free 68.8 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_30 locally
25/02/04 17:13:46 INFO Executor: Finished task 21.0 in stage 50.0 (TID 561). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO TaskSetManager: Starting task 31.0 in stage 50.0 (TID 571) (10.0.0.43, executor driver, partition 31, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO Executor: Running task 31.0 in stage 50.0 (TID 571)
25/02/04 17:13:46 INFO TaskSetManager: Starting task 32.0 in stage 50.0 (TID 572) (10.0.0.43, executor driver, partition 32, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO TaskSetManager: Starting task 33.0 in stage 50.0 (TID 573) (10.0.0.43, executor driver, partition 33, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO TaskSetManager: Finished task 25.0 in stage 50.0 (TID 565) in 285 ms on 10.0.0.43 (executor driver) (22/200)
25/02/04 17:13:46 INFO Executor: Running task 32.0 in stage 50.0 (TID 572)
25/02/04 17:13:46 INFO Executor: Running task 33.0 in stage 50.0 (TID 573)
25/02/04 17:13:46 INFO TaskSetManager: Finished task 23.0 in stage 50.0 (TID 563) in 285 ms on 10.0.0.43 (executor driver) (23/200)
25/02/04 17:13:46 INFO TaskSetManager: Finished task 21.0 in stage 50.0 (TID 561) in 300 ms on 10.0.0.43 (executor driver) (24/200)
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_31 stored as values in memory (estimated size 1222.2 KiB, free 85.6 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_31 locally
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000022_562' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000022
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000022_562: Committed. Elapsed time: 1 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO Executor: Finished task 22.0 in stage 50.0 (TID 562). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_33 stored as values in memory (estimated size 1063.3 KiB, free 82.4 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_33 locally
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_32 stored as values in memory (estimated size 1297.1 KiB, free 75.3 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_32 locally
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO TaskSetManager: Starting task 34.0 in stage 50.0 (TID 574) (10.0.0.43, executor driver, partition 34, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO TaskSetManager: Finished task 22.0 in stage 50.0 (TID 562) in 341 ms on 10.0.0.43 (executor driver) (25/200)
25/02/04 17:13:46 INFO Executor: Running task 34.0 in stage 50.0 (TID 574)
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_34 stored as values in memory (estimated size 1134.6 KiB, free 12.2 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_34 locally
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000024_564' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000024
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000024_564: Committed. Elapsed time: 1 ms.
25/02/04 17:13:46 INFO Executor: Finished task 24.0 in stage 50.0 (TID 564). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO TaskSetManager: Starting task 35.0 in stage 50.0 (TID 575) (10.0.0.43, executor driver, partition 35, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO Executor: Running task 35.0 in stage 50.0 (TID 575)
25/02/04 17:13:46 INFO TaskSetManager: Finished task 24.0 in stage 50.0 (TID 564) in 391 ms on 10.0.0.43 (executor driver) (26/200)
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000026_566' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000026
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000026_566: Committed. Elapsed time: 0 ms.
25/02/04 17:13:46 INFO Executor: Finished task 26.0 in stage 50.0 (TID 566). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO TaskSetManager: Starting task 36.0 in stage 50.0 (TID 576) (10.0.0.43, executor driver, partition 36, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO TaskSetManager: Finished task 26.0 in stage 50.0 (TID 566) in 393 ms on 10.0.0.43 (executor driver) (27/200)
25/02/04 17:13:46 INFO Executor: Running task 36.0 in stage 50.0 (TID 576)
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_35 stored as values in memory (estimated size 1098.4 KiB, free 29.1 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_35 locally
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_36 stored as values in memory (estimated size 1064.4 KiB, free 28.1 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_36 locally
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:46 INFO MemoryStore: 5 blocks selected for dropping (6.1 MiB bytes)
25/02/04 17:13:46 INFO BlockManager: Dropping block rdd_72_60 from memory
25/02/04 17:13:46 INFO BlockManager: Writing block rdd_72_60 to disk
25/02/04 17:13:46 INFO BlockManagerInfo: Updated rdd_72_60 on disk on 10.0.0.43:62420 (current size: 1347.2 KiB, original size: 0.0 B)
25/02/04 17:13:46 INFO BlockManager: Dropping block rdd_72_62 from memory
25/02/04 17:13:46 INFO BlockManager: Writing block rdd_72_62 to disk
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO BlockManagerInfo: Updated rdd_72_62 on disk on 10.0.0.43:62420 (current size: 1038.0 KiB, original size: 0.0 B)
25/02/04 17:13:46 INFO BlockManager: Dropping block rdd_72_64 from memory
25/02/04 17:13:46 INFO BlockManager: Writing block rdd_72_64 to disk
25/02/04 17:13:46 INFO BlockManagerInfo: Updated rdd_72_64 on disk on 10.0.0.43:62420 (current size: 1181.5 KiB, original size: 0.0 B)
25/02/04 17:13:46 INFO BlockManager: Dropping block rdd_72_63 from memory
25/02/04 17:13:46 INFO BlockManager: Writing block rdd_72_63 to disk
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO BlockManagerInfo: Updated rdd_72_63 on disk on 10.0.0.43:62420 (current size: 1201.6 KiB, original size: 0.0 B)
25/02/04 17:13:46 INFO BlockManager: Dropping block rdd_72_61 from memory
25/02/04 17:13:46 INFO BlockManager: Writing block rdd_72_61 to disk
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO BlockManagerInfo: Updated rdd_72_61 on disk on 10.0.0.43:62420 (current size: 1180.0 KiB, original size: 0.0 B)
25/02/04 17:13:46 INFO MemoryStore: After dropping 5 blocks, free memory is 8.2 MiB
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000027_567' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000027
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000027_567: Committed. Elapsed time: 0 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000028_568' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000028
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000028_568: Committed. Elapsed time: 1 ms.
25/02/04 17:13:46 INFO Executor: Finished task 28.0 in stage 50.0 (TID 568). 17997 bytes result sent to driver
25/02/04 17:13:46 INFO Executor: Finished task 27.0 in stage 50.0 (TID 567). 17997 bytes result sent to driver
25/02/04 17:13:46 INFO TaskSetManager: Starting task 37.0 in stage 50.0 (TID 577) (10.0.0.43, executor driver, partition 37, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO Executor: Running task 37.0 in stage 50.0 (TID 577)
25/02/04 17:13:46 INFO TaskSetManager: Starting task 38.0 in stage 50.0 (TID 578) (10.0.0.43, executor driver, partition 38, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO TaskSetManager: Finished task 28.0 in stage 50.0 (TID 568) in 426 ms on 10.0.0.43 (executor driver) (28/200)
25/02/04 17:13:46 INFO TaskSetManager: Finished task 27.0 in stage 50.0 (TID 567) in 441 ms on 10.0.0.43 (executor driver) (29/200)
25/02/04 17:13:46 INFO Executor: Running task 38.0 in stage 50.0 (TID 578)
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000029_569' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000029
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000029_569: Committed. Elapsed time: 1 ms.
25/02/04 17:13:46 INFO Executor: Finished task 29.0 in stage 50.0 (TID 569). 17954 bytes result sent to driver
25/02/04 17:13:46 INFO TaskSetManager: Starting task 39.0 in stage 50.0 (TID 579) (10.0.0.43, executor driver, partition 39, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:46 INFO TaskSetManager: Finished task 29.0 in stage 50.0 (TID 569) in 390 ms on 10.0.0.43 (executor driver) (30/200)
25/02/04 17:13:46 INFO Executor: Running task 39.0 in stage 50.0 (TID 579)
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_38 stored as values in memory (estimated size 1115.5 KiB, free 42.7 MiB)
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_39 stored as values in memory (estimated size 1282.7 KiB, free 42.7 MiB)
25/02/04 17:13:46 INFO MemoryStore: Block rdd_72_37 stored as values in memory (estimated size 1228.3 KiB, free 42.7 MiB)
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_38 locally
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_37 locally
25/02/04 17:13:46 INFO BlockManager: Found block rdd_72_39 locally
25/02/04 17:13:46 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:46 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.0.43:62420 on disk (size: 112.1 KiB)
25/02/04 17:13:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000030_570' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000030
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000031_571' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000031
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000030_570: Committed. Elapsed time: 3 ms.
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000031_571: Committed. Elapsed time: 3 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000033_573' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000033
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000036_576' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000036
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000033_573: Committed. Elapsed time: 5 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000034_574' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000034
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000036_576: Committed. Elapsed time: 6 ms.
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000034_574: Committed. Elapsed time: 6 ms.
25/02/04 17:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000032_572' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000032
25/02/04 17:13:46 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000032_572: Committed. Elapsed time: 6 ms.
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000035_575' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000035
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000035_575: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 34.0 in stage 50.0 (TID 574). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 31.0 in stage 50.0 (TID 571). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 32.0 in stage 50.0 (TID 572). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 33.0 in stage 50.0 (TID 573). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 35.0 in stage 50.0 (TID 575). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 36.0 in stage 50.0 (TID 576). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 30.0 in stage 50.0 (TID 570). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 40.0 in stage 50.0 (TID 580) (10.0.0.43, executor driver, partition 40, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 40.0 in stage 50.0 (TID 580)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 41.0 in stage 50.0 (TID 581) (10.0.0.43, executor driver, partition 41, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO TaskSetManager: Starting task 42.0 in stage 50.0 (TID 582) (10.0.0.43, executor driver, partition 42, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 41.0 in stage 50.0 (TID 581)
25/02/04 17:13:47 INFO Executor: Running task 42.0 in stage 50.0 (TID 582)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 43.0 in stage 50.0 (TID 583) (10.0.0.43, executor driver, partition 43, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 43.0 in stage 50.0 (TID 583)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 44.0 in stage 50.0 (TID 584) (10.0.0.43, executor driver, partition 44, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 44.0 in stage 50.0 (TID 584)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 45.0 in stage 50.0 (TID 585) (10.0.0.43, executor driver, partition 45, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 45.0 in stage 50.0 (TID 585)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 46.0 in stage 50.0 (TID 586) (10.0.0.43, executor driver, partition 46, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 46.0 in stage 50.0 (TID 586)
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO TaskSetManager: Finished task 31.0 in stage 50.0 (TID 571) in 1157 ms on 10.0.0.43 (executor driver) (31/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 33.0 in stage 50.0 (TID 573) in 1157 ms on 10.0.0.43 (executor driver) (32/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 34.0 in stage 50.0 (TID 574) in 1107 ms on 10.0.0.43 (executor driver) (33/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 36.0 in stage 50.0 (TID 576) in 1050 ms on 10.0.0.43 (executor driver) (34/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 35.0 in stage 50.0 (TID 575) in 1053 ms on 10.0.0.43 (executor driver) (35/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 30.0 in stage 50.0 (TID 570) in 1176 ms on 10.0.0.43 (executor driver) (36/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 32.0 in stage 50.0 (TID 572) in 1161 ms on 10.0.0.43 (executor driver) (37/200)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_44 stored as values in memory (estimated size 1177.9 KiB, free 103.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_41 stored as values in memory (estimated size 1231.3 KiB, free 101.3 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_45 stored as values in memory (estimated size 1353.6 KiB, free 103.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_40 stored as values in memory (estimated size 1050.1 KiB, free 101.3 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_45 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_40 locally
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_43 stored as values in memory (estimated size 1258.3 KiB, free 101.3 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_46 stored as values in memory (estimated size 1512.7 KiB, free 106.0 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_44 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_41 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_43 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_46 locally
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_42 stored as values in memory (estimated size 1541.0 KiB, free 99.8 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_42 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO MemoryStore: 6 blocks selected for dropping (6.7 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_65 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_65 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_65 on disk on 10.0.0.43:62420 (current size: 1371.8 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_66 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_66 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_66 on disk on 10.0.0.43:62420 (current size: 1008.2 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_69 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_69 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_69 on disk on 10.0.0.43:62420 (current size: 923.7 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_70 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_70 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_70 on disk on 10.0.0.43:62420 (current size: 993.3 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_68 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_68 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_68 on disk on 10.0.0.43:62420 (current size: 1060.9 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_67 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_67 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_67 on disk on 10.0.0.43:62420 (current size: 1079.9 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 6 blocks, free memory is 8.4 MiB
25/02/04 17:13:47 INFO MemoryStore: 2 blocks selected for dropping (2.4 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_71 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_71 to disk
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_71 on disk on 10.0.0.43:62420 (current size: 1086.2 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_72 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_72 to disk
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_72 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 2 blocks, free memory is 2.8 MiB
25/02/04 17:13:47 INFO MemoryStore: 3 blocks selected for dropping (3.6 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_73 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_73 to disk
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_73 on disk on 10.0.0.43:62420 (current size: 1176.8 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_74 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_74 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_74 on disk on 10.0.0.43:62420 (current size: 1257.7 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_75 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_75 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_75 on disk on 10.0.0.43:62420 (current size: 1009.8 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 3 blocks, free memory is 4.3 MiB
25/02/04 17:13:47 INFO MemoryStore: 2 blocks selected for dropping (2.0 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_76 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_76 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_76 on disk on 10.0.0.43:62420 (current size: 1081.3 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_77 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_77 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_77 on disk on 10.0.0.43:62420 (current size: 880.8 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:13:47 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_78 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_78 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_78 on disk on 10.0.0.43:62420 (current size: 1044.3 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_79 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_79 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_79 on disk on 10.0.0.43:62420 (current size: 984.7 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 2 blocks, free memory is 2.5 MiB
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000039_579' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000039
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000037_577' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000037
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000039_579: Committed. Elapsed time: 3 ms.
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000037_577: Committed. Elapsed time: 3 ms.
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000038_578' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000038
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000038_578: Committed. Elapsed time: 2 ms.
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO Executor: Finished task 37.0 in stage 50.0 (TID 577). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 39.0 in stage 50.0 (TID 579). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 38.0 in stage 50.0 (TID 578). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO TaskSetManager: Starting task 47.0 in stage 50.0 (TID 587) (10.0.0.43, executor driver, partition 47, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO Executor: Running task 47.0 in stage 50.0 (TID 587)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 48.0 in stage 50.0 (TID 588) (10.0.0.43, executor driver, partition 48, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 48.0 in stage 50.0 (TID 588)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 49.0 in stage 50.0 (TID 589) (10.0.0.43, executor driver, partition 49, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 49.0 in stage 50.0 (TID 589)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 37.0 in stage 50.0 (TID 577) in 1137 ms on 10.0.0.43 (executor driver) (38/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 39.0 in stage 50.0 (TID 579) in 1129 ms on 10.0.0.43 (executor driver) (39/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 38.0 in stage 50.0 (TID 578) in 1136 ms on 10.0.0.43 (executor driver) (40/200)
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000040_580' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000040
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000040_580: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 40.0 in stage 50.0 (TID 580). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 50.0 in stage 50.0 (TID 590) (10.0.0.43, executor driver, partition 50, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO TaskSetManager: Finished task 40.0 in stage 50.0 (TID 580) in 388 ms on 10.0.0.43 (executor driver) (41/200)
25/02/04 17:13:47 INFO Executor: Running task 50.0 in stage 50.0 (TID 590)
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000044_584' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000044
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000044_584: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 44.0 in stage 50.0 (TID 584). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO TaskSetManager: Starting task 51.0 in stage 50.0 (TID 591) (10.0.0.43, executor driver, partition 51, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO Executor: Running task 51.0 in stage 50.0 (TID 591)
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO TaskSetManager: Finished task 44.0 in stage 50.0 (TID 584) in 362 ms on 10.0.0.43 (executor driver) (42/200)
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_49 stored as values in memory (estimated size 1056.0 KiB, free 68.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_48 stored as values in memory (estimated size 1275.9 KiB, free 68.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_50 stored as values in memory (estimated size 1555.2 KiB, free 68.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_47 stored as values in memory (estimated size 1176.4 KiB, free 68.5 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_51 stored as values in memory (estimated size 1019.7 KiB, free 68.5 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_49 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_48 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_47 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_50 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_51 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_81 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_81 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_81 on disk on 10.0.0.43:62420 (current size: 1237.5 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_80 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_80 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_80 on disk on 10.0.0.43:62420 (current size: 1030.9 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 2 blocks, free memory is 2.9 MiB
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000043_583' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000043
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000043_583: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000045_585' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000045
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000045_585: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000041_581' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000041
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000041_581: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 43.0 in stage 50.0 (TID 583). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 45.0 in stage 50.0 (TID 585). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 52.0 in stage 50.0 (TID 592) (10.0.0.43, executor driver, partition 52, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO TaskSetManager: Starting task 53.0 in stage 50.0 (TID 593) (10.0.0.43, executor driver, partition 53, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 53.0 in stage 50.0 (TID 593)
25/02/04 17:13:47 INFO Executor: Running task 52.0 in stage 50.0 (TID 592)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 43.0 in stage 50.0 (TID 583) in 499 ms on 10.0.0.43 (executor driver) (43/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 45.0 in stage 50.0 (TID 585) in 499 ms on 10.0.0.43 (executor driver) (44/200)
25/02/04 17:13:47 INFO Executor: Finished task 41.0 in stage 50.0 (TID 581). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 54.0 in stage 50.0 (TID 594) (10.0.0.43, executor driver, partition 54, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 54.0 in stage 50.0 (TID 594)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO TaskSetManager: Finished task 41.0 in stage 50.0 (TID 581) in 528 ms on 10.0.0.43 (executor driver) (45/200)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_53 stored as values in memory (estimated size 1058.2 KiB, free 55.8 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_53 locally
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000046_586' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000046
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000046_586: Committed. Elapsed time: 1 ms.
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO Executor: Finished task 46.0 in stage 50.0 (TID 586). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_52 stored as values in memory (estimated size 1374.8 KiB, free 54.4 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_52 locally
25/02/04 17:13:47 INFO TaskSetManager: Starting task 55.0 in stage 50.0 (TID 595) (10.0.0.43, executor driver, partition 55, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 55.0 in stage 50.0 (TID 595)
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO TaskSetManager: Finished task 46.0 in stage 50.0 (TID 586) in 545 ms on 10.0.0.43 (executor driver) (46/200)
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000042_582' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000042
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000042_582: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO Executor: Finished task 42.0 in stage 50.0 (TID 582). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 56.0 in stage 50.0 (TID 596) (10.0.0.43, executor driver, partition 56, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 56.0 in stage 50.0 (TID 596)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 42.0 in stage 50.0 (TID 582) in 576 ms on 10.0.0.43 (executor driver) (47/200)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_55 stored as values in memory (estimated size 1096.5 KiB, free 38.3 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_55 locally
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_56 stored as values in memory (estimated size 1129.4 KiB, free 37.2 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_56 locally
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_54 stored as values in memory (estimated size 1153.3 KiB, free 39.4 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_54 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO MemoryStore: 5 blocks selected for dropping (5.5 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_82 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_82 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_82 on disk on 10.0.0.43:62420 (current size: 1208.8 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_83 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_83 to disk
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_83 on disk on 10.0.0.43:62420 (current size: 957.7 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_84 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_84 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_84 on disk on 10.0.0.43:62420 (current size: 1065.4 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_85 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_85 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_85 on disk on 10.0.0.43:62420 (current size: 972.6 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_86 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_86 to disk
25/02/04 17:13:47 INFO BlockManagerInfo: Updated rdd_72_86 on disk on 10.0.0.43:62420 (current size: 1061.2 KiB, original size: 0.0 B)
25/02/04 17:13:47 INFO MemoryStore: After dropping 5 blocks, free memory is 8.7 MiB
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000047_587' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000047
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000047_587: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000051_591' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000051
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000049_589' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000049
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000049_589: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000051_591: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 47.0 in stage 50.0 (TID 587). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 49.0 in stage 50.0 (TID 589). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO Executor: Finished task 51.0 in stage 50.0 (TID 591). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO TaskSetManager: Starting task 57.0 in stage 50.0 (TID 597) (10.0.0.43, executor driver, partition 57, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO Executor: Running task 57.0 in stage 50.0 (TID 597)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 58.0 in stage 50.0 (TID 598) (10.0.0.43, executor driver, partition 58, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO TaskSetManager: Finished task 47.0 in stage 50.0 (TID 587) in 381 ms on 10.0.0.43 (executor driver) (48/200)
25/02/04 17:13:47 INFO Executor: Running task 58.0 in stage 50.0 (TID 598)
25/02/04 17:13:47 INFO TaskSetManager: Starting task 59.0 in stage 50.0 (TID 599) (10.0.0.43, executor driver, partition 59, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 59.0 in stage 50.0 (TID 599)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 49.0 in stage 50.0 (TID 589) in 377 ms on 10.0.0.43 (executor driver) (49/200)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 51.0 in stage 50.0 (TID 591) in 362 ms on 10.0.0.43 (executor driver) (50/200)
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000048_588' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000048
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000048_588: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 48.0 in stage 50.0 (TID 588). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 60.0 in stage 50.0 (TID 600) (10.0.0.43, executor driver, partition 60, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 60.0 in stage 50.0 (TID 600)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_58 stored as values in memory (estimated size 960.6 KiB, free 79.0 MiB)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_57 stored as values in memory (estimated size 1342.1 KiB, free 79.0 MiB)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 48.0 in stage 50.0 (TID 588) in 420 ms on 10.0.0.43 (executor driver) (51/200)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_59 stored as values in memory (estimated size 1403.8 KiB, free 79.0 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_58 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_57 locally
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_59 locally
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000050_590' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000050
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000050_590: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 50.0 in stage 50.0 (TID 590). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 61.0 in stage 50.0 (TID 601) (10.0.0.43, executor driver, partition 61, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 61.0 in stage 50.0 (TID 601)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 50.0 in stage 50.0 (TID 590) in 421 ms on 10.0.0.43 (executor driver) (52/200)
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_60 stored as values in memory (estimated size 1426.3 KiB, free 93.6 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_60 locally
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_61 stored as values in memory (estimated size 1250.6 KiB, free 92.4 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_61 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000053_593' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000053
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000053_593: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 53.0 in stage 50.0 (TID 593). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 62.0 in stage 50.0 (TID 602) (10.0.0.43, executor driver, partition 62, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 62.0 in stage 50.0 (TID 602)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 53.0 in stage 50.0 (TID 593) in 297 ms on 10.0.0.43 (executor driver) (53/200)
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000052_592' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000052
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000052_592: Committed. Elapsed time: 0 ms.
25/02/04 17:13:47 INFO Executor: Finished task 52.0 in stage 50.0 (TID 592). 17954 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 63.0 in stage 50.0 (TID 603) (10.0.0.43, executor driver, partition 63, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO Executor: Running task 63.0 in stage 50.0 (TID 603)
25/02/04 17:13:47 INFO TaskSetManager: Finished task 52.0 in stage 50.0 (TID 592) in 312 ms on 10.0.0.43 (executor driver) (54/200)
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_62 stored as values in memory (estimated size 1097.7 KiB, free 57.4 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_62 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_63 stored as values in memory (estimated size 1263.8 KiB, free 36.1 MiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_63 locally
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000056_596' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000056
25/02/04 17:13:47 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000056_596: Committed. Elapsed time: 1 ms.
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO Executor: Finished task 56.0 in stage 50.0 (TID 596). 17997 bytes result sent to driver
25/02/04 17:13:47 INFO TaskSetManager: Starting task 64.0 in stage 50.0 (TID 604) (10.0.0.43, executor driver, partition 64, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:47 INFO TaskSetManager: Finished task 56.0 in stage 50.0 (TID 596) in 306 ms on 10.0.0.43 (executor driver) (55/200)
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO Executor: Running task 64.0 in stage 50.0 (TID 604)
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: Block rdd_72_64 stored as values in memory (estimated size 1254.2 KiB, free 918.6 KiB)
25/02/04 17:13:47 INFO BlockManager: Found block rdd_72_64 locally
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:47 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:47 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:13:47 INFO BlockManager: Dropping block rdd_72_87 from memory
25/02/04 17:13:47 INFO BlockManager: Writing block rdd_72_87 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_87 on disk on 10.0.0.43:62420 (current size: 986.6 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_88 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_88 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_88 on disk on 10.0.0.43:62420 (current size: 1270.3 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO MemoryStore: After dropping 2 blocks, free memory is 3.2 MiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1025.4 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_90 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_90 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_90 on disk on 10.0.0.43:62420 (current size: 966.9 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 1766.1 KiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1209.1 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_91 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_91 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_91 on disk on 10.0.0.43:62420 (current size: 1143.1 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1436.1 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_89 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_89 to disk
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_89 on disk on 10.0.0.43:62420 (current size: 1370.1 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.8 MiB
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000054_594' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000054
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000055_595' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000055
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000054_594: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000055_595: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO Executor: Finished task 54.0 in stage 50.0 (TID 594). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 55.0 in stage 50.0 (TID 595). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 65.0 in stage 50.0 (TID 605) (10.0.0.43, executor driver, partition 65, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 65.0 in stage 50.0 (TID 605)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 54.0 in stage 50.0 (TID 594) in 479 ms on 10.0.0.43 (executor driver) (56/200)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 66.0 in stage 50.0 (TID 606) (10.0.0.43, executor driver, partition 66, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 66.0 in stage 50.0 (TID 606)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 55.0 in stage 50.0 (TID 595) in 453 ms on 10.0.0.43 (executor driver) (57/200)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000058_598' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000058
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000058_598: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 58.0 in stage 50.0 (TID 598). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 67.0 in stage 50.0 (TID 607) (10.0.0.43, executor driver, partition 67, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 58.0 in stage 50.0 (TID 598) in 291 ms on 10.0.0.43 (executor driver) (58/200)
25/02/04 17:13:48 INFO Executor: Running task 67.0 in stage 50.0 (TID 607)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_65 stored as values in memory (estimated size 1448.7 KiB, free 35.4 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_65 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_66 stored as values in memory (estimated size 1069.9 KiB, free 65.3 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_66 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000062_602' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000062
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000062_602: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000057_597' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000057
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000057_597: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 62.0 in stage 50.0 (TID 602). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 68.0 in stage 50.0 (TID 608) (10.0.0.43, executor driver, partition 68, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 68.0 in stage 50.0 (TID 608)
25/02/04 17:13:48 INFO Executor: Finished task 57.0 in stage 50.0 (TID 597). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Finished task 62.0 in stage 50.0 (TID 602) in 237 ms on 10.0.0.43 (executor driver) (59/200)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 69.0 in stage 50.0 (TID 609) (10.0.0.43, executor driver, partition 69, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 69.0 in stage 50.0 (TID 609)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000059_599' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000059
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000059_599: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO TaskSetManager: Finished task 57.0 in stage 50.0 (TID 597) in 344 ms on 10.0.0.43 (executor driver) (60/200)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_67 stored as values in memory (estimated size 1146.0 KiB, free 69.2 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_67 locally
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000061_601' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000061
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000061_601: Committed. Elapsed time: 2 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_68 stored as values in memory (estimated size 1124.1 KiB, free 62.1 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_68 locally
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_69 stored as values in memory (estimated size 981.1 KiB, free 57.2 MiB)
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_69 locally
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO Executor: Finished task 59.0 in stage 50.0 (TID 599). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 61.0 in stage 50.0 (TID 601). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO TaskSetManager: Starting task 70.0 in stage 50.0 (TID 610) (10.0.0.43, executor driver, partition 70, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000060_600' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000060
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000060_600: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Running task 70.0 in stage 50.0 (TID 610)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 71.0 in stage 50.0 (TID 611) (10.0.0.43, executor driver, partition 71, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 59.0 in stage 50.0 (TID 599) in 366 ms on 10.0.0.43 (executor driver) (61/200)
25/02/04 17:13:48 INFO Executor: Running task 71.0 in stage 50.0 (TID 611)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 61.0 in stage 50.0 (TID 601) in 317 ms on 10.0.0.43 (executor driver) (62/200)
25/02/04 17:13:48 INFO Executor: Finished task 60.0 in stage 50.0 (TID 600). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 72.0 in stage 50.0 (TID 612) (10.0.0.43, executor driver, partition 72, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 72.0 in stage 50.0 (TID 612)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 60.0 in stage 50.0 (TID 600) in 358 ms on 10.0.0.43 (executor driver) (63/200)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000063_603' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000063
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000063_603: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 63.0 in stage 50.0 (TID 603). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 73.0 in stage 50.0 (TID 613) (10.0.0.43, executor driver, partition 73, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 73.0 in stage 50.0 (TID 613)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 63.0 in stage 50.0 (TID 603) in 294 ms on 10.0.0.43 (executor driver) (64/200)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_71 stored as values in memory (estimated size 1153.0 KiB, free 54.0 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_71 locally
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_70 stored as values in memory (estimated size 1056.1 KiB, free 53.0 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_70 locally
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_72 stored as values in memory (estimated size 1253.6 KiB, free 48.7 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_72 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_73 stored as values in memory (estimated size 1243.1 KiB, free 591.6 KiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_73 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: 2 blocks selected for dropping (2.6 MiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_94 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_94 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_94 on disk on 10.0.0.43:62420 (current size: 1355.6 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_93 from memory
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_93 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_93 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 2 blocks, free memory is 3.1 MiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1066.1 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_92 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_92 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_92 on disk on 10.0.0.43:62420 (current size: 1005.9 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 1739.7 KiB
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (998.9 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_95 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_95 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_95 on disk on 10.0.0.43:62420 (current size: 940.1 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1038.0 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_96 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_96 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_96 on disk on 10.0.0.43:62420 (current size: 977.5 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:13:48 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_97 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_97 to disk
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_97 on disk on 10.0.0.43:62420 (current size: 1303.1 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_98 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_98 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_98 on disk on 10.0.0.43:62420 (current size: 1385.8 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_99 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_99 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_99 on disk on 10.0.0.43:62420 (current size: 880.3 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_100 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_100 to disk
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_100 on disk on 10.0.0.43:62420 (current size: 1141.2 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 4 blocks, free memory is 5.1 MiB
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000064_604' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000064
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000064_604: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 64.0 in stage 50.0 (TID 604). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 74.0 in stage 50.0 (TID 614) (10.0.0.43, executor driver, partition 74, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 64.0 in stage 50.0 (TID 604) in 344 ms on 10.0.0.43 (executor driver) (65/200)
25/02/04 17:13:48 INFO Executor: Running task 74.0 in stage 50.0 (TID 614)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000065_605' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000065
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000065_605: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 65.0 in stage 50.0 (TID 605). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 75.0 in stage 50.0 (TID 615) (10.0.0.43, executor driver, partition 75, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 65.0 in stage 50.0 (TID 605) in 254 ms on 10.0.0.43 (executor driver) (66/200)
25/02/04 17:13:48 INFO Executor: Running task 75.0 in stage 50.0 (TID 615)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_74 stored as values in memory (estimated size 1337.1 KiB, free 27.8 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_74 locally
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000067_607' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000067
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000067_607: Committed. Elapsed time: 3 ms.
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_75 stored as values in memory (estimated size 1068.8 KiB, free 64.7 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_75 locally
25/02/04 17:13:48 INFO Executor: Finished task 67.0 in stage 50.0 (TID 607). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 76.0 in stage 50.0 (TID 616) (10.0.0.43, executor driver, partition 76, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 76.0 in stage 50.0 (TID 616)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 67.0 in stage 50.0 (TID 607) in 296 ms on 10.0.0.43 (executor driver) (67/200)
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000069_609' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000069
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000069_609: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000068_608' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000068
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000068_608: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 69.0 in stage 50.0 (TID 609). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 68.0 in stage 50.0 (TID 608). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 77.0 in stage 50.0 (TID 617) (10.0.0.43, executor driver, partition 77, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Starting task 78.0 in stage 50.0 (TID 618) (10.0.0.43, executor driver, partition 78, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 69.0 in stage 50.0 (TID 609) in 287 ms on 10.0.0.43 (executor driver) (68/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 68.0 in stage 50.0 (TID 608) in 289 ms on 10.0.0.43 (executor driver) (69/200)
25/02/04 17:13:48 INFO Executor: Running task 77.0 in stage 50.0 (TID 617)
25/02/04 17:13:48 INFO Executor: Running task 78.0 in stage 50.0 (TID 618)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000066_606' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000066
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000066_606: Committed. Elapsed time: 7 ms.
25/02/04 17:13:48 INFO Executor: Finished task 66.0 in stage 50.0 (TID 606). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 79.0 in stage 50.0 (TID 619) (10.0.0.43, executor driver, partition 79, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 79.0 in stage 50.0 (TID 619)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO TaskSetManager: Finished task 66.0 in stage 50.0 (TID 606) in 346 ms on 10.0.0.43 (executor driver) (70/200)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000071_611' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000071
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000071_611: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000070_610' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000070
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000070_610: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 71.0 in stage 50.0 (TID 611). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO Executor: Finished task 70.0 in stage 50.0 (TID 610). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 80.0 in stage 50.0 (TID 620) (10.0.0.43, executor driver, partition 80, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 80.0 in stage 50.0 (TID 620)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_77 stored as values in memory (estimated size 934.4 KiB, free 87.8 MiB)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 81.0 in stage 50.0 (TID 621) (10.0.0.43, executor driver, partition 81, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_77 locally
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_78 stored as values in memory (estimated size 1105.7 KiB, free 86.7 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_78 locally
25/02/04 17:13:48 INFO TaskSetManager: Finished task 71.0 in stage 50.0 (TID 611) in 259 ms on 10.0.0.43 (executor driver) (71/200)
25/02/04 17:13:48 INFO Executor: Running task 81.0 in stage 50.0 (TID 621)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 70.0 in stage 50.0 (TID 610) in 269 ms on 10.0.0.43 (executor driver) (72/200)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_76 stored as values in memory (estimated size 1148.0 KiB, free 85.6 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_76 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_81 stored as values in memory (estimated size 1309.1 KiB, free 36.3 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_81 locally
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_79 stored as values in memory (estimated size 1046.6 KiB, free 35.3 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_79 locally
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_80 stored as values in memory (estimated size 1093.8 KiB, free 34.2 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_80 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000072_612' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000072
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000072_612: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 72.0 in stage 50.0 (TID 612). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 82.0 in stage 50.0 (TID 622) (10.0.0.43, executor driver, partition 82, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 82.0 in stage 50.0 (TID 622)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO TaskSetManager: Finished task 72.0 in stage 50.0 (TID 612) in 329 ms on 10.0.0.43 (executor driver) (73/200)
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_82 stored as values in memory (estimated size 1281.3 KiB, free 997.4 KiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_82 locally
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: 2 blocks selected for dropping (2022.9 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_101 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_101 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_101 on disk on 10.0.0.43:62420 (current size: 897.5 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_103 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_103 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_103 on disk on 10.0.0.43:62420 (current size: 1003.8 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO MemoryStore: After dropping 2 blocks, free memory is 2.9 MiB
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1372.4 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_102 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_102 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_102 on disk on 10.0.0.43:62420 (current size: 1296.9 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 1832.7 KiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1184.6 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_104 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_104 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_104 on disk on 10.0.0.43:62420 (current size: 1116.1 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1205.0 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_105 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_105 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_105 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:13:48 INFO MemoryStore: 4 blocks selected for dropping (4.6 MiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_107 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_107 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_107 on disk on 10.0.0.43:62420 (current size: 1159.8 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_109 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_109 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_109 on disk on 10.0.0.43:62420 (current size: 981.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_108 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_108 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_108 on disk on 10.0.0.43:62420 (current size: 959.4 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_106 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_106 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_106 on disk on 10.0.0.43:62420 (current size: 1350.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 4 blocks, free memory is 5.2 MiB
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000073_613' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000073
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000073_613: Committed. Elapsed time: 19 ms.
25/02/04 17:13:48 INFO Executor: Finished task 73.0 in stage 50.0 (TID 613). 17954 bytes result sent to driver
25/02/04 17:13:48 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:48 INFO TaskSetManager: Starting task 83.0 in stage 50.0 (TID 623) (10.0.0.43, executor driver, partition 83, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 73.0 in stage 50.0 (TID 613) in 433 ms on 10.0.0.43 (executor driver) (74/200)
25/02/04 17:13:48 INFO Executor: Running task 83.0 in stage 50.0 (TID 623)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000077_617' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000077
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000077_617: Committed. Elapsed time: 4 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000075_615' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000075
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000075_615: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO Executor: Finished task 77.0 in stage 50.0 (TID 617). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 75.0 in stage 50.0 (TID 615). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 84.0 in stage 50.0 (TID 624) (10.0.0.43, executor driver, partition 84, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 84.0 in stage 50.0 (TID 624)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 85.0 in stage 50.0 (TID 625) (10.0.0.43, executor driver, partition 85, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 77.0 in stage 50.0 (TID 617) in 234 ms on 10.0.0.43 (executor driver) (75/200)
25/02/04 17:13:48 INFO Executor: Running task 85.0 in stage 50.0 (TID 625)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 75.0 in stage 50.0 (TID 615) in 309 ms on 10.0.0.43 (executor driver) (76/200)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_83 stored as values in memory (estimated size 1017.8 KiB, free 90.2 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_83 locally
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000078_618' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000078
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000076_616' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000076
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000079_619' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000079
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000076_616: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_85 stored as values in memory (estimated size 1035.6 KiB, free 89.2 MiB)
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000078_618: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_85 locally
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000079_619: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO Executor: Finished task 78.0 in stage 50.0 (TID 618). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 86.0 in stage 50.0 (TID 626) (10.0.0.43, executor driver, partition 86, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Finished task 76.0 in stage 50.0 (TID 616). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 79.0 in stage 50.0 (TID 619). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_84 stored as values in memory (estimated size 1123.3 KiB, free 122.1 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_84 locally
25/02/04 17:13:48 INFO Executor: Running task 86.0 in stage 50.0 (TID 626)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 87.0 in stage 50.0 (TID 627) (10.0.0.43, executor driver, partition 87, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 78.0 in stage 50.0 (TID 618) in 270 ms on 10.0.0.43 (executor driver) (77/200)
25/02/04 17:13:48 INFO Executor: Running task 87.0 in stage 50.0 (TID 627)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000080_620' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000080
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000080_620: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO TaskSetManager: Starting task 88.0 in stage 50.0 (TID 628) (10.0.0.43, executor driver, partition 88, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000081_621' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000081
25/02/04 17:13:48 INFO TaskSetManager: Finished task 79.0 in stage 50.0 (TID 619) in 248 ms on 10.0.0.43 (executor driver) (78/200)
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000081_621: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Running task 88.0 in stage 50.0 (TID 628)
25/02/04 17:13:48 INFO Executor: Finished task 80.0 in stage 50.0 (TID 620). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 89.0 in stage 50.0 (TID 629) (10.0.0.43, executor driver, partition 89, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 89.0 in stage 50.0 (TID 629)
25/02/04 17:13:48 INFO Executor: Finished task 81.0 in stage 50.0 (TID 621). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 90.0 in stage 50.0 (TID 630) (10.0.0.43, executor driver, partition 90, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 80.0 in stage 50.0 (TID 620) in 243 ms on 10.0.0.43 (executor driver) (79/200)
25/02/04 17:13:48 INFO Executor: Running task 90.0 in stage 50.0 (TID 630)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 81.0 in stage 50.0 (TID 621) in 244 ms on 10.0.0.43 (executor driver) (80/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 76.0 in stage 50.0 (TID 616) in 294 ms on 10.0.0.43 (executor driver) (81/200)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_90 stored as values in memory (estimated size 1025.4 KiB, free 103.1 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_90 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_87 stored as values in memory (estimated size 1050.2 KiB, free 91.1 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_87 locally
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_89 stored as values in memory (estimated size 1436.1 KiB, free 89.7 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_89 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_88 stored as values in memory (estimated size 1331.9 KiB, free 63.3 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_88 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_86 stored as values in memory (estimated size 1128.6 KiB, free 62.2 MiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_86 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000074_614' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000074
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000074_614: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 74.0 in stage 50.0 (TID 614). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 91.0 in stage 50.0 (TID 631) (10.0.0.43, executor driver, partition 91, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 74.0 in stage 50.0 (TID 614) in 402 ms on 10.0.0.43 (executor driver) (82/200)
25/02/04 17:13:48 INFO Executor: Running task 91.0 in stage 50.0 (TID 631)
25/02/04 17:13:48 INFO MemoryStore: Block rdd_72_91 stored as values in memory (estimated size 1209.1 KiB, free 1133.6 KiB)
25/02/04 17:13:48 INFO BlockManager: Found block rdd_72_91 locally
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:48 INFO MemoryStore: 2 blocks selected for dropping (2010.5 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_110 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_110 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_110 on disk on 10.0.0.43:62420 (current size: 920.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_111 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_111 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_111 on disk on 10.0.0.43:62420 (current size: 978.0 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 2 blocks, free memory is 3.0 MiB
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1125.1 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_112 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_112 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_112 on disk on 10.0.0.43:62420 (current size: 1062.2 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 1709.2 KiB
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1203.2 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_113 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_113 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_113 on disk on 10.0.0.43:62420 (current size: 1133.4 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: 1 blocks selected for dropping (1560.3 KiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_117 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_117 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_117 on disk on 10.0.0.43:62420 (current size: 1476.3 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 1 blocks, free memory is 2.9 MiB
25/02/04 17:13:48 INFO MemoryStore: 3 blocks selected for dropping (3.7 MiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_114 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_114 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_114 on disk on 10.0.0.43:62420 (current size: 1318.6 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_115 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_115 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_115 on disk on 10.0.0.43:62420 (current size: 826.4 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_116 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_116 to disk
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_116 on disk on 10.0.0.43:62420 (current size: 1464.6 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO MemoryStore: After dropping 3 blocks, free memory is 4.6 MiB
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:48 INFO MemoryStore: 7 blocks selected for dropping (8.3 MiB bytes)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_121 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_121 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_121 on disk on 10.0.0.43:62420 (current size: 1114.7 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_119 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_119 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_119 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_120 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_120 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_120 on disk on 10.0.0.43:62420 (current size: 1062.9 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_118 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_118 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_118 on disk on 10.0.0.43:62420 (current size: 1235.9 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_122 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_122 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_122 on disk on 10.0.0.43:62420 (current size: 1302.6 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_123 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_123 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_123 on disk on 10.0.0.43:62420 (current size: 1192.5 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO BlockManager: Dropping block rdd_72_125 from memory
25/02/04 17:13:48 INFO BlockManager: Writing block rdd_72_125 to disk
25/02/04 17:13:48 INFO BlockManagerInfo: Updated rdd_72_125 on disk on 10.0.0.43:62420 (current size: 1138.8 KiB, original size: 0.0 B)
25/02/04 17:13:48 INFO MemoryStore: After dropping 7 blocks, free memory is 8.9 MiB
25/02/04 17:13:48 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:48 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:48 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000088_628' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000088
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000088_628: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000084_624' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000084
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000084_624: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000090_630' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000090
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000090_630: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000085_625' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000085
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000085_625: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000086_626' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000086
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000086_626: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000083_623' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000083
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000083_623: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000082_622' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000082
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000082_622: Committed. Elapsed time: 1 ms.
25/02/04 17:13:48 INFO Executor: Finished task 84.0 in stage 50.0 (TID 624). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 86.0 in stage 50.0 (TID 626). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 88.0 in stage 50.0 (TID 628). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 85.0 in stage 50.0 (TID 625). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 82.0 in stage 50.0 (TID 622). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 83.0 in stage 50.0 (TID 623). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO Executor: Finished task 90.0 in stage 50.0 (TID 630). 17997 bytes result sent to driver
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000089_629' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000089
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000089_629: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 89.0 in stage 50.0 (TID 629). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:48 INFO TaskSetManager: Starting task 92.0 in stage 50.0 (TID 632) (10.0.0.43, executor driver, partition 92, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 92.0 in stage 50.0 (TID 632)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 93.0 in stage 50.0 (TID 633) (10.0.0.43, executor driver, partition 93, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Starting task 94.0 in stage 50.0 (TID 634) (10.0.0.43, executor driver, partition 94, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 93.0 in stage 50.0 (TID 633)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 95.0 in stage 50.0 (TID 635) (10.0.0.43, executor driver, partition 95, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 94.0 in stage 50.0 (TID 634)
25/02/04 17:13:48 INFO Executor: Running task 95.0 in stage 50.0 (TID 635)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 96.0 in stage 50.0 (TID 636) (10.0.0.43, executor driver, partition 96, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Starting task 97.0 in stage 50.0 (TID 637) (10.0.0.43, executor driver, partition 97, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 96.0 in stage 50.0 (TID 636)
25/02/04 17:13:48 INFO Executor: Running task 97.0 in stage 50.0 (TID 637)
25/02/04 17:13:48 INFO TaskSetManager: Starting task 98.0 in stage 50.0 (TID 638) (10.0.0.43, executor driver, partition 98, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Starting task 99.0 in stage 50.0 (TID 639) (10.0.0.43, executor driver, partition 99, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO Executor: Running task 98.0 in stage 50.0 (TID 638)
25/02/04 17:13:48 INFO Executor: Running task 99.0 in stage 50.0 (TID 639)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 84.0 in stage 50.0 (TID 624) in 305 ms on 10.0.0.43 (executor driver) (83/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 88.0 in stage 50.0 (TID 628) in 265 ms on 10.0.0.43 (executor driver) (84/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 86.0 in stage 50.0 (TID 626) in 270 ms on 10.0.0.43 (executor driver) (85/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 83.0 in stage 50.0 (TID 623) in 324 ms on 10.0.0.43 (executor driver) (86/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 90.0 in stage 50.0 (TID 630) in 265 ms on 10.0.0.43 (executor driver) (87/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 82.0 in stage 50.0 (TID 622) in 438 ms on 10.0.0.43 (executor driver) (88/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 89.0 in stage 50.0 (TID 629) in 266 ms on 10.0.0.43 (executor driver) (89/200)
25/02/04 17:13:48 INFO TaskSetManager: Finished task 85.0 in stage 50.0 (TID 625) in 305 ms on 10.0.0.43 (executor driver) (90/200)
25/02/04 17:13:48 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000087_627' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000087
25/02/04 17:13:48 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000087_627: Committed. Elapsed time: 0 ms.
25/02/04 17:13:48 INFO Executor: Finished task 87.0 in stage 50.0 (TID 627). 17954 bytes result sent to driver
25/02/04 17:13:48 INFO TaskSetManager: Starting task 100.0 in stage 50.0 (TID 640) (10.0.0.43, executor driver, partition 100, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:48 INFO TaskSetManager: Finished task 87.0 in stage 50.0 (TID 627) in 271 ms on 10.0.0.43 (executor driver) (91/200)
25/02/04 17:13:48 INFO Executor: Running task 100.0 in stage 50.0 (TID 640)
25/02/04 17:13:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_97 stored as values in memory (estimated size 1377.5 KiB, free 145.0 MiB)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_100 stored as values in memory (estimated size 1207.1 KiB, free 146.4 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_100 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_96 stored as values in memory (estimated size 1038.0 KiB, free 146.4 MiB)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_94 stored as values in memory (estimated size 1436.0 KiB, free 145.0 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_94 locally
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_96 locally
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_97 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_92 stored as values in memory (estimated size 1066.1 KiB, free 144.0 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_92 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_93 stored as values in memory (estimated size 1206.0 KiB, free 142.8 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_93 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_98 stored as values in memory (estimated size 1466.2 KiB, free 141.4 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_98 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_95 stored as values in memory (estimated size 998.9 KiB, free 146.4 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_95 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_99 stored as values in memory (estimated size 934.9 KiB, free 140.4 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_99 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_126 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_126 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_126 on disk on 10.0.0.43:62420 (current size: 1010.3 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_124 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_124 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_124 on disk on 10.0.0.43:62420 (current size: 1116.4 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO MemoryStore: After dropping 2 blocks, free memory is 8.6 MiB
25/02/04 17:13:49 INFO MemoryStore: 5 blocks selected for dropping (6.6 MiB bytes)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_128 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_128 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_128 on disk on 10.0.0.43:62420 (current size: 1113.1 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_129 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_129 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_129 on disk on 10.0.0.43:62420 (current size: 1334.1 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_130 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_130 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_130 on disk on 10.0.0.43:62420 (current size: 1100.2 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_127 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_127 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_127 on disk on 10.0.0.43:62420 (current size: 1582.0 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_131 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_131 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_131 on disk on 10.0.0.43:62420 (current size: 1276.0 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO MemoryStore: After dropping 5 blocks, free memory is 9.3 MiB
25/02/04 17:13:49 INFO MemoryStore: 1 blocks selected for dropping (919.7 KiB bytes)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_133 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_133 to disk
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_133 on disk on 10.0.0.43:62420 (current size: 865.8 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:13:49 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_132 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_132 to disk
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_132 on disk on 10.0.0.43:62420 (current size: 1164.2 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_134 from memory
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_134 to disk
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_134 on disk on 10.0.0.43:62420 (current size: 1088.2 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO MemoryStore: After dropping 2 blocks, free memory is 2.5 MiB
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO MemoryStore: 2 blocks selected for dropping (2.4 MiB bytes)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_136 from memory
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_136 to disk
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_136 on disk on 10.0.0.43:62420 (current size: 1351.4 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_135 from memory
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_135 to disk
25/02/04 17:13:49 INFO BlockManagerInfo: Updated rdd_72_135 on disk on 10.0.0.43:62420 (current size: 966.4 KiB, original size: 0.0 B)
25/02/04 17:13:49 INFO MemoryStore: After dropping 2 blocks, free memory is 2.9 MiB
25/02/04 17:13:49 INFO UnsafeExternalSorter: Thread 74 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000091_631' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000091
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000091_631: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO Executor: Finished task 91.0 in stage 50.0 (TID 631). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO TaskSetManager: Starting task 101.0 in stage 50.0 (TID 641) (10.0.0.43, executor driver, partition 101, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO TaskSetManager: Finished task 91.0 in stage 50.0 (TID 631) in 578 ms on 10.0.0.43 (executor driver) (92/200)
25/02/04 17:13:49 INFO Executor: Running task 101.0 in stage 50.0 (TID 641)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_101 stored as values in memory (estimated size 956.2 KiB, free 17.6 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_101 locally
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000095_635' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000095
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000092_632' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000092
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000092_632: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000095_635: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO Executor: Finished task 95.0 in stage 50.0 (TID 635). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 102.0 in stage 50.0 (TID 642) (10.0.0.43, executor driver, partition 102, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO Executor: Finished task 92.0 in stage 50.0 (TID 632). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Finished task 95.0 in stage 50.0 (TID 635) in 427 ms on 10.0.0.43 (executor driver) (93/200)
25/02/04 17:13:49 INFO Executor: Running task 102.0 in stage 50.0 (TID 642)
25/02/04 17:13:49 INFO TaskSetManager: Starting task 103.0 in stage 50.0 (TID 643) (10.0.0.43, executor driver, partition 103, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 92.0 in stage 50.0 (TID 632) in 433 ms on 10.0.0.43 (executor driver) (94/200)
25/02/04 17:13:49 INFO Executor: Running task 103.0 in stage 50.0 (TID 643)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_103 stored as values in memory (estimated size 1066.7 KiB, free 98.5 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_103 locally
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000099_639' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000099
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000099_639: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO Executor: Finished task 99.0 in stage 50.0 (TID 639). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_102 stored as values in memory (estimated size 1372.4 KiB, free 95.2 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_102 locally
25/02/04 17:13:49 INFO TaskSetManager: Starting task 104.0 in stage 50.0 (TID 644) (10.0.0.43, executor driver, partition 104, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO Executor: Running task 104.0 in stage 50.0 (TID 644)
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000097_637' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000097
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000097_637: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000096_636' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000096
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000096_636: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO Executor: Finished task 96.0 in stage 50.0 (TID 636). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO TaskSetManager: Starting task 105.0 in stage 50.0 (TID 645) (10.0.0.43, executor driver, partition 105, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 99.0 in stage 50.0 (TID 639) in 449 ms on 10.0.0.43 (executor driver) (95/200)
25/02/04 17:13:49 INFO Executor: Finished task 97.0 in stage 50.0 (TID 637). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 106.0 in stage 50.0 (TID 646) (10.0.0.43, executor driver, partition 106, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 96.0 in stage 50.0 (TID 636) in 450 ms on 10.0.0.43 (executor driver) (96/200)
25/02/04 17:13:49 INFO TaskSetManager: Finished task 97.0 in stage 50.0 (TID 637) in 450 ms on 10.0.0.43 (executor driver) (97/200)
25/02/04 17:13:49 INFO Executor: Running task 105.0 in stage 50.0 (TID 645)
25/02/04 17:13:49 INFO Executor: Running task 106.0 in stage 50.0 (TID 646)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_104 stored as values in memory (estimated size 1184.6 KiB, free 64.1 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_104 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_105 stored as values in memory (estimated size 1205.0 KiB, free 53.1 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_105 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_106 stored as values in memory (estimated size 1425.5 KiB, free 49.7 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_106 locally
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000093_633' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000093
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000093_633: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO Executor: Finished task 93.0 in stage 50.0 (TID 633). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 107.0 in stage 50.0 (TID 647) (10.0.0.43, executor driver, partition 107, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO Executor: Running task 107.0 in stage 50.0 (TID 647)
25/02/04 17:13:49 INFO TaskSetManager: Finished task 93.0 in stage 50.0 (TID 633) in 535 ms on 10.0.0.43 (executor driver) (98/200)
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000094_634' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000094
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000094_634: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO Executor: Finished task 94.0 in stage 50.0 (TID 634). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 108.0 in stage 50.0 (TID 648) (10.0.0.43, executor driver, partition 108, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO Executor: Running task 108.0 in stage 50.0 (TID 648)
25/02/04 17:13:49 INFO TaskSetManager: Finished task 94.0 in stage 50.0 (TID 634) in 553 ms on 10.0.0.43 (executor driver) (99/200)
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_107 stored as values in memory (estimated size 1226.5 KiB, free 94.5 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_107 locally
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000100_640' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000100
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000100_640: Committed. Elapsed time: 0 ms.
25/02/04 17:13:49 INFO Executor: Finished task 100.0 in stage 50.0 (TID 640). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_108 stored as values in memory (estimated size 1017.1 KiB, free 93.5 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_108 locally
25/02/04 17:13:49 INFO TaskSetManager: Starting task 109.0 in stage 50.0 (TID 649) (10.0.0.43, executor driver, partition 109, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO Executor: Running task 109.0 in stage 50.0 (TID 649)
25/02/04 17:13:49 INFO TaskSetManager: Finished task 100.0 in stage 50.0 (TID 640) in 560 ms on 10.0.0.43 (executor driver) (100/200)
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_109 stored as values in memory (estimated size 1040.2 KiB, free 24.5 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_109 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000101_641' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000101
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000101_641: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000103_643' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000103
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000103_643: Committed. Elapsed time: 2 ms.
25/02/04 17:13:49 INFO Executor: Finished task 101.0 in stage 50.0 (TID 641). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO Executor: Finished task 103.0 in stage 50.0 (TID 643). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 110.0 in stage 50.0 (TID 650) (10.0.0.43, executor driver, partition 110, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Starting task 111.0 in stage 50.0 (TID 651) (10.0.0.43, executor driver, partition 111, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 101.0 in stage 50.0 (TID 641) in 466 ms on 10.0.0.43 (executor driver) (101/200)
25/02/04 17:13:49 INFO Executor: Running task 110.0 in stage 50.0 (TID 650)
25/02/04 17:13:49 INFO TaskSetManager: Finished task 103.0 in stage 50.0 (TID 643) in 386 ms on 10.0.0.43 (executor driver) (102/200)
25/02/04 17:13:49 INFO Executor: Running task 111.0 in stage 50.0 (TID 651)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_110 stored as values in memory (estimated size 975.1 KiB, free 75.7 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_110 locally
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_111 stored as values in memory (estimated size 1035.3 KiB, free 74.7 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_111 locally
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000104_644' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000104
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000104_644: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000098_638' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000098
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000098_638: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000102_642' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000102
25/02/04 17:13:49 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000102_642: Committed. Elapsed time: 1 ms.
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO Executor: Finished task 104.0 in stage 50.0 (TID 644). 17997 bytes result sent to driver
25/02/04 17:13:49 INFO Executor: Finished task 98.0 in stage 50.0 (TID 638). 18040 bytes result sent to driver
25/02/04 17:13:49 INFO Executor: Finished task 102.0 in stage 50.0 (TID 642). 17954 bytes result sent to driver
25/02/04 17:13:49 INFO TaskSetManager: Starting task 112.0 in stage 50.0 (TID 652) (10.0.0.43, executor driver, partition 112, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 104.0 in stage 50.0 (TID 644) in 478 ms on 10.0.0.43 (executor driver) (103/200)
25/02/04 17:13:49 INFO Executor: Running task 112.0 in stage 50.0 (TID 652)
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO TaskSetManager: Starting task 113.0 in stage 50.0 (TID 653) (10.0.0.43, executor driver, partition 113, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO TaskSetManager: Finished task 98.0 in stage 50.0 (TID 638) in 939 ms on 10.0.0.43 (executor driver) (104/200)
25/02/04 17:13:49 INFO Executor: Running task 113.0 in stage 50.0 (TID 653)
25/02/04 17:13:49 INFO TaskSetManager: Starting task 114.0 in stage 50.0 (TID 654) (10.0.0.43, executor driver, partition 114, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:49 INFO TaskSetManager: Finished task 102.0 in stage 50.0 (TID 642) in 517 ms on 10.0.0.43 (executor driver) (105/200)
25/02/04 17:13:49 INFO Executor: Running task 114.0 in stage 50.0 (TID 654)
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_113 stored as values in memory (estimated size 1203.2 KiB, free 41.5 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_113 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_112 stored as values in memory (estimated size 1125.1 KiB, free 22.4 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_112 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO MemoryStore: Block rdd_72_114 stored as values in memory (estimated size 1391.4 KiB, free 19.0 MiB)
25/02/04 17:13:49 INFO BlockManager: Found block rdd_72_114 locally
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO MemoryStore: 1 blocks selected for dropping (1027.9 KiB bytes)
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO BlockManager: Dropping block rdd_72_137 from memory
25/02/04 17:13:49 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:49 INFO BlockManager: Writing block rdd_72_137 to disk
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_137 on disk on 10.0.0.43:62420 (current size: 970.1 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO MemoryStore: After dropping 1 blocks, free memory is 8.0 MiB
25/02/04 17:13:50 INFO MemoryStore: 4 blocks selected for dropping (4.4 MiB bytes)
25/02/04 17:13:50 INFO BlockManager: Dropping block rdd_72_138 from memory
25/02/04 17:13:50 INFO BlockManager: Writing block rdd_72_138 to disk
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_138 on disk on 10.0.0.43:62420 (current size: 1111.5 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO BlockManager: Dropping block rdd_72_139 from memory
25/02/04 17:13:50 INFO BlockManager: Writing block rdd_72_139 to disk
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_139 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO BlockManager: Dropping block rdd_72_144 from memory
25/02/04 17:13:50 INFO BlockManager: Writing block rdd_72_144 to disk
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_144 on disk on 10.0.0.43:62420 (current size: 966.7 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO BlockManager: Dropping block rdd_72_143 from memory
25/02/04 17:13:50 INFO BlockManager: Writing block rdd_72_143 to disk
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_143 on disk on 10.0.0.43:62420 (current size: 1131.3 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO MemoryStore: After dropping 4 blocks, free memory is 4.5 MiB
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000109_649' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000109
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000109_649: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000105_645' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000105
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000105_645: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000107_647' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000107
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000107_647: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000108_648' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000108
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000108_648: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO Executor: Finished task 108.0 in stage 50.0 (TID 648). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 109.0 in stage 50.0 (TID 649). 17997 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 107.0 in stage 50.0 (TID 647). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 105.0 in stage 50.0 (TID 645). 17997 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 115.0 in stage 50.0 (TID 655) (10.0.0.43, executor driver, partition 115, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO TaskSetManager: Starting task 116.0 in stage 50.0 (TID 656) (10.0.0.43, executor driver, partition 116, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO TaskSetManager: Starting task 117.0 in stage 50.0 (TID 657) (10.0.0.43, executor driver, partition 117, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO TaskSetManager: Finished task 108.0 in stage 50.0 (TID 648) in 605 ms on 10.0.0.43 (executor driver) (106/200)
25/02/04 17:13:50 INFO TaskSetManager: Starting task 118.0 in stage 50.0 (TID 658) (10.0.0.43, executor driver, partition 118, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 115.0 in stage 50.0 (TID 655)
25/02/04 17:13:50 INFO Executor: Running task 118.0 in stage 50.0 (TID 658)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 109.0 in stage 50.0 (TID 649) in 600 ms on 10.0.0.43 (executor driver) (107/200)
25/02/04 17:13:50 INFO Executor: Running task 117.0 in stage 50.0 (TID 657)
25/02/04 17:13:50 INFO Executor: Running task 116.0 in stage 50.0 (TID 656)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 105.0 in stage 50.0 (TID 645) in 721 ms on 10.0.0.43 (executor driver) (108/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 107.0 in stage 50.0 (TID 647) in 642 ms on 10.0.0.43 (executor driver) (109/200)
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_115 stored as values in memory (estimated size 879.4 KiB, free 77.6 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_115 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_116 stored as values in memory (estimated size 1543.8 KiB, free 76.1 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_116 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_118 stored as values in memory (estimated size 1312.1 KiB, free 73.3 MiB)
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_117 stored as values in memory (estimated size 1560.3 KiB, free 73.3 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_117 locally
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_118 locally
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO MemoryStore: 1 blocks selected for dropping (1171.1 KiB bytes)
25/02/04 17:13:50 INFO BlockManager: Dropping block rdd_72_142 from memory
25/02/04 17:13:50 INFO BlockManager: Writing block rdd_72_142 to disk
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO BlockManagerInfo: Updated rdd_72_142 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 0.0 B)
25/02/04 17:13:50 INFO MemoryStore: After dropping 1 blocks, free memory is 2.5 MiB
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000106_646' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000106
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000106_646: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000111_651' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000111
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000111_651: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000113_653' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000113
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000113_653: Committed. Elapsed time: 0 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000110_650' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000110
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000110_650: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO Executor: Finished task 113.0 in stage 50.0 (TID 653). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 110.0 in stage 50.0 (TID 650). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 119.0 in stage 50.0 (TID 659) (10.0.0.43, executor driver, partition 119, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Finished task 111.0 in stage 50.0 (TID 651). 17997 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 106.0 in stage 50.0 (TID 646). 17997 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 120.0 in stage 50.0 (TID 660) (10.0.0.43, executor driver, partition 120, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 119.0 in stage 50.0 (TID 659)
25/02/04 17:13:50 INFO TaskSetManager: Starting task 121.0 in stage 50.0 (TID 661) (10.0.0.43, executor driver, partition 121, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 120.0 in stage 50.0 (TID 660)
25/02/04 17:13:50 INFO Executor: Running task 121.0 in stage 50.0 (TID 661)
25/02/04 17:13:50 INFO TaskSetManager: Starting task 122.0 in stage 50.0 (TID 662) (10.0.0.43, executor driver, partition 122, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 122.0 in stage 50.0 (TID 662)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 106.0 in stage 50.0 (TID 646) in 1262 ms on 10.0.0.43 (executor driver) (110/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 111.0 in stage 50.0 (TID 651) in 901 ms on 10.0.0.43 (executor driver) (111/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 110.0 in stage 50.0 (TID 650) in 910 ms on 10.0.0.43 (executor driver) (112/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 113.0 in stage 50.0 (TID 653) in 775 ms on 10.0.0.43 (executor driver) (113/200)
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_121 stored as values in memory (estimated size 1182.1 KiB, free 65.3 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_121 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_120 stored as values in memory (estimated size 1129.3 KiB, free 64.2 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_120 locally
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000112_652' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000112
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000112_652: Committed. Elapsed time: 2 ms.
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000115_655' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000115
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000115_655: Committed. Elapsed time: 3 ms.
25/02/04 17:13:50 INFO Executor: Finished task 112.0 in stage 50.0 (TID 652). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO Executor: Finished task 115.0 in stage 50.0 (TID 655). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 123.0 in stage 50.0 (TID 663) (10.0.0.43, executor driver, partition 123, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO TaskSetManager: Starting task 124.0 in stage 50.0 (TID 664) (10.0.0.43, executor driver, partition 124, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 123.0 in stage 50.0 (TID 663)
25/02/04 17:13:50 INFO Executor: Running task 124.0 in stage 50.0 (TID 664)
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000114_654' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000114
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000114_654: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:50 INFO Executor: Finished task 114.0 in stage 50.0 (TID 654). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 125.0 in stage 50.0 (TID 665) (10.0.0.43, executor driver, partition 125, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 125.0 in stage 50.0 (TID 665)
25/02/04 17:13:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:50 INFO TaskSetManager: Finished task 114.0 in stage 50.0 (TID 654) in 896 ms on 10.0.0.43 (executor driver) (114/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 112.0 in stage 50.0 (TID 652) in 916 ms on 10.0.0.43 (executor driver) (115/200)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 115.0 in stage 50.0 (TID 655) in 683 ms on 10.0.0.43 (executor driver) (116/200)
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_124 stored as values in memory (estimated size 1178.8 KiB, free 96.9 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_124 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_122 stored as values in memory (estimated size 1375.8 KiB, free 95.6 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_122 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_125 stored as values in memory (estimated size 1204.4 KiB, free 94.4 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_125 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_119 stored as values in memory (estimated size 1062.9 KiB, free 93.4 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_119 locally
25/02/04 17:13:50 INFO MemoryStore: Block rdd_72_123 stored as values in memory (estimated size 1264.0 KiB, free 110.1 MiB)
25/02/04 17:13:50 INFO BlockManager: Found block rdd_72_123 locally
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000118_658' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000118
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000118_658: Committed. Elapsed time: 1 ms.
25/02/04 17:13:50 INFO Executor: Finished task 118.0 in stage 50.0 (TID 658). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 126.0 in stage 50.0 (TID 666) (10.0.0.43, executor driver, partition 126, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 126.0 in stage 50.0 (TID 666)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 118.0 in stage 50.0 (TID 658) in 734 ms on 10.0.0.43 (executor driver) (117/200)
25/02/04 17:13:50 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000116_656' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000116
25/02/04 17:13:50 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000116_656: Committed. Elapsed time: 6 ms.
25/02/04 17:13:50 INFO Executor: Finished task 116.0 in stage 50.0 (TID 656). 17954 bytes result sent to driver
25/02/04 17:13:50 INFO TaskSetManager: Starting task 127.0 in stage 50.0 (TID 667) (10.0.0.43, executor driver, partition 127, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:50 INFO Executor: Running task 127.0 in stage 50.0 (TID 667)
25/02/04 17:13:50 INFO TaskSetManager: Finished task 116.0 in stage 50.0 (TID 656) in 751 ms on 10.0.0.43 (executor driver) (118/200)
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000117_657' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000117
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000117_657: Committed. Elapsed time: 1 ms.
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO Executor: Finished task 117.0 in stage 50.0 (TID 657). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO TaskSetManager: Starting task 128.0 in stage 50.0 (TID 668) (10.0.0.43, executor driver, partition 128, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO TaskSetManager: Finished task 117.0 in stage 50.0 (TID 657) in 1033 ms on 10.0.0.43 (executor driver) (119/200)
25/02/04 17:13:51 INFO Executor: Running task 128.0 in stage 50.0 (TID 668)
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_126 stored as values in memory (estimated size 1073.8 KiB, free 25.6 MiB)
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_127 stored as values in memory (estimated size 1660.8 KiB, free 25.6 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_126 locally
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_127 locally
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO MemoryStore: 1 blocks selected for dropping (1202.8 KiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_140 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_140 to disk
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_140 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 1 blocks, free memory is 4.8 MiB
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO MemoryStore: 7 blocks selected for dropping (8.3 MiB bytes)
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_146 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_146 to disk
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_146 on disk on 10.0.0.43:62420 (current size: 1156.8 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_145 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_145 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_145 on disk on 10.0.0.43:62420 (current size: 1250.7 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_141 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_141 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_141 on disk on 10.0.0.43:62420 (current size: 1197.5 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_147 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_147 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_147 on disk on 10.0.0.43:62420 (current size: 1044.9 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_148 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_148 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_148 on disk on 10.0.0.43:62420 (current size: 1192.4 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_150 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_150 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_150 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_149 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_149 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_149 on disk on 10.0.0.43:62420 (current size: 1102.0 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 7 blocks, free memory is 9.1 MiB
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO MemoryStore: 1 blocks selected for dropping (113.3 KiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block broadcast_25_piece0 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block broadcast_25_piece0 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated broadcast_25_piece0 on disk on 10.0.0.43:62420 (current size: 113.3 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 1 blocks, free memory is 1206.5 KiB
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_128 stored as values in memory (estimated size 1177.6 KiB, free 28.9 KiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_128 locally
25/02/04 17:13:51 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_155 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_155 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_155 on disk on 10.0.0.43:62420 (current size: 1075.9 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_154 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_154 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_154 on disk on 10.0.0.43:62420 (current size: 1008.9 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 2 blocks, free memory is 2.2 MiB
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000119_659' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000119
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000119_659: Committed. Elapsed time: 1 ms.
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000120_660' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000120
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000120_660: Committed. Elapsed time: 1 ms.
25/02/04 17:13:51 INFO Executor: Finished task 119.0 in stage 50.0 (TID 659). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO TaskSetManager: Starting task 129.0 in stage 50.0 (TID 669) (10.0.0.43, executor driver, partition 129, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO Executor: Running task 129.0 in stage 50.0 (TID 669)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 119.0 in stage 50.0 (TID 659) in 858 ms on 10.0.0.43 (executor driver) (120/200)
25/02/04 17:13:51 INFO Executor: Finished task 120.0 in stage 50.0 (TID 660). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO TaskSetManager: Starting task 130.0 in stage 50.0 (TID 670) (10.0.0.43, executor driver, partition 130, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO Executor: Running task 130.0 in stage 50.0 (TID 670)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 120.0 in stage 50.0 (TID 660) in 870 ms on 10.0.0.43 (executor driver) (121/200)
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_129 stored as values in memory (estimated size 1408.3 KiB, free 30.7 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_129 locally
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_130 stored as values in memory (estimated size 1167.7 KiB, free 29.6 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_130 locally
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000121_661' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000121
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000123_663' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000123
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000126_666' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000126
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000124_664' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000124
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000125_665' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000125
25/02/04 17:13:51 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000122_662' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000122
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000121_661: Committed. Elapsed time: 3 ms.
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000124_664: Committed. Elapsed time: 4 ms.
25/02/04 17:13:51 INFO Executor: Finished task 124.0 in stage 50.0 (TID 664). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000125_665: Committed. Elapsed time: 1 ms.
25/02/04 17:13:51 INFO Executor: Finished task 121.0 in stage 50.0 (TID 661). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO Executor: Finished task 125.0 in stage 50.0 (TID 665). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000126_666: Committed. Elapsed time: 4 ms.
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000123_663: Committed. Elapsed time: 3 ms.
25/02/04 17:13:51 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000122_662: Committed. Elapsed time: 9 ms.
25/02/04 17:13:51 INFO TaskSetManager: Starting task 131.0 in stage 50.0 (TID 671) (10.0.0.43, executor driver, partition 131, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO Executor: Finished task 123.0 in stage 50.0 (TID 663). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO Executor: Finished task 122.0 in stage 50.0 (TID 662). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO Executor: Finished task 126.0 in stage 50.0 (TID 666). 17954 bytes result sent to driver
25/02/04 17:13:51 INFO TaskSetManager: Starting task 132.0 in stage 50.0 (TID 672) (10.0.0.43, executor driver, partition 132, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO TaskSetManager: Starting task 133.0 in stage 50.0 (TID 673) (10.0.0.43, executor driver, partition 133, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO TaskSetManager: Starting task 134.0 in stage 50.0 (TID 674) (10.0.0.43, executor driver, partition 134, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO TaskSetManager: Starting task 135.0 in stage 50.0 (TID 675) (10.0.0.43, executor driver, partition 135, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO Executor: Running task 131.0 in stage 50.0 (TID 671)
25/02/04 17:13:51 INFO Executor: Running task 132.0 in stage 50.0 (TID 672)
25/02/04 17:13:51 INFO Executor: Running task 133.0 in stage 50.0 (TID 673)
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO TaskSetManager: Finished task 124.0 in stage 50.0 (TID 664) in 957 ms on 10.0.0.43 (executor driver) (122/200)
25/02/04 17:13:51 INFO Executor: Running task 134.0 in stage 50.0 (TID 674)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 125.0 in stage 50.0 (TID 665) in 941 ms on 10.0.0.43 (executor driver) (123/200)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 121.0 in stage 50.0 (TID 661) in 1078 ms on 10.0.0.43 (executor driver) (124/200)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 123.0 in stage 50.0 (TID 663) in 961 ms on 10.0.0.43 (executor driver) (125/200)
25/02/04 17:13:51 INFO Executor: Running task 135.0 in stage 50.0 (TID 675)
25/02/04 17:13:51 INFO TaskSetManager: Starting task 136.0 in stage 50.0 (TID 676) (10.0.0.43, executor driver, partition 136, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:51 INFO Executor: Running task 136.0 in stage 50.0 (TID 676)
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO TaskSetManager: Finished task 126.0 in stage 50.0 (TID 666) in 875 ms on 10.0.0.43 (executor driver) (126/200)
25/02/04 17:13:51 INFO TaskSetManager: Finished task 122.0 in stage 50.0 (TID 662) in 1079 ms on 10.0.0.43 (executor driver) (127/200)
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_136 stored as values in memory (estimated size 1429.3 KiB, free 80.3 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_136 locally
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_133 stored as values in memory (estimated size 919.7 KiB, free 79.4 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_133 locally
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_135 stored as values in memory (estimated size 1025.8 KiB, free 78.4 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_135 locally
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_131 stored as values in memory (estimated size 1353.8 KiB, free 71.8 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_131 locally
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_132 stored as values in memory (estimated size 1234.5 KiB, free 15.8 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_132 locally
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO MemoryStore: Block rdd_72_134 stored as values in memory (estimated size 1147.5 KiB, free 8.7 MiB)
25/02/04 17:13:51 INFO BlockManager: Found block rdd_72_134 locally
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:51 INFO MemoryStore: 1 blocks selected for dropping (1217.8 KiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_151 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_151 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_151 on disk on 10.0.0.43:62420 (current size: 1149.0 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 1 blocks, free memory is 2.9 MiB
25/02/04 17:13:51 INFO MemoryStore: 1 blocks selected for dropping (1410.1 KiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_152 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_152 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_152 on disk on 10.0.0.43:62420 (current size: 1331.2 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:13:51 INFO MemoryStore: 2 blocks selected for dropping (2.0 MiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_153 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_153 to disk
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_153 on disk on 10.0.0.43:62420 (current size: 939.3 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_156 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_156 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_156 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 2 blocks, free memory is 2.3 MiB
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:51 INFO MemoryStore: 1 blocks selected for dropping (1199.3 KiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_157 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_157 to disk
25/02/04 17:13:51 INFO BlockManagerInfo: Updated rdd_72_157 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 0.0 B)
25/02/04 17:13:51 INFO MemoryStore: After dropping 1 blocks, free memory is 2.5 MiB
25/02/04 17:13:51 INFO MemoryStore: 3 blocks selected for dropping (3.7 MiB bytes)
25/02/04 17:13:51 INFO BlockManager: Dropping block rdd_72_158 from memory
25/02/04 17:13:51 INFO BlockManager: Writing block rdd_72_158 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_158 on disk on 10.0.0.43:62420 (current size: 1322.5 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_160 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_160 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_160 on disk on 10.0.0.43:62420 (current size: 1140.9 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_161 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_161 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_161 on disk on 10.0.0.43:62420 (current size: 1075.6 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 3 blocks, free memory is 4.1 MiB
25/02/04 17:13:52 INFO MemoryStore: 2 blocks selected for dropping (2.8 MiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_163 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_163 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_163 on disk on 10.0.0.43:62420 (current size: 1255.9 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_159 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_159 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_159 on disk on 10.0.0.43:62420 (current size: 1457.3 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 2 blocks, free memory is 4.9 MiB
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000127_667' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000127
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000128_668' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000128
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000127_667: Committed. Elapsed time: 47 ms.
25/02/04 17:13:52 INFO Executor: Finished task 127.0 in stage 50.0 (TID 667). 17997 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 137.0 in stage 50.0 (TID 677) (10.0.0.43, executor driver, partition 137, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO TaskSetManager: Finished task 127.0 in stage 50.0 (TID 667) in 1290 ms on 10.0.0.43 (executor driver) (128/200)
25/02/04 17:13:52 INFO Executor: Running task 137.0 in stage 50.0 (TID 677)
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000130_670' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000130
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000129_669' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000129
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000130_670: Committed. Elapsed time: 4 ms.
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000129_669: Committed. Elapsed time: 3 ms.
25/02/04 17:13:52 INFO Executor: Finished task 129.0 in stage 50.0 (TID 669). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO Executor: Finished task 130.0 in stage 50.0 (TID 670). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 138.0 in stage 50.0 (TID 678) (10.0.0.43, executor driver, partition 138, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO TaskSetManager: Starting task 139.0 in stage 50.0 (TID 679) (10.0.0.43, executor driver, partition 139, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO TaskSetManager: Finished task 130.0 in stage 50.0 (TID 670) in 665 ms on 10.0.0.43 (executor driver) (129/200)
25/02/04 17:13:52 INFO Executor: Running task 139.0 in stage 50.0 (TID 679)
25/02/04 17:13:52 INFO Executor: Running task 138.0 in stage 50.0 (TID 678)
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000128_668: Committed. Elapsed time: 48 ms.
25/02/04 17:13:52 INFO TaskSetManager: Finished task 129.0 in stage 50.0 (TID 669) in 676 ms on 10.0.0.43 (executor driver) (130/200)
25/02/04 17:13:52 INFO Executor: Finished task 128.0 in stage 50.0 (TID 668). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 140.0 in stage 50.0 (TID 680) (10.0.0.43, executor driver, partition 140, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 140.0 in stage 50.0 (TID 680)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 128.0 in stage 50.0 (TID 668) in 1031 ms on 10.0.0.43 (executor driver) (131/200)
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_137 stored as values in memory (estimated size 1027.9 KiB, free 57.9 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_137 locally
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_139 stored as values in memory (estimated size 1149.9 KiB, free 55.6 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_139 locally
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_140 stored as values in memory (estimated size 1202.8 KiB, free 55.6 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_140 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_138 stored as values in memory (estimated size 1174.8 KiB, free 54.5 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_138 locally
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000133_673' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000133
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000133_673: Committed. Elapsed time: 0 ms.
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000136_676' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000136
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000136_676: Committed. Elapsed time: 0 ms.
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000135_675' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000135
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000135_675: Committed. Elapsed time: 1 ms.
25/02/04 17:13:52 INFO Executor: Finished task 133.0 in stage 50.0 (TID 673). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 141.0 in stage 50.0 (TID 681) (10.0.0.43, executor driver, partition 141, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Finished task 135.0 in stage 50.0 (TID 675). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Finished task 133.0 in stage 50.0 (TID 673) in 666 ms on 10.0.0.43 (executor driver) (132/200)
25/02/04 17:13:52 INFO TaskSetManager: Starting task 142.0 in stage 50.0 (TID 682) (10.0.0.43, executor driver, partition 142, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 141.0 in stage 50.0 (TID 681)
25/02/04 17:13:52 INFO Executor: Running task 142.0 in stage 50.0 (TID 682)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 135.0 in stage 50.0 (TID 675) in 667 ms on 10.0.0.43 (executor driver) (133/200)
25/02/04 17:13:52 INFO Executor: Finished task 136.0 in stage 50.0 (TID 676). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 143.0 in stage 50.0 (TID 683) (10.0.0.43, executor driver, partition 143, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 143.0 in stage 50.0 (TID 683)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 136.0 in stage 50.0 (TID 676) in 669 ms on 10.0.0.43 (executor driver) (134/200)
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_142 stored as values in memory (estimated size 1171.1 KiB, free 35.3 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_142 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_141 stored as values in memory (estimated size 1268.3 KiB, free 34.1 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_141 locally
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_143 stored as values in memory (estimated size 1200.3 KiB, free 8.9 MiB)
25/02/04 17:13:52 INFO MemoryStore: 3 blocks selected for dropping (3.8 MiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_162 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_162 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_162 on disk on 10.0.0.43:62420 (current size: 1171.5 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_164 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_164 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_164 on disk on 10.0.0.43:62420 (current size: 1357.3 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_165 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_165 to disk
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_143 locally
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_165 on disk on 10.0.0.43:62420 (current size: 1119.3 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO MemoryStore: After dropping 3 blocks, free memory is 8.7 MiB
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO MemoryStore: 1 blocks selected for dropping (1547.2 KiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_166 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_166 to disk
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_166 on disk on 10.0.0.43:62420 (current size: 1469.1 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO MemoryStore: After dropping 1 blocks, free memory is 2009.4 KiB
25/02/04 17:13:52 INFO MemoryStore: 1 blocks selected for dropping (1054.2 KiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_167 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_167 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_167 on disk on 10.0.0.43:62420 (current size: 994.1 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 1 blocks, free memory is 2.7 MiB
25/02/04 17:13:52 INFO MemoryStore: 1 blocks selected for dropping (1113.0 KiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_169 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_169 to disk
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_169 on disk on 10.0.0.43:62420 (current size: 1051.8 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 1 blocks, free memory is 1872.7 KiB
25/02/04 17:13:52 INFO MemoryStore: 1 blocks selected for dropping (1077.6 KiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_168 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_168 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_168 on disk on 10.0.0.43:62420 (current size: 1014.6 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:13:52 INFO MemoryStore: 1 blocks selected for dropping (1245.6 KiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_170 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_170 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_170 on disk on 10.0.0.43:62420 (current size: 1180.1 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO MemoryStore: 4 blocks selected for dropping (4.3 MiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_175 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_175 to disk
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_175 on disk on 10.0.0.43:62420 (current size: 1032.3 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_172 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_172 to disk
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_172 on disk on 10.0.0.43:62420 (current size: 882.2 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_171 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_171 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_171 on disk on 10.0.0.43:62420 (current size: 1224.6 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_173 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_173 to disk
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_173 on disk on 10.0.0.43:62420 (current size: 1039.3 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 4 blocks, free memory is 4.9 MiB
25/02/04 17:13:52 INFO MemoryStore: 6 blocks selected for dropping (7.1 MiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_174 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_174 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_174 on disk on 10.0.0.43:62420 (current size: 1240.5 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_176 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_176 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_176 on disk on 10.0.0.43:62420 (current size: 959.7 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_180 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_180 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_180 on disk on 10.0.0.43:62420 (current size: 1018.4 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_179 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_179 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_179 on disk on 10.0.0.43:62420 (current size: 1388.5 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_178 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_178 to disk
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_178 on disk on 10.0.0.43:62420 (current size: 1282.9 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_183 from memory
25/02/04 17:13:52 INFO BlockManager: Writing block rdd_72_183 to disk
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO BlockManagerInfo: Updated rdd_72_183 on disk on 10.0.0.43:62420 (current size: 1032.0 KiB, original size: 0.0 B)
25/02/04 17:13:52 INFO MemoryStore: After dropping 6 blocks, free memory is 8.1 MiB
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000131_671' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000131
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000131_671: Committed. Elapsed time: 1 ms.
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000134_674' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000134
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000134_674: Committed. Elapsed time: 0 ms.
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000132_672' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000132
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000132_672: Committed. Elapsed time: 0 ms.
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO Executor: Finished task 134.0 in stage 50.0 (TID 674). 17997 bytes result sent to driver
25/02/04 17:13:52 INFO Executor: Finished task 131.0 in stage 50.0 (TID 671). 17997 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 144.0 in stage 50.0 (TID 684) (10.0.0.43, executor driver, partition 144, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Finished task 132.0 in stage 50.0 (TID 672). 17997 bytes result sent to driver
25/02/04 17:13:52 INFO Executor: Running task 144.0 in stage 50.0 (TID 684)
25/02/04 17:13:52 INFO TaskSetManager: Starting task 145.0 in stage 50.0 (TID 685) (10.0.0.43, executor driver, partition 145, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO TaskSetManager: Finished task 134.0 in stage 50.0 (TID 674) in 1008 ms on 10.0.0.43 (executor driver) (135/200)
25/02/04 17:13:52 INFO Executor: Running task 145.0 in stage 50.0 (TID 685)
25/02/04 17:13:52 INFO TaskSetManager: Starting task 146.0 in stage 50.0 (TID 686) (10.0.0.43, executor driver, partition 146, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 146.0 in stage 50.0 (TID 686)
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000137_677' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000137
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000137_677: Committed. Elapsed time: 1 ms.
25/02/04 17:13:52 INFO Executor: Finished task 137.0 in stage 50.0 (TID 677). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 147.0 in stage 50.0 (TID 687) (10.0.0.43, executor driver, partition 147, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 147.0 in stage 50.0 (TID 687)
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_147 stored as values in memory (estimated size 1105.9 KiB, free 83.7 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_147 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_146 stored as values in memory (estimated size 1225.4 KiB, free 82.5 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_146 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_145 stored as values in memory (estimated size 1331.0 KiB, free 83.7 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_145 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_144 stored as values in memory (estimated size 1027.6 KiB, free 81.4 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_144 locally
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000138_678' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000138
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000138_678: Committed. Elapsed time: 3 ms.
25/02/04 17:13:52 INFO Executor: Finished task 138.0 in stage 50.0 (TID 678). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 148.0 in stage 50.0 (TID 688) (10.0.0.43, executor driver, partition 148, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000139_679' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000139
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000139_679: Committed. Elapsed time: 3 ms.
25/02/04 17:13:52 INFO Executor: Finished task 139.0 in stage 50.0 (TID 679). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO Executor: Running task 148.0 in stage 50.0 (TID 688)
25/02/04 17:13:52 INFO TaskSetManager: Starting task 149.0 in stage 50.0 (TID 689) (10.0.0.43, executor driver, partition 149, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO Executor: Running task 149.0 in stage 50.0 (TID 689)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 138.0 in stage 50.0 (TID 678) in 700 ms on 10.0.0.43 (executor driver) (136/200)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 139.0 in stage 50.0 (TID 679) in 703 ms on 10.0.0.43 (executor driver) (137/200)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 137.0 in stage 50.0 (TID 677) in 729 ms on 10.0.0.43 (executor driver) (138/200)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 131.0 in stage 50.0 (TID 671) in 1163 ms on 10.0.0.43 (executor driver) (139/200)
25/02/04 17:13:52 INFO TaskSetManager: Finished task 132.0 in stage 50.0 (TID 672) in 1163 ms on 10.0.0.43 (executor driver) (140/200)
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_149 stored as values in memory (estimated size 1166.6 KiB, free 28.4 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_149 locally
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_148 stored as values in memory (estimated size 1260.4 KiB, free 27.1 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_148 locally
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000140_680' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000140
25/02/04 17:13:52 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000140_680: Committed. Elapsed time: 0 ms.
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO Executor: Finished task 140.0 in stage 50.0 (TID 680). 17954 bytes result sent to driver
25/02/04 17:13:52 INFO TaskSetManager: Starting task 150.0 in stage 50.0 (TID 690) (10.0.0.43, executor driver, partition 150, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:52 INFO TaskSetManager: Finished task 140.0 in stage 50.0 (TID 680) in 755 ms on 10.0.0.43 (executor driver) (141/200)
25/02/04 17:13:52 INFO Executor: Running task 150.0 in stage 50.0 (TID 690)
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO MemoryStore: Block rdd_72_150 stored as values in memory (estimated size 1152.4 KiB, free 8.0 MiB)
25/02/04 17:13:52 INFO BlockManager: Found block rdd_72_150 locally
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:52 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:52 INFO MemoryStore: 2 blocks selected for dropping (2.5 MiB bytes)
25/02/04 17:13:52 INFO BlockManager: Dropping block rdd_72_181 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_181 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_181 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_177 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_177 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_177 on disk on 10.0.0.43:62420 (current size: 1310.4 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO MemoryStore: After dropping 2 blocks, free memory is 4.5 MiB
25/02/04 17:13:53 INFO MemoryStore: 6 blocks selected for dropping (7.6 MiB bytes)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_184 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_184 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_184 on disk on 10.0.0.43:62420 (current size: 962.8 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_182 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_182 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_182 on disk on 10.0.0.43:62420 (current size: 1110.7 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_185 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_185 to disk
25/02/04 17:13:53 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_185 on disk on 10.0.0.43:62420 (current size: 1088.7 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_186 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_186 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_186 on disk on 10.0.0.43:62420 (current size: 1048.2 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_187 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_187 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_187 on disk on 10.0.0.43:62420 (current size: 1739.0 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_189 from memory
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_189 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_189 on disk on 10.0.0.43:62420 (current size: 1400.9 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO MemoryStore: After dropping 6 blocks, free memory is 8.1 MiB
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000147_687' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000147
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000147_687: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO Executor: Finished task 147.0 in stage 50.0 (TID 687). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000144_684' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000144
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000144_684: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO TaskSetManager: Starting task 151.0 in stage 50.0 (TID 691) (10.0.0.43, executor driver, partition 151, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO TaskSetManager: Finished task 147.0 in stage 50.0 (TID 687) in 519 ms on 10.0.0.43 (executor driver) (142/200)
25/02/04 17:13:53 INFO Executor: Running task 151.0 in stage 50.0 (TID 691)
25/02/04 17:13:53 INFO Executor: Finished task 144.0 in stage 50.0 (TID 684). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO TaskSetManager: Starting task 152.0 in stage 50.0 (TID 692) (10.0.0.43, executor driver, partition 152, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO Executor: Running task 152.0 in stage 50.0 (TID 692)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 144.0 in stage 50.0 (TID 684) in 573 ms on 10.0.0.43 (executor driver) (143/200)
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000142_682' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000142
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000142_682: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000141_681' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000141
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000141_681: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000146_686' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000146
25/02/04 17:13:53 INFO Executor: Finished task 141.0 in stage 50.0 (TID 681). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO Executor: Finished task 142.0 in stage 50.0 (TID 682). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000146_686: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO TaskSetManager: Starting task 153.0 in stage 50.0 (TID 693) (10.0.0.43, executor driver, partition 153, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO Executor: Running task 153.0 in stage 50.0 (TID 693)
25/02/04 17:13:53 INFO TaskSetManager: Starting task 154.0 in stage 50.0 (TID 694) (10.0.0.43, executor driver, partition 154, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO TaskSetManager: Finished task 141.0 in stage 50.0 (TID 681) in 916 ms on 10.0.0.43 (executor driver) (144/200)
25/02/04 17:13:53 INFO Executor: Running task 154.0 in stage 50.0 (TID 694)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 142.0 in stage 50.0 (TID 682) in 914 ms on 10.0.0.43 (executor driver) (145/200)
25/02/04 17:13:53 INFO Executor: Finished task 146.0 in stage 50.0 (TID 686). 17997 bytes result sent to driver
25/02/04 17:13:53 INFO TaskSetManager: Starting task 155.0 in stage 50.0 (TID 695) (10.0.0.43, executor driver, partition 155, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO TaskSetManager: Finished task 146.0 in stage 50.0 (TID 686) in 573 ms on 10.0.0.43 (executor driver) (146/200)
25/02/04 17:13:53 INFO Executor: Running task 155.0 in stage 50.0 (TID 695)
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000143_683' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000143
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000143_683: Committed. Elapsed time: 1 ms.
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000145_685' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000145
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000145_685: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO Executor: Finished task 143.0 in stage 50.0 (TID 683). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO Executor: Finished task 145.0 in stage 50.0 (TID 685). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO TaskSetManager: Starting task 156.0 in stage 50.0 (TID 696) (10.0.0.43, executor driver, partition 156, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO TaskSetManager: Starting task 157.0 in stage 50.0 (TID 697) (10.0.0.43, executor driver, partition 157, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO Executor: Running task 156.0 in stage 50.0 (TID 696)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 145.0 in stage 50.0 (TID 685) in 581 ms on 10.0.0.43 (executor driver) (147/200)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 143.0 in stage 50.0 (TID 683) in 916 ms on 10.0.0.43 (executor driver) (148/200)
25/02/04 17:13:53 INFO Executor: Running task 157.0 in stage 50.0 (TID 697)
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000149_689' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000149
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000149_689: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO Executor: Finished task 149.0 in stage 50.0 (TID 689). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO TaskSetManager: Starting task 158.0 in stage 50.0 (TID 698) (10.0.0.43, executor driver, partition 158, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_153 stored as values in memory (estimated size 994.4 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_151 stored as values in memory (estimated size 1217.8 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_156 stored as values in memory (estimated size 1061.6 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_152 stored as values in memory (estimated size 1410.1 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_157 stored as values in memory (estimated size 1199.3 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_155 stored as values in memory (estimated size 1139.9 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_154 stored as values in memory (estimated size 1069.8 KiB, free 134.2 MiB)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 149.0 in stage 50.0 (TID 689) in 526 ms on 10.0.0.43 (executor driver) (149/200)
25/02/04 17:13:53 INFO Executor: Running task 158.0 in stage 50.0 (TID 698)
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_153 locally
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_152 locally
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_157 locally
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_155 locally
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_156 locally
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000148_688' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000148
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000148_688: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO Executor: Finished task 148.0 in stage 50.0 (TID 688). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO TaskSetManager: Starting task 159.0 in stage 50.0 (TID 699) (10.0.0.43, executor driver, partition 159, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_151 locally
25/02/04 17:13:53 INFO TaskSetManager: Finished task 148.0 in stage 50.0 (TID 688) in 556 ms on 10.0.0.43 (executor driver) (150/200)
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_154 locally
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_158 stored as values in memory (estimated size 1398.2 KiB, free 82.8 MiB)
25/02/04 17:13:53 INFO Executor: Running task 159.0 in stage 50.0 (TID 699)
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_158 locally
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_159 stored as values in memory (estimated size 1537.9 KiB, free 65.1 MiB)
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_159 locally
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO MemoryStore: 5 blocks selected for dropping (6.5 MiB bytes)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_188 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_188 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_188 on disk on 10.0.0.43:62420 (current size: 1143.5 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_190 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_190 to disk
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_190 on disk on 10.0.0.43:62420 (current size: 1253.6 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_191 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_191 to disk
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_191 on disk on 10.0.0.43:62420 (current size: 1355.3 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_192 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_192 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_192 on disk on 10.0.0.43:62420 (current size: 1012.3 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_196 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_196 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_196 on disk on 10.0.0.43:62420 (current size: 1587.2 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO MemoryStore: After dropping 5 blocks, free memory is 9.5 MiB
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000150_690' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000150
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000150_690: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO Executor: Finished task 150.0 in stage 50.0 (TID 690). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO TaskSetManager: Starting task 160.0 in stage 50.0 (TID 700) (10.0.0.43, executor driver, partition 160, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO Executor: Running task 160.0 in stage 50.0 (TID 700)
25/02/04 17:13:53 INFO TaskSetManager: Finished task 150.0 in stage 50.0 (TID 690) in 604 ms on 10.0.0.43 (executor driver) (151/200)
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO MemoryStore: Block rdd_72_160 stored as values in memory (estimated size 1206.5 KiB, free 16.4 MiB)
25/02/04 17:13:53 INFO BlockManager: Found block rdd_72_160 locally
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:53 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_193 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_193 to disk
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_193 on disk on 10.0.0.43:62420 (current size: 1194.9 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO BlockManager: Dropping block rdd_72_194 from memory
25/02/04 17:13:53 INFO BlockManager: Writing block rdd_72_194 to disk
25/02/04 17:13:53 INFO BlockManagerInfo: Updated rdd_72_194 on disk on 10.0.0.43:62420 (current size: 952.6 KiB, original size: 0.0 B)
25/02/04 17:13:53 INFO MemoryStore: After dropping 2 blocks, free memory is 8.6 MiB
25/02/04 17:13:53 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000156_696' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000156
25/02/04 17:13:53 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000156_696: Committed. Elapsed time: 0 ms.
25/02/04 17:13:53 INFO Executor: Finished task 156.0 in stage 50.0 (TID 696). 17954 bytes result sent to driver
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:53 INFO TaskSetManager: Starting task 161.0 in stage 50.0 (TID 701) (10.0.0.43, executor driver, partition 161, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:53 INFO TaskSetManager: Finished task 156.0 in stage 50.0 (TID 696) in 652 ms on 10.0.0.43 (executor driver) (152/200)
25/02/04 17:13:53 INFO Executor: Running task 161.0 in stage 50.0 (TID 701)
25/02/04 17:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_161 stored as values in memory (estimated size 1138.7 KiB, free 81.3 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_161 locally
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000155_695' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000155
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000155_695: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO Executor: Finished task 155.0 in stage 50.0 (TID 695). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 162.0 in stage 50.0 (TID 702) (10.0.0.43, executor driver, partition 162, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 162.0 in stage 50.0 (TID 702)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 155.0 in stage 50.0 (TID 695) in 772 ms on 10.0.0.43 (executor driver) (153/200)
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000153_693' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000153
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000153_693: Committed. Elapsed time: 13 ms.
25/02/04 17:13:54 INFO Executor: Finished task 153.0 in stage 50.0 (TID 693). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 163.0 in stage 50.0 (TID 703) (10.0.0.43, executor driver, partition 163, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000157_697' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000157
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000157_697: Committed. Elapsed time: 0 ms.
25/02/04 17:13:54 INFO Executor: Running task 163.0 in stage 50.0 (TID 703)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 153.0 in stage 50.0 (TID 693) in 855 ms on 10.0.0.43 (executor driver) (154/200)
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000152_692' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000152
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000152_692: Committed. Elapsed time: 0 ms.
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_162 stored as values in memory (estimated size 1247.5 KiB, free 100.1 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_162 locally
25/02/04 17:13:54 INFO Executor: Finished task 157.0 in stage 50.0 (TID 697). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO Executor: Finished task 152.0 in stage 50.0 (TID 692). 17954 bytes result sent to driver
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO TaskSetManager: Starting task 164.0 in stage 50.0 (TID 704) (10.0.0.43, executor driver, partition 164, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Starting task 165.0 in stage 50.0 (TID 705) (10.0.0.43, executor driver, partition 165, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 165.0 in stage 50.0 (TID 705)
25/02/04 17:13:54 INFO Executor: Running task 164.0 in stage 50.0 (TID 704)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 152.0 in stage 50.0 (TID 692) in 891 ms on 10.0.0.43 (executor driver) (155/200)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 157.0 in stage 50.0 (TID 697) in 877 ms on 10.0.0.43 (executor driver) (156/200)
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_164 stored as values in memory (estimated size 1434.8 KiB, free 80.7 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_164 locally
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_163 stored as values in memory (estimated size 1328.4 KiB, free 79.4 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_163 locally
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_165 stored as values in memory (estimated size 1185.7 KiB, free 89.2 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_165 locally
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000151_691' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000151
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000151_691: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000154_694' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000154
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000154_694: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO Executor: Finished task 154.0 in stage 50.0 (TID 694). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO Executor: Finished task 151.0 in stage 50.0 (TID 691). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 166.0 in stage 50.0 (TID 706) (10.0.0.43, executor driver, partition 166, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 166.0 in stage 50.0 (TID 706)
25/02/04 17:13:54 INFO TaskSetManager: Starting task 167.0 in stage 50.0 (TID 707) (10.0.0.43, executor driver, partition 167, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Finished task 154.0 in stage 50.0 (TID 694) in 1154 ms on 10.0.0.43 (executor driver) (157/200)
25/02/04 17:13:54 INFO Executor: Running task 167.0 in stage 50.0 (TID 707)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 151.0 in stage 50.0 (TID 691) in 1169 ms on 10.0.0.43 (executor driver) (158/200)
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000158_698' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000158
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000158_698: Committed. Elapsed time: 0 ms.
25/02/04 17:13:54 INFO Executor: Finished task 158.0 in stage 50.0 (TID 698). 17954 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 168.0 in stage 50.0 (TID 708) (10.0.0.43, executor driver, partition 168, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 168.0 in stage 50.0 (TID 708)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 158.0 in stage 50.0 (TID 698) in 1083 ms on 10.0.0.43 (executor driver) (159/200)
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_166 stored as values in memory (estimated size 1547.2 KiB, free 74.7 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_166 locally
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_168 stored as values in memory (estimated size 1077.6 KiB, free 73.6 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_168 locally
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_167 stored as values in memory (estimated size 1054.2 KiB, free 72.6 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_167 locally
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000159_699' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000159
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000159_699: Committed. Elapsed time: 0 ms.
25/02/04 17:13:54 INFO Executor: Finished task 159.0 in stage 50.0 (TID 699). 18040 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 169.0 in stage 50.0 (TID 709) (10.0.0.43, executor driver, partition 169, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Finished task 159.0 in stage 50.0 (TID 699) in 1159 ms on 10.0.0.43 (executor driver) (160/200)
25/02/04 17:13:54 INFO Executor: Running task 169.0 in stage 50.0 (TID 709)
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_169 stored as values in memory (estimated size 1113.0 KiB, free 5.7 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_169 locally
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO MemoryStore: 1 blocks selected for dropping (968.9 KiB bytes)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_195 from memory
25/02/04 17:13:54 INFO BlockManager: Writing block rdd_72_195 to disk
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_195 on disk on 10.0.0.43:62420 (current size: 910.4 KiB, original size: 0.0 B)
25/02/04 17:13:54 INFO MemoryStore: After dropping 1 blocks, free memory is 2.7 MiB
25/02/04 17:13:54 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:54 INFO MemoryStore: 4 blocks selected for dropping (3.6 MiB bytes)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_199 from memory
25/02/04 17:13:54 INFO BlockManager: Writing block rdd_72_199 to disk
25/02/04 17:13:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_199 on disk on 10.0.0.43:62420 (current size: 1179.4 KiB, original size: 0.0 B)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_197 from memory
25/02/04 17:13:54 INFO BlockManager: Writing block rdd_72_197 to disk
25/02/04 17:13:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_197 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 0.0 B)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_198 from memory
25/02/04 17:13:54 INFO BlockManager: Writing block rdd_72_198 to disk
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_198 on disk on 10.0.0.43:62420 (current size: 947.7 KiB, original size: 0.0 B)
25/02/04 17:13:54 INFO BlockManager: Dropping block broadcast_25 from memory
25/02/04 17:13:54 INFO BlockManager: Writing block broadcast_25 to disk
25/02/04 17:13:54 INFO MemoryStore: After dropping 4 blocks, free memory is 4.3 MiB
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000160_700' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000160
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000160_700: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000161_701' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000161
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000161_701: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO Executor: Finished task 160.0 in stage 50.0 (TID 700). 17954 bytes result sent to driver
25/02/04 17:13:54 INFO Executor: Finished task 161.0 in stage 50.0 (TID 701). 17954 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 170.0 in stage 50.0 (TID 710) (10.0.0.43, executor driver, partition 170, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 170.0 in stage 50.0 (TID 710)
25/02/04 17:13:54 INFO TaskSetManager: Starting task 171.0 in stage 50.0 (TID 711) (10.0.0.43, executor driver, partition 171, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO Executor: Running task 171.0 in stage 50.0 (TID 711)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 160.0 in stage 50.0 (TID 700) in 1177 ms on 10.0.0.43 (executor driver) (161/200)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 161.0 in stage 50.0 (TID 701) in 771 ms on 10.0.0.43 (executor driver) (162/200)
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_171 stored as values in memory (estimated size 1299.1 KiB, free 27.0 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_171 locally
25/02/04 17:13:54 INFO MemoryStore: Block rdd_72_170 stored as values in memory (estimated size 1245.6 KiB, free 25.8 MiB)
25/02/04 17:13:54 INFO BlockManager: Found block rdd_72_170 locally
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:54 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_3 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_3 on disk on 10.0.0.43:62420 (current size: 987.2 KiB, original size: 987.2 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_4 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_4 on disk on 10.0.0.43:62420 (current size: 1183.4 KiB, original size: 1183.4 KiB)
25/02/04 17:13:54 INFO MemoryStore: After dropping 2 blocks, free memory is 4.0 MiB
25/02/04 17:13:54 INFO MemoryStore: 7 blocks selected for dropping (8.3 MiB bytes)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_1 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_1 on disk on 10.0.0.43:62420 (current size: 1494.1 KiB, original size: 1494.1 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_2 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_2 on disk on 10.0.0.43:62420 (current size: 1110.3 KiB, original size: 1110.3 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_7 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_7 on disk on 10.0.0.43:62420 (current size: 895.3 KiB, original size: 895.3 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_6 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_6 on disk on 10.0.0.43:62420 (current size: 1175.2 KiB, original size: 1175.2 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_8 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_8 on disk on 10.0.0.43:62420 (current size: 1237.7 KiB, original size: 1237.7 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_5 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_5 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 1031.0 KiB)
25/02/04 17:13:54 INFO BlockManager: Dropping block rdd_72_9 from memory
25/02/04 17:13:54 INFO BlockManagerInfo: Updated rdd_72_9 on disk on 10.0.0.43:62420 (current size: 1084.9 KiB, original size: 1084.9 KiB)
25/02/04 17:13:54 INFO MemoryStore: After dropping 7 blocks, free memory is 8.3 MiB
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000167_707' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000167
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000167_707: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000163_703' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000163
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000163_703: Committed. Elapsed time: 2 ms.
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000162_702' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000162
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000162_702: Committed. Elapsed time: 0 ms.
25/02/04 17:13:54 INFO Executor: Finished task 167.0 in stage 50.0 (TID 707). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO Executor: Finished task 162.0 in stage 50.0 (TID 702). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO Executor: Finished task 163.0 in stage 50.0 (TID 703). 17997 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 172.0 in stage 50.0 (TID 712) (10.0.0.43, executor driver, partition 172, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Finished task 162.0 in stage 50.0 (TID 702) in 941 ms on 10.0.0.43 (executor driver) (163/200)
25/02/04 17:13:54 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000168_708' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000168
25/02/04 17:13:54 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000168_708: Committed. Elapsed time: 1 ms.
25/02/04 17:13:54 INFO Executor: Finished task 168.0 in stage 50.0 (TID 708). 17954 bytes result sent to driver
25/02/04 17:13:54 INFO TaskSetManager: Starting task 173.0 in stage 50.0 (TID 713) (10.0.0.43, executor driver, partition 173, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Starting task 174.0 in stage 50.0 (TID 714) (10.0.0.43, executor driver, partition 174, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Starting task 175.0 in stage 50.0 (TID 715) (10.0.0.43, executor driver, partition 175, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:54 INFO TaskSetManager: Finished task 163.0 in stage 50.0 (TID 703) in 866 ms on 10.0.0.43 (executor driver) (164/200)
25/02/04 17:13:54 INFO Executor: Running task 172.0 in stage 50.0 (TID 712)
25/02/04 17:13:54 INFO Executor: Running task 173.0 in stage 50.0 (TID 713)
25/02/04 17:13:54 INFO Executor: Running task 174.0 in stage 50.0 (TID 714)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 167.0 in stage 50.0 (TID 707) in 564 ms on 10.0.0.43 (executor driver) (165/200)
25/02/04 17:13:54 INFO Executor: Running task 175.0 in stage 50.0 (TID 715)
25/02/04 17:13:54 INFO TaskSetManager: Finished task 168.0 in stage 50.0 (TID 708) in 548 ms on 10.0.0.43 (executor driver) (166/200)
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000165_705' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000165
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000165_705: Committed. Elapsed time: 0 ms.
25/02/04 17:13:55 INFO Executor: Finished task 165.0 in stage 50.0 (TID 705). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 176.0 in stage 50.0 (TID 716) (10.0.0.43, executor driver, partition 176, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_172 stored as values in memory (estimated size 936.9 KiB, free 101.2 MiB)
25/02/04 17:13:55 INFO Executor: Running task 176.0 in stage 50.0 (TID 716)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_172 locally
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_173 stored as values in memory (estimated size 1103.4 KiB, free 100.2 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_173 locally
25/02/04 17:13:55 INFO TaskSetManager: Finished task 165.0 in stage 50.0 (TID 705) in 874 ms on 10.0.0.43 (executor driver) (167/200)
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_175 stored as values in memory (estimated size 1094.3 KiB, free 96.7 MiB)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_176 stored as values in memory (estimated size 1020.3 KiB, free 96.7 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_175 locally
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_176 locally
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_174 stored as values in memory (estimated size 1313.1 KiB, free 96.7 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_174 locally
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000164_704' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000164
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000164_704: Committed. Elapsed time: 1 ms.
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO Executor: Finished task 164.0 in stage 50.0 (TID 704). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 177.0 in stage 50.0 (TID 717) (10.0.0.43, executor driver, partition 177, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO TaskSetManager: Finished task 164.0 in stage 50.0 (TID 704) in 1222 ms on 10.0.0.43 (executor driver) (168/200)
25/02/04 17:13:55 INFO Executor: Running task 177.0 in stage 50.0 (TID 717)
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_177 stored as values in memory (estimated size 1384.6 KiB, free 31.5 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_177 locally
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:55 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:55 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000169_709' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000169
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000169_709: Committed. Elapsed time: 1 ms.
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000172_712' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000172
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000172_712: Committed. Elapsed time: 2 ms.
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000176_716' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000176
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000176_716: Committed. Elapsed time: 7 ms.
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO Executor: Finished task 176.0 in stage 50.0 (TID 716). 17997 bytes result sent to driver
25/02/04 17:13:55 INFO Executor: Finished task 169.0 in stage 50.0 (TID 709). 17997 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 178.0 in stage 50.0 (TID 718) (10.0.0.43, executor driver, partition 178, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO TaskSetManager: Starting task 179.0 in stage 50.0 (TID 719) (10.0.0.43, executor driver, partition 179, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 178.0 in stage 50.0 (TID 718)
25/02/04 17:13:55 INFO Executor: Running task 179.0 in stage 50.0 (TID 719)
25/02/04 17:13:55 INFO Executor: Finished task 172.0 in stage 50.0 (TID 712). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 180.0 in stage 50.0 (TID 720) (10.0.0.43, executor driver, partition 180, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 180.0 in stage 50.0 (TID 720)
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000171_711' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000171
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000171_711: Committed. Elapsed time: 2 ms.
25/02/04 17:13:55 INFO TaskSetManager: Finished task 169.0 in stage 50.0 (TID 709) in 1184 ms on 10.0.0.43 (executor driver) (169/200)
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000170_710' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000170
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000170_710: Committed. Elapsed time: 2 ms.
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000175_715' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000175
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000175_715: Committed. Elapsed time: 1 ms.
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_179 stored as values in memory (estimated size 1459.9 KiB, free 147.5 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_179 locally
25/02/04 17:13:55 INFO TaskSetManager: Finished task 172.0 in stage 50.0 (TID 712) in 752 ms on 10.0.0.43 (executor driver) (170/200)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_180 stored as values in memory (estimated size 1080.7 KiB, free 147.5 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_180 locally
25/02/04 17:13:55 INFO TaskSetManager: Finished task 176.0 in stage 50.0 (TID 716) in 718 ms on 10.0.0.43 (executor driver) (171/200)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_178 stored as values in memory (estimated size 1351.0 KiB, free 146.2 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_178 locally
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO Executor: Finished task 175.0 in stage 50.0 (TID 715). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO Executor: Finished task 171.0 in stage 50.0 (TID 711). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO Executor: Finished task 170.0 in stage 50.0 (TID 710). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 181.0 in stage 50.0 (TID 721) (10.0.0.43, executor driver, partition 181, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 181.0 in stage 50.0 (TID 721)
25/02/04 17:13:55 INFO TaskSetManager: Starting task 182.0 in stage 50.0 (TID 722) (10.0.0.43, executor driver, partition 182, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO TaskSetManager: Starting task 183.0 in stage 50.0 (TID 723) (10.0.0.43, executor driver, partition 183, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 182.0 in stage 50.0 (TID 722)
25/02/04 17:13:55 INFO TaskSetManager: Finished task 175.0 in stage 50.0 (TID 715) in 760 ms on 10.0.0.43 (executor driver) (172/200)
25/02/04 17:13:55 INFO Executor: Running task 183.0 in stage 50.0 (TID 723)
25/02/04 17:13:55 INFO TaskSetManager: Finished task 170.0 in stage 50.0 (TID 710) in 1070 ms on 10.0.0.43 (executor driver) (173/200)
25/02/04 17:13:55 INFO TaskSetManager: Finished task 171.0 in stage 50.0 (TID 711) in 1068 ms on 10.0.0.43 (executor driver) (174/200)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_181 stored as values in memory (estimated size 1168.3 KiB, free 93.0 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_181 locally
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_183 stored as values in memory (estimated size 1091.3 KiB, free 92.0 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_183 locally
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_182 stored as values in memory (estimated size 1175.7 KiB, free 84.2 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_182 locally
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000166_706' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000166
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000166_706: Committed. Elapsed time: 0 ms.
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO Executor: Finished task 166.0 in stage 50.0 (TID 706). 18040 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 184.0 in stage 50.0 (TID 724) (10.0.0.43, executor driver, partition 184, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO TaskSetManager: Finished task 166.0 in stage 50.0 (TID 706) in 1356 ms on 10.0.0.43 (executor driver) (175/200)
25/02/04 17:13:55 INFO Executor: Running task 184.0 in stage 50.0 (TID 724)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_184 stored as values in memory (estimated size 1023.9 KiB, free 37.8 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_184 locally
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000173_713' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000173
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000173_713: Committed. Elapsed time: 0 ms.
25/02/04 17:13:55 INFO Executor: Finished task 173.0 in stage 50.0 (TID 713). 17954 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 185.0 in stage 50.0 (TID 725) (10.0.0.43, executor driver, partition 185, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 185.0 in stage 50.0 (TID 725)
25/02/04 17:13:55 INFO TaskSetManager: Finished task 173.0 in stage 50.0 (TID 713) in 839 ms on 10.0.0.43 (executor driver) (176/200)
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_185 stored as values in memory (estimated size 1151.8 KiB, free 30.7 MiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_185 locally
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000174_714' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000174
25/02/04 17:13:55 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000174_714: Committed. Elapsed time: 1 ms.
25/02/04 17:13:55 INFO Executor: Finished task 174.0 in stage 50.0 (TID 714). 17997 bytes result sent to driver
25/02/04 17:13:55 INFO TaskSetManager: Starting task 186.0 in stage 50.0 (TID 726) (10.0.0.43, executor driver, partition 186, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:55 INFO Executor: Running task 186.0 in stage 50.0 (TID 726)
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO TaskSetManager: Finished task 174.0 in stage 50.0 (TID 714) in 979 ms on 10.0.0.43 (executor driver) (177/200)
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:55 INFO MemoryStore: Block rdd_72_186 stored as values in memory (estimated size 1115.1 KiB, free 1631.8 KiB)
25/02/04 17:13:55 INFO BlockManager: Found block rdd_72_186 locally
25/02/04 17:13:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO MemoryStore: 1 blocks selected for dropping (1104.4 KiB bytes)
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_0 from memory
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_0 on disk on 10.0.0.43:62420 (current size: 1043.3 KiB, original size: 1043.3 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:13:56 INFO MemoryStore: 1 blocks selected for dropping (1153.5 KiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_11 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_11 on disk on 10.0.0.43:62420 (current size: 1090.0 KiB, original size: 1090.0 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 1 blocks, free memory is 1585.7 KiB
25/02/04 17:13:56 INFO MemoryStore: 1 blocks selected for dropping (1538.4 KiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_17 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_17 on disk on 10.0.0.43:62420 (current size: 1455.6 KiB, original size: 1455.6 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:13:56 INFO MemoryStore: 1 blocks selected for dropping (1160.4 KiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_10 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_10 on disk on 10.0.0.43:62420 (current size: 1093.3 KiB, original size: 1093.3 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:13:56 INFO MemoryStore: 3 blocks selected for dropping (3.7 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_13 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_13 on disk on 10.0.0.43:62420 (current size: 1373.4 KiB, original size: 1373.4 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_16 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_16 on disk on 10.0.0.43:62420 (current size: 1109.4 KiB, original size: 1109.4 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_12 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_12 on disk on 10.0.0.43:62420 (current size: 1138.3 KiB, original size: 1138.3 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 3 blocks, free memory is 4.2 MiB
25/02/04 17:13:56 INFO MemoryStore: 6 blocks selected for dropping (8.0 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_14 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_14 on disk on 10.0.0.43:62420 (current size: 1827.2 KiB, original size: 1827.2 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_19 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_19 on disk on 10.0.0.43:62420 (current size: 1310.5 KiB, original size: 1310.5 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_15 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_15 on disk on 10.0.0.43:62420 (current size: 1246.0 KiB, original size: 1246.0 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_18 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_18 on disk on 10.0.0.43:62420 (current size: 918.0 KiB, original size: 918.0 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_26 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_26 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 1185.0 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_22 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_22 on disk on 10.0.0.43:62420 (current size: 1206.1 KiB, original size: 1206.1 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 6 blocks, free memory is 8.1 MiB
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:56 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000180_720' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000180
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000180_720: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000185_725' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000185
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000185_725: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 185.0 in stage 50.0 (TID 725). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO Executor: Finished task 180.0 in stage 50.0 (TID 720). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 187.0 in stage 50.0 (TID 727) (10.0.0.43, executor driver, partition 187, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 187.0 in stage 50.0 (TID 727)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000184_724' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000184
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000184_724: Committed. Elapsed time: 3 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000181_721' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000181
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000181_721: Committed. Elapsed time: 4 ms.
25/02/04 17:13:56 INFO Executor: Finished task 184.0 in stage 50.0 (TID 724). 17997 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Finished task 185.0 in stage 50.0 (TID 725) in 431 ms on 10.0.0.43 (executor driver) (178/200)
25/02/04 17:13:56 INFO Executor: Finished task 181.0 in stage 50.0 (TID 721). 17997 bytes result sent to driver
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000178_718' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000178
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000178_718: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 178.0 in stage 50.0 (TID 718). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 188.0 in stage 50.0 (TID 728) (10.0.0.43, executor driver, partition 188, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Starting task 189.0 in stage 50.0 (TID 729) (10.0.0.43, executor driver, partition 189, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Starting task 190.0 in stage 50.0 (TID 730) (10.0.0.43, executor driver, partition 190, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Finished task 180.0 in stage 50.0 (TID 720) in 566 ms on 10.0.0.43 (executor driver) (179/200)
25/02/04 17:13:56 INFO TaskSetManager: Starting task 191.0 in stage 50.0 (TID 731) (10.0.0.43, executor driver, partition 191, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 191.0 in stage 50.0 (TID 731)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 181.0 in stage 50.0 (TID 721) in 518 ms on 10.0.0.43 (executor driver) (180/200)
25/02/04 17:13:56 INFO Executor: Running task 188.0 in stage 50.0 (TID 728)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 178.0 in stage 50.0 (TID 718) in 621 ms on 10.0.0.43 (executor driver) (181/200)
25/02/04 17:13:56 INFO Executor: Running task 189.0 in stage 50.0 (TID 729)
25/02/04 17:13:56 INFO Executor: Running task 190.0 in stage 50.0 (TID 730)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 184.0 in stage 50.0 (TID 724) in 487 ms on 10.0.0.43 (executor driver) (182/200)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000179_719' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000179
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000179_719: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000183_723' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000183
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000183_723: Committed. Elapsed time: 2 ms.
25/02/04 17:13:56 INFO Executor: Finished task 183.0 in stage 50.0 (TID 723). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 192.0 in stage 50.0 (TID 732) (10.0.0.43, executor driver, partition 192, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Finished task 183.0 in stage 50.0 (TID 723) in 521 ms on 10.0.0.43 (executor driver) (183/200)
25/02/04 17:13:56 INFO Executor: Running task 192.0 in stage 50.0 (TID 732)
25/02/04 17:13:56 INFO Executor: Finished task 179.0 in stage 50.0 (TID 719). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 193.0 in stage 50.0 (TID 733) (10.0.0.43, executor driver, partition 193, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Finished task 179.0 in stage 50.0 (TID 719) in 614 ms on 10.0.0.43 (executor driver) (184/200)
25/02/04 17:13:56 INFO Executor: Running task 193.0 in stage 50.0 (TID 733)
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_188 stored as values in memory (estimated size 1209.4 KiB, free 139.0 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_188 locally
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000177_717' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000177
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000177_717: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 177.0 in stage 50.0 (TID 717). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 194.0 in stage 50.0 (TID 734) (10.0.0.43, executor driver, partition 194, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 194.0 in stage 50.0 (TID 734)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 177.0 in stage 50.0 (TID 717) in 922 ms on 10.0.0.43 (executor driver) (185/200)
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_193 stored as values in memory (estimated size 1261.6 KiB, free 137.7 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_193 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_192 stored as values in memory (estimated size 1074.5 KiB, free 136.7 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_192 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_191 stored as values in memory (estimated size 1429.8 KiB, free 135.3 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_191 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_194 stored as values in memory (estimated size 1006.5 KiB, free 134.3 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_194 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_190 stored as values in memory (estimated size 1326.0 KiB, free 133.0 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_190 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_187 stored as values in memory (estimated size 1826.0 KiB, free 131.2 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_187 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_189 stored as values in memory (estimated size 1483.9 KiB, free 147.8 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_189 locally
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000182_722' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000182
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000182_722: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO Executor: Finished task 182.0 in stage 50.0 (TID 722). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 195.0 in stage 50.0 (TID 735) (10.0.0.43, executor driver, partition 195, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 195.0 in stage 50.0 (TID 735)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 182.0 in stage 50.0 (TID 722) in 626 ms on 10.0.0.43 (executor driver) (186/200)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000186_726' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000186
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000186_726: Committed. Elapsed time: 2 ms.
25/02/04 17:13:56 INFO Executor: Finished task 186.0 in stage 50.0 (TID 726). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 196.0 in stage 50.0 (TID 736) (10.0.0.43, executor driver, partition 196, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO TaskSetManager: Finished task 186.0 in stage 50.0 (TID 726) in 431 ms on 10.0.0.43 (executor driver) (187/200)
25/02/04 17:13:56 INFO Executor: Running task 196.0 in stage 50.0 (TID 736)
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_196 stored as values in memory (estimated size 1663.1 KiB, free 27.2 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_196 locally
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_195 stored as values in memory (estimated size 968.9 KiB, free 25.2 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_195 locally
25/02/04 17:13:56 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 22.0 MiB to disk (0  time so far)
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_21 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_21 on disk on 10.0.0.43:62420 (current size: 911.0 KiB, original size: 911.0 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_20 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_20 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 1080.3 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:13:56 INFO MemoryStore: 7 blocks selected for dropping (7.7 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_25 from memory
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_25 on disk on 10.0.0.43:62420 (current size: 930.4 KiB, original size: 930.4 KiB)
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_24 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_24 on disk on 10.0.0.43:62420 (current size: 1032.1 KiB, original size: 1032.1 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_23 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_23 on disk on 10.0.0.43:62420 (current size: 1091.7 KiB, original size: 1091.7 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_28 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_28 on disk on 10.0.0.43:62420 (current size: 1014.4 KiB, original size: 1014.4 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_27 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_27 on disk on 10.0.0.43:62420 (current size: 811.7 KiB, original size: 811.7 KiB)
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_29 from memory
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_29 on disk on 10.0.0.43:62420 (current size: 1303.4 KiB, original size: 1303.4 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_30 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_30 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 1269.9 KiB)
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO MemoryStore: After dropping 7 blocks, free memory is 8.1 MiB
25/02/04 17:13:56 INFO MemoryStore: 4 blocks selected for dropping (4.6 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_31 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_31 on disk on 10.0.0.43:62420 (current size: 1153.2 KiB, original size: 1153.2 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_33 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_33 on disk on 10.0.0.43:62420 (current size: 1002.7 KiB, original size: 1002.7 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_32 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_32 on disk on 10.0.0.43:62420 (current size: 1224.7 KiB, original size: 1224.7 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_34 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_34 on disk on 10.0.0.43:62420 (current size: 1065.7 KiB, original size: 1065.7 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 4 blocks, free memory is 4.7 MiB
25/02/04 17:13:56 INFO MemoryStore: 5 blocks selected for dropping (5.7 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_35 from memory
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_35 on disk on 10.0.0.43:62420 (current size: 1036.4 KiB, original size: 1036.4 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_36 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_36 on disk on 10.0.0.43:62420 (current size: 1002.0 KiB, original size: 1002.0 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_38 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_38 on disk on 10.0.0.43:62420 (current size: 1049.2 KiB, original size: 1049.2 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_37 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_37 on disk on 10.0.0.43:62420 (current size: 1156.5 KiB, original size: 1156.5 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_39 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_39 on disk on 10.0.0.43:62420 (current size: 1210.6 KiB, original size: 1210.6 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 5 blocks, free memory is 8.3 MiB
25/02/04 17:13:56 INFO MemoryStore: 2 blocks selected for dropping (2.4 MiB bytes)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_44 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_44 on disk on 10.0.0.43:62420 (current size: 1113.5 KiB, original size: 1113.5 KiB)
25/02/04 17:13:56 INFO BlockManager: Dropping block rdd_72_41 from memory
25/02/04 17:13:56 INFO BlockManagerInfo: Updated rdd_72_41 on disk on 10.0.0.43:62420 (current size: 1165.3 KiB, original size: 1165.3 KiB)
25/02/04 17:13:56 INFO MemoryStore: After dropping 2 blocks, free memory is 2.7 MiB
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000192_732' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000192
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000192_732: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000191_731' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000191
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000191_731: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000194_734' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000194
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000194_734: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO Executor: Finished task 192.0 in stage 50.0 (TID 732). 17997 bytes result sent to driver
25/02/04 17:13:56 INFO Executor: Finished task 194.0 in stage 50.0 (TID 734). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO Executor: Finished task 191.0 in stage 50.0 (TID 731). 17997 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 197.0 in stage 50.0 (TID 737) (10.0.0.43, executor driver, partition 197, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 197.0 in stage 50.0 (TID 737)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000190_730' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000190
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000190_730: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO TaskSetManager: Starting task 198.0 in stage 50.0 (TID 738) (10.0.0.43, executor driver, partition 198, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Finished task 190.0 in stage 50.0 (TID 730). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Starting task 199.0 in stage 50.0 (TID 739) (10.0.0.43, executor driver, partition 199, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:56 INFO Executor: Running task 198.0 in stage 50.0 (TID 738)
25/02/04 17:13:56 INFO Executor: Running task 199.0 in stage 50.0 (TID 739)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000188_728' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000188
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000188_728: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO Executor: Finished task 188.0 in stage 50.0 (TID 728). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_199 stored as values in memory (estimated size 1240.6 KiB, free 140.8 MiB)
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_197 stored as values in memory (estimated size 1149.1 KiB, free 140.8 MiB)
25/02/04 17:13:56 INFO MemoryStore: Block rdd_72_198 stored as values in memory (estimated size 1005.0 KiB, free 140.8 MiB)
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_197 locally
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_198 locally
25/02/04 17:13:56 INFO BlockManager: Found block rdd_72_199 locally
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000189_729' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000189
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000189_729: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 189.0 in stage 50.0 (TID 729). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO TaskSetManager: Finished task 191.0 in stage 50.0 (TID 731) in 514 ms on 10.0.0.43 (executor driver) (188/200)
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO TaskSetManager: Finished task 194.0 in stage 50.0 (TID 734) in 486 ms on 10.0.0.43 (executor driver) (189/200)
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:56 INFO TaskSetManager: Finished task 192.0 in stage 50.0 (TID 732) in 509 ms on 10.0.0.43 (executor driver) (190/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 190.0 in stage 50.0 (TID 730) in 517 ms on 10.0.0.43 (executor driver) (191/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 189.0 in stage 50.0 (TID 729) in 528 ms on 10.0.0.43 (executor driver) (192/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 188.0 in stage 50.0 (TID 728) in 539 ms on 10.0.0.43 (executor driver) (193/200)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000195_735' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000195
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000195_735: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO Executor: Finished task 195.0 in stage 50.0 (TID 735). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Finished task 195.0 in stage 50.0 (TID 735) in 441 ms on 10.0.0.43 (executor driver) (194/200)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000193_733' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000193
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000193_733: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO Executor: Finished task 193.0 in stage 50.0 (TID 733). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Finished task 193.0 in stage 50.0 (TID 733) in 555 ms on 10.0.0.43 (executor driver) (195/200)
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000196_736' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000196
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000196_736: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000187_727' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000187
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000187_727: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 187.0 in stage 50.0 (TID 727). 18083 bytes result sent to driver
25/02/04 17:13:56 INFO Executor: Finished task 196.0 in stage 50.0 (TID 736). 18083 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Finished task 196.0 in stage 50.0 (TID 736) in 573 ms on 10.0.0.43 (executor driver) (196/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 187.0 in stage 50.0 (TID 727) in 754 ms on 10.0.0.43 (executor driver) (197/200)
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000198_738' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000198
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000198_738: Committed. Elapsed time: 1 ms.
25/02/04 17:13:56 INFO Executor: Finished task 198.0 in stage 50.0 (TID 738). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000199_739' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000199
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000199_739: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713421260852523407045367_0050_m_000197_737' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/training/_temporary/0/task_202502041713421260852523407045367_0050_m_000197
25/02/04 17:13:56 INFO SparkHadoopMapRedUtil: attempt_202502041713421260852523407045367_0050_m_000197_737: Committed. Elapsed time: 0 ms.
25/02/04 17:13:56 INFO Executor: Finished task 199.0 in stage 50.0 (TID 739). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO Executor: Finished task 197.0 in stage 50.0 (TID 737). 17954 bytes result sent to driver
25/02/04 17:13:56 INFO TaskSetManager: Finished task 199.0 in stage 50.0 (TID 739) in 289 ms on 10.0.0.43 (executor driver) (198/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 198.0 in stage 50.0 (TID 738) in 312 ms on 10.0.0.43 (executor driver) (199/200)
25/02/04 17:13:56 INFO TaskSetManager: Finished task 197.0 in stage 50.0 (TID 737) in 351 ms on 10.0.0.43 (executor driver) (200/200)
25/02/04 17:13:56 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
25/02/04 17:13:56 INFO DAGScheduler: ResultStage 50 (parquet at NativeMethodAccessorImpl.java:0) finished in 14.001 s
25/02/04 17:13:57 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:13:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
25/02/04 17:13:57 INFO DAGScheduler: Job 16 finished: parquet at NativeMethodAccessorImpl.java:0, took 14.050835 s
25/02/04 17:13:57 INFO FileFormatWriter: Start to commit write Job dbf11f80-60ac-488f-af89-e9ace662a86b.
25/02/04 17:13:57 INFO FileFormatWriter: Write Job dbf11f80-60ac-488f-af89-e9ace662a86b committed. Elapsed time: 225 ms.
25/02/04 17:13:57 INFO FileFormatWriter: Finished processing stats for write job dbf11f80-60ac-488f-af89-e9ace662a86b.
25/02/04 17:13:57 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO CodeGenerator: Code generated in 165.244583 ms
25/02/04 17:13:58 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:13:58 INFO DAGScheduler: Got job 17 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
25/02/04 17:13:58 INFO DAGScheduler: Final stage: ResultStage 59 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:13:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58, ShuffleMapStage 55)
25/02/04 17:13:58 INFO DAGScheduler: Missing parents: List()
25/02/04 17:13:58 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[86] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:13:58 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 299.8 KiB, free 180.0 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 113.3 KiB, free 179.9 MiB)
25/02/04 17:13:58 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.0.43:62420 (size: 113.3 KiB, free: 366.2 MiB)
25/02/04 17:13:58 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
25/02/04 17:13:58 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 59 (MapPartitionsRDD[86] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:13:58 INFO TaskSchedulerImpl: Adding task set 59.0 with 200 tasks resource profile 0
25/02/04 17:13:58 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 740) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 741) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 742) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 743) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 744) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 5.0 in stage 59.0 (TID 745) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 6.0 in stage 59.0 (TID 746) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 7.0 in stage 59.0 (TID 747) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 8.0 in stage 59.0 (TID 748) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO TaskSetManager: Starting task 9.0 in stage 59.0 (TID 749) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:58 INFO Executor: Running task 9.0 in stage 59.0 (TID 749)
25/02/04 17:13:58 INFO Executor: Running task 0.0 in stage 59.0 (TID 740)
25/02/04 17:13:58 INFO Executor: Running task 7.0 in stage 59.0 (TID 747)
25/02/04 17:13:58 INFO Executor: Running task 5.0 in stage 59.0 (TID 745)
25/02/04 17:13:58 INFO Executor: Running task 4.0 in stage 59.0 (TID 744)
25/02/04 17:13:58 INFO Executor: Running task 1.0 in stage 59.0 (TID 741)
25/02/04 17:13:58 INFO Executor: Running task 2.0 in stage 59.0 (TID 742)
25/02/04 17:13:58 INFO Executor: Running task 3.0 in stage 59.0 (TID 743)
25/02/04 17:13:58 INFO Executor: Running task 8.0 in stage 59.0 (TID 748)
25/02/04 17:13:58 INFO Executor: Running task 6.0 in stage 59.0 (TID 746)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_3 stored as values in memory (estimated size 1048.3 KiB, free 169.4 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_8 stored as values in memory (estimated size 1311.0 KiB, free 176.3 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_7 stored as values in memory (estimated size 950.4 KiB, free 168.2 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_4 stored as values in memory (estimated size 1252.8 KiB, free 168.2 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_2 stored as values in memory (estimated size 1178.9 KiB, free 173.1 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_1 stored as values in memory (estimated size 1576.2 KiB, free 169.4 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_6 stored as values in memory (estimated size 1246.8 KiB, free 171.0 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_5 stored as values in memory (estimated size 1094.6 KiB, free 171.0 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_9 stored as values in memory (estimated size 1150.5 KiB, free 172.1 MiB)
25/02/04 17:13:58 INFO MemoryStore: Block rdd_72_0 stored as values in memory (estimated size 1104.4 KiB, free 171.0 MiB)
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_4 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_8 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_0 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_9 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_5 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_7 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_1 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_6 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_2 locally
25/02/04 17:13:58 INFO BlockManager: Found block rdd_72_3 locally
25/02/04 17:13:58 INFO CodeGenerator: Code generated in 20.469 ms
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO MemoryStore: 5 blocks selected for dropping (6.6 MiB bytes)
25/02/04 17:13:58 INFO BlockManager: Dropping block rdd_72_45 from memory
25/02/04 17:13:58 INFO BlockManagerInfo: Updated rdd_72_45 on disk on 10.0.0.43:62420 (current size: 1289.8 KiB, original size: 1289.8 KiB)
25/02/04 17:13:58 INFO BlockManager: Dropping block rdd_72_40 from memory
25/02/04 17:13:58 INFO BlockManagerInfo: Updated rdd_72_40 on disk on 10.0.0.43:62420 (current size: 989.0 KiB, original size: 989.0 KiB)
25/02/04 17:13:58 INFO BlockManager: Dropping block rdd_72_43 from memory
25/02/04 17:13:58 INFO BlockManagerInfo: Updated rdd_72_43 on disk on 10.0.0.43:62420 (current size: 1189.7 KiB, original size: 1189.7 KiB)
25/02/04 17:13:58 INFO BlockManager: Dropping block rdd_72_46 from memory
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:58 INFO BlockManagerInfo: Updated rdd_72_46 on disk on 10.0.0.43:62420 (current size: 1433.6 KiB, original size: 1433.6 KiB)
25/02/04 17:13:58 INFO BlockManager: Dropping block rdd_72_42 from memory
25/02/04 17:13:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:58 INFO BlockManagerInfo: Updated rdd_72_42 on disk on 10.0.0.43:62420 (current size: 1453.8 KiB, original size: 1453.8 KiB)
25/02/04 17:13:58 INFO MemoryStore: After dropping 5 blocks, free memory is 8.8 MiB
25/02/04 17:13:58 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:58 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:58 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:13:59 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:13:59 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000004_744' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000004
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000007_747' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000007
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000004_744: Committed. Elapsed time: 6 ms.
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000007_747: Committed. Elapsed time: 6 ms.
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000009_749' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000009
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000009_749: Committed. Elapsed time: 7 ms.
25/02/04 17:13:59 INFO Executor: Finished task 7.0 in stage 59.0 (TID 747). 17997 bytes result sent to driver
25/02/04 17:13:59 INFO Executor: Finished task 4.0 in stage 59.0 (TID 744). 17997 bytes result sent to driver
25/02/04 17:13:59 INFO Executor: Finished task 9.0 in stage 59.0 (TID 749). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000005_745' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000005
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000005_745: Committed. Elapsed time: 11 ms.
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000006_746' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000006
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000006_746: Committed. Elapsed time: 11 ms.
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000002_742' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000002
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000002_742: Committed. Elapsed time: 13 ms.
25/02/04 17:13:59 INFO Executor: Finished task 2.0 in stage 59.0 (TID 742). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO Executor: Finished task 5.0 in stage 59.0 (TID 745). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO TaskSetManager: Starting task 10.0 in stage 59.0 (TID 750) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 10.0 in stage 59.0 (TID 750)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 9.0 in stage 59.0 (TID 749) in 904 ms on 10.0.0.43 (executor driver) (1/200)
25/02/04 17:13:59 INFO TaskSetManager: Starting task 11.0 in stage 59.0 (TID 751) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO TaskSetManager: Finished task 4.0 in stage 59.0 (TID 744) in 907 ms on 10.0.0.43 (executor driver) (2/200)
25/02/04 17:13:59 INFO Executor: Running task 11.0 in stage 59.0 (TID 751)
25/02/04 17:13:59 INFO TaskSetManager: Starting task 12.0 in stage 59.0 (TID 752) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 12.0 in stage 59.0 (TID 752)
25/02/04 17:13:59 INFO TaskSetManager: Starting task 13.0 in stage 59.0 (TID 753) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 13.0 in stage 59.0 (TID 753)
25/02/04 17:13:59 INFO TaskSetManager: Starting task 14.0 in stage 59.0 (TID 754) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO TaskSetManager: Finished task 7.0 in stage 59.0 (TID 747) in 915 ms on 10.0.0.43 (executor driver) (3/200)
25/02/04 17:13:59 INFO Executor: Running task 14.0 in stage 59.0 (TID 754)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 742) in 918 ms on 10.0.0.43 (executor driver) (4/200)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 5.0 in stage 59.0 (TID 745) in 917 ms on 10.0.0.43 (executor driver) (5/200)
25/02/04 17:13:59 INFO Executor: Finished task 6.0 in stage 59.0 (TID 746). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO TaskSetManager: Starting task 15.0 in stage 59.0 (TID 755) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 15.0 in stage 59.0 (TID 755)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 6.0 in stage 59.0 (TID 746) in 921 ms on 10.0.0.43 (executor driver) (6/200)
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_10 stored as values in memory (estimated size 1160.4 KiB, free 123.6 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_10 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_11 stored as values in memory (estimated size 1153.5 KiB, free 122.5 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_11 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_13 stored as values in memory (estimated size 1448.0 KiB, free 121.1 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_13 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_12 stored as values in memory (estimated size 1209.2 KiB, free 119.9 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_12 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_15 stored as values in memory (estimated size 1319.8 KiB, free 118.6 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_15 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_14 stored as values in memory (estimated size 1929.1 KiB, free 116.8 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_14 locally
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000001_741' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000001
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000001_741: Committed. Elapsed time: 9 ms.
25/02/04 17:13:59 INFO Executor: Finished task 1.0 in stage 59.0 (TID 741). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO TaskSetManager: Starting task 16.0 in stage 59.0 (TID 756) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000008_748' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000008
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000008_748: Committed. Elapsed time: 0 ms.
25/02/04 17:13:59 INFO Executor: Running task 16.0 in stage 59.0 (TID 756)
25/02/04 17:13:59 INFO Executor: Finished task 8.0 in stage 59.0 (TID 748). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO TaskSetManager: Starting task 17.0 in stage 59.0 (TID 757) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 741) in 952 ms on 10.0.0.43 (executor driver) (7/200)
25/02/04 17:13:59 INFO Executor: Running task 17.0 in stage 59.0 (TID 757)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 8.0 in stage 59.0 (TID 748) in 948 ms on 10.0.0.43 (executor driver) (8/200)
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000003_743' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000003
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000003_743: Committed. Elapsed time: 0 ms.
25/02/04 17:13:59 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000000_740' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000000
25/02/04 17:13:59 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000000_740: Committed. Elapsed time: 0 ms.
25/02/04 17:13:59 INFO Executor: Finished task 3.0 in stage 59.0 (TID 743). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO Executor: Finished task 0.0 in stage 59.0 (TID 740). 17954 bytes result sent to driver
25/02/04 17:13:59 INFO TaskSetManager: Starting task 18.0 in stage 59.0 (TID 758) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 18.0 in stage 59.0 (TID 758)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 743) in 981 ms on 10.0.0.43 (executor driver) (9/200)
25/02/04 17:13:59 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 740) in 987 ms on 10.0.0.43 (executor driver) (10/200)
25/02/04 17:13:59 INFO TaskSetManager: Starting task 19.0 in stage 59.0 (TID 759) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:13:59 INFO Executor: Running task 19.0 in stage 59.0 (TID 759)
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_17 stored as values in memory (estimated size 1538.4 KiB, free 163.7 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_17 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_16 stored as values in memory (estimated size 1175.6 KiB, free 165.2 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_16 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_18 stored as values in memory (estimated size 974.0 KiB, free 126.0 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_18 locally
25/02/04 17:13:59 INFO MemoryStore: Block rdd_72_19 stored as values in memory (estimated size 1392.1 KiB, free 122.7 MiB)
25/02/04 17:13:59 INFO BlockManager: Found block rdd_72_19 locally
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:13:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:13:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:13:59 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:59 INFO MemoryStore: 1 blocks selected for dropping (1056.0 KiB bytes)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_49 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_49 on disk on 10.0.0.43:62420 (current size: 990.4 KiB, original size: 990.4 KiB)
25/02/04 17:13:59 INFO UnsafeExternalSorter: Thread 75 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:59 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:13:59 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:13:59 INFO MemoryStore: 6 blocks selected for dropping (7.3 MiB bytes)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_48 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_48 on disk on 10.0.0.43:62420 (current size: 1205.2 KiB, original size: 1205.2 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_47 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_47 on disk on 10.0.0.43:62420 (current size: 1107.8 KiB, original size: 1107.8 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_50 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_50 on disk on 10.0.0.43:62420 (current size: 1473.5 KiB, original size: 1473.5 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_51 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_51 on disk on 10.0.0.43:62420 (current size: 958.4 KiB, original size: 958.4 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_53 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_53 on disk on 10.0.0.43:62420 (current size: 997.8 KiB, original size: 997.8 KiB)
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_52 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_52 on disk on 10.0.0.43:62420 (current size: 1301.8 KiB, original size: 1301.8 KiB)
25/02/04 17:13:59 INFO MemoryStore: After dropping 6 blocks, free memory is 9.2 MiB
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO MemoryStore: 6 blocks selected for dropping (6.9 MiB bytes)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_55 from memory
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_55 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 1031.0 KiB)
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_56 from memory
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_56 on disk on 10.0.0.43:62420 (current size: 1068.0 KiB, original size: 1068.0 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_54 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_54 on disk on 10.0.0.43:62420 (current size: 1092.8 KiB, original size: 1092.8 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_58 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_58 on disk on 10.0.0.43:62420 (current size: 901.1 KiB, original size: 901.1 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_57 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_57 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 1269.9 KiB)
25/02/04 17:13:59 INFO BlockManager: Dropping block rdd_72_59 from memory
25/02/04 17:13:59 INFO BlockManagerInfo: Updated rdd_72_59 on disk on 10.0.0.43:62420 (current size: 1326.4 KiB, original size: 1326.4 KiB)
25/02/04 17:13:59 INFO MemoryStore: After dropping 6 blocks, free memory is 8.1 MiB
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:13:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:13:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.0.43:62420 on disk (size: 113.3 KiB)
25/02/04 17:14:00 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:00 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000015_755' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000015
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000016_756' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000016
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000010_750' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000010
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000016_756: Committed. Elapsed time: 6 ms.
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000015_755: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000010_750: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000011_751' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000011
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000011_751: Committed. Elapsed time: 2 ms.
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000012_752' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000012
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000012_752: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 11.0 in stage 59.0 (TID 751). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO Executor: Finished task 12.0 in stage 59.0 (TID 752). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO Executor: Finished task 10.0 in stage 59.0 (TID 750). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO Executor: Finished task 15.0 in stage 59.0 (TID 755). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO Executor: Finished task 16.0 in stage 59.0 (TID 756). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000018_758' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000018
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000018_758: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 18.0 in stage 59.0 (TID 758). 17997 bytes result sent to driver
25/02/04 17:14:00 INFO TaskSetManager: Starting task 20.0 in stage 59.0 (TID 760) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 20.0 in stage 59.0 (TID 760)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 11.0 in stage 59.0 (TID 751) in 1219 ms on 10.0.0.43 (executor driver) (11/200)
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000019_759' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000019
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000019_759: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 19.0 in stage 59.0 (TID 759). 17954 bytes result sent to driver
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000013_753' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000013
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000013_753: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 13.0 in stage 59.0 (TID 753). 18083 bytes result sent to driver
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000017_757' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000017
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000017_757: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 17.0 in stage 59.0 (TID 757). 18040 bytes result sent to driver
25/02/04 17:14:00 INFO TaskSetManager: Starting task 21.0 in stage 59.0 (TID 761) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 21.0 in stage 59.0 (TID 761)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 10.0 in stage 59.0 (TID 750) in 1260 ms on 10.0.0.43 (executor driver) (12/200)
25/02/04 17:14:00 INFO TaskSetManager: Starting task 22.0 in stage 59.0 (TID 762) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 22.0 in stage 59.0 (TID 762)
25/02/04 17:14:00 INFO TaskSetManager: Starting task 23.0 in stage 59.0 (TID 763) (10.0.0.43, executor driver, partition 23, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO TaskSetManager: Starting task 24.0 in stage 59.0 (TID 764) (10.0.0.43, executor driver, partition 24, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 24.0 in stage 59.0 (TID 764)
25/02/04 17:14:00 INFO Executor: Running task 23.0 in stage 59.0 (TID 763)
25/02/04 17:14:00 INFO TaskSetManager: Starting task 25.0 in stage 59.0 (TID 765) (10.0.0.43, executor driver, partition 25, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO TaskSetManager: Finished task 12.0 in stage 59.0 (TID 752) in 1273 ms on 10.0.0.43 (executor driver) (13/200)
25/02/04 17:14:00 INFO Executor: Running task 25.0 in stage 59.0 (TID 765)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 15.0 in stage 59.0 (TID 755) in 1265 ms on 10.0.0.43 (executor driver) (14/200)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 18.0 in stage 59.0 (TID 758) in 1216 ms on 10.0.0.43 (executor driver) (15/200)
25/02/04 17:14:00 INFO TaskSetManager: Starting task 26.0 in stage 59.0 (TID 766) (10.0.0.43, executor driver, partition 26, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO TaskSetManager: Starting task 27.0 in stage 59.0 (TID 767) (10.0.0.43, executor driver, partition 27, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 26.0 in stage 59.0 (TID 766)
25/02/04 17:14:00 INFO TaskSetManager: Starting task 28.0 in stage 59.0 (TID 768) (10.0.0.43, executor driver, partition 28, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 27.0 in stage 59.0 (TID 767)
25/02/04 17:14:00 INFO Executor: Running task 28.0 in stage 59.0 (TID 768)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 19.0 in stage 59.0 (TID 759) in 1207 ms on 10.0.0.43 (executor driver) (16/200)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 16.0 in stage 59.0 (TID 756) in 1242 ms on 10.0.0.43 (executor driver) (17/200)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 13.0 in stage 59.0 (TID 753) in 1276 ms on 10.0.0.43 (executor driver) (18/200)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 17.0 in stage 59.0 (TID 757) in 1241 ms on 10.0.0.43 (executor driver) (19/200)
25/02/04 17:14:00 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000014_754' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000014
25/02/04 17:14:00 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000014_754: Committed. Elapsed time: 0 ms.
25/02/04 17:14:00 INFO Executor: Finished task 14.0 in stage 59.0 (TID 754). 18040 bytes result sent to driver
25/02/04 17:14:00 INFO TaskSetManager: Starting task 29.0 in stage 59.0 (TID 769) (10.0.0.43, executor driver, partition 29, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:00 INFO Executor: Running task 29.0 in stage 59.0 (TID 769)
25/02/04 17:14:00 INFO TaskSetManager: Finished task 14.0 in stage 59.0 (TID 754) in 1278 ms on 10.0.0.43 (executor driver) (20/200)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_29 stored as values in memory (estimated size 1378.9 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_27 stored as values in memory (estimated size 866.2 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_21 stored as values in memory (estimated size 968.7 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_22 stored as values in memory (estimated size 1279.5 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_25 stored as values in memory (estimated size 985.1 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_28 stored as values in memory (estimated size 1076.3 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_26 stored as values in memory (estimated size 1254.6 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_20 stored as values in memory (estimated size 1143.9 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_24 stored as values in memory (estimated size 1092.3 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO MemoryStore: Block rdd_72_23 stored as values in memory (estimated size 1151.9 KiB, free 166.1 MiB)
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_29 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_23 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_22 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_27 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_20 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_24 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_28 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_25 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_26 locally
25/02/04 17:14:00 INFO BlockManager: Found block rdd_72_21 locally
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:00 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:00 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:01 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:14:01 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:01 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000023_763' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000023
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000023_763: Committed. Elapsed time: 3 ms.
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000028_768' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000028
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000028_768: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000025_765' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000025
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000025_765: Committed. Elapsed time: 6 ms.
25/02/04 17:14:01 INFO Executor: Finished task 25.0 in stage 59.0 (TID 765). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO Executor: Finished task 28.0 in stage 59.0 (TID 768). 17997 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 30.0 in stage 59.0 (TID 770) (10.0.0.43, executor driver, partition 30, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Finished task 23.0 in stage 59.0 (TID 763). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 31.0 in stage 59.0 (TID 771) (10.0.0.43, executor driver, partition 31, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 30.0 in stage 59.0 (TID 770)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 32.0 in stage 59.0 (TID 772) (10.0.0.43, executor driver, partition 32, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000026_766' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000026
25/02/04 17:14:01 INFO TaskSetManager: Finished task 25.0 in stage 59.0 (TID 765) in 625 ms on 10.0.0.43 (executor driver) (21/200)
25/02/04 17:14:01 INFO Executor: Running task 31.0 in stage 59.0 (TID 771)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 28.0 in stage 59.0 (TID 768) in 616 ms on 10.0.0.43 (executor driver) (22/200)
25/02/04 17:14:01 INFO Executor: Running task 32.0 in stage 59.0 (TID 772)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 23.0 in stage 59.0 (TID 763) in 629 ms on 10.0.0.43 (executor driver) (23/200)
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000026_766: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO Executor: Finished task 26.0 in stage 59.0 (TID 766). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 33.0 in stage 59.0 (TID 773) (10.0.0.43, executor driver, partition 33, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 26.0 in stage 59.0 (TID 766) in 623 ms on 10.0.0.43 (executor driver) (24/200)
25/02/04 17:14:01 INFO Executor: Running task 33.0 in stage 59.0 (TID 773)
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000027_767' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000027
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000027_767: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 27.0 in stage 59.0 (TID 767). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 34.0 in stage 59.0 (TID 774) (10.0.0.43, executor driver, partition 34, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 34.0 in stage 59.0 (TID 774)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 27.0 in stage 59.0 (TID 767) in 627 ms on 10.0.0.43 (executor driver) (25/200)
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000020_760' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000020
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000020_760: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 20.0 in stage 59.0 (TID 760). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 35.0 in stage 59.0 (TID 775) (10.0.0.43, executor driver, partition 35, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 35.0 in stage 59.0 (TID 775)
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000024_764' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000024
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000024_764: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO Executor: Finished task 24.0 in stage 59.0 (TID 764). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Finished task 20.0 in stage 59.0 (TID 760) in 713 ms on 10.0.0.43 (executor driver) (26/200)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 36.0 in stage 59.0 (TID 776) (10.0.0.43, executor driver, partition 36, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 24.0 in stage 59.0 (TID 764) in 643 ms on 10.0.0.43 (executor driver) (27/200)
25/02/04 17:14:01 INFO Executor: Running task 36.0 in stage 59.0 (TID 776)
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000021_761' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000021
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000021_761: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000022_762' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000022
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000022_762: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 22.0 in stage 59.0 (TID 762). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO Executor: Finished task 21.0 in stage 59.0 (TID 761). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 37.0 in stage 59.0 (TID 777) (10.0.0.43, executor driver, partition 37, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000029_769' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000029
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000029_769: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Running task 37.0 in stage 59.0 (TID 777)
25/02/04 17:14:01 INFO Executor: Finished task 29.0 in stage 59.0 (TID 769). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 38.0 in stage 59.0 (TID 778) (10.0.0.43, executor driver, partition 38, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 38.0 in stage 59.0 (TID 778)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 39.0 in stage 59.0 (TID 779) (10.0.0.43, executor driver, partition 39, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 22.0 in stage 59.0 (TID 762) in 652 ms on 10.0.0.43 (executor driver) (28/200)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 21.0 in stage 59.0 (TID 761) in 665 ms on 10.0.0.43 (executor driver) (29/200)
25/02/04 17:14:01 INFO Executor: Running task 39.0 in stage 59.0 (TID 779)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 29.0 in stage 59.0 (TID 769) in 635 ms on 10.0.0.43 (executor driver) (30/200)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_36 stored as values in memory (estimated size 1064.4 KiB, free 163.8 MiB)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_39 stored as values in memory (estimated size 1282.7 KiB, free 163.8 MiB)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_37 stored as values in memory (estimated size 1228.3 KiB, free 160.3 MiB)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_32 stored as values in memory (estimated size 1297.1 KiB, free 160.3 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_36 locally
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_37 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_33 stored as values in memory (estimated size 1063.3 KiB, free 160.3 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_33 locally
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_32 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_34 stored as values in memory (estimated size 1134.6 KiB, free 157.0 MiB)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_38 stored as values in memory (estimated size 1115.5 KiB, free 158.1 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_38 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_35 stored as values in memory (estimated size 1098.4 KiB, free 158.1 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_34 locally
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_35 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_31 stored as values in memory (estimated size 1222.2 KiB, free 155.8 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_31 locally
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_39 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_30 stored as values in memory (estimated size 1339.9 KiB, free 154.5 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_30 locally
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO MemoryStore: 6 blocks selected for dropping (7.6 MiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_60 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_60 on disk on 10.0.0.43:62420 (current size: 1347.2 KiB, original size: 1347.2 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_61 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_61 on disk on 10.0.0.43:62420 (current size: 1180.0 KiB, original size: 1180.0 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_62 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_62 on disk on 10.0.0.43:62420 (current size: 1038.0 KiB, original size: 1038.0 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_63 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_63 on disk on 10.0.0.43:62420 (current size: 1201.6 KiB, original size: 1201.6 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_64 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_64 on disk on 10.0.0.43:62420 (current size: 1181.5 KiB, original size: 1181.5 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_65 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_65 on disk on 10.0.0.43:62420 (current size: 1371.8 KiB, original size: 1371.8 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 6 blocks, free memory is 8.1 MiB
25/02/04 17:14:01 INFO MemoryStore: 8 blocks selected for dropping (8.8 MiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_66 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_66 on disk on 10.0.0.43:62420 (current size: 1008.2 KiB, original size: 1008.2 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_67 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_67 on disk on 10.0.0.43:62420 (current size: 1079.9 KiB, original size: 1079.9 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_68 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_68 on disk on 10.0.0.43:62420 (current size: 1060.9 KiB, original size: 1060.9 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_69 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_69 on disk on 10.0.0.43:62420 (current size: 923.7 KiB, original size: 923.7 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_71 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_71 on disk on 10.0.0.43:62420 (current size: 1086.2 KiB, original size: 1086.2 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_70 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_70 on disk on 10.0.0.43:62420 (current size: 993.3 KiB, original size: 993.3 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_72 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_72 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 1185.0 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_73 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_73 on disk on 10.0.0.43:62420 (current size: 1176.8 KiB, original size: 1176.8 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 8 blocks, free memory is 8.9 MiB
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000036_776' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000036
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000036_776: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO Executor: Finished task 36.0 in stage 59.0 (TID 776). 17997 bytes result sent to driver
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000035_775' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000035
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000035_775: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO Executor: Finished task 35.0 in stage 59.0 (TID 775). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000037_777' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000037
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000037_777: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 37.0 in stage 59.0 (TID 777). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000033_773' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000033
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000033_773: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000034_774' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000034
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000034_774: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 33.0 in stage 59.0 (TID 773). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO Executor: Finished task 34.0 in stage 59.0 (TID 774). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000032_772' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000032
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000032_772: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 32.0 in stage 59.0 (TID 772). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000031_771' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000031
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000031_771: Committed. Elapsed time: 1 ms.
25/02/04 17:14:01 INFO TaskSetManager: Starting task 40.0 in stage 59.0 (TID 780) (10.0.0.43, executor driver, partition 40, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Finished task 31.0 in stage 59.0 (TID 771). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO Executor: Running task 40.0 in stage 59.0 (TID 780)
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000038_778' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000038
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000038_778: Committed. Elapsed time: 0 ms.
25/02/04 17:14:01 INFO Executor: Finished task 38.0 in stage 59.0 (TID 778). 17954 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 41.0 in stage 59.0 (TID 781) (10.0.0.43, executor driver, partition 41, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 36.0 in stage 59.0 (TID 776) in 375 ms on 10.0.0.43 (executor driver) (31/200)
25/02/04 17:14:01 INFO Executor: Running task 41.0 in stage 59.0 (TID 781)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 42.0 in stage 59.0 (TID 782) (10.0.0.43, executor driver, partition 42, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 42.0 in stage 59.0 (TID 782)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 43.0 in stage 59.0 (TID 783) (10.0.0.43, executor driver, partition 43, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 35.0 in stage 59.0 (TID 775) in 382 ms on 10.0.0.43 (executor driver) (32/200)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 33.0 in stage 59.0 (TID 773) in 390 ms on 10.0.0.43 (executor driver) (33/200)
25/02/04 17:14:01 INFO Executor: Running task 43.0 in stage 59.0 (TID 783)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 44.0 in stage 59.0 (TID 784) (10.0.0.43, executor driver, partition 44, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Starting task 45.0 in stage 59.0 (TID 785) (10.0.0.43, executor driver, partition 45, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Starting task 46.0 in stage 59.0 (TID 786) (10.0.0.43, executor driver, partition 46, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 45.0 in stage 59.0 (TID 785)
25/02/04 17:14:01 INFO TaskSetManager: Starting task 47.0 in stage 59.0 (TID 787) (10.0.0.43, executor driver, partition 47, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 44.0 in stage 59.0 (TID 784)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 34.0 in stage 59.0 (TID 774) in 387 ms on 10.0.0.43 (executor driver) (34/200)
25/02/04 17:14:01 INFO Executor: Running task 46.0 in stage 59.0 (TID 786)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 37.0 in stage 59.0 (TID 777) in 378 ms on 10.0.0.43 (executor driver) (35/200)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 32.0 in stage 59.0 (TID 772) in 399 ms on 10.0.0.43 (executor driver) (36/200)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 31.0 in stage 59.0 (TID 771) in 401 ms on 10.0.0.43 (executor driver) (37/200)
25/02/04 17:14:01 INFO Executor: Running task 47.0 in stage 59.0 (TID 787)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 38.0 in stage 59.0 (TID 778) in 379 ms on 10.0.0.43 (executor driver) (38/200)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_43 stored as values in memory (estimated size 1258.3 KiB, free 132.6 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_43 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_40 stored as values in memory (estimated size 1050.1 KiB, free 132.6 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_40 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_44 stored as values in memory (estimated size 1177.9 KiB, free 131.5 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_44 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_45 stored as values in memory (estimated size 1353.6 KiB, free 130.2 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_45 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_41 stored as values in memory (estimated size 1231.3 KiB, free 129.0 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_41 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_42 stored as values in memory (estimated size 1541.0 KiB, free 127.5 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_42 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_47 stored as values in memory (estimated size 1176.4 KiB, free 126.3 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_47 locally
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_46 stored as values in memory (estimated size 1512.7 KiB, free 124.8 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_46 locally
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000030_770' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000030
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000030_770: Committed. Elapsed time: 15 ms.
25/02/04 17:14:01 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000039_779' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000039
25/02/04 17:14:01 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000039_779: Committed. Elapsed time: 3 ms.
25/02/04 17:14:01 INFO Executor: Finished task 30.0 in stage 59.0 (TID 770). 17997 bytes result sent to driver
25/02/04 17:14:01 INFO Executor: Finished task 39.0 in stage 59.0 (TID 779). 17997 bytes result sent to driver
25/02/04 17:14:01 INFO TaskSetManager: Starting task 48.0 in stage 59.0 (TID 788) (10.0.0.43, executor driver, partition 48, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO Executor: Running task 48.0 in stage 59.0 (TID 788)
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_48 stored as values in memory (estimated size 1275.9 KiB, free 13.6 MiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_48 locally
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO MemoryStore: 5 blocks selected for dropping (5.5 MiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_74 from memory
25/02/04 17:14:01 INFO TaskSetManager: Starting task 49.0 in stage 59.0 (TID 789) (10.0.0.43, executor driver, partition 49, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:01 INFO TaskSetManager: Finished task 30.0 in stage 59.0 (TID 770) in 797 ms on 10.0.0.43 (executor driver) (39/200)
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_74 on disk on 10.0.0.43:62420 (current size: 1257.7 KiB, original size: 1257.7 KiB)
25/02/04 17:14:01 INFO Executor: Running task 49.0 in stage 59.0 (TID 789)
25/02/04 17:14:01 INFO TaskSetManager: Finished task 39.0 in stage 59.0 (TID 779) in 769 ms on 10.0.0.43 (executor driver) (40/200)
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_75 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_75 on disk on 10.0.0.43:62420 (current size: 1009.8 KiB, original size: 1009.8 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_77 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_77 on disk on 10.0.0.43:62420 (current size: 880.8 KiB, original size: 880.8 KiB)
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_78 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_78 on disk on 10.0.0.43:62420 (current size: 1044.3 KiB, original size: 1044.3 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_76 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_76 on disk on 10.0.0.43:62420 (current size: 1081.3 KiB, original size: 1081.3 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 5 blocks, free memory is 9.1 MiB
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO MemoryStore: Block rdd_72_49 stored as values in memory (estimated size 1056.0 KiB, free 28.6 KiB)
25/02/04 17:14:01 INFO BlockManager: Found block rdd_72_49 locally
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1309.1 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_81 from memory
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_81 on disk on 10.0.0.43:62420 (current size: 1237.5 KiB, original size: 1237.5 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 1337.8 KiB
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1046.6 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_79 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_79 on disk on 10.0.0.43:62420 (current size: 984.7 KiB, original size: 984.7 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1093.8 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_80 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_80 on disk on 10.0.0.43:62420 (current size: 1030.9 KiB, original size: 1030.9 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 1302.2 KiB
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1281.3 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_82 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_82 on disk on 10.0.0.43:62420 (current size: 1208.8 KiB, original size: 1208.8 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 2.1 MiB
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1017.8 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_83 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_83 on disk on 10.0.0.43:62420 (current size: 957.7 KiB, original size: 957.7 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:14:01 INFO MemoryStore: 1 blocks selected for dropping (1035.6 KiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_85 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_85 on disk on 10.0.0.43:62420 (current size: 972.6 KiB, original size: 972.6 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 1 blocks, free memory is 2.7 MiB
25/02/04 17:14:01 INFO MemoryStore: 4 blocks selected for dropping (4.5 MiB bytes)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_84 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_84 on disk on 10.0.0.43:62420 (current size: 1065.4 KiB, original size: 1065.4 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_90 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_90 on disk on 10.0.0.43:62420 (current size: 966.9 KiB, original size: 966.9 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_87 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_87 on disk on 10.0.0.43:62420 (current size: 986.6 KiB, original size: 986.6 KiB)
25/02/04 17:14:01 INFO BlockManager: Dropping block rdd_72_89 from memory
25/02/04 17:14:01 INFO BlockManagerInfo: Updated rdd_72_89 on disk on 10.0.0.43:62420 (current size: 1370.1 KiB, original size: 1370.1 KiB)
25/02/04 17:14:01 INFO MemoryStore: After dropping 4 blocks, free memory is 5.2 MiB
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO MemoryStore: 6 blocks selected for dropping (7.1 MiB bytes)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_88 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_88 on disk on 10.0.0.43:62420 (current size: 1270.3 KiB, original size: 1270.3 KiB)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_86 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_86 on disk on 10.0.0.43:62420 (current size: 1061.2 KiB, original size: 1061.2 KiB)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_91 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_91 on disk on 10.0.0.43:62420 (current size: 1143.1 KiB, original size: 1143.1 KiB)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_97 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_97 on disk on 10.0.0.43:62420 (current size: 1303.1 KiB, original size: 1303.1 KiB)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_100 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_100 on disk on 10.0.0.43:62420 (current size: 1141.2 KiB, original size: 1141.2 KiB)
25/02/04 17:14:02 INFO BlockManager: Dropping block rdd_72_96 from memory
25/02/04 17:14:02 INFO BlockManagerInfo: Updated rdd_72_96 on disk on 10.0.0.43:62420 (current size: 977.5 KiB, original size: 977.5 KiB)
25/02/04 17:14:02 INFO MemoryStore: After dropping 6 blocks, free memory is 8.3 MiB
25/02/04 17:14:02 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:02 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000047_787' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000047
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000047_787: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO Executor: Finished task 47.0 in stage 59.0 (TID 787). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 50.0 in stage 59.0 (TID 790) (10.0.0.43, executor driver, partition 50, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 50.0 in stage 59.0 (TID 790)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 47.0 in stage 59.0 (TID 787) in 741 ms on 10.0.0.43 (executor driver) (41/200)
25/02/04 17:14:02 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_50 stored as values in memory (estimated size 1555.2 KiB, free 164.8 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_50 locally
25/02/04 17:14:02 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000042_782' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000042
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000046_786' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000046
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000042_782: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000046_786: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000044_784' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000044
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000044_784: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000041_781' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000041
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000041_781: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000045_785' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000045
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000045_785: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO Executor: Finished task 46.0 in stage 59.0 (TID 786). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 41.0 in stage 59.0 (TID 781). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 44.0 in stage 59.0 (TID 784). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 45.0 in stage 59.0 (TID 785). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 42.0 in stage 59.0 (TID 782). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 51.0 in stage 59.0 (TID 791) (10.0.0.43, executor driver, partition 51, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 51.0 in stage 59.0 (TID 791)
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000040_780' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000040
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000040_780: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO TaskSetManager: Starting task 52.0 in stage 59.0 (TID 792) (10.0.0.43, executor driver, partition 52, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Finished task 40.0 in stage 59.0 (TID 780). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 53.0 in stage 59.0 (TID 793) (10.0.0.43, executor driver, partition 53, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 53.0 in stage 59.0 (TID 793)
25/02/04 17:14:02 INFO Executor: Running task 52.0 in stage 59.0 (TID 792)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 54.0 in stage 59.0 (TID 794) (10.0.0.43, executor driver, partition 54, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Starting task 55.0 in stage 59.0 (TID 795) (10.0.0.43, executor driver, partition 55, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Finished task 41.0 in stage 59.0 (TID 781) in 831 ms on 10.0.0.43 (executor driver) (42/200)
25/02/04 17:14:02 INFO Executor: Running task 55.0 in stage 59.0 (TID 795)
25/02/04 17:14:02 INFO Executor: Running task 54.0 in stage 59.0 (TID 794)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 44.0 in stage 59.0 (TID 784) in 828 ms on 10.0.0.43 (executor driver) (43/200)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 42.0 in stage 59.0 (TID 782) in 830 ms on 10.0.0.43 (executor driver) (44/200)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 45.0 in stage 59.0 (TID 785) in 828 ms on 10.0.0.43 (executor driver) (45/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 56.0 in stage 59.0 (TID 796) (10.0.0.43, executor driver, partition 56, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 56.0 in stage 59.0 (TID 796)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 40.0 in stage 59.0 (TID 780) in 842 ms on 10.0.0.43 (executor driver) (46/200)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 46.0 in stage 59.0 (TID 786) in 833 ms on 10.0.0.43 (executor driver) (47/200)
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_52 stored as values in memory (estimated size 1374.8 KiB, free 179.4 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_52 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_53 stored as values in memory (estimated size 1058.2 KiB, free 178.4 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_53 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_55 stored as values in memory (estimated size 1096.5 KiB, free 177.3 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_55 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_51 stored as values in memory (estimated size 1019.7 KiB, free 176.3 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_51 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_54 stored as values in memory (estimated size 1153.3 KiB, free 175.2 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_54 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_56 stored as values in memory (estimated size 1129.4 KiB, free 174.1 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_56 locally
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000048_788' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000048
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000048_788: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO Executor: Finished task 48.0 in stage 59.0 (TID 788). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 57.0 in stage 59.0 (TID 797) (10.0.0.43, executor driver, partition 57, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Finished task 48.0 in stage 59.0 (TID 788) in 591 ms on 10.0.0.43 (executor driver) (48/200)
25/02/04 17:14:02 INFO Executor: Running task 57.0 in stage 59.0 (TID 797)
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_57 stored as values in memory (estimated size 1342.1 KiB, free 54.8 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_57 locally
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000043_783' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000043
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000043_783: Committed. Elapsed time: 0 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000049_789' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000049
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000049_789: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO Executor: Finished task 49.0 in stage 59.0 (TID 789). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 43.0 in stage 59.0 (TID 783). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 58.0 in stage 59.0 (TID 798) (10.0.0.43, executor driver, partition 58, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 58.0 in stage 59.0 (TID 798)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 59.0 in stage 59.0 (TID 799) (10.0.0.43, executor driver, partition 59, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO Executor: Running task 59.0 in stage 59.0 (TID 799)
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO TaskSetManager: Finished task 49.0 in stage 59.0 (TID 789) in 795 ms on 10.0.0.43 (executor driver) (49/200)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 43.0 in stage 59.0 (TID 783) in 1142 ms on 10.0.0.43 (executor driver) (50/200)
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_58 stored as values in memory (estimated size 960.6 KiB, free 35.9 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_58 locally
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_59 stored as values in memory (estimated size 1403.8 KiB, free 34.5 MiB)
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_59 locally
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000056_796' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000056
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000051_791' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000051
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000051_791: Committed. Elapsed time: 2 ms.
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000056_796: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000053_793' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000053
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000053_793: Committed. Elapsed time: 3 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000054_794' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000054
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000054_794: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000055_795' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000055
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000055_795: Committed. Elapsed time: 1 ms.
25/02/04 17:14:02 INFO Executor: Finished task 56.0 in stage 59.0 (TID 796). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 55.0 in stage 59.0 (TID 795). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 53.0 in stage 59.0 (TID 793). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 51.0 in stage 59.0 (TID 791). 17997 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 54.0 in stage 59.0 (TID 794). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 60.0 in stage 59.0 (TID 800) (10.0.0.43, executor driver, partition 60, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 60.0 in stage 59.0 (TID 800)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 56.0 in stage 59.0 (TID 796) in 528 ms on 10.0.0.43 (executor driver) (51/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 61.0 in stage 59.0 (TID 801) (10.0.0.43, executor driver, partition 61, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Starting task 62.0 in stage 59.0 (TID 802) (10.0.0.43, executor driver, partition 62, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 61.0 in stage 59.0 (TID 801)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 53.0 in stage 59.0 (TID 793) in 535 ms on 10.0.0.43 (executor driver) (52/200)
25/02/04 17:14:02 INFO TaskSetManager: Finished task 51.0 in stage 59.0 (TID 791) in 539 ms on 10.0.0.43 (executor driver) (53/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 63.0 in stage 59.0 (TID 803) (10.0.0.43, executor driver, partition 63, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Finished task 55.0 in stage 59.0 (TID 795) in 537 ms on 10.0.0.43 (executor driver) (54/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 64.0 in stage 59.0 (TID 804) (10.0.0.43, executor driver, partition 64, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Finished task 54.0 in stage 59.0 (TID 794) in 580 ms on 10.0.0.43 (executor driver) (55/200)
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000050_790' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000050
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000050_790: Committed. Elapsed time: 3 ms.
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000052_792' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000052
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000052_792: Committed. Elapsed time: 3 ms.
25/02/04 17:14:02 INFO Executor: Finished task 52.0 in stage 59.0 (TID 792). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO Executor: Finished task 50.0 in stage 59.0 (TID 790). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Starting task 65.0 in stage 59.0 (TID 805) (10.0.0.43, executor driver, partition 65, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO TaskSetManager: Starting task 66.0 in stage 59.0 (TID 806) (10.0.0.43, executor driver, partition 66, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000057_797' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000057
25/02/04 17:14:02 INFO TaskSetManager: Finished task 50.0 in stage 59.0 (TID 790) in 693 ms on 10.0.0.43 (executor driver) (56/200)
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000057_797: Committed. Elapsed time: 16 ms.
25/02/04 17:14:02 INFO TaskSetManager: Finished task 52.0 in stage 59.0 (TID 792) in 606 ms on 10.0.0.43 (executor driver) (57/200)
25/02/04 17:14:02 INFO Executor: Finished task 57.0 in stage 59.0 (TID 797). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Finished task 57.0 in stage 59.0 (TID 797) in 513 ms on 10.0.0.43 (executor driver) (58/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 67.0 in stage 59.0 (TID 807) (10.0.0.43, executor driver, partition 67, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 67.0 in stage 59.0 (TID 807)
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_61 stored as values in memory (estimated size 1250.6 KiB, free 133.9 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_61 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_60 stored as values in memory (estimated size 1426.3 KiB, free 133.9 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_60 locally
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000058_798' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000058
25/02/04 17:14:02 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000058_798: Committed. Elapsed time: 10 ms.
25/02/04 17:14:02 INFO Executor: Finished task 58.0 in stage 59.0 (TID 798). 17954 bytes result sent to driver
25/02/04 17:14:02 INFO TaskSetManager: Finished task 58.0 in stage 59.0 (TID 798) in 344 ms on 10.0.0.43 (executor driver) (59/200)
25/02/04 17:14:02 INFO TaskSetManager: Starting task 68.0 in stage 59.0 (TID 808) (10.0.0.43, executor driver, partition 68, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:02 INFO Executor: Running task 68.0 in stage 59.0 (TID 808)
25/02/04 17:14:02 INFO Executor: Running task 63.0 in stage 59.0 (TID 803)
25/02/04 17:14:02 INFO Executor: Running task 66.0 in stage 59.0 (TID 806)
25/02/04 17:14:02 INFO Executor: Running task 62.0 in stage 59.0 (TID 802)
25/02/04 17:14:02 INFO Executor: Running task 64.0 in stage 59.0 (TID 804)
25/02/04 17:14:02 INFO Executor: Running task 65.0 in stage 59.0 (TID 805)
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_67 stored as values in memory (estimated size 1146.0 KiB, free 112.8 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_67 locally
25/02/04 17:14:02 INFO MemoryStore: Block rdd_72_68 stored as values in memory (estimated size 1124.1 KiB, free 111.7 MiB)
25/02/04 17:14:02 INFO BlockManager: Found block rdd_72_68 locally
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000059_799' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000059
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000059_799: Committed. Elapsed time: 2 ms.
25/02/04 17:14:03 INFO Executor: Finished task 59.0 in stage 59.0 (TID 799). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_62 stored as values in memory (estimated size 1097.7 KiB, free 93.1 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_62 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_66 stored as values in memory (estimated size 1069.9 KiB, free 93.1 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_66 locally
25/02/04 17:14:03 INFO TaskSetManager: Starting task 69.0 in stage 59.0 (TID 809) (10.0.0.43, executor driver, partition 69, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 69.0 in stage 59.0 (TID 809)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 59.0 in stage 59.0 (TID 799) in 449 ms on 10.0.0.43 (executor driver) (60/200)
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_64 stored as values in memory (estimated size 1254.2 KiB, free 80.1 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_64 locally
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_63 stored as values in memory (estimated size 1263.8 KiB, free 68.8 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_63 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_65 stored as values in memory (estimated size 1448.7 KiB, free 27.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_65 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_69 stored as values in memory (estimated size 981.1 KiB, free 4.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_69 locally
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: 1 blocks selected for dropping (1436.0 KiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_94 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_94 on disk on 10.0.0.43:62420 (current size: 1355.6 KiB, original size: 1355.6 KiB)
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO MemoryStore: After dropping 1 blocks, free memory is 3.1 MiB
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: 4 blocks selected for dropping (4.6 MiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_92 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_92 on disk on 10.0.0.43:62420 (current size: 1005.9 KiB, original size: 1005.9 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_93 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_93 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 1137.0 KiB)
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_98 from memory
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_98 on disk on 10.0.0.43:62420 (current size: 1385.8 KiB, original size: 1385.8 KiB)
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_95 from memory
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_95 on disk on 10.0.0.43:62420 (current size: 940.1 KiB, original size: 940.1 KiB)
25/02/04 17:14:03 INFO MemoryStore: After dropping 4 blocks, free memory is 4.7 MiB
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: 7 blocks selected for dropping (8.0 MiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_99 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_99 on disk on 10.0.0.43:62420 (current size: 880.3 KiB, original size: 880.3 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_101 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_101 on disk on 10.0.0.43:62420 (current size: 897.5 KiB, original size: 897.5 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_103 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_103 on disk on 10.0.0.43:62420 (current size: 1003.8 KiB, original size: 1003.8 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_102 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_102 on disk on 10.0.0.43:62420 (current size: 1296.9 KiB, original size: 1296.9 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_104 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_104 on disk on 10.0.0.43:62420 (current size: 1116.1 KiB, original size: 1116.1 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_105 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_105 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 1137.0 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_106 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_106 on disk on 10.0.0.43:62420 (current size: 1350.0 KiB, original size: 1350.0 KiB)
25/02/04 17:14:03 INFO MemoryStore: After dropping 7 blocks, free memory is 8.7 MiB
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000068_808' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000068
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000068_808: Committed. Elapsed time: 1 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000061_801' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000061
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000061_801: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000067_807' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000067
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000067_807: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 68.0 in stage 59.0 (TID 808). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 61.0 in stage 59.0 (TID 801). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 67.0 in stage 59.0 (TID 807). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000060_800' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000060
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000060_800: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO TaskSetManager: Starting task 70.0 in stage 59.0 (TID 810) (10.0.0.43, executor driver, partition 70, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Finished task 60.0 in stage 59.0 (TID 800). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Finished task 68.0 in stage 59.0 (TID 808) in 427 ms on 10.0.0.43 (executor driver) (61/200)
25/02/04 17:14:03 INFO Executor: Running task 70.0 in stage 59.0 (TID 810)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 71.0 in stage 59.0 (TID 811) (10.0.0.43, executor driver, partition 71, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Starting task 72.0 in stage 59.0 (TID 812) (10.0.0.43, executor driver, partition 72, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 71.0 in stage 59.0 (TID 811)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 73.0 in stage 59.0 (TID 813) (10.0.0.43, executor driver, partition 73, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 72.0 in stage 59.0 (TID 812)
25/02/04 17:14:03 INFO Executor: Running task 73.0 in stage 59.0 (TID 813)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 67.0 in stage 59.0 (TID 807) in 482 ms on 10.0.0.43 (executor driver) (62/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 61.0 in stage 59.0 (TID 801) in 566 ms on 10.0.0.43 (executor driver) (63/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 60.0 in stage 59.0 (TID 800) in 571 ms on 10.0.0.43 (executor driver) (64/200)
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000066_806' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000066
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000063_803' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000063
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000063_803: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000066_806: Committed. Elapsed time: 1 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000064_804' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000064
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000064_804: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000062_802' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000062
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000062_802: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 63.0 in stage 59.0 (TID 803). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 62.0 in stage 59.0 (TID 802). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 66.0 in stage 59.0 (TID 806). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 74.0 in stage 59.0 (TID 814) (10.0.0.43, executor driver, partition 74, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Finished task 64.0 in stage 59.0 (TID 804). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Running task 74.0 in stage 59.0 (TID 814)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 75.0 in stage 59.0 (TID 815) (10.0.0.43, executor driver, partition 75, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Starting task 76.0 in stage 59.0 (TID 816) (10.0.0.43, executor driver, partition 76, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 75.0 in stage 59.0 (TID 815)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 77.0 in stage 59.0 (TID 817) (10.0.0.43, executor driver, partition 77, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Finished task 63.0 in stage 59.0 (TID 803) in 581 ms on 10.0.0.43 (executor driver) (65/200)
25/02/04 17:14:03 INFO Executor: Running task 76.0 in stage 59.0 (TID 816)
25/02/04 17:14:03 INFO Executor: Running task 77.0 in stage 59.0 (TID 817)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 64.0 in stage 59.0 (TID 804) in 557 ms on 10.0.0.43 (executor driver) (66/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 66.0 in stage 59.0 (TID 806) in 526 ms on 10.0.0.43 (executor driver) (67/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 62.0 in stage 59.0 (TID 802) in 586 ms on 10.0.0.43 (executor driver) (68/200)
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_71 stored as values in memory (estimated size 1153.0 KiB, free 136.3 MiB)
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_73 stored as values in memory (estimated size 1243.1 KiB, free 135.1 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_71 locally
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_73 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_72 stored as values in memory (estimated size 1253.6 KiB, free 136.3 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_72 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_70 stored as values in memory (estimated size 1056.1 KiB, free 134.1 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_70 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_76 stored as values in memory (estimated size 1148.0 KiB, free 145.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_76 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_75 stored as values in memory (estimated size 1068.8 KiB, free 146.8 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_75 locally
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000069_809' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000069
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000069_809: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_77 stored as values in memory (estimated size 934.4 KiB, free 145.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_77 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_74 stored as values in memory (estimated size 1337.1 KiB, free 163.4 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_74 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO Executor: Finished task 69.0 in stage 59.0 (TID 809). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 78.0 in stage 59.0 (TID 818) (10.0.0.43, executor driver, partition 78, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 78.0 in stage 59.0 (TID 818)
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000065_805' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000065
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000065_805: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 65.0 in stage 59.0 (TID 805). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 79.0 in stage 59.0 (TID 819) (10.0.0.43, executor driver, partition 79, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 79.0 in stage 59.0 (TID 819)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 65.0 in stage 59.0 (TID 805) in 614 ms on 10.0.0.43 (executor driver) (69/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 69.0 in stage 59.0 (TID 809) in 444 ms on 10.0.0.43 (executor driver) (70/200)
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_79 stored as values in memory (estimated size 1046.6 KiB, free 62.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_79 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_78 stored as values in memory (estimated size 1105.7 KiB, free 61.6 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_78 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO MemoryStore: 1 blocks selected for dropping (1226.5 KiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_107 from memory
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_107 on disk on 10.0.0.43:62420 (current size: 1159.8 KiB, original size: 1159.8 KiB)
25/02/04 17:14:03 INFO MemoryStore: After dropping 1 blocks, free memory is 8.8 MiB
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO MemoryStore: 7 blocks selected for dropping (7.6 MiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_108 from memory
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_108 on disk on 10.0.0.43:62420 (current size: 959.4 KiB, original size: 959.4 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_109 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_109 on disk on 10.0.0.43:62420 (current size: 981.0 KiB, original size: 981.0 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_110 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_110 on disk on 10.0.0.43:62420 (current size: 920.0 KiB, original size: 920.0 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_111 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_111 on disk on 10.0.0.43:62420 (current size: 978.0 KiB, original size: 978.0 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_113 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_113 on disk on 10.0.0.43:62420 (current size: 1133.4 KiB, original size: 1133.4 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_112 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_112 on disk on 10.0.0.43:62420 (current size: 1062.2 KiB, original size: 1062.2 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_114 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_114 on disk on 10.0.0.43:62420 (current size: 1318.6 KiB, original size: 1318.6 KiB)
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO MemoryStore: After dropping 7 blocks, free memory is 8.4 MiB
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:03 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:03 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000071_811' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000071
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000071_811: Committed. Elapsed time: 1 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000070_810' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000070
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000070_810: Committed. Elapsed time: 2 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000073_813' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000073
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000073_813: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000075_815' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000075
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000075_815: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000076_816' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000076
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000076_816: Committed. Elapsed time: 4 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000079_819' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000079
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000079_819: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000072_812' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000072
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000072_812: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 70.0 in stage 59.0 (TID 810). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 75.0 in stage 59.0 (TID 815). 17997 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 79.0 in stage 59.0 (TID 819). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 71.0 in stage 59.0 (TID 811). 17997 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 72.0 in stage 59.0 (TID 812). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 76.0 in stage 59.0 (TID 816). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000077_817' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000077
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000077_817: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 77.0 in stage 59.0 (TID 817). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO Executor: Finished task 73.0 in stage 59.0 (TID 813). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 80.0 in stage 59.0 (TID 820) (10.0.0.43, executor driver, partition 80, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 80.0 in stage 59.0 (TID 820)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 81.0 in stage 59.0 (TID 821) (10.0.0.43, executor driver, partition 81, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 81.0 in stage 59.0 (TID 821)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 70.0 in stage 59.0 (TID 810) in 419 ms on 10.0.0.43 (executor driver) (71/200)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 75.0 in stage 59.0 (TID 815) in 393 ms on 10.0.0.43 (executor driver) (72/200)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 82.0 in stage 59.0 (TID 822) (10.0.0.43, executor driver, partition 82, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 82.0 in stage 59.0 (TID 822)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 83.0 in stage 59.0 (TID 823) (10.0.0.43, executor driver, partition 83, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 83.0 in stage 59.0 (TID 823)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 84.0 in stage 59.0 (TID 824) (10.0.0.43, executor driver, partition 84, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Finished task 79.0 in stage 59.0 (TID 819) in 311 ms on 10.0.0.43 (executor driver) (73/200)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 85.0 in stage 59.0 (TID 825) (10.0.0.43, executor driver, partition 85, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Starting task 86.0 in stage 59.0 (TID 826) (10.0.0.43, executor driver, partition 86, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Finished task 72.0 in stage 59.0 (TID 812) in 415 ms on 10.0.0.43 (executor driver) (74/200)
25/02/04 17:14:03 INFO Executor: Running task 84.0 in stage 59.0 (TID 824)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 71.0 in stage 59.0 (TID 811) in 415 ms on 10.0.0.43 (executor driver) (75/200)
25/02/04 17:14:03 INFO Executor: Running task 86.0 in stage 59.0 (TID 826)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 76.0 in stage 59.0 (TID 816) in 394 ms on 10.0.0.43 (executor driver) (76/200)
25/02/04 17:14:03 INFO TaskSetManager: Starting task 87.0 in stage 59.0 (TID 827) (10.0.0.43, executor driver, partition 87, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Finished task 77.0 in stage 59.0 (TID 817) in 395 ms on 10.0.0.43 (executor driver) (77/200)
25/02/04 17:14:03 INFO Executor: Running task 87.0 in stage 59.0 (TID 827)
25/02/04 17:14:03 INFO Executor: Running task 85.0 in stage 59.0 (TID 825)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 73.0 in stage 59.0 (TID 813) in 416 ms on 10.0.0.43 (executor driver) (78/200)
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000074_814' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000074
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000074_814: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 74.0 in stage 59.0 (TID 814). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 88.0 in stage 59.0 (TID 828) (10.0.0.43, executor driver, partition 88, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO TaskSetManager: Finished task 74.0 in stage 59.0 (TID 814) in 415 ms on 10.0.0.43 (executor driver) (79/200)
25/02/04 17:14:03 INFO Executor: Running task 88.0 in stage 59.0 (TID 828)
25/02/04 17:14:03 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000078_818' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000078
25/02/04 17:14:03 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000078_818: Committed. Elapsed time: 0 ms.
25/02/04 17:14:03 INFO Executor: Finished task 78.0 in stage 59.0 (TID 818). 17954 bytes result sent to driver
25/02/04 17:14:03 INFO TaskSetManager: Starting task 89.0 in stage 59.0 (TID 829) (10.0.0.43, executor driver, partition 89, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:03 INFO Executor: Running task 89.0 in stage 59.0 (TID 829)
25/02/04 17:14:03 INFO TaskSetManager: Finished task 78.0 in stage 59.0 (TID 818) in 343 ms on 10.0.0.43 (executor driver) (80/200)
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_84 stored as values in memory (estimated size 1123.3 KiB, free 169.3 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_84 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_85 stored as values in memory (estimated size 1035.6 KiB, free 168.3 MiB)
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_87 stored as values in memory (estimated size 1050.2 KiB, free 167.3 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_87 locally
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_85 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_82 stored as values in memory (estimated size 1281.3 KiB, free 164.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_82 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_88 stored as values in memory (estimated size 1331.9 KiB, free 164.7 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_88 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_86 stored as values in memory (estimated size 1128.6 KiB, free 163.6 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_86 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_81 stored as values in memory (estimated size 1309.1 KiB, free 162.3 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_81 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_89 stored as values in memory (estimated size 1436.1 KiB, free 159.9 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_89 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_83 stored as values in memory (estimated size 1017.8 KiB, free 158.9 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_83 locally
25/02/04 17:14:03 INFO MemoryStore: Block rdd_72_80 stored as values in memory (estimated size 1093.8 KiB, free 158.9 MiB)
25/02/04 17:14:03 INFO BlockManager: Found block rdd_72_80 locally
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:03 INFO MemoryStore: 3 blocks selected for dropping (3.9 MiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_115 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_115 on disk on 10.0.0.43:62420 (current size: 826.4 KiB, original size: 826.4 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_116 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_116 on disk on 10.0.0.43:62420 (current size: 1464.6 KiB, original size: 1464.6 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_117 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_117 on disk on 10.0.0.43:62420 (current size: 1476.3 KiB, original size: 1476.3 KiB)
25/02/04 17:14:03 INFO MemoryStore: After dropping 3 blocks, free memory is 8.8 MiB
25/02/04 17:14:03 INFO MemoryStore: 5 blocks selected for dropping (6.0 MiB bytes)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_118 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_118 on disk on 10.0.0.43:62420 (current size: 1235.9 KiB, original size: 1235.9 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_121 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_121 on disk on 10.0.0.43:62420 (current size: 1114.7 KiB, original size: 1114.7 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_120 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_120 on disk on 10.0.0.43:62420 (current size: 1062.9 KiB, original size: 1062.9 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_124 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_124 on disk on 10.0.0.43:62420 (current size: 1116.4 KiB, original size: 1116.4 KiB)
25/02/04 17:14:03 INFO BlockManager: Dropping block rdd_72_122 from memory
25/02/04 17:14:03 INFO BlockManagerInfo: Updated rdd_72_122 on disk on 10.0.0.43:62420 (current size: 1302.6 KiB, original size: 1302.6 KiB)
25/02/04 17:14:03 INFO MemoryStore: After dropping 5 blocks, free memory is 8.8 MiB
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000085_825' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000085
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000087_827' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000087
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000085_825: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000087_827: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000086_826' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000086
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000086_826: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO Executor: Finished task 87.0 in stage 59.0 (TID 827). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO Executor: Finished task 85.0 in stage 59.0 (TID 825). 17997 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 90.0 in stage 59.0 (TID 830) (10.0.0.43, executor driver, partition 90, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Finished task 86.0 in stage 59.0 (TID 826). 17997 bytes result sent to driver
25/02/04 17:14:04 INFO Executor: Running task 90.0 in stage 59.0 (TID 830)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 91.0 in stage 59.0 (TID 831) (10.0.0.43, executor driver, partition 91, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO TaskSetManager: Starting task 92.0 in stage 59.0 (TID 832) (10.0.0.43, executor driver, partition 92, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO TaskSetManager: Finished task 87.0 in stage 59.0 (TID 827) in 346 ms on 10.0.0.43 (executor driver) (81/200)
25/02/04 17:14:04 INFO Executor: Running task 91.0 in stage 59.0 (TID 831)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 85.0 in stage 59.0 (TID 825) in 347 ms on 10.0.0.43 (executor driver) (82/200)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 86.0 in stage 59.0 (TID 826) in 348 ms on 10.0.0.43 (executor driver) (83/200)
25/02/04 17:14:04 INFO Executor: Running task 92.0 in stage 59.0 (TID 832)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000083_823' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000083
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000083_823: Committed. Elapsed time: 4 ms.
25/02/04 17:14:04 INFO Executor: Finished task 83.0 in stage 59.0 (TID 823). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 93.0 in stage 59.0 (TID 833) (10.0.0.43, executor driver, partition 93, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 93.0 in stage 59.0 (TID 833)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 83.0 in stage 59.0 (TID 823) in 351 ms on 10.0.0.43 (executor driver) (84/200)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000082_822' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000082
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000082_822: Committed. Elapsed time: 3 ms.
25/02/04 17:14:04 INFO Executor: Finished task 82.0 in stage 59.0 (TID 822). 17997 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 94.0 in stage 59.0 (TID 834) (10.0.0.43, executor driver, partition 94, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 94.0 in stage 59.0 (TID 834)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000088_828' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000088
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000088_828: Committed. Elapsed time: 2 ms.
25/02/04 17:14:04 INFO Executor: Finished task 88.0 in stage 59.0 (TID 828). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 95.0 in stage 59.0 (TID 835) (10.0.0.43, executor driver, partition 95, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 95.0 in stage 59.0 (TID 835)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000084_824' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000084
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000084_824: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO Executor: Finished task 84.0 in stage 59.0 (TID 824). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Finished task 82.0 in stage 59.0 (TID 822) in 385 ms on 10.0.0.43 (executor driver) (85/200)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 96.0 in stage 59.0 (TID 836) (10.0.0.43, executor driver, partition 96, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 96.0 in stage 59.0 (TID 836)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 84.0 in stage 59.0 (TID 824) in 390 ms on 10.0.0.43 (executor driver) (86/200)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_91 stored as values in memory (estimated size 1209.1 KiB, free 130.4 MiB)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 88.0 in stage 59.0 (TID 828) in 371 ms on 10.0.0.43 (executor driver) (87/200)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_91 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_90 stored as values in memory (estimated size 1025.4 KiB, free 146.4 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_90 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_92 stored as values in memory (estimated size 1066.1 KiB, free 130.4 MiB)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_93 stored as values in memory (estimated size 1206.0 KiB, free 146.4 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_93 locally
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_92 locally
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000080_820' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000080
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000080_820: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000089_829' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000089
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000089_829: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO Executor: Finished task 80.0 in stage 59.0 (TID 820). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO Executor: Finished task 89.0 in stage 59.0 (TID 829). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 97.0 in stage 59.0 (TID 837) (10.0.0.43, executor driver, partition 97, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO TaskSetManager: Finished task 80.0 in stage 59.0 (TID 820) in 406 ms on 10.0.0.43 (executor driver) (88/200)
25/02/04 17:14:04 INFO Executor: Running task 97.0 in stage 59.0 (TID 837)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 98.0 in stage 59.0 (TID 838) (10.0.0.43, executor driver, partition 98, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 98.0 in stage 59.0 (TID 838)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 89.0 in stage 59.0 (TID 829) in 377 ms on 10.0.0.43 (executor driver) (89/200)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000081_821' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000081
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000081_821: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO Executor: Finished task 81.0 in stage 59.0 (TID 821). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 99.0 in stage 59.0 (TID 839) (10.0.0.43, executor driver, partition 99, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO TaskSetManager: Finished task 81.0 in stage 59.0 (TID 821) in 412 ms on 10.0.0.43 (executor driver) (90/200)
25/02/04 17:14:04 INFO Executor: Running task 99.0 in stage 59.0 (TID 839)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_94 stored as values in memory (estimated size 1436.0 KiB, free 161.6 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_94 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_98 stored as values in memory (estimated size 1466.2 KiB, free 161.6 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_98 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_99 stored as values in memory (estimated size 934.9 KiB, free 160.7 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_99 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_95 stored as values in memory (estimated size 998.9 KiB, free 159.7 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_95 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_96 stored as values in memory (estimated size 1038.0 KiB, free 158.7 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_96 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_97 stored as values in memory (estimated size 1377.5 KiB, free 157.3 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_97 locally
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO MemoryStore: 5 blocks selected for dropping (6.1 MiB bytes)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_125 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_125 on disk on 10.0.0.43:62420 (current size: 1138.8 KiB, original size: 1138.8 KiB)
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_119 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_119 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 1002.4 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_123 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_123 on disk on 10.0.0.43:62420 (current size: 1192.5 KiB, original size: 1192.5 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_126 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_126 on disk on 10.0.0.43:62420 (current size: 1010.3 KiB, original size: 1010.3 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_127 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_127 on disk on 10.0.0.43:62420 (current size: 1582.0 KiB, original size: 1582.0 KiB)
25/02/04 17:14:04 INFO MemoryStore: After dropping 5 blocks, free memory is 9.4 MiB
25/02/04 17:14:04 INFO MemoryStore: 1 blocks selected for dropping (1177.6 KiB bytes)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_128 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_128 on disk on 10.0.0.43:62420 (current size: 1113.1 KiB, original size: 1113.1 KiB)
25/02/04 17:14:04 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:14:04 INFO MemoryStore: 7 blocks selected for dropping (8.3 MiB bytes)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_129 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_129 on disk on 10.0.0.43:62420 (current size: 1334.1 KiB, original size: 1334.1 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_130 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_130 on disk on 10.0.0.43:62420 (current size: 1100.2 KiB, original size: 1100.2 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_136 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_136 on disk on 10.0.0.43:62420 (current size: 1351.4 KiB, original size: 1351.4 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_133 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_133 on disk on 10.0.0.43:62420 (current size: 865.8 KiB, original size: 865.8 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_135 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_135 on disk on 10.0.0.43:62420 (current size: 966.4 KiB, original size: 966.4 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_131 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_131 on disk on 10.0.0.43:62420 (current size: 1276.0 KiB, original size: 1276.0 KiB)
25/02/04 17:14:04 INFO BlockManager: Dropping block rdd_72_132 from memory
25/02/04 17:14:04 INFO BlockManagerInfo: Updated rdd_72_132 on disk on 10.0.0.43:62420 (current size: 1164.2 KiB, original size: 1164.2 KiB)
25/02/04 17:14:04 INFO MemoryStore: After dropping 7 blocks, free memory is 8.9 MiB
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO UnsafeExternalSorter: Thread 69 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000095_835' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000095
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000095_835: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO Executor: Finished task 95.0 in stage 59.0 (TID 835). 17997 bytes result sent to driver
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000090_830' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000090
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000090_830: Committed. Elapsed time: 3 ms.
25/02/04 17:14:04 INFO Executor: Finished task 90.0 in stage 59.0 (TID 830). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 100.0 in stage 59.0 (TID 840) (10.0.0.43, executor driver, partition 100, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 100.0 in stage 59.0 (TID 840)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 101.0 in stage 59.0 (TID 841) (10.0.0.43, executor driver, partition 101, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 101.0 in stage 59.0 (TID 841)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 95.0 in stage 59.0 (TID 835) in 371 ms on 10.0.0.43 (executor driver) (91/200)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 90.0 in stage 59.0 (TID 830) in 416 ms on 10.0.0.43 (executor driver) (92/200)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_101 stored as values in memory (estimated size 956.2 KiB, free 33.7 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_101 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_100 stored as values in memory (estimated size 1207.1 KiB, free 32.5 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_100 locally
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000099_839' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000099
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000099_839: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000093_833' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000093
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000093_833: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000092_832' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000092
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000092_832: Committed. Elapsed time: 1 ms.
25/02/04 17:14:04 INFO Executor: Finished task 99.0 in stage 59.0 (TID 839). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:04 INFO Executor: Finished task 93.0 in stage 59.0 (TID 833). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO Executor: Finished task 92.0 in stage 59.0 (TID 832). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 102.0 in stage 59.0 (TID 842) (10.0.0.43, executor driver, partition 102, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO TaskSetManager: Finished task 99.0 in stage 59.0 (TID 839) in 680 ms on 10.0.0.43 (executor driver) (93/200)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 103.0 in stage 59.0 (TID 843) (10.0.0.43, executor driver, partition 103, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 102.0 in stage 59.0 (TID 842)
25/02/04 17:14:04 INFO Executor: Running task 103.0 in stage 59.0 (TID 843)
25/02/04 17:14:04 INFO TaskSetManager: Starting task 104.0 in stage 59.0 (TID 844) (10.0.0.43, executor driver, partition 104, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 104.0 in stage 59.0 (TID 844)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 93.0 in stage 59.0 (TID 833) in 743 ms on 10.0.0.43 (executor driver) (94/200)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 92.0 in stage 59.0 (TID 832) in 749 ms on 10.0.0.43 (executor driver) (95/200)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000096_836' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000096
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000096_836: Committed. Elapsed time: 2 ms.
25/02/04 17:14:04 INFO Executor: Finished task 96.0 in stage 59.0 (TID 836). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 105.0 in stage 59.0 (TID 845) (10.0.0.43, executor driver, partition 105, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 105.0 in stage 59.0 (TID 845)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 96.0 in stage 59.0 (TID 836) in 719 ms on 10.0.0.43 (executor driver) (96/200)
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000091_831' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000091
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000091_831: Committed. Elapsed time: 4 ms.
25/02/04 17:14:04 INFO Executor: Finished task 91.0 in stage 59.0 (TID 831). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 106.0 in stage 59.0 (TID 846) (10.0.0.43, executor driver, partition 106, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 106.0 in stage 59.0 (TID 846)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 91.0 in stage 59.0 (TID 831) in 796 ms on 10.0.0.43 (executor driver) (97/200)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_102 stored as values in memory (estimated size 1372.4 KiB, free 149.4 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_102 locally
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000097_837' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000097
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000097_837: Committed. Elapsed time: 10 ms.
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_105 stored as values in memory (estimated size 1205.0 KiB, free 148.2 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_105 locally
25/02/04 17:14:04 INFO Executor: Finished task 97.0 in stage 59.0 (TID 837). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO TaskSetManager: Starting task 107.0 in stage 59.0 (TID 847) (10.0.0.43, executor driver, partition 107, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:04 INFO Executor: Running task 107.0 in stage 59.0 (TID 847)
25/02/04 17:14:04 INFO TaskSetManager: Finished task 97.0 in stage 59.0 (TID 837) in 748 ms on 10.0.0.43 (executor driver) (98/200)
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_103 stored as values in memory (estimated size 1066.7 KiB, free 147.1 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_103 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_104 stored as values in memory (estimated size 1184.6 KiB, free 146.0 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_104 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_106 stored as values in memory (estimated size 1425.5 KiB, free 144.6 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_106 locally
25/02/04 17:14:04 INFO MemoryStore: Block rdd_72_107 stored as values in memory (estimated size 1226.5 KiB, free 143.4 MiB)
25/02/04 17:14:04 INFO BlockManager: Found block rdd_72_107 locally
25/02/04 17:14:04 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000094_834' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000094
25/02/04 17:14:04 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000094_834: Committed. Elapsed time: 0 ms.
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO Executor: Finished task 94.0 in stage 59.0 (TID 834). 17954 bytes result sent to driver
25/02/04 17:14:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:04 INFO TaskSetManager: Starting task 108.0 in stage 59.0 (TID 848) (10.0.0.43, executor driver, partition 108, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO TaskSetManager: Finished task 94.0 in stage 59.0 (TID 834) in 853 ms on 10.0.0.43 (executor driver) (99/200)
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO Executor: Running task 108.0 in stage 59.0 (TID 848)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_108 stored as values in memory (estimated size 1017.1 KiB, free 20.4 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_108 locally
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000098_838' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000098
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000098_838: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO Executor: Finished task 98.0 in stage 59.0 (TID 838). 18040 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 109.0 in stage 59.0 (TID 849) (10.0.0.43, executor driver, partition 109, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 109.0 in stage 59.0 (TID 849)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 98.0 in stage 59.0 (TID 838) in 1005 ms on 10.0.0.43 (executor driver) (100/200)
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000101_841' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000101
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000101_841: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 101.0 in stage 59.0 (TID 841). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 110.0 in stage 59.0 (TID 850) (10.0.0.43, executor driver, partition 110, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 110.0 in stage 59.0 (TID 850)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 101.0 in stage 59.0 (TID 841) in 667 ms on 10.0.0.43 (executor driver) (101/200)
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000100_840' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000100
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000100_840: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 100.0 in stage 59.0 (TID 840). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 111.0 in stage 59.0 (TID 851) (10.0.0.43, executor driver, partition 111, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 111.0 in stage 59.0 (TID 851)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 100.0 in stage 59.0 (TID 840) in 681 ms on 10.0.0.43 (executor driver) (102/200)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_109 stored as values in memory (estimated size 1040.2 KiB, free 39.5 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_109 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_110 stored as values in memory (estimated size 975.1 KiB, free 38.6 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_110 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_111 stored as values in memory (estimated size 1035.3 KiB, free 55.5 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_111 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000105_845' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000105
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000105_845: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 105.0 in stage 59.0 (TID 845). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO TaskSetManager: Starting task 112.0 in stage 59.0 (TID 852) (10.0.0.43, executor driver, partition 112, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Finished task 105.0 in stage 59.0 (TID 845) in 351 ms on 10.0.0.43 (executor driver) (103/200)
25/02/04 17:14:05 INFO Executor: Running task 112.0 in stage 59.0 (TID 852)
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000103_843' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000103
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000103_843: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000102_842' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000102
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000102_842: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 103.0 in stage 59.0 (TID 843). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Finished task 102.0 in stage 59.0 (TID 842). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 113.0 in stage 59.0 (TID 853) (10.0.0.43, executor driver, partition 113, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000107_847' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000107
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000107_847: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO Executor: Running task 113.0 in stage 59.0 (TID 853)
25/02/04 17:14:05 INFO TaskSetManager: Starting task 114.0 in stage 59.0 (TID 854) (10.0.0.43, executor driver, partition 114, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Finished task 107.0 in stage 59.0 (TID 847). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Running task 114.0 in stage 59.0 (TID 854)
25/02/04 17:14:05 INFO TaskSetManager: Starting task 115.0 in stage 59.0 (TID 855) (10.0.0.43, executor driver, partition 115, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Finished task 103.0 in stage 59.0 (TID 843) in 413 ms on 10.0.0.43 (executor driver) (104/200)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 102.0 in stage 59.0 (TID 842) in 415 ms on 10.0.0.43 (executor driver) (105/200)
25/02/04 17:14:05 INFO Executor: Running task 115.0 in stage 59.0 (TID 855)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 107.0 in stage 59.0 (TID 847) in 357 ms on 10.0.0.43 (executor driver) (106/200)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_112 stored as values in memory (estimated size 1125.1 KiB, free 58.4 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_112 locally
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000104_844' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000104
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000104_844: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 104.0 in stage 59.0 (TID 844). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 116.0 in stage 59.0 (TID 856) (10.0.0.43, executor driver, partition 116, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 116.0 in stage 59.0 (TID 856)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 104.0 in stage 59.0 (TID 844) in 426 ms on 10.0.0.43 (executor driver) (107/200)
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_114 stored as values in memory (estimated size 1391.4 KiB, free 109.1 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_114 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_115 stored as values in memory (estimated size 879.4 KiB, free 108.2 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_115 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_113 stored as values in memory (estimated size 1203.2 KiB, free 107.1 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_113 locally
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000106_846' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000106
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000106_846: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 106.0 in stage 59.0 (TID 846). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 117.0 in stage 59.0 (TID 857) (10.0.0.43, executor driver, partition 117, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_116 stored as values in memory (estimated size 1543.8 KiB, free 97.0 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_116 locally
25/02/04 17:14:05 INFO TaskSetManager: Finished task 106.0 in stage 59.0 (TID 846) in 403 ms on 10.0.0.43 (executor driver) (108/200)
25/02/04 17:14:05 INFO Executor: Running task 117.0 in stage 59.0 (TID 857)
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000108_848' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000108
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000108_848: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 108.0 in stage 59.0 (TID 848). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 118.0 in stage 59.0 (TID 858) (10.0.0.43, executor driver, partition 118, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 118.0 in stage 59.0 (TID 858)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 108.0 in stage 59.0 (TID 848) in 380 ms on 10.0.0.43 (executor driver) (109/200)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_117 stored as values in memory (estimated size 1560.3 KiB, free 30.0 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_117 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_118 stored as values in memory (estimated size 1312.1 KiB, free 14.7 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_118 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO MemoryStore: 7 blocks selected for dropping (8.0 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_134 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_134 on disk on 10.0.0.43:62420 (current size: 1088.2 KiB, original size: 1088.2 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_137 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_137 on disk on 10.0.0.43:62420 (current size: 970.1 KiB, original size: 970.1 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_139 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_139 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 1080.3 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_140 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_140 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 1134.0 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_138 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_138 on disk on 10.0.0.43:62420 (current size: 1111.5 KiB, original size: 1111.5 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_142 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_142 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 1105.0 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_141 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_141 on disk on 10.0.0.43:62420 (current size: 1197.5 KiB, original size: 1197.5 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 7 blocks, free memory is 8.7 MiB
25/02/04 17:14:05 INFO MemoryStore: 3 blocks selected for dropping (3.4 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_143 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_143 on disk on 10.0.0.43:62420 (current size: 1131.3 KiB, original size: 1131.3 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_147 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_147 on disk on 10.0.0.43:62420 (current size: 1044.9 KiB, original size: 1044.9 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_146 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_146 on disk on 10.0.0.43:62420 (current size: 1156.8 KiB, original size: 1156.8 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 3 blocks, free memory is 4.1 MiB
25/02/04 17:14:05 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_145 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_145 on disk on 10.0.0.43:62420 (current size: 1250.7 KiB, original size: 1250.7 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_144 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_144 on disk on 10.0.0.43:62420 (current size: 966.7 KiB, original size: 966.7 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:05 INFO MemoryStore: 7 blocks selected for dropping (8.1 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_149 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_149 on disk on 10.0.0.43:62420 (current size: 1102.0 KiB, original size: 1102.0 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_148 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_148 on disk on 10.0.0.43:62420 (current size: 1192.4 KiB, original size: 1192.4 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_150 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_150 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 1086.5 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_153 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_153 on disk on 10.0.0.43:62420 (current size: 939.3 KiB, original size: 939.3 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_152 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_152 on disk on 10.0.0.43:62420 (current size: 1331.2 KiB, original size: 1331.2 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_157 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_157 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 1134.0 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_155 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_155 on disk on 10.0.0.43:62420 (current size: 1075.9 KiB, original size: 1075.9 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 7 blocks, free memory is 8.6 MiB
25/02/04 17:14:05 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_156 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_156 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 1002.4 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_151 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_151 on disk on 10.0.0.43:62420 (current size: 1149.0 KiB, original size: 1149.0 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 2 blocks, free memory is 2.8 MiB
25/02/04 17:14:05 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000109_849' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000109
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000110_850' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000110
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000109_849: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000111_851' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000111
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000110_850: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000111_851: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 109.0 in stage 59.0 (TID 849). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Finished task 111.0 in stage 59.0 (TID 851). 17997 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Finished task 110.0 in stage 59.0 (TID 850). 17997 bytes result sent to driver
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO TaskSetManager: Starting task 119.0 in stage 59.0 (TID 859) (10.0.0.43, executor driver, partition 119, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 119.0 in stage 59.0 (TID 859)
25/02/04 17:14:05 INFO TaskSetManager: Starting task 120.0 in stage 59.0 (TID 860) (10.0.0.43, executor driver, partition 120, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Starting task 121.0 in stage 59.0 (TID 861) (10.0.0.43, executor driver, partition 121, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Finished task 109.0 in stage 59.0 (TID 849) in 350 ms on 10.0.0.43 (executor driver) (110/200)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 110.0 in stage 59.0 (TID 850) in 337 ms on 10.0.0.43 (executor driver) (111/200)
25/02/04 17:14:05 INFO Executor: Running task 121.0 in stage 59.0 (TID 861)
25/02/04 17:14:05 INFO Executor: Running task 120.0 in stage 59.0 (TID 860)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 111.0 in stage 59.0 (TID 851) in 329 ms on 10.0.0.43 (executor driver) (112/200)
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_121 stored as values in memory (estimated size 1182.1 KiB, free 48.2 MiB)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_120 stored as values in memory (estimated size 1129.3 KiB, free 48.2 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_121 locally
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_120 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_119 stored as values in memory (estimated size 1062.9 KiB, free 47.2 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_119 locally
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO MemoryStore: 3 blocks selected for dropping (3.9 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_154 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_154 on disk on 10.0.0.43:62420 (current size: 1008.9 KiB, original size: 1008.9 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_158 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_158 on disk on 10.0.0.43:62420 (current size: 1322.5 KiB, original size: 1322.5 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_159 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_159 on disk on 10.0.0.43:62420 (current size: 1457.3 KiB, original size: 1457.3 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 3 blocks, free memory is 9.1 MiB
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000112_852' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000112
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000112_852: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Finished task 112.0 in stage 59.0 (TID 852). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 122.0 in stage 59.0 (TID 862) (10.0.0.43, executor driver, partition 122, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Finished task 112.0 in stage 59.0 (TID 852) in 396 ms on 10.0.0.43 (executor driver) (113/200)
25/02/04 17:14:05 INFO Executor: Running task 122.0 in stage 59.0 (TID 862)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_122 stored as values in memory (estimated size 1375.8 KiB, free 15.8 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_122 locally
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000118_858' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000118
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000118_858: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000115_855' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000115
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000115_855: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO Executor: Finished task 118.0 in stage 59.0 (TID 858). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Finished task 115.0 in stage 59.0 (TID 855). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO TaskSetManager: Starting task 123.0 in stage 59.0 (TID 863) (10.0.0.43, executor driver, partition 123, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO TaskSetManager: Starting task 124.0 in stage 59.0 (TID 864) (10.0.0.43, executor driver, partition 124, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 123.0 in stage 59.0 (TID 863)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 118.0 in stage 59.0 (TID 858) in 320 ms on 10.0.0.43 (executor driver) (114/200)
25/02/04 17:14:05 INFO Executor: Running task 124.0 in stage 59.0 (TID 864)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 115.0 in stage 59.0 (TID 855) in 377 ms on 10.0.0.43 (executor driver) (115/200)
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_123 stored as values in memory (estimated size 1264.0 KiB, free 53.8 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_123 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_124 stored as values in memory (estimated size 1178.8 KiB, free 60.2 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_124 locally
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000113_853' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000113
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000113_853: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO Executor: Finished task 113.0 in stage 59.0 (TID 853). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000114_854' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000114
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000114_854: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO TaskSetManager: Starting task 125.0 in stage 59.0 (TID 865) (10.0.0.43, executor driver, partition 125, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Finished task 114.0 in stage 59.0 (TID 854). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Finished task 113.0 in stage 59.0 (TID 853) in 421 ms on 10.0.0.43 (executor driver) (116/200)
25/02/04 17:14:05 INFO TaskSetManager: Starting task 126.0 in stage 59.0 (TID 866) (10.0.0.43, executor driver, partition 126, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 126.0 in stage 59.0 (TID 866)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 114.0 in stage 59.0 (TID 854) in 423 ms on 10.0.0.43 (executor driver) (117/200)
25/02/04 17:14:05 INFO Executor: Running task 125.0 in stage 59.0 (TID 865)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_126 stored as values in memory (estimated size 1073.8 KiB, free 42.5 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_126 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_125 stored as values in memory (estimated size 1204.4 KiB, free 43.5 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_125 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000119_859' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000119
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000121_861' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000121
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000119_859: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000121_861: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO Executor: Finished task 119.0 in stage 59.0 (TID 859). 17997 bytes result sent to driver
25/02/04 17:14:05 INFO Executor: Finished task 121.0 in stage 59.0 (TID 861). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 127.0 in stage 59.0 (TID 867) (10.0.0.43, executor driver, partition 127, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO TaskSetManager: Finished task 119.0 in stage 59.0 (TID 859) in 330 ms on 10.0.0.43 (executor driver) (118/200)
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000120_860' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000120
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000120_860: Committed. Elapsed time: 0 ms.
25/02/04 17:14:05 INFO Executor: Running task 127.0 in stage 59.0 (TID 867)
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO Executor: Finished task 120.0 in stage 59.0 (TID 860). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000116_856' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000116
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000116_856: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO TaskSetManager: Starting task 128.0 in stage 59.0 (TID 868) (10.0.0.43, executor driver, partition 128, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 128.0 in stage 59.0 (TID 868)
25/02/04 17:14:05 INFO TaskSetManager: Starting task 129.0 in stage 59.0 (TID 869) (10.0.0.43, executor driver, partition 129, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 129.0 in stage 59.0 (TID 869)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 120.0 in stage 59.0 (TID 860) in 328 ms on 10.0.0.43 (executor driver) (119/200)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 121.0 in stage 59.0 (TID 861) in 327 ms on 10.0.0.43 (executor driver) (120/200)
25/02/04 17:14:05 INFO Executor: Finished task 116.0 in stage 59.0 (TID 856). 17954 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 130.0 in stage 59.0 (TID 870) (10.0.0.43, executor driver, partition 130, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 130.0 in stage 59.0 (TID 870)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 116.0 in stage 59.0 (TID 856) in 563 ms on 10.0.0.43 (executor driver) (121/200)
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_127 stored as values in memory (estimated size 1660.8 KiB, free 76.8 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_127 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_129 stored as values in memory (estimated size 1408.3 KiB, free 75.5 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_129 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_130 stored as values in memory (estimated size 1167.7 KiB, free 74.3 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_130 locally
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_128 stored as values in memory (estimated size 1177.6 KiB, free 73.2 MiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_128 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:05 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000117_857' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000117
25/02/04 17:14:05 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000117_857: Committed. Elapsed time: 1 ms.
25/02/04 17:14:05 INFO Executor: Finished task 117.0 in stage 59.0 (TID 857). 18040 bytes result sent to driver
25/02/04 17:14:05 INFO TaskSetManager: Starting task 131.0 in stage 59.0 (TID 871) (10.0.0.43, executor driver, partition 131, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:05 INFO Executor: Running task 131.0 in stage 59.0 (TID 871)
25/02/04 17:14:05 INFO TaskSetManager: Finished task 117.0 in stage 59.0 (TID 857) in 608 ms on 10.0.0.43 (executor driver) (122/200)
25/02/04 17:14:05 INFO MemoryStore: Block rdd_72_131 stored as values in memory (estimated size 1353.8 KiB, free 871.0 KiB)
25/02/04 17:14:05 INFO BlockManager: Found block rdd_72_131 locally
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:05 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_160 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_160 on disk on 10.0.0.43:62420 (current size: 1140.9 KiB, original size: 1140.9 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_161 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_161 on disk on 10.0.0.43:62420 (current size: 1075.6 KiB, original size: 1075.6 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 2 blocks, free memory is 3.1 MiB
25/02/04 17:14:05 INFO MemoryStore: 1 blocks selected for dropping (1247.5 KiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_162 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_162 on disk on 10.0.0.43:62420 (current size: 1171.5 KiB, original size: 1171.5 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 1 blocks, free memory is 1903.8 KiB
25/02/04 17:14:05 INFO MemoryStore: 1 blocks selected for dropping (1434.8 KiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_164 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_164 on disk on 10.0.0.43:62420 (current size: 1357.3 KiB, original size: 1357.3 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 1 blocks, free memory is 2.8 MiB
25/02/04 17:14:05 INFO MemoryStore: 1 blocks selected for dropping (1328.4 KiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_163 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_163 on disk on 10.0.0.43:62420 (current size: 1255.9 KiB, original size: 1255.9 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 1 blocks, free memory is 3.1 MiB
25/02/04 17:14:05 INFO MemoryStore: 3 blocks selected for dropping (3.7 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_165 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_165 on disk on 10.0.0.43:62420 (current size: 1119.3 KiB, original size: 1119.3 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_166 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_166 on disk on 10.0.0.43:62420 (current size: 1469.1 KiB, original size: 1469.1 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_168 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_168 on disk on 10.0.0.43:62420 (current size: 1014.6 KiB, original size: 1014.6 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 3 blocks, free memory is 4.8 MiB
25/02/04 17:14:05 INFO MemoryStore: 7 blocks selected for dropping (7.7 MiB bytes)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_167 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_167 on disk on 10.0.0.43:62420 (current size: 994.1 KiB, original size: 994.1 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_169 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_169 on disk on 10.0.0.43:62420 (current size: 1051.8 KiB, original size: 1051.8 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_171 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_171 on disk on 10.0.0.43:62420 (current size: 1224.6 KiB, original size: 1224.6 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_170 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_170 on disk on 10.0.0.43:62420 (current size: 1180.1 KiB, original size: 1180.1 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_172 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_172 on disk on 10.0.0.43:62420 (current size: 882.2 KiB, original size: 882.2 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_173 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_173 on disk on 10.0.0.43:62420 (current size: 1039.3 KiB, original size: 1039.3 KiB)
25/02/04 17:14:05 INFO BlockManager: Dropping block rdd_72_175 from memory
25/02/04 17:14:05 INFO BlockManagerInfo: Updated rdd_72_175 on disk on 10.0.0.43:62420 (current size: 1032.3 KiB, original size: 1032.3 KiB)
25/02/04 17:14:05 INFO MemoryStore: After dropping 7 blocks, free memory is 8.4 MiB
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000126_866' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000126
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000126_866: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO Executor: Finished task 126.0 in stage 59.0 (TID 866). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO TaskSetManager: Starting task 132.0 in stage 59.0 (TID 872) (10.0.0.43, executor driver, partition 132, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 132.0 in stage 59.0 (TID 872)
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000122_862' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000122
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000122_862: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000123_863' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000123
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000123_863: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO TaskSetManager: Finished task 126.0 in stage 59.0 (TID 866) in 339 ms on 10.0.0.43 (executor driver) (123/200)
25/02/04 17:14:06 INFO Executor: Finished task 122.0 in stage 59.0 (TID 862). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000124_864' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000124
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000124_864: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO Executor: Finished task 123.0 in stage 59.0 (TID 863). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 124.0 in stage 59.0 (TID 864). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO TaskSetManager: Starting task 133.0 in stage 59.0 (TID 873) (10.0.0.43, executor driver, partition 133, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Finished task 122.0 in stage 59.0 (TID 862) in 424 ms on 10.0.0.43 (executor driver) (124/200)
25/02/04 17:14:06 INFO TaskSetManager: Starting task 134.0 in stage 59.0 (TID 874) (10.0.0.43, executor driver, partition 134, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Finished task 123.0 in stage 59.0 (TID 863) in 386 ms on 10.0.0.43 (executor driver) (125/200)
25/02/04 17:14:06 INFO TaskSetManager: Starting task 135.0 in stage 59.0 (TID 875) (10.0.0.43, executor driver, partition 135, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 134.0 in stage 59.0 (TID 874)
25/02/04 17:14:06 INFO Executor: Running task 133.0 in stage 59.0 (TID 873)
25/02/04 17:14:06 INFO TaskSetManager: Finished task 124.0 in stage 59.0 (TID 864) in 387 ms on 10.0.0.43 (executor driver) (126/200)
25/02/04 17:14:06 INFO Executor: Running task 135.0 in stage 59.0 (TID 875)
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_133 stored as values in memory (estimated size 919.7 KiB, free 69.5 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_133 locally
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_134 stored as values in memory (estimated size 1147.5 KiB, free 68.4 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_134 locally
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_132 stored as values in memory (estimated size 1234.5 KiB, free 64.7 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_132 locally
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_135 stored as values in memory (estimated size 1025.8 KiB, free 59.9 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_135 locally
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:06 INFO BlockManager: Dropping block rdd_72_176 from memory
25/02/04 17:14:06 INFO BlockManagerInfo: Updated rdd_72_176 on disk on 10.0.0.43:62420 (current size: 959.7 KiB, original size: 959.7 KiB)
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO BlockManager: Dropping block rdd_72_174 from memory
25/02/04 17:14:06 INFO BlockManagerInfo: Updated rdd_72_174 on disk on 10.0.0.43:62420 (current size: 1240.5 KiB, original size: 1240.5 KiB)
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO MemoryStore: After dropping 2 blocks, free memory is 8.5 MiB
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000125_865' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000125
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000125_865: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO Executor: Finished task 125.0 in stage 59.0 (TID 865). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO TaskSetManager: Starting task 136.0 in stage 59.0 (TID 876) (10.0.0.43, executor driver, partition 136, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 136.0 in stage 59.0 (TID 876)
25/02/04 17:14:06 INFO TaskSetManager: Finished task 125.0 in stage 59.0 (TID 865) in 431 ms on 10.0.0.43 (executor driver) (127/200)
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_136 stored as values in memory (estimated size 1429.3 KiB, free 19.1 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_136 locally
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000128_868' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000128
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000128_868: Committed. Elapsed time: 1 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000130_870' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000130
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000130_870: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000127_867' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000127
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000127_867: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000129_869' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000129
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000129_869: Committed. Elapsed time: 0 ms.
25/02/04 17:14:06 INFO Executor: Finished task 128.0 in stage 59.0 (TID 868). 17997 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 127.0 in stage 59.0 (TID 867). 17997 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 129.0 in stage 59.0 (TID 869). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 130.0 in stage 59.0 (TID 870). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO TaskSetManager: Starting task 137.0 in stage 59.0 (TID 877) (10.0.0.43, executor driver, partition 137, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Finished task 128.0 in stage 59.0 (TID 868) in 345 ms on 10.0.0.43 (executor driver) (128/200)
25/02/04 17:14:06 INFO Executor: Running task 137.0 in stage 59.0 (TID 877)
25/02/04 17:14:06 INFO TaskSetManager: Starting task 138.0 in stage 59.0 (TID 878) (10.0.0.43, executor driver, partition 138, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Starting task 139.0 in stage 59.0 (TID 879) (10.0.0.43, executor driver, partition 139, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 138.0 in stage 59.0 (TID 878)
25/02/04 17:14:06 INFO Executor: Running task 139.0 in stage 59.0 (TID 879)
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO TaskSetManager: Starting task 140.0 in stage 59.0 (TID 880) (10.0.0.43, executor driver, partition 140, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO Executor: Running task 140.0 in stage 59.0 (TID 880)
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO TaskSetManager: Finished task 129.0 in stage 59.0 (TID 869) in 347 ms on 10.0.0.43 (executor driver) (129/200)
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO TaskSetManager: Finished task 127.0 in stage 59.0 (TID 867) in 356 ms on 10.0.0.43 (executor driver) (130/200)
25/02/04 17:14:06 INFO TaskSetManager: Finished task 130.0 in stage 59.0 (TID 870) in 805 ms on 10.0.0.43 (executor driver) (131/200)
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000134_874' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000134
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000133_873' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000133
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000131_871' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000131
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000134_874: Committed. Elapsed time: 4 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000132_872' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000132
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000132_872: Committed. Elapsed time: 4 ms.
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000131_871: Committed. Elapsed time: 5 ms.
25/02/04 17:14:06 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000135_875' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000135
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000135_875: Committed. Elapsed time: 5 ms.
25/02/04 17:14:06 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000133_873: Committed. Elapsed time: 4 ms.
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_139 stored as values in memory (estimated size 1149.9 KiB, free 154.6 MiB)
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_140 stored as values in memory (estimated size 1202.8 KiB, free 154.6 MiB)
25/02/04 17:14:06 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_139 locally
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_137 stored as values in memory (estimated size 1027.9 KiB, free 154.6 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_137 locally
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_138 stored as values in memory (estimated size 1174.8 KiB, free 154.6 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_140 locally
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_138 locally
25/02/04 17:14:06 INFO Executor: Finished task 133.0 in stage 59.0 (TID 873). 17997 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 131.0 in stage 59.0 (TID 871). 17997 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 135.0 in stage 59.0 (TID 875). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 132.0 in stage 59.0 (TID 872). 17954 bytes result sent to driver
25/02/04 17:14:06 INFO Executor: Finished task 134.0 in stage 59.0 (TID 874). 17997 bytes result sent to driver
25/02/04 17:14:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:06 INFO TaskSetManager: Starting task 141.0 in stage 59.0 (TID 881) (10.0.0.43, executor driver, partition 141, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 141.0 in stage 59.0 (TID 881)
25/02/04 17:14:06 INFO TaskSetManager: Starting task 142.0 in stage 59.0 (TID 882) (10.0.0.43, executor driver, partition 142, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Finished task 131.0 in stage 59.0 (TID 871) in 981 ms on 10.0.0.43 (executor driver) (132/200)
25/02/04 17:14:06 INFO Executor: Running task 142.0 in stage 59.0 (TID 882)
25/02/04 17:14:06 INFO TaskSetManager: Finished task 133.0 in stage 59.0 (TID 873) in 864 ms on 10.0.0.43 (executor driver) (133/200)
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO TaskSetManager: Starting task 143.0 in stage 59.0 (TID 883) (10.0.0.43, executor driver, partition 143, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 143.0 in stage 59.0 (TID 883)
25/02/04 17:14:06 INFO TaskSetManager: Starting task 144.0 in stage 59.0 (TID 884) (10.0.0.43, executor driver, partition 144, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO TaskSetManager: Starting task 145.0 in stage 59.0 (TID 885) (10.0.0.43, executor driver, partition 145, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:06 INFO Executor: Running task 144.0 in stage 59.0 (TID 884)
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO Executor: Running task 145.0 in stage 59.0 (TID 885)
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO TaskSetManager: Finished task 132.0 in stage 59.0 (TID 872) in 874 ms on 10.0.0.43 (executor driver) (134/200)
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO TaskSetManager: Finished task 135.0 in stage 59.0 (TID 875) in 870 ms on 10.0.0.43 (executor driver) (135/200)
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_142 stored as values in memory (estimated size 1171.1 KiB, free 103.5 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_142 locally
25/02/04 17:14:06 INFO TaskSetManager: Finished task 134.0 in stage 59.0 (TID 874) in 884 ms on 10.0.0.43 (executor driver) (136/200)
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_145 stored as values in memory (estimated size 1331.0 KiB, free 92.2 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_145 locally
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_141 stored as values in memory (estimated size 1268.3 KiB, free 91.0 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_141 locally
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_144 stored as values in memory (estimated size 1027.6 KiB, free 79.1 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_144 locally
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO MemoryStore: Block rdd_72_143 stored as values in memory (estimated size 1200.3 KiB, free 16.8 MiB)
25/02/04 17:14:06 INFO BlockManager: Found block rdd_72_143 locally
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO MemoryStore: 6 blocks selected for dropping (7.4 MiB bytes)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_177 from memory
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_177 on disk on 10.0.0.43:62420 (current size: 1310.4 KiB, original size: 1310.4 KiB)
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_179 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_179 on disk on 10.0.0.43:62420 (current size: 1388.5 KiB, original size: 1388.5 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_180 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_180 on disk on 10.0.0.43:62420 (current size: 1018.4 KiB, original size: 1018.4 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_178 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_178 on disk on 10.0.0.43:62420 (current size: 1282.9 KiB, original size: 1282.9 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_181 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_181 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 1105.0 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_183 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_183 on disk on 10.0.0.43:62420 (current size: 1032.0 KiB, original size: 1032.0 KiB)
25/02/04 17:14:07 INFO MemoryStore: After dropping 6 blocks, free memory is 8.2 MiB
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000141_881' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000141
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000145_885' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000145
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000139_879' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000139
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000142_882' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000142
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000139_879: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000141_881: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000138_878' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000138
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000138_878: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000142_882: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000145_885: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO Executor: Finished task 139.0 in stage 59.0 (TID 879). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 142.0 in stage 59.0 (TID 882). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 138.0 in stage 59.0 (TID 878). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 141.0 in stage 59.0 (TID 881). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 145.0 in stage 59.0 (TID 885). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000137_877' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000137
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000137_877: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000140_880' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000140
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000140_880: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000136_876' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000136
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000136_876: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 137.0 in stage 59.0 (TID 877). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 140.0 in stage 59.0 (TID 880). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 136.0 in stage 59.0 (TID 876). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO TaskSetManager: Starting task 146.0 in stage 59.0 (TID 886) (10.0.0.43, executor driver, partition 146, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000144_884' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000144
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000144_884: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 144.0 in stage 59.0 (TID 884). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Running task 146.0 in stage 59.0 (TID 886)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 147.0 in stage 59.0 (TID 887) (10.0.0.43, executor driver, partition 147, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 147.0 in stage 59.0 (TID 887)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 141.0 in stage 59.0 (TID 881) in 389 ms on 10.0.0.43 (executor driver) (137/200)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 148.0 in stage 59.0 (TID 888) (10.0.0.43, executor driver, partition 148, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Finished task 145.0 in stage 59.0 (TID 885) in 337 ms on 10.0.0.43 (executor driver) (138/200)
25/02/04 17:14:07 INFO Executor: Running task 148.0 in stage 59.0 (TID 888)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 149.0 in stage 59.0 (TID 889) (10.0.0.43, executor driver, partition 149, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 149.0 in stage 59.0 (TID 889)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 150.0 in stage 59.0 (TID 890) (10.0.0.43, executor driver, partition 150, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Finished task 138.0 in stage 59.0 (TID 878) in 1046 ms on 10.0.0.43 (executor driver) (139/200)
25/02/04 17:14:07 INFO Executor: Running task 150.0 in stage 59.0 (TID 890)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 142.0 in stage 59.0 (TID 882) in 347 ms on 10.0.0.43 (executor driver) (140/200)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 151.0 in stage 59.0 (TID 891) (10.0.0.43, executor driver, partition 151, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 151.0 in stage 59.0 (TID 891)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 152.0 in stage 59.0 (TID 892) (10.0.0.43, executor driver, partition 152, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 152.0 in stage 59.0 (TID 892)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 153.0 in stage 59.0 (TID 893) (10.0.0.43, executor driver, partition 153, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 153.0 in stage 59.0 (TID 893)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 154.0 in stage 59.0 (TID 894) (10.0.0.43, executor driver, partition 154, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 154.0 in stage 59.0 (TID 894)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 139.0 in stage 59.0 (TID 879) in 1048 ms on 10.0.0.43 (executor driver) (141/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 136.0 in stage 59.0 (TID 876) in 1123 ms on 10.0.0.43 (executor driver) (142/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 144.0 in stage 59.0 (TID 884) in 340 ms on 10.0.0.43 (executor driver) (143/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 137.0 in stage 59.0 (TID 877) in 1057 ms on 10.0.0.43 (executor driver) (144/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 140.0 in stage 59.0 (TID 880) in 1048 ms on 10.0.0.43 (executor driver) (145/200)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_153 stored as values in memory (estimated size 994.4 KiB, free 173.2 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_153 locally
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000143_883' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000143
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000143_883: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_151 stored as values in memory (estimated size 1217.8 KiB, free 169.7 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_149 stored as values in memory (estimated size 1166.6 KiB, free 169.7 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_150 stored as values in memory (estimated size 1152.4 KiB, free 168.5 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_154 stored as values in memory (estimated size 1069.8 KiB, free 167.5 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_152 stored as values in memory (estimated size 1410.1 KiB, free 166.1 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_148 stored as values in memory (estimated size 1260.4 KiB, free 168.5 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_147 stored as values in memory (estimated size 1105.9 KiB, free 163.8 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_146 stored as values in memory (estimated size 1225.4 KiB, free 163.8 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_151 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_150 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_149 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_154 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_146 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_147 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_148 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_152 locally
25/02/04 17:14:07 INFO Executor: Finished task 143.0 in stage 59.0 (TID 883). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO TaskSetManager: Starting task 155.0 in stage 59.0 (TID 895) (10.0.0.43, executor driver, partition 155, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 155.0 in stage 59.0 (TID 895)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 143.0 in stage 59.0 (TID 883) in 378 ms on 10.0.0.43 (executor driver) (146/200)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_155 stored as values in memory (estimated size 1139.9 KiB, free 162.7 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_155 locally
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO MemoryStore: 7 blocks selected for dropping (7.8 MiB bytes)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_182 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_182 on disk on 10.0.0.43:62420 (current size: 1110.7 KiB, original size: 1110.7 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_184 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_184 on disk on 10.0.0.43:62420 (current size: 962.8 KiB, original size: 962.8 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_185 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_185 on disk on 10.0.0.43:62420 (current size: 1088.7 KiB, original size: 1088.7 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_186 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_186 on disk on 10.0.0.43:62420 (current size: 1048.2 KiB, original size: 1048.2 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_188 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_188 on disk on 10.0.0.43:62420 (current size: 1143.5 KiB, original size: 1143.5 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_193 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_193 on disk on 10.0.0.43:62420 (current size: 1194.9 KiB, original size: 1194.9 KiB)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_192 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_192 on disk on 10.0.0.43:62420 (current size: 1012.3 KiB, original size: 1012.3 KiB)
25/02/04 17:14:07 INFO MemoryStore: After dropping 7 blocks, free memory is 8.5 MiB
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000150_890' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000150
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000150_890: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000153_893' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000153
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000153_893: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000151_891' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000151
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000151_891: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000148_888' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000148
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000148_888: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000154_894' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000154
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000154_894: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000149_889' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000149
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000149_889: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 149.0 in stage 59.0 (TID 889). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 153.0 in stage 59.0 (TID 893). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 150.0 in stage 59.0 (TID 890). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 154.0 in stage 59.0 (TID 894). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 148.0 in stage 59.0 (TID 888). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 151.0 in stage 59.0 (TID 891). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000147_887' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000147
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000147_887: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000155_895' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000155
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000155_895: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 147.0 in stage 59.0 (TID 887). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO Executor: Finished task 155.0 in stage 59.0 (TID 895). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000146_886' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000146
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000146_886: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 146.0 in stage 59.0 (TID 886). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO TaskSetManager: Starting task 156.0 in stage 59.0 (TID 896) (10.0.0.43, executor driver, partition 156, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 156.0 in stage 59.0 (TID 896)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 157.0 in stage 59.0 (TID 897) (10.0.0.43, executor driver, partition 157, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Finished task 149.0 in stage 59.0 (TID 889) in 325 ms on 10.0.0.43 (executor driver) (147/200)
25/02/04 17:14:07 INFO Executor: Running task 157.0 in stage 59.0 (TID 897)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 158.0 in stage 59.0 (TID 898) (10.0.0.43, executor driver, partition 158, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 158.0 in stage 59.0 (TID 898)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 150.0 in stage 59.0 (TID 890) in 325 ms on 10.0.0.43 (executor driver) (148/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 153.0 in stage 59.0 (TID 893) in 324 ms on 10.0.0.43 (executor driver) (149/200)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 159.0 in stage 59.0 (TID 899) (10.0.0.43, executor driver, partition 159, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 159.0 in stage 59.0 (TID 899)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 160.0 in stage 59.0 (TID 900) (10.0.0.43, executor driver, partition 160, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Starting task 161.0 in stage 59.0 (TID 901) (10.0.0.43, executor driver, partition 161, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 160.0 in stage 59.0 (TID 900)
25/02/04 17:14:07 INFO Executor: Running task 161.0 in stage 59.0 (TID 901)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 162.0 in stage 59.0 (TID 902) (10.0.0.43, executor driver, partition 162, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO Executor: Running task 162.0 in stage 59.0 (TID 902)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 163.0 in stage 59.0 (TID 903) (10.0.0.43, executor driver, partition 163, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Finished task 155.0 in stage 59.0 (TID 895) in 291 ms on 10.0.0.43 (executor driver) (150/200)
25/02/04 17:14:07 INFO Executor: Running task 163.0 in stage 59.0 (TID 903)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 154.0 in stage 59.0 (TID 894) in 325 ms on 10.0.0.43 (executor driver) (151/200)
25/02/04 17:14:07 INFO TaskSetManager: Starting task 164.0 in stage 59.0 (TID 904) (10.0.0.43, executor driver, partition 164, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO TaskSetManager: Finished task 148.0 in stage 59.0 (TID 888) in 327 ms on 10.0.0.43 (executor driver) (152/200)
25/02/04 17:14:07 INFO Executor: Running task 164.0 in stage 59.0 (TID 904)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 151.0 in stage 59.0 (TID 891) in 326 ms on 10.0.0.43 (executor driver) (153/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 147.0 in stage 59.0 (TID 887) in 329 ms on 10.0.0.43 (executor driver) (154/200)
25/02/04 17:14:07 INFO TaskSetManager: Finished task 146.0 in stage 59.0 (TID 886) in 399 ms on 10.0.0.43 (executor driver) (155/200)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_158 stored as values in memory (estimated size 1398.2 KiB, free 169.1 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_158 locally
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_156 stored as values in memory (estimated size 1061.6 KiB, free 168.1 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_156 locally
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_159 stored as values in memory (estimated size 1537.9 KiB, free 160.4 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_157 stored as values in memory (estimated size 1199.3 KiB, free 166.9 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_159 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_157 locally
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_164 stored as values in memory (estimated size 1434.8 KiB, free 162.9 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_164 locally
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_161 stored as values in memory (estimated size 1138.7 KiB, free 160.4 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_162 stored as values in memory (estimated size 1247.5 KiB, free 159.2 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_160 stored as values in memory (estimated size 1206.5 KiB, free 161.7 MiB)
25/02/04 17:14:07 INFO MemoryStore: Block rdd_72_163 stored as values in memory (estimated size 1328.4 KiB, free 160.4 MiB)
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_163 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_160 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_162 locally
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_161 locally
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000152_892' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000152
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000152_892: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO Executor: Finished task 152.0 in stage 59.0 (TID 892). 17954 bytes result sent to driver
25/02/04 17:14:07 INFO TaskSetManager: Starting task 165.0 in stage 59.0 (TID 905) (10.0.0.43, executor driver, partition 165, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO TaskSetManager: Finished task 152.0 in stage 59.0 (TID 892) in 451 ms on 10.0.0.43 (executor driver) (156/200)
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO MemoryStore: 1 blocks selected for dropping (1429.8 KiB bytes)
25/02/04 17:14:07 INFO BlockManager: Dropping block rdd_72_191 from memory
25/02/04 17:14:07 INFO BlockManagerInfo: Updated rdd_72_191 on disk on 10.0.0.43:62420 (current size: 1355.3 KiB, original size: 1355.3 KiB)
25/02/04 17:14:07 INFO MemoryStore: After dropping 1 blocks, free memory is 2.6 MiB
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO Executor: Running task 165.0 in stage 59.0 (TID 905)
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO MemoryStore: 2 blocks selected for dropping (413.2 KiB bytes)
25/02/04 17:14:07 INFO BlockManager: Dropping block broadcast_26_piece0 from memory
25/02/04 17:14:07 INFO BlockManager: Writing block broadcast_26_piece0 to disk
25/02/04 17:14:07 INFO BlockManagerInfo: Updated broadcast_26_piece0 on disk on 10.0.0.43:62420 (current size: 113.3 KiB, original size: 0.0 B)
25/02/04 17:14:07 INFO BlockManager: Dropping block broadcast_26 from memory
25/02/04 17:14:07 INFO BlockManager: Writing block broadcast_26 to disk
25/02/04 17:14:07 INFO MemoryStore: After dropping 2 blocks, free memory is 1050.2 KiB
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:07 INFO MemoryStore: Will not store rdd_72_165
25/02/04 17:14:07 WARN MemoryStore: Not enough space to cache rdd_72_165 in memory! (computed 1185.7 KiB so far)
25/02/04 17:14:07 INFO MemoryStore: Memory use = 205.3 MiB (blocks) + 1024.0 KiB (scratch space shared across 1 tasks(s)) = 206.3 MiB. Storage limit = 206.3 MiB.
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 INFO BlockManager: Found block rdd_72_165 locally
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:07 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000161_901' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000161
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000161_901: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000158_898' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000158
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000158_898: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000163_903' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000163
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000163_903: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000156_896' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000156
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000156_896: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000157_897' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000157
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000160_900' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000160
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000160_900: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000157_897: Committed. Elapsed time: 1 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000164_904' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000164
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000164_904: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000162_902' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000162
25/02/04 17:14:07 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000162_902: Committed. Elapsed time: 0 ms.
25/02/04 17:14:07 INFO Executor: Finished task 157.0 in stage 59.0 (TID 897). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 166.0 in stage 59.0 (TID 906) (10.0.0.43, executor driver, partition 166, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 166.0 in stage 59.0 (TID 906)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 157.0 in stage 59.0 (TID 897) in 434 ms on 10.0.0.43 (executor driver) (157/200)
25/02/04 17:14:08 INFO Executor: Finished task 156.0 in stage 59.0 (TID 896). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 160.0 in stage 59.0 (TID 900). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 163.0 in stage 59.0 (TID 903). 17997 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 164.0 in stage 59.0 (TID 904). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 161.0 in stage 59.0 (TID 901). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 162.0 in stage 59.0 (TID 902). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 158.0 in stage 59.0 (TID 898). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 167.0 in stage 59.0 (TID 907) (10.0.0.43, executor driver, partition 167, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 168.0 in stage 59.0 (TID 908) (10.0.0.43, executor driver, partition 168, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 167.0 in stage 59.0 (TID 907)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 169.0 in stage 59.0 (TID 909) (10.0.0.43, executor driver, partition 169, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Finished task 156.0 in stage 59.0 (TID 896) in 481 ms on 10.0.0.43 (executor driver) (158/200)
25/02/04 17:14:08 INFO Executor: Running task 169.0 in stage 59.0 (TID 909)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 170.0 in stage 59.0 (TID 910) (10.0.0.43, executor driver, partition 170, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 171.0 in stage 59.0 (TID 911) (10.0.0.43, executor driver, partition 171, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 170.0 in stage 59.0 (TID 910)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 172.0 in stage 59.0 (TID 912) (10.0.0.43, executor driver, partition 172, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 173.0 in stage 59.0 (TID 913) (10.0.0.43, executor driver, partition 173, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 172.0 in stage 59.0 (TID 912)
25/02/04 17:14:08 INFO Executor: Running task 173.0 in stage 59.0 (TID 913)
25/02/04 17:14:08 INFO Executor: Running task 171.0 in stage 59.0 (TID 911)
25/02/04 17:14:08 INFO Executor: Running task 168.0 in stage 59.0 (TID 908)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 161.0 in stage 59.0 (TID 901) in 482 ms on 10.0.0.43 (executor driver) (159/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 164.0 in stage 59.0 (TID 904) in 482 ms on 10.0.0.43 (executor driver) (160/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 158.0 in stage 59.0 (TID 898) in 485 ms on 10.0.0.43 (executor driver) (161/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 162.0 in stage 59.0 (TID 902) in 486 ms on 10.0.0.43 (executor driver) (162/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 160.0 in stage 59.0 (TID 900) in 499 ms on 10.0.0.43 (executor driver) (163/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 163.0 in stage 59.0 (TID 903) in 505 ms on 10.0.0.43 (executor driver) (164/200)
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_173 stored as values in memory (estimated size 1103.4 KiB, free 140.0 MiB)
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_167 stored as values in memory (estimated size 1054.2 KiB, free 140.0 MiB)
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_172 stored as values in memory (estimated size 936.9 KiB, free 140.0 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_172 locally
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_167 locally
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_173 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_169 stored as values in memory (estimated size 1113.0 KiB, free 137.9 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_169 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_166 stored as values in memory (estimated size 1547.2 KiB, free 136.4 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_166 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_170 stored as values in memory (estimated size 1245.6 KiB, free 135.1 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_170 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_171 stored as values in memory (estimated size 1299.1 KiB, free 133.9 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_171 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_168 stored as values in memory (estimated size 1077.6 KiB, free 133.5 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_168 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000159_899' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000159
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000159_899: Committed. Elapsed time: 4 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1006.5 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_194 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_194 on disk on 10.0.0.43:62420 (current size: 952.6 KiB, original size: 952.6 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 8.9 MiB
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1326.0 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_190 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_190 on disk on 10.0.0.43:62420 (current size: 1253.6 KiB, original size: 1253.6 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 2.1 MiB
25/02/04 17:14:08 INFO Executor: Finished task 159.0 in stage 59.0 (TID 899). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 174.0 in stage 59.0 (TID 914) (10.0.0.43, executor driver, partition 174, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 174.0 in stage 59.0 (TID 914)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 159.0 in stage 59.0 (TID 899) in 608 ms on 10.0.0.43 (executor driver) (165/200)
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO MemoryStore: Will not store rdd_72_174
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_72_174 in memory.
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 WARN MemoryStore: Not enough space to cache rdd_72_174 in memory! (computed 384.0 B so far)
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: Memory use = 212.2 MiB (blocks) + 0.0 B (scratch space shared across 0 tasks(s)) = 212.2 MiB. Storage limit = 212.3 MiB.
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_174 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: 2 blocks selected for dropping (3.2 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_187 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_187 on disk on 10.0.0.43:62420 (current size: 1739.0 KiB, original size: 1739.0 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_189 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_189 on disk on 10.0.0.43:62420 (current size: 1400.9 KiB, original size: 1400.9 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 2 blocks, free memory is 3.3 MiB
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1663.1 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_196 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_196 on disk on 10.0.0.43:62420 (current size: 1587.2 KiB, original size: 1587.2 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 2.5 MiB
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_195 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_195 on disk on 10.0.0.43:62420 (current size: 910.4 KiB, original size: 910.4 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_199 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_199 on disk on 10.0.0.43:62420 (current size: 1179.4 KiB, original size: 1179.4 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 2 blocks, free memory is 3.2 MiB
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: 3 blocks selected for dropping (3.4 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_197 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_197 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 1086.5 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_198 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_198 on disk on 10.0.0.43:62420 (current size: 947.7 KiB, original size: 947.7 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_8 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_8 on disk on 10.0.0.43:62420 (current size: 1237.7 KiB, original size: 1237.7 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 3 blocks, free memory is 4.5 MiB
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000165_905' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000165
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000165_905: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO Executor: Finished task 165.0 in stage 59.0 (TID 905). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 175.0 in stage 59.0 (TID 915) (10.0.0.43, executor driver, partition 175, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 175.0 in stage 59.0 (TID 915)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 165.0 in stage 59.0 (TID 905) in 597 ms on 10.0.0.43 (executor driver) (166/200)
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_175 stored as values in memory (estimated size 1094.3 KiB, free 25.5 MiB)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000172_912' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000172
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_175 locally
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000172_912: Committed. Elapsed time: 1 ms.
25/02/04 17:14:08 INFO Executor: Finished task 172.0 in stage 59.0 (TID 912). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 176.0 in stage 59.0 (TID 916) (10.0.0.43, executor driver, partition 176, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 176.0 in stage 59.0 (TID 916)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 172.0 in stage 59.0 (TID 912) in 270 ms on 10.0.0.43 (executor driver) (167/200)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000168_908' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000168
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000168_908: Committed. Elapsed time: 3 ms.
25/02/04 17:14:08 INFO Executor: Finished task 168.0 in stage 59.0 (TID 908). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 177.0 in stage 59.0 (TID 917) (10.0.0.43, executor driver, partition 177, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 177.0 in stage 59.0 (TID 917)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000167_907' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000167
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000167_907: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO TaskSetManager: Finished task 168.0 in stage 59.0 (TID 908) in 282 ms on 10.0.0.43 (executor driver) (168/200)
25/02/04 17:14:08 INFO Executor: Finished task 167.0 in stage 59.0 (TID 907). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 178.0 in stage 59.0 (TID 918) (10.0.0.43, executor driver, partition 178, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 178.0 in stage 59.0 (TID 918)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 167.0 in stage 59.0 (TID 907) in 291 ms on 10.0.0.43 (executor driver) (169/200)
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_176 stored as values in memory (estimated size 1020.3 KiB, free 56.5 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_176 locally
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000173_913' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000173
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000173_913: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO Executor: Finished task 173.0 in stage 59.0 (TID 913). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 179.0 in stage 59.0 (TID 919) (10.0.0.43, executor driver, partition 179, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 179.0 in stage 59.0 (TID 919)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 173.0 in stage 59.0 (TID 913) in 292 ms on 10.0.0.43 (executor driver) (170/200)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000170_910' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000170
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000170_910: Committed. Elapsed time: 1 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000169_909' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000169
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000169_909: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000171_911' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000171
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000171_911: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO Executor: Finished task 170.0 in stage 59.0 (TID 910). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 171.0 in stage 59.0 (TID 911). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 169.0 in stage 59.0 (TID 909). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 180.0 in stage 59.0 (TID 920) (10.0.0.43, executor driver, partition 180, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 181.0 in stage 59.0 (TID 921) (10.0.0.43, executor driver, partition 181, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 182.0 in stage 59.0 (TID 922) (10.0.0.43, executor driver, partition 182, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 180.0 in stage 59.0 (TID 920)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 170.0 in stage 59.0 (TID 910) in 332 ms on 10.0.0.43 (executor driver) (171/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 171.0 in stage 59.0 (TID 911) in 332 ms on 10.0.0.43 (executor driver) (172/200)
25/02/04 17:14:08 INFO Executor: Running task 182.0 in stage 59.0 (TID 922)
25/02/04 17:14:08 INFO Executor: Running task 181.0 in stage 59.0 (TID 921)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 169.0 in stage 59.0 (TID 909) in 336 ms on 10.0.0.43 (executor driver) (173/200)
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_179 stored as values in memory (estimated size 1459.9 KiB, free 121.7 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_179 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_178 stored as values in memory (estimated size 1351.0 KiB, free 121.7 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_178 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_181 stored as values in memory (estimated size 1168.3 KiB, free 96.1 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_181 locally
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_180 stored as values in memory (estimated size 1080.7 KiB, free 95.0 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_180 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_177 stored as values in memory (estimated size 1384.6 KiB, free 66.2 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_177 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_182 stored as values in memory (estimated size 1175.7 KiB, free 38.0 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_182 locally
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000166_906' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000166
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000166_906: Committed. Elapsed time: 1 ms.
25/02/04 17:14:08 INFO Executor: Finished task 166.0 in stage 59.0 (TID 906). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 183.0 in stage 59.0 (TID 923) (10.0.0.43, executor driver, partition 183, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO TaskSetManager: Finished task 166.0 in stage 59.0 (TID 906) in 432 ms on 10.0.0.43 (executor driver) (174/200)
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO Executor: Running task 183.0 in stage 59.0 (TID 923)
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_3 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_3 on disk on 10.0.0.43:62420 (current size: 987.2 KiB, original size: 987.2 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_4 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_4 on disk on 10.0.0.43:62420 (current size: 1183.4 KiB, original size: 1183.4 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_2 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_2 on disk on 10.0.0.43:62420 (current size: 1110.3 KiB, original size: 1110.3 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_1 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_1 on disk on 10.0.0.43:62420 (current size: 1494.1 KiB, original size: 1494.1 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 4 blocks, free memory is 10.0 MiB
25/02/04 17:14:08 INFO MemoryStore: Block rdd_72_183 stored as values in memory (estimated size 1091.3 KiB, free 2.9 MiB)
25/02/04 17:14:08 INFO BlockManager: Found block rdd_72_183 locally
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:08 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_7 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_7 on disk on 10.0.0.43:62420 (current size: 895.3 KiB, original size: 895.3 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_6 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_6 on disk on 10.0.0.43:62420 (current size: 1175.2 KiB, original size: 1175.2 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 2 blocks, free memory is 3.0 MiB
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1094.6 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_5 from memory
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_5 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 1031.0 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 1663.0 KiB
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1150.5 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_9 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_9 on disk on 10.0.0.43:62420 (current size: 1084.9 KiB, original size: 1084.9 KiB)
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO MemoryStore: 1 blocks selected for dropping (1104.4 KiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_0 from memory
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_0 on disk on 10.0.0.43:62420 (current size: 1043.3 KiB, original size: 1043.3 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:14:08 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_10 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_10 on disk on 10.0.0.43:62420 (current size: 1093.3 KiB, original size: 1093.3 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_11 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_11 on disk on 10.0.0.43:62420 (current size: 1090.0 KiB, original size: 1090.0 KiB)
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_13 from memory
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_13 on disk on 10.0.0.43:62420 (current size: 1373.4 KiB, original size: 1373.4 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_12 from memory
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_12 on disk on 10.0.0.43:62420 (current size: 1138.3 KiB, original size: 1138.3 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 4 blocks, free memory is 5.2 MiB
25/02/04 17:14:08 INFO MemoryStore: 6 blocks selected for dropping (8.1 MiB bytes)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_15 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_15 on disk on 10.0.0.43:62420 (current size: 1246.0 KiB, original size: 1246.0 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_14 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_14 on disk on 10.0.0.43:62420 (current size: 1827.2 KiB, original size: 1827.2 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_17 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_17 on disk on 10.0.0.43:62420 (current size: 1455.6 KiB, original size: 1455.6 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_16 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_16 on disk on 10.0.0.43:62420 (current size: 1109.4 KiB, original size: 1109.4 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_18 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_18 on disk on 10.0.0.43:62420 (current size: 918.0 KiB, original size: 918.0 KiB)
25/02/04 17:14:08 INFO BlockManager: Dropping block rdd_72_19 from memory
25/02/04 17:14:08 INFO BlockManagerInfo: Updated rdd_72_19 on disk on 10.0.0.43:62420 (current size: 1310.5 KiB, original size: 1310.5 KiB)
25/02/04 17:14:08 INFO MemoryStore: After dropping 6 blocks, free memory is 9.3 MiB
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000180_920' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000180
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000180_920: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000176_916' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000176
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000176_916: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000181_921' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000181
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000181_921: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO Executor: Finished task 176.0 in stage 59.0 (TID 916). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 181.0 in stage 59.0 (TID 921). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 180.0 in stage 59.0 (TID 920). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 184.0 in stage 59.0 (TID 924) (10.0.0.43, executor driver, partition 184, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Starting task 185.0 in stage 59.0 (TID 925) (10.0.0.43, executor driver, partition 185, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 184.0 in stage 59.0 (TID 924)
25/02/04 17:14:08 INFO Executor: Running task 185.0 in stage 59.0 (TID 925)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 176.0 in stage 59.0 (TID 916) in 470 ms on 10.0.0.43 (executor driver) (175/200)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000175_915' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000175
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000175_915: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000177_917' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000177
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000177_917: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000178_918' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000178
25/02/04 17:14:08 INFO Executor: Finished task 175.0 in stage 59.0 (TID 915). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000178_918: Committed. Elapsed time: 1 ms.
25/02/04 17:14:08 INFO Executor: Finished task 178.0 in stage 59.0 (TID 918). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO Executor: Finished task 177.0 in stage 59.0 (TID 917). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Starting task 186.0 in stage 59.0 (TID 926) (10.0.0.43, executor driver, partition 186, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 186.0 in stage 59.0 (TID 926)
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000174_914' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000174
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000174_914: Committed. Elapsed time: 4 ms.
25/02/04 17:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000179_919' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000179
25/02/04 17:14:08 INFO TaskSetManager: Starting task 187.0 in stage 59.0 (TID 927) (10.0.0.43, executor driver, partition 187, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000179_919: Committed. Elapsed time: 0 ms.
25/02/04 17:14:08 INFO Executor: Finished task 174.0 in stage 59.0 (TID 914). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Finished task 181.0 in stage 59.0 (TID 921) in 414 ms on 10.0.0.43 (executor driver) (176/200)
25/02/04 17:14:08 INFO Executor: Running task 187.0 in stage 59.0 (TID 927)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 188.0 in stage 59.0 (TID 928) (10.0.0.43, executor driver, partition 188, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 188.0 in stage 59.0 (TID 928)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 189.0 in stage 59.0 (TID 929) (10.0.0.43, executor driver, partition 189, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Finished task 178.0 in stage 59.0 (TID 918) in 464 ms on 10.0.0.43 (executor driver) (177/200)
25/02/04 17:14:08 INFO Executor: Finished task 179.0 in stage 59.0 (TID 919). 17954 bytes result sent to driver
25/02/04 17:14:08 INFO TaskSetManager: Finished task 180.0 in stage 59.0 (TID 920) in 416 ms on 10.0.0.43 (executor driver) (178/200)
25/02/04 17:14:08 INFO Executor: Running task 189.0 in stage 59.0 (TID 929)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 175.0 in stage 59.0 (TID 915) in 515 ms on 10.0.0.43 (executor driver) (179/200)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 190.0 in stage 59.0 (TID 930) (10.0.0.43, executor driver, partition 190, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO Executor: Running task 190.0 in stage 59.0 (TID 930)
25/02/04 17:14:08 INFO TaskSetManager: Starting task 191.0 in stage 59.0 (TID 931) (10.0.0.43, executor driver, partition 191, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:08 INFO TaskSetManager: Finished task 179.0 in stage 59.0 (TID 919) in 460 ms on 10.0.0.43 (executor driver) (180/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 174.0 in stage 59.0 (TID 914) in 630 ms on 10.0.0.43 (executor driver) (181/200)
25/02/04 17:14:08 INFO TaskSetManager: Finished task 177.0 in stage 59.0 (TID 917) in 470 ms on 10.0.0.43 (executor driver) (182/200)
25/02/04 17:14:08 INFO Executor: Running task 191.0 in stage 59.0 (TID 931)
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_185 stored as values in memory (estimated size 1151.8 KiB, free 176.2 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_185 locally
25/02/04 17:14:09 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000183_923' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000183
25/02/04 17:14:09 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000182_922' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000182
25/02/04 17:14:09 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000183_923: Committed. Elapsed time: 9 ms.
25/02/04 17:14:09 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000182_922: Committed. Elapsed time: 9 ms.
25/02/04 17:14:09 INFO Executor: Finished task 182.0 in stage 59.0 (TID 922). 17997 bytes result sent to driver
25/02/04 17:14:09 INFO Executor: Finished task 183.0 in stage 59.0 (TID 923). 17997 bytes result sent to driver
25/02/04 17:14:09 INFO TaskSetManager: Starting task 192.0 in stage 59.0 (TID 932) (10.0.0.43, executor driver, partition 192, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:09 INFO Executor: Running task 192.0 in stage 59.0 (TID 932)
25/02/04 17:14:09 INFO TaskSetManager: Starting task 193.0 in stage 59.0 (TID 933) (10.0.0.43, executor driver, partition 193, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:09 INFO Executor: Running task 193.0 in stage 59.0 (TID 933)
25/02/04 17:14:09 INFO TaskSetManager: Finished task 182.0 in stage 59.0 (TID 922) in 946 ms on 10.0.0.43 (executor driver) (183/200)
25/02/04 17:14:09 INFO TaskSetManager: Finished task 183.0 in stage 59.0 (TID 923) in 909 ms on 10.0.0.43 (executor driver) (184/200)
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_189 stored as values in memory (estimated size 1483.9 KiB, free 174.7 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_189 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_188 stored as values in memory (estimated size 1209.4 KiB, free 173.6 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_188 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_191 stored as values in memory (estimated size 1429.8 KiB, free 172.2 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_191 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_186 stored as values in memory (estimated size 1115.1 KiB, free 171.1 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_186 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_184 stored as values in memory (estimated size 1023.9 KiB, free 170.1 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_184 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_190 stored as values in memory (estimated size 1326.0 KiB, free 167.0 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_190 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_187 stored as values in memory (estimated size 1826.0 KiB, free 167.0 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_187 locally
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_192 stored as values in memory (estimated size 1074.5 KiB, free 164.3 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_192 locally
25/02/04 17:14:09 INFO MemoryStore: Block rdd_72_193 stored as values in memory (estimated size 1261.6 KiB, free 164.3 MiB)
25/02/04 17:14:09 INFO BlockManager: Found block rdd_72_193 locally
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:09 INFO MemoryStore: 4 blocks selected for dropping (4.4 MiB bytes)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_29 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_29 on disk on 10.0.0.43:62420 (current size: 1303.4 KiB, original size: 1303.4 KiB)
25/02/04 17:14:09 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_25 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_25 on disk on 10.0.0.43:62420 (current size: 930.4 KiB, original size: 930.4 KiB)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_28 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_28 on disk on 10.0.0.43:62420 (current size: 1014.4 KiB, original size: 1014.4 KiB)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_24 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_24 on disk on 10.0.0.43:62420 (current size: 1032.1 KiB, original size: 1032.1 KiB)
25/02/04 17:14:09 INFO MemoryStore: After dropping 4 blocks, free memory is 8.8 MiB
25/02/04 17:14:09 INFO MemoryStore: 1 blocks selected for dropping (1254.6 KiB bytes)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_26 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_26 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 1185.0 KiB)
25/02/04 17:14:09 INFO MemoryStore: After dropping 1 blocks, free memory is 2.1 MiB
25/02/04 17:14:09 INFO MemoryStore: 2 blocks selected for dropping (2.4 MiB bytes)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_20 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_20 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 1080.3 KiB)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_22 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_22 on disk on 10.0.0.43:62420 (current size: 1206.1 KiB, original size: 1206.1 KiB)
25/02/04 17:14:09 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:09 INFO MemoryStore: 2 blocks selected for dropping (1834.9 KiB bytes)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_21 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_21 on disk on 10.0.0.43:62420 (current size: 911.0 KiB, original size: 911.0 KiB)
25/02/04 17:14:09 INFO BlockManager: Dropping block rdd_72_27 from memory
25/02/04 17:14:09 INFO BlockManagerInfo: Updated rdd_72_27 on disk on 10.0.0.43:62420 (current size: 811.7 KiB, original size: 811.7 KiB)
25/02/04 17:14:09 INFO MemoryStore: After dropping 2 blocks, free memory is 2.2 MiB
25/02/04 17:14:09 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:09 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000188_928' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000188
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000185_925' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000185
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000185_925: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000188_928: Committed. Elapsed time: 1 ms.
25/02/04 17:14:10 INFO Executor: Finished task 188.0 in stage 59.0 (TID 928). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO Executor: Finished task 185.0 in stage 59.0 (TID 925). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000193_933' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000193
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000193_933: Committed. Elapsed time: 1 ms.
25/02/04 17:14:10 INFO TaskSetManager: Starting task 194.0 in stage 59.0 (TID 934) (10.0.0.43, executor driver, partition 194, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO Executor: Finished task 193.0 in stage 59.0 (TID 933). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO Executor: Running task 194.0 in stage 59.0 (TID 934)
25/02/04 17:14:10 INFO TaskSetManager: Starting task 195.0 in stage 59.0 (TID 935) (10.0.0.43, executor driver, partition 195, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO Executor: Running task 195.0 in stage 59.0 (TID 935)
25/02/04 17:14:10 INFO TaskSetManager: Starting task 196.0 in stage 59.0 (TID 936) (10.0.0.43, executor driver, partition 196, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO TaskSetManager: Finished task 188.0 in stage 59.0 (TID 928) in 1209 ms on 10.0.0.43 (executor driver) (185/200)
25/02/04 17:14:10 INFO Executor: Running task 196.0 in stage 59.0 (TID 936)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 193.0 in stage 59.0 (TID 933) in 693 ms on 10.0.0.43 (executor driver) (186/200)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 185.0 in stage 59.0 (TID 925) in 1229 ms on 10.0.0.43 (executor driver) (187/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000192_932' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000192
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000192_932: Committed. Elapsed time: 1 ms.
25/02/04 17:14:10 INFO Executor: Finished task 192.0 in stage 59.0 (TID 932). 17997 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Starting task 197.0 in stage 59.0 (TID 937) (10.0.0.43, executor driver, partition 197, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO Executor: Running task 197.0 in stage 59.0 (TID 937)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 192.0 in stage 59.0 (TID 932) in 728 ms on 10.0.0.43 (executor driver) (188/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000191_931' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000191
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000191_931: Committed. Elapsed time: 7 ms.
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000184_924' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000184
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000186_926' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000186
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000186_926: Committed. Elapsed time: 7 ms.
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000184_924: Committed. Elapsed time: 10 ms.
25/02/04 17:14:10 INFO Executor: Finished task 184.0 in stage 59.0 (TID 924). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO Executor: Finished task 186.0 in stage 59.0 (TID 926). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO Executor: Finished task 191.0 in stage 59.0 (TID 931). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Starting task 198.0 in stage 59.0 (TID 938) (10.0.0.43, executor driver, partition 198, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO Executor: Running task 198.0 in stage 59.0 (TID 938)
25/02/04 17:14:10 INFO TaskSetManager: Starting task 199.0 in stage 59.0 (TID 939) (10.0.0.43, executor driver, partition 199, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:10 INFO Executor: Running task 199.0 in stage 59.0 (TID 939)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 186.0 in stage 59.0 (TID 926) in 1264 ms on 10.0.0.43 (executor driver) (189/200)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 184.0 in stage 59.0 (TID 924) in 1277 ms on 10.0.0.43 (executor driver) (190/200)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 191.0 in stage 59.0 (TID 931) in 1258 ms on 10.0.0.43 (executor driver) (191/200)
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_197 stored as values in memory (estimated size 1149.1 KiB, free 165.2 MiB)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000190_930' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000190
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000190_930: Committed. Elapsed time: 1 ms.
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_197 locally
25/02/04 17:14:10 INFO Executor: Finished task 190.0 in stage 59.0 (TID 930). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 190.0 in stage 59.0 (TID 930) in 1279 ms on 10.0.0.43 (executor driver) (192/200)
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_199 stored as values in memory (estimated size 1240.6 KiB, free 163.0 MiB)
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_198 stored as values in memory (estimated size 1005.0 KiB, free 163.0 MiB)
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_199 locally
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_198 locally
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_195 stored as values in memory (estimated size 968.9 KiB, free 162.0 MiB)
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_195 locally
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_194 stored as values in memory (estimated size 1006.5 KiB, free 163.3 MiB)
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_194 locally
25/02/04 17:14:10 INFO MemoryStore: Block rdd_72_196 stored as values in memory (estimated size 1663.1 KiB, free 161.7 MiB)
25/02/04 17:14:10 INFO BlockManager: Found block rdd_72_196 locally
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000189_929' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000189
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000189_929: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO Executor: Finished task 189.0 in stage 59.0 (TID 929). 18040 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 189.0 in stage 59.0 (TID 929) in 1298 ms on 10.0.0.43 (executor driver) (193/200)
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000187_927' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000187
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000187_927: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:10 INFO Executor: Finished task 187.0 in stage 59.0 (TID 927). 18040 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 187.0 in stage 59.0 (TID 927) in 1452 ms on 10.0.0.43 (executor driver) (194/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000198_938' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000198
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000198_938: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000195_935' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000195
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000195_935: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO Executor: Finished task 198.0 in stage 59.0 (TID 938). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO Executor: Finished task 195.0 in stage 59.0 (TID 935). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000197_937' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000197
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000197_937: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO TaskSetManager: Finished task 198.0 in stage 59.0 (TID 938) in 243 ms on 10.0.0.43 (executor driver) (195/200)
25/02/04 17:14:10 INFO Executor: Finished task 197.0 in stage 59.0 (TID 937). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 195.0 in stage 59.0 (TID 935) in 281 ms on 10.0.0.43 (executor driver) (196/200)
25/02/04 17:14:10 INFO TaskSetManager: Finished task 197.0 in stage 59.0 (TID 937) in 258 ms on 10.0.0.43 (executor driver) (197/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000194_934' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000194
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000194_934: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO Executor: Finished task 194.0 in stage 59.0 (TID 934). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 194.0 in stage 59.0 (TID 934) in 286 ms on 10.0.0.43 (executor driver) (198/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000199_939' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000199
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000199_939: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO Executor: Finished task 199.0 in stage 59.0 (TID 939). 17997 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 199.0 in stage 59.0 (TID 939) in 272 ms on 10.0.0.43 (executor driver) (199/200)
25/02/04 17:14:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502041713582919559572137284598_0059_m_000196_936' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/validation/_temporary/0/task_202502041713582919559572137284598_0059_m_000196
25/02/04 17:14:10 INFO SparkHadoopMapRedUtil: attempt_202502041713582919559572137284598_0059_m_000196_936: Committed. Elapsed time: 0 ms.
25/02/04 17:14:10 INFO Executor: Finished task 196.0 in stage 59.0 (TID 936). 17954 bytes result sent to driver
25/02/04 17:14:10 INFO TaskSetManager: Finished task 196.0 in stage 59.0 (TID 936) in 339 ms on 10.0.0.43 (executor driver) (200/200)
25/02/04 17:14:10 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
25/02/04 17:14:10 INFO DAGScheduler: ResultStage 59 (parquet at NativeMethodAccessorImpl.java:0) finished in 12.230 s
25/02/04 17:14:10 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:14:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
25/02/04 17:14:10 INFO DAGScheduler: Job 17 finished: parquet at NativeMethodAccessorImpl.java:0, took 12.272725 s
25/02/04 17:14:10 INFO FileFormatWriter: Start to commit write Job 0496145e-f8dd-47ca-bf7d-9c38f06a2e7e.
25/02/04 17:14:10 INFO FileFormatWriter: Write Job 0496145e-f8dd-47ca-bf7d-9c38f06a2e7e committed. Elapsed time: 198 ms.
25/02/04 17:14:10 INFO FileFormatWriter: Finished processing stats for write job 0496145e-f8dd-47ca-bf7d-9c38f06a2e7e.
25/02/04 17:14:10 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO CodeGenerator: Code generated in 92.378334 ms
25/02/04 17:14:11 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:11 INFO DAGScheduler: Got job 18 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
25/02/04 17:14:11 INFO DAGScheduler: Final stage: ResultStage 68 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 64)
25/02/04 17:14:11 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:11 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[91] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:11 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 299.8 KiB, free 167.4 MiB)
25/02/04 17:14:11 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 113.3 KiB, free 167.3 MiB)
25/02/04 17:14:11 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.0.43:62420 (size: 113.3 KiB, free: 366.2 MiB)
25/02/04 17:14:11 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:11 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 68 (MapPartitionsRDD[91] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:14:11 INFO TaskSchedulerImpl: Adding task set 68.0 with 200 tasks resource profile 0
25/02/04 17:14:11 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 940) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 941) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 942) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 943) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 944) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 945) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 946) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 947) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 8.0 in stage 68.0 (TID 948) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO TaskSetManager: Starting task 9.0 in stage 68.0 (TID 949) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:11 INFO Executor: Running task 9.0 in stage 68.0 (TID 949)
25/02/04 17:14:11 INFO Executor: Running task 8.0 in stage 68.0 (TID 948)
25/02/04 17:14:11 INFO Executor: Running task 2.0 in stage 68.0 (TID 942)
25/02/04 17:14:11 INFO Executor: Running task 0.0 in stage 68.0 (TID 940)
25/02/04 17:14:11 INFO Executor: Running task 5.0 in stage 68.0 (TID 945)
25/02/04 17:14:11 INFO Executor: Running task 3.0 in stage 68.0 (TID 943)
25/02/04 17:14:11 INFO Executor: Running task 6.0 in stage 68.0 (TID 946)
25/02/04 17:14:11 INFO Executor: Running task 4.0 in stage 68.0 (TID 944)
25/02/04 17:14:11 INFO Executor: Running task 1.0 in stage 68.0 (TID 941)
25/02/04 17:14:11 INFO Executor: Running task 7.0 in stage 68.0 (TID 947)
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_6 stored as values in memory (estimated size 1246.8 KiB, free 164.0 MiB)
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_0 stored as values in memory (estimated size 1104.4 KiB, free 166.2 MiB)
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_7 stored as values in memory (estimated size 950.4 KiB, free 164.0 MiB)
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_4 stored as values in memory (estimated size 1252.8 KiB, free 162.8 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_4 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_9 stored as values in memory (estimated size 1150.5 KiB, free 161.7 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_9 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_1 stored as values in memory (estimated size 1576.2 KiB, free 160.1 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_1 locally
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_0 locally
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_7 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_8 stored as values in memory (estimated size 1311.0 KiB, free 158.9 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_8 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_5 stored as values in memory (estimated size 1094.6 KiB, free 157.8 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_5 locally
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_6 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_3 stored as values in memory (estimated size 1048.3 KiB, free 156.8 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_3 locally
25/02/04 17:14:11 INFO MemoryStore: Block rdd_72_2 stored as values in memory (estimated size 1178.9 KiB, free 155.6 MiB)
25/02/04 17:14:11 INFO BlockManager: Found block rdd_72_2 locally
25/02/04 17:14:11 INFO CodeGenerator: Code generated in 19.297333 ms
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:11 INFO MemoryStore: 1 blocks selected for dropping (1151.9 KiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_23 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_23 on disk on 10.0.0.43:62420 (current size: 1091.7 KiB, original size: 1091.7 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:14:11 INFO MemoryStore: 1 blocks selected for dropping (1064.4 KiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_36 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_36 on disk on 10.0.0.43:62420 (current size: 1002.0 KiB, original size: 1002.0 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 1 blocks, free memory is 1246.8 KiB
25/02/04 17:14:11 INFO MemoryStore: 1 blocks selected for dropping (1282.7 KiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_39 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_39 on disk on 10.0.0.43:62420 (current size: 1210.6 KiB, original size: 1210.6 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:14:11 INFO MemoryStore: 1 blocks selected for dropping (1228.3 KiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_37 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_37 on disk on 10.0.0.43:62420 (current size: 1156.5 KiB, original size: 1156.5 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 1 blocks, free memory is 2.9 MiB
25/02/04 17:14:11 INFO MemoryStore: 1 blocks selected for dropping (1297.1 KiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_32 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_32 on disk on 10.0.0.43:62420 (current size: 1224.7 KiB, original size: 1224.7 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 1 blocks, free memory is 3.2 MiB
25/02/04 17:14:11 INFO MemoryStore: 3 blocks selected for dropping (3.2 MiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_33 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_33 on disk on 10.0.0.43:62420 (current size: 1002.7 KiB, original size: 1002.7 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_34 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_34 on disk on 10.0.0.43:62420 (current size: 1065.7 KiB, original size: 1065.7 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_38 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_38 on disk on 10.0.0.43:62420 (current size: 1049.2 KiB, original size: 1049.2 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 3 blocks, free memory is 4.4 MiB
25/02/04 17:14:11 INFO MemoryStore: 7 blocks selected for dropping (8.3 MiB bytes)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_35 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_35 on disk on 10.0.0.43:62420 (current size: 1036.4 KiB, original size: 1036.4 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_31 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_31 on disk on 10.0.0.43:62420 (current size: 1153.2 KiB, original size: 1153.2 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_30 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_30 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 1269.9 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_43 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_43 on disk on 10.0.0.43:62420 (current size: 1189.7 KiB, original size: 1189.7 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_40 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_40 on disk on 10.0.0.43:62420 (current size: 989.0 KiB, original size: 989.0 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_44 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_44 on disk on 10.0.0.43:62420 (current size: 1113.5 KiB, original size: 1113.5 KiB)
25/02/04 17:14:11 INFO BlockManager: Dropping block rdd_72_45 from memory
25/02/04 17:14:11 INFO BlockManagerInfo: Updated rdd_72_45 on disk on 10.0.0.43:62420 (current size: 1289.8 KiB, original size: 1289.8 KiB)
25/02/04 17:14:11 INFO MemoryStore: After dropping 7 blocks, free memory is 8.7 MiB
25/02/04 17:14:11 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:11 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000009_949' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000009
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000009_949: Committed. Elapsed time: 1 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000007_947' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000007
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000007_947: Committed. Elapsed time: 2 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000002_942' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000002
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000002_942: Committed. Elapsed time: 2 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000000_940' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000000
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000000_940: Committed. Elapsed time: 2 ms.
25/02/04 17:14:12 INFO Executor: Finished task 9.0 in stage 68.0 (TID 949). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 0.0 in stage 68.0 (TID 940). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 7.0 in stage 68.0 (TID 947). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 2.0 in stage 68.0 (TID 942). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 10.0 in stage 68.0 (TID 950) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 10.0 in stage 68.0 (TID 950)
25/02/04 17:14:12 INFO TaskSetManager: Starting task 11.0 in stage 68.0 (TID 951) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Starting task 12.0 in stage 68.0 (TID 952) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 11.0 in stage 68.0 (TID 951)
25/02/04 17:14:12 INFO Executor: Running task 12.0 in stage 68.0 (TID 952)
25/02/04 17:14:12 INFO TaskSetManager: Starting task 13.0 in stage 68.0 (TID 953) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 13.0 in stage 68.0 (TID 953)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 947) in 765 ms on 10.0.0.43 (executor driver) (1/200)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 9.0 in stage 68.0 (TID 949) in 766 ms on 10.0.0.43 (executor driver) (2/200)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 942) in 767 ms on 10.0.0.43 (executor driver) (3/200)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 940) in 771 ms on 10.0.0.43 (executor driver) (4/200)
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_11 stored as values in memory (estimated size 1153.5 KiB, free 81.7 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_11 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_12 stored as values in memory (estimated size 1209.2 KiB, free 81.7 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_12 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_10 stored as values in memory (estimated size 1160.4 KiB, free 80.6 MiB)
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_13 stored as values in memory (estimated size 1448.0 KiB, free 79.2 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_10 locally
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_13 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000003_943' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000003
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000003_943: Committed. Elapsed time: 1 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000005_945' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000005
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000005_945: Committed. Elapsed time: 1 ms.
25/02/04 17:14:12 INFO Executor: Finished task 3.0 in stage 68.0 (TID 943). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 5.0 in stage 68.0 (TID 945). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 14.0 in stage 68.0 (TID 954) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 14.0 in stage 68.0 (TID 954)
25/02/04 17:14:12 INFO TaskSetManager: Starting task 15.0 in stage 68.0 (TID 955) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 15.0 in stage 68.0 (TID 955)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 943) in 812 ms on 10.0.0.43 (executor driver) (5/200)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 945) in 812 ms on 10.0.0.43 (executor driver) (6/200)
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000008_948' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000008
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000008_948: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 8.0 in stage 68.0 (TID 948). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 16.0 in stage 68.0 (TID 956) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 16.0 in stage 68.0 (TID 956)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 8.0 in stage 68.0 (TID 948) in 814 ms on 10.0.0.43 (executor driver) (7/200)
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000006_946' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000006
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000006_946: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 6.0 in stage 68.0 (TID 946). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 17.0 in stage 68.0 (TID 957) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 17.0 in stage 68.0 (TID 957)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 946) in 828 ms on 10.0.0.43 (executor driver) (8/200)
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_16 stored as values in memory (estimated size 1175.6 KiB, free 145.8 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_16 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_15 stored as values in memory (estimated size 1319.8 KiB, free 144.5 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_15 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_14 stored as values in memory (estimated size 1929.1 KiB, free 142.6 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_14 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_17 stored as values in memory (estimated size 1538.4 KiB, free 53.4 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_17 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:12 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000004_944' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000004
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000004_944: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 4.0 in stage 68.0 (TID 944). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 18.0 in stage 68.0 (TID 958) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 944) in 939 ms on 10.0.0.43 (executor driver) (9/200)
25/02/04 17:14:12 INFO Executor: Running task 18.0 in stage 68.0 (TID 958)
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_18 stored as values in memory (estimated size 974.0 KiB, free 15.8 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_18 locally
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000001_941' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000001
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000001_941: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 1.0 in stage 68.0 (TID 941). 18040 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 19.0 in stage 68.0 (TID 959) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 19.0 in stage 68.0 (TID 959)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 941) in 1004 ms on 10.0.0.43 (executor driver) (10/200)
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_19 stored as values in memory (estimated size 1392.1 KiB, free 17.7 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_19 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000016_956' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000016
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000016_956: Committed. Elapsed time: 2 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000015_955' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000015
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000015_955: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000010_950' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000010
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000010_950: Committed. Elapsed time: 3 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000012_952' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000012
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000012_952: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 16.0 in stage 68.0 (TID 956). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 12.0 in stage 68.0 (TID 952). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 10.0 in stage 68.0 (TID 950). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 15.0 in stage 68.0 (TID 955). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000011_951' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000011
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000011_951: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Finished task 11.0 in stage 68.0 (TID 951). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 20.0 in stage 68.0 (TID 960) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 20.0 in stage 68.0 (TID 960)
25/02/04 17:14:12 INFO TaskSetManager: Starting task 21.0 in stage 68.0 (TID 961) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Finished task 16.0 in stage 68.0 (TID 956) in 319 ms on 10.0.0.43 (executor driver) (11/200)
25/02/04 17:14:12 INFO Executor: Running task 21.0 in stage 68.0 (TID 961)
25/02/04 17:14:12 INFO TaskSetManager: Starting task 22.0 in stage 68.0 (TID 962) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Starting task 23.0 in stage 68.0 (TID 963) (10.0.0.43, executor driver, partition 23, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Starting task 24.0 in stage 68.0 (TID 964) (10.0.0.43, executor driver, partition 24, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Finished task 15.0 in stage 68.0 (TID 955) in 325 ms on 10.0.0.43 (executor driver) (12/200)
25/02/04 17:14:12 INFO Executor: Running task 24.0 in stage 68.0 (TID 964)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 11.0 in stage 68.0 (TID 951) in 378 ms on 10.0.0.43 (executor driver) (13/200)
25/02/04 17:14:12 INFO Executor: Running task 23.0 in stage 68.0 (TID 963)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 10.0 in stage 68.0 (TID 950) in 380 ms on 10.0.0.43 (executor driver) (14/200)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 12.0 in stage 68.0 (TID 952) in 378 ms on 10.0.0.43 (executor driver) (15/200)
25/02/04 17:14:12 INFO Executor: Running task 22.0 in stage 68.0 (TID 962)
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_21 stored as values in memory (estimated size 968.7 KiB, free 95.0 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_21 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_24 stored as values in memory (estimated size 1092.3 KiB, free 94.0 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_24 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_23 stored as values in memory (estimated size 1151.9 KiB, free 92.8 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_23 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_20 stored as values in memory (estimated size 1143.9 KiB, free 91.7 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_20 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_22 stored as values in memory (estimated size 1279.5 KiB, free 85.9 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_22 locally
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000017_957' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000017
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000017_957: Committed. Elapsed time: 35 ms.
25/02/04 17:14:12 INFO Executor: Finished task 17.0 in stage 68.0 (TID 957). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 25.0 in stage 68.0 (TID 965) (10.0.0.43, executor driver, partition 25, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Finished task 17.0 in stage 68.0 (TID 957) in 421 ms on 10.0.0.43 (executor driver) (16/200)
25/02/04 17:14:12 INFO Executor: Running task 25.0 in stage 68.0 (TID 965)
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000013_953' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000013
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000013_953: Committed. Elapsed time: 2 ms.
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO Executor: Finished task 13.0 in stage 68.0 (TID 953). 18040 bytes result sent to driver
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO TaskSetManager: Starting task 26.0 in stage 68.0 (TID 966) (10.0.0.43, executor driver, partition 26, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO TaskSetManager: Finished task 13.0 in stage 68.0 (TID 953) in 495 ms on 10.0.0.43 (executor driver) (17/200)
25/02/04 17:14:12 INFO Executor: Running task 26.0 in stage 68.0 (TID 966)
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_26 stored as values in memory (estimated size 1254.6 KiB, free 29.3 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_26 locally
25/02/04 17:14:12 INFO MemoryStore: Block rdd_72_25 stored as values in memory (estimated size 985.1 KiB, free 28.4 MiB)
25/02/04 17:14:12 INFO BlockManager: Found block rdd_72_25 locally
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:12 INFO MemoryStore: 5 blocks selected for dropping (6.6 MiB bytes)
25/02/04 17:14:12 INFO BlockManager: Dropping block rdd_72_41 from memory
25/02/04 17:14:12 INFO BlockManagerInfo: Updated rdd_72_41 on disk on 10.0.0.43:62420 (current size: 1165.3 KiB, original size: 1165.3 KiB)
25/02/04 17:14:12 INFO BlockManager: Dropping block rdd_72_42 from memory
25/02/04 17:14:12 INFO BlockManagerInfo: Updated rdd_72_42 on disk on 10.0.0.43:62420 (current size: 1453.8 KiB, original size: 1453.8 KiB)
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO BlockManager: Dropping block rdd_72_47 from memory
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO BlockManagerInfo: Updated rdd_72_47 on disk on 10.0.0.43:62420 (current size: 1107.8 KiB, original size: 1107.8 KiB)
25/02/04 17:14:12 INFO BlockManager: Dropping block rdd_72_46 from memory
25/02/04 17:14:12 INFO BlockManagerInfo: Updated rdd_72_46 on disk on 10.0.0.43:62420 (current size: 1433.6 KiB, original size: 1433.6 KiB)
25/02/04 17:14:12 INFO BlockManager: Dropping block rdd_72_48 from memory
25/02/04 17:14:12 INFO BlockManagerInfo: Updated rdd_72_48 on disk on 10.0.0.43:62420 (current size: 1205.2 KiB, original size: 1205.2 KiB)
25/02/04 17:14:12 INFO MemoryStore: After dropping 5 blocks, free memory is 8.9 MiB
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000018_958' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000018
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000018_958: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000019_959' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000019
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000019_959: Committed. Elapsed time: 1 ms.
25/02/04 17:14:12 INFO Executor: Finished task 18.0 in stage 68.0 (TID 958). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO Executor: Finished task 19.0 in stage 68.0 (TID 959). 17997 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 27.0 in stage 68.0 (TID 967) (10.0.0.43, executor driver, partition 27, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO TaskSetManager: Starting task 28.0 in stage 68.0 (TID 968) (10.0.0.43, executor driver, partition 28, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 27.0 in stage 68.0 (TID 967)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 18.0 in stage 68.0 (TID 958) in 406 ms on 10.0.0.43 (executor driver) (18/200)
25/02/04 17:14:12 INFO Executor: Running task 28.0 in stage 68.0 (TID 968)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 19.0 in stage 68.0 (TID 959) in 338 ms on 10.0.0.43 (executor driver) (19/200)
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000014_954' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000014
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000014_954: Committed. Elapsed time: 1 ms.
25/02/04 17:14:12 INFO Executor: Finished task 14.0 in stage 68.0 (TID 954). 18040 bytes result sent to driver
25/02/04 17:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000020_960' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000020
25/02/04 17:14:12 INFO TaskSetManager: Starting task 29.0 in stage 68.0 (TID 969) (10.0.0.43, executor driver, partition 29, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000020_960: Committed. Elapsed time: 0 ms.
25/02/04 17:14:12 INFO Executor: Running task 29.0 in stage 68.0 (TID 969)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 14.0 in stage 68.0 (TID 954) in 539 ms on 10.0.0.43 (executor driver) (20/200)
25/02/04 17:14:12 INFO Executor: Finished task 20.0 in stage 68.0 (TID 960). 17954 bytes result sent to driver
25/02/04 17:14:12 INFO TaskSetManager: Starting task 30.0 in stage 68.0 (TID 970) (10.0.0.43, executor driver, partition 30, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:12 INFO Executor: Running task 30.0 in stage 68.0 (TID 970)
25/02/04 17:14:12 INFO TaskSetManager: Finished task 20.0 in stage 68.0 (TID 960) in 218 ms on 10.0.0.43 (executor driver) (21/200)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000021_961' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000021
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000023_963' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000023
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000024_964' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000024
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000023_963: Committed. Elapsed time: 5 ms.
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000021_961: Committed. Elapsed time: 6 ms.
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000024_964: Committed. Elapsed time: 2 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000022_962' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000022
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000022_962: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_30 stored as values in memory (estimated size 1339.9 KiB, free 120.4 MiB)
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_29 stored as values in memory (estimated size 1378.9 KiB, free 120.4 MiB)
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_28 stored as values in memory (estimated size 1076.3 KiB, free 120.4 MiB)
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_27 stored as values in memory (estimated size 866.2 KiB, free 120.4 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_28 locally
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_30 locally
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_29 locally
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_27 locally
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.0.43:62420 on disk (size: 113.3 KiB)
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO Executor: Finished task 21.0 in stage 68.0 (TID 961). 17997 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 22.0 in stage 68.0 (TID 962). 17997 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 23.0 in stage 68.0 (TID 963). 17997 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 24.0 in stage 68.0 (TID 964). 17997 bytes result sent to driver
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO TaskSetManager: Starting task 31.0 in stage 68.0 (TID 971) (10.0.0.43, executor driver, partition 31, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO Executor: Running task 31.0 in stage 68.0 (TID 971)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO TaskSetManager: Finished task 22.0 in stage 68.0 (TID 962) in 1009 ms on 10.0.0.43 (executor driver) (22/200)
25/02/04 17:14:13 INFO TaskSetManager: Starting task 32.0 in stage 68.0 (TID 972) (10.0.0.43, executor driver, partition 32, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 32.0 in stage 68.0 (TID 972)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO TaskSetManager: Finished task 21.0 in stage 68.0 (TID 961) in 1016 ms on 10.0.0.43 (executor driver) (23/200)
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO TaskSetManager: Starting task 33.0 in stage 68.0 (TID 973) (10.0.0.43, executor driver, partition 33, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 33.0 in stage 68.0 (TID 973)
25/02/04 17:14:13 INFO TaskSetManager: Starting task 34.0 in stage 68.0 (TID 974) (10.0.0.43, executor driver, partition 34, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 34.0 in stage 68.0 (TID 974)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 23.0 in stage 68.0 (TID 963) in 1017 ms on 10.0.0.43 (executor driver) (24/200)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 24.0 in stage 68.0 (TID 964) in 1017 ms on 10.0.0.43 (executor driver) (25/200)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_33 stored as values in memory (estimated size 1063.3 KiB, free 125.3 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_33 locally
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_31 stored as values in memory (estimated size 1222.2 KiB, free 124.2 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_31 locally
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_32 stored as values in memory (estimated size 1297.1 KiB, free 122.9 MiB)
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_34 stored as values in memory (estimated size 1134.6 KiB, free 121.8 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_32 locally
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_34 locally
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000025_965' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000025
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000025_965: Committed. Elapsed time: 10 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000029_969' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000029
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000029_969: Committed. Elapsed time: 5 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000028_968' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000028
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000028_968: Committed. Elapsed time: 1 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000026_966' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000026
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000026_966: Committed. Elapsed time: 14 ms.
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO Executor: Finished task 26.0 in stage 68.0 (TID 966). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 25.0 in stage 68.0 (TID 965). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 28.0 in stage 68.0 (TID 968). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 29.0 in stage 68.0 (TID 969). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO TaskSetManager: Starting task 35.0 in stage 68.0 (TID 975) (10.0.0.43, executor driver, partition 35, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 35.0 in stage 68.0 (TID 975)
25/02/04 17:14:13 INFO TaskSetManager: Starting task 36.0 in stage 68.0 (TID 976) (10.0.0.43, executor driver, partition 36, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 36.0 in stage 68.0 (TID 976)
25/02/04 17:14:13 INFO TaskSetManager: Starting task 37.0 in stage 68.0 (TID 977) (10.0.0.43, executor driver, partition 37, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO TaskSetManager: Starting task 38.0 in stage 68.0 (TID 978) (10.0.0.43, executor driver, partition 38, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 37.0 in stage 68.0 (TID 977)
25/02/04 17:14:13 INFO Executor: Running task 38.0 in stage 68.0 (TID 978)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 28.0 in stage 68.0 (TID 968) in 920 ms on 10.0.0.43 (executor driver) (26/200)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 26.0 in stage 68.0 (TID 966) in 1003 ms on 10.0.0.43 (executor driver) (27/200)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 29.0 in stage 68.0 (TID 969) in 909 ms on 10.0.0.43 (executor driver) (28/200)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 25.0 in stage 68.0 (TID 965) in 1015 ms on 10.0.0.43 (executor driver) (29/200)
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_36 stored as values in memory (estimated size 1064.4 KiB, free 70.7 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_36 locally
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_38 stored as values in memory (estimated size 1115.5 KiB, free 69.7 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_38 locally
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_37 stored as values in memory (estimated size 1228.3 KiB, free 68.5 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_37 locally
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_35 stored as values in memory (estimated size 1098.4 KiB, free 67.4 MiB)
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_35 locally
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO MemoryStore: 1 blocks selected for dropping (1056.0 KiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_49 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_49 on disk on 10.0.0.43:62420 (current size: 990.4 KiB, original size: 990.4 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 1 blocks, free memory is 8.4 MiB
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000030_970' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000030
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000030_970: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO Executor: Finished task 30.0 in stage 68.0 (TID 970). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO TaskSetManager: Starting task 39.0 in stage 68.0 (TID 979) (10.0.0.43, executor driver, partition 39, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 39.0 in stage 68.0 (TID 979)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 30.0 in stage 68.0 (TID 970) in 1118 ms on 10.0.0.43 (executor driver) (30/200)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO MemoryStore: Block rdd_72_39 stored as values in memory (estimated size 1282.7 KiB, free 11.2 MiB)
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_39 locally
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000027_967' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000027
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000027_967: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO Executor: Finished task 27.0 in stage 68.0 (TID 967). 17997 bytes result sent to driver
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO TaskSetManager: Starting task 40.0 in stage 68.0 (TID 980) (10.0.0.43, executor driver, partition 40, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO Executor: Running task 40.0 in stage 68.0 (TID 980)
25/02/04 17:14:13 INFO TaskSetManager: Finished task 27.0 in stage 68.0 (TID 967) in 1234 ms on 10.0.0.43 (executor driver) (31/200)
25/02/04 17:14:13 INFO MemoryStore: 6 blocks selected for dropping (7.1 MiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_50 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_50 on disk on 10.0.0.43:62420 (current size: 1473.5 KiB, original size: 1473.5 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_52 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_52 on disk on 10.0.0.43:62420 (current size: 1301.8 KiB, original size: 1301.8 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_53 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_53 on disk on 10.0.0.43:62420 (current size: 997.8 KiB, original size: 997.8 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_55 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_55 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 1031.0 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_51 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_51 on disk on 10.0.0.43:62420 (current size: 958.4 KiB, original size: 958.4 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_54 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_54 on disk on 10.0.0.43:62420 (current size: 1092.8 KiB, original size: 1092.8 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 6 blocks, free memory is 8.2 MiB
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO MemoryStore: Will not store rdd_72_40
25/02/04 17:14:13 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_72_40 in memory.
25/02/04 17:14:13 WARN MemoryStore: Not enough space to cache rdd_72_40 in memory! (computed 384.0 B so far)
25/02/04 17:14:13 INFO MemoryStore: Memory use = 214.1 MiB (blocks) + 0.0 B (scratch space shared across 0 tasks(s)) = 214.1 MiB. Storage limit = 214.3 MiB.
25/02/04 17:14:13 INFO BlockManager: Found block rdd_72_40 locally
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:13 INFO MemoryStore: 2 blocks selected for dropping (2.4 MiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_56 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_56 on disk on 10.0.0.43:62420 (current size: 1068.0 KiB, original size: 1068.0 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_57 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_57 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 1269.9 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 2 blocks, free memory is 2.6 MiB
25/02/04 17:14:13 INFO MemoryStore: 1 blocks selected for dropping (960.6 KiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_58 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_58 on disk on 10.0.0.43:62420 (current size: 901.1 KiB, original size: 901.1 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 1 blocks, free memory is 1378.6 KiB
25/02/04 17:14:13 INFO MemoryStore: 2 blocks selected for dropping (2.6 MiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_59 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_59 on disk on 10.0.0.43:62420 (current size: 1326.4 KiB, original size: 1326.4 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_61 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_61 on disk on 10.0.0.43:62420 (current size: 1180.0 KiB, original size: 1180.0 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 2 blocks, free memory is 3.2 MiB
25/02/04 17:14:13 INFO MemoryStore: 4 blocks selected for dropping (4.7 MiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_60 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_60 on disk on 10.0.0.43:62420 (current size: 1347.2 KiB, original size: 1347.2 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_67 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_67 on disk on 10.0.0.43:62420 (current size: 1079.9 KiB, original size: 1079.9 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_68 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_68 on disk on 10.0.0.43:62420 (current size: 1060.9 KiB, original size: 1060.9 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_62 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_62 on disk on 10.0.0.43:62420 (current size: 1038.0 KiB, original size: 1038.0 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 4 blocks, free memory is 4.9 MiB
25/02/04 17:14:13 INFO MemoryStore: 7 blocks selected for dropping (8.2 MiB bytes)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_66 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_66 on disk on 10.0.0.43:62420 (current size: 1008.2 KiB, original size: 1008.2 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_64 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_64 on disk on 10.0.0.43:62420 (current size: 1181.5 KiB, original size: 1181.5 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_63 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_63 on disk on 10.0.0.43:62420 (current size: 1201.6 KiB, original size: 1201.6 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_65 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_65 on disk on 10.0.0.43:62420 (current size: 1371.8 KiB, original size: 1371.8 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_69 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_69 on disk on 10.0.0.43:62420 (current size: 923.7 KiB, original size: 923.7 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_71 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_71 on disk on 10.0.0.43:62420 (current size: 1086.2 KiB, original size: 1086.2 KiB)
25/02/04 17:14:13 INFO BlockManager: Dropping block rdd_72_73 from memory
25/02/04 17:14:13 INFO BlockManagerInfo: Updated rdd_72_73 on disk on 10.0.0.43:62420 (current size: 1176.8 KiB, original size: 1176.8 KiB)
25/02/04 17:14:13 INFO MemoryStore: After dropping 7 blocks, free memory is 9.1 MiB
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000033_973' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000033
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000033_973: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000034_974' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000034
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000034_974: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000031_971' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000031
25/02/04 17:14:13 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000031_971: Committed. Elapsed time: 0 ms.
25/02/04 17:14:13 INFO Executor: Finished task 34.0 in stage 68.0 (TID 974). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 33.0 in stage 68.0 (TID 973). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO Executor: Finished task 31.0 in stage 68.0 (TID 971). 17954 bytes result sent to driver
25/02/04 17:14:13 INFO TaskSetManager: Starting task 41.0 in stage 68.0 (TID 981) (10.0.0.43, executor driver, partition 41, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO TaskSetManager: Starting task 42.0 in stage 68.0 (TID 982) (10.0.0.43, executor driver, partition 42, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO TaskSetManager: Starting task 43.0 in stage 68.0 (TID 983) (10.0.0.43, executor driver, partition 43, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:13 INFO Executor: Running task 41.0 in stage 68.0 (TID 981)
25/02/04 17:14:13 INFO Executor: Running task 42.0 in stage 68.0 (TID 982)
25/02/04 17:14:13 INFO Executor: Running task 43.0 in stage 68.0 (TID 983)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 31.0 in stage 68.0 (TID 971) in 544 ms on 10.0.0.43 (executor driver) (32/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 34.0 in stage 68.0 (TID 974) in 506 ms on 10.0.0.43 (executor driver) (33/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 33.0 in stage 68.0 (TID 973) in 506 ms on 10.0.0.43 (executor driver) (34/200)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000032_972' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000032
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000032_972: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO Executor: Finished task 32.0 in stage 68.0 (TID 972). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO TaskSetManager: Starting task 44.0 in stage 68.0 (TID 984) (10.0.0.43, executor driver, partition 44, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 44.0 in stage 68.0 (TID 984)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 32.0 in stage 68.0 (TID 972) in 568 ms on 10.0.0.43 (executor driver) (35/200)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000037_977' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000037
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000037_977: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000036_976' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000036
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000036_976: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000038_978' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000038
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000038_978: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000035_975' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000035
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000035_975: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_43 stored as values in memory (estimated size 1258.3 KiB, free 133.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_43 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_41 stored as values in memory (estimated size 1231.3 KiB, free 133.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_41 locally
25/02/04 17:14:14 INFO Executor: Finished task 36.0 in stage 68.0 (TID 976). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_42 stored as values in memory (estimated size 1541.0 KiB, free 133.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_42 locally
25/02/04 17:14:14 INFO Executor: Finished task 38.0 in stage 68.0 (TID 978). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 45.0 in stage 68.0 (TID 985) (10.0.0.43, executor driver, partition 45, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO TaskSetManager: Starting task 46.0 in stage 68.0 (TID 986) (10.0.0.43, executor driver, partition 46, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 45.0 in stage 68.0 (TID 985)
25/02/04 17:14:14 INFO Executor: Running task 46.0 in stage 68.0 (TID 986)
25/02/04 17:14:14 INFO Executor: Finished task 37.0 in stage 68.0 (TID 977). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Finished task 38.0 in stage 68.0 (TID 978) in 466 ms on 10.0.0.43 (executor driver) (36/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 36.0 in stage 68.0 (TID 976) in 466 ms on 10.0.0.43 (executor driver) (37/200)
25/02/04 17:14:14 INFO Executor: Finished task 35.0 in stage 68.0 (TID 975). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 47.0 in stage 68.0 (TID 987) (10.0.0.43, executor driver, partition 47, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 47.0 in stage 68.0 (TID 987)
25/02/04 17:14:14 INFO TaskSetManager: Starting task 48.0 in stage 68.0 (TID 988) (10.0.0.43, executor driver, partition 48, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 48.0 in stage 68.0 (TID 988)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 37.0 in stage 68.0 (TID 977) in 468 ms on 10.0.0.43 (executor driver) (38/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 35.0 in stage 68.0 (TID 975) in 469 ms on 10.0.0.43 (executor driver) (39/200)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_44 stored as values in memory (estimated size 1177.9 KiB, free 112.0 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_44 locally
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_45 stored as values in memory (estimated size 1353.6 KiB, free 95.5 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_45 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_47 stored as values in memory (estimated size 1176.4 KiB, free 95.5 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_47 locally
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_46 stored as values in memory (estimated size 1512.7 KiB, free 91.9 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_46 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_48 stored as values in memory (estimated size 1275.9 KiB, free 80.5 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_48 locally
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:14 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_72 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_72 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 1185.0 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_70 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_70 on disk on 10.0.0.43:62420 (current size: 993.3 KiB, original size: 993.3 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 2 blocks, free memory is 2.7 MiB
25/02/04 17:14:14 INFO MemoryStore: 7 blocks selected for dropping (7.6 MiB bytes)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_76 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_76 on disk on 10.0.0.43:62420 (current size: 1081.3 KiB, original size: 1081.3 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_75 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_75 on disk on 10.0.0.43:62420 (current size: 1009.8 KiB, original size: 1009.8 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_77 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_77 on disk on 10.0.0.43:62420 (current size: 880.8 KiB, original size: 880.8 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_74 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_74 on disk on 10.0.0.43:62420 (current size: 1257.7 KiB, original size: 1257.7 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_79 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_79 on disk on 10.0.0.43:62420 (current size: 984.7 KiB, original size: 984.7 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_78 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_78 on disk on 10.0.0.43:62420 (current size: 1044.3 KiB, original size: 1044.3 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_84 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_84 on disk on 10.0.0.43:62420 (current size: 1065.4 KiB, original size: 1065.4 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 7 blocks, free memory is 8.3 MiB
25/02/04 17:14:14 INFO MemoryStore: 2 blocks selected for dropping (2.0 MiB bytes)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_85 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_85 on disk on 10.0.0.43:62420 (current size: 972.6 KiB, original size: 972.6 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_87 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_87 on disk on 10.0.0.43:62420 (current size: 986.6 KiB, original size: 986.6 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:14 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:14 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_82 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_82 on disk on 10.0.0.43:62420 (current size: 1208.8 KiB, original size: 1208.8 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_88 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_88 on disk on 10.0.0.43:62420 (current size: 1270.3 KiB, original size: 1270.3 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_86 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_86 on disk on 10.0.0.43:62420 (current size: 1061.2 KiB, original size: 1061.2 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_81 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_81 on disk on 10.0.0.43:62420 (current size: 1237.5 KiB, original size: 1237.5 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 4 blocks, free memory is 9.0 MiB
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000040_980' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000040
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000040_980: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000039_979' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000039
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000039_979: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 40.0 in stage 68.0 (TID 980). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 39.0 in stage 68.0 (TID 979). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 49.0 in stage 68.0 (TID 989) (10.0.0.43, executor driver, partition 49, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO TaskSetManager: Finished task 40.0 in stage 68.0 (TID 980) in 333 ms on 10.0.0.43 (executor driver) (40/200)
25/02/04 17:14:14 INFO Executor: Running task 49.0 in stage 68.0 (TID 989)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO TaskSetManager: Starting task 50.0 in stage 68.0 (TID 990) (10.0.0.43, executor driver, partition 50, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO Executor: Running task 50.0 in stage 68.0 (TID 990)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 39.0 in stage 68.0 (TID 979) in 436 ms on 10.0.0.43 (executor driver) (41/200)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_49 stored as values in memory (estimated size 1056.0 KiB, free 30.4 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_49 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_50 stored as values in memory (estimated size 1555.2 KiB, free 30.4 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_50 locally
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO MemoryStore: 4 blocks selected for dropping (4.6 MiB bytes)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_89 from memory
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_89 on disk on 10.0.0.43:62420 (current size: 1370.1 KiB, original size: 1370.1 KiB)
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_83 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_83 on disk on 10.0.0.43:62420 (current size: 957.7 KiB, original size: 957.7 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_80 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_80 on disk on 10.0.0.43:62420 (current size: 1030.9 KiB, original size: 1030.9 KiB)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_91 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_91 on disk on 10.0.0.43:62420 (current size: 1143.1 KiB, original size: 1143.1 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 4 blocks, free memory is 9.1 MiB
25/02/04 17:14:14 INFO MemoryStore: 1 blocks selected for dropping (1025.4 KiB bytes)
25/02/04 17:14:14 INFO BlockManager: Dropping block rdd_72_90 from memory
25/02/04 17:14:14 INFO BlockManagerInfo: Updated rdd_72_90 on disk on 10.0.0.43:62420 (current size: 966.9 KiB, original size: 966.9 KiB)
25/02/04 17:14:14 INFO MemoryStore: After dropping 1 blocks, free memory is 2.1 MiB
25/02/04 17:14:14 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000048_988' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000048
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000048_988: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000043_983' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000043
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000043_983: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000041_981' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000041
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000041_981: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000047_987' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000047
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000047_987: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 41.0 in stage 68.0 (TID 981). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 48.0 in stage 68.0 (TID 988). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 47.0 in stage 68.0 (TID 987). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 43.0 in stage 68.0 (TID 983). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 51.0 in stage 68.0 (TID 991) (10.0.0.43, executor driver, partition 51, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 51.0 in stage 68.0 (TID 991)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 41.0 in stage 68.0 (TID 981) in 420 ms on 10.0.0.43 (executor driver) (42/200)
25/02/04 17:14:14 INFO TaskSetManager: Starting task 52.0 in stage 68.0 (TID 992) (10.0.0.43, executor driver, partition 52, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO TaskSetManager: Starting task 53.0 in stage 68.0 (TID 993) (10.0.0.43, executor driver, partition 53, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO TaskSetManager: Starting task 54.0 in stage 68.0 (TID 994) (10.0.0.43, executor driver, partition 54, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 53.0 in stage 68.0 (TID 993)
25/02/04 17:14:14 INFO Executor: Running task 54.0 in stage 68.0 (TID 994)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 48.0 in stage 68.0 (TID 988) in 353 ms on 10.0.0.43 (executor driver) (43/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 47.0 in stage 68.0 (TID 987) in 354 ms on 10.0.0.43 (executor driver) (44/200)
25/02/04 17:14:14 INFO Executor: Running task 52.0 in stage 68.0 (TID 992)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 43.0 in stage 68.0 (TID 983) in 424 ms on 10.0.0.43 (executor driver) (45/200)
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_51 stored as values in memory (estimated size 1019.7 KiB, free 122.4 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_51 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_54 stored as values in memory (estimated size 1153.3 KiB, free 121.3 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_54 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_53 stored as values in memory (estimated size 1058.2 KiB, free 120.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_53 locally
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000045_985' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000045
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000045_985: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000044_984' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000044
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000044_984: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_52 stored as values in memory (estimated size 1374.8 KiB, free 136.9 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_52 locally
25/02/04 17:14:14 INFO Executor: Finished task 45.0 in stage 68.0 (TID 985). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 44.0 in stage 68.0 (TID 984). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 55.0 in stage 68.0 (TID 995) (10.0.0.43, executor driver, partition 55, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 55.0 in stage 68.0 (TID 995)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 44.0 in stage 68.0 (TID 984) in 397 ms on 10.0.0.43 (executor driver) (46/200)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO TaskSetManager: Starting task 56.0 in stage 68.0 (TID 996) (10.0.0.43, executor driver, partition 56, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO TaskSetManager: Finished task 45.0 in stage 68.0 (TID 985) in 386 ms on 10.0.0.43 (executor driver) (47/200)
25/02/04 17:14:14 INFO Executor: Running task 56.0 in stage 68.0 (TID 996)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_56 stored as values in memory (estimated size 1129.4 KiB, free 103.6 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_56 locally
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000049_989' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000049
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000049_989: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_55 stored as values in memory (estimated size 1096.5 KiB, free 100.5 MiB)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO Executor: Finished task 49.0 in stage 68.0 (TID 989). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_55 locally
25/02/04 17:14:14 INFO TaskSetManager: Starting task 57.0 in stage 68.0 (TID 997) (10.0.0.43, executor driver, partition 57, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO Executor: Running task 57.0 in stage 68.0 (TID 997)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000042_982' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000042
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000042_982: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 42.0 in stage 68.0 (TID 982). 18040 bytes result sent to driver
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000046_986' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000046
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000046_986: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 46.0 in stage 68.0 (TID 986). 18040 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 58.0 in stage 68.0 (TID 998) (10.0.0.43, executor driver, partition 58, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 58.0 in stage 68.0 (TID 998)
25/02/04 17:14:14 INFO TaskSetManager: Starting task 59.0 in stage 68.0 (TID 999) (10.0.0.43, executor driver, partition 59, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO TaskSetManager: Finished task 42.0 in stage 68.0 (TID 982) in 626 ms on 10.0.0.43 (executor driver) (48/200)
25/02/04 17:14:14 INFO Executor: Running task 59.0 in stage 68.0 (TID 999)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 49.0 in stage 68.0 (TID 989) in 384 ms on 10.0.0.43 (executor driver) (49/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 46.0 in stage 68.0 (TID 986) in 559 ms on 10.0.0.43 (executor driver) (50/200)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_57 stored as values in memory (estimated size 1342.1 KiB, free 72.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_57 locally
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_58 stored as values in memory (estimated size 960.6 KiB, free 71.2 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_58 locally
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_59 stored as values in memory (estimated size 1403.8 KiB, free 41.9 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_59 locally
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000051_991' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000051
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000051_991: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO Executor: Finished task 51.0 in stage 68.0 (TID 991). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO TaskSetManager: Starting task 60.0 in stage 68.0 (TID 1000) (10.0.0.43, executor driver, partition 60, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 60.0 in stage 68.0 (TID 1000)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000054_994' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000054
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000054_994: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000050_990' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000050
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000050_990: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO TaskSetManager: Finished task 51.0 in stage 68.0 (TID 991) in 343 ms on 10.0.0.43 (executor driver) (51/200)
25/02/04 17:14:14 INFO Executor: Finished task 50.0 in stage 68.0 (TID 990). 18040 bytes result sent to driver
25/02/04 17:14:14 INFO Executor: Finished task 54.0 in stage 68.0 (TID 994). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 61.0 in stage 68.0 (TID 1001) (10.0.0.43, executor driver, partition 61, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 61.0 in stage 68.0 (TID 1001)
25/02/04 17:14:14 INFO TaskSetManager: Starting task 62.0 in stage 68.0 (TID 1002) (10.0.0.43, executor driver, partition 62, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 62.0 in stage 68.0 (TID 1002)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 50.0 in stage 68.0 (TID 990) in 513 ms on 10.0.0.43 (executor driver) (52/200)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 54.0 in stage 68.0 (TID 994) in 341 ms on 10.0.0.43 (executor driver) (53/200)
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000053_993' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000053
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000053_993: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 53.0 in stage 68.0 (TID 993). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 63.0 in stage 68.0 (TID 1003) (10.0.0.43, executor driver, partition 63, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000056_996' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000056
25/02/04 17:14:14 INFO Executor: Running task 63.0 in stage 68.0 (TID 1003)
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000056_996: Committed. Elapsed time: 8 ms.
25/02/04 17:14:14 INFO TaskSetManager: Finished task 53.0 in stage 68.0 (TID 993) in 406 ms on 10.0.0.43 (executor driver) (54/200)
25/02/04 17:14:14 INFO Executor: Finished task 56.0 in stage 68.0 (TID 996). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_62 stored as values in memory (estimated size 1097.7 KiB, free 83.3 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_62 locally
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_61 stored as values in memory (estimated size 1250.6 KiB, free 82.1 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_61 locally
25/02/04 17:14:14 INFO TaskSetManager: Starting task 64.0 in stage 68.0 (TID 1004) (10.0.0.43, executor driver, partition 64, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 64.0 in stage 68.0 (TID 1004)
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_60 stored as values in memory (estimated size 1426.3 KiB, free 80.7 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_60 locally
25/02/04 17:14:14 INFO TaskSetManager: Finished task 56.0 in stage 68.0 (TID 996) in 381 ms on 10.0.0.43 (executor driver) (55/200)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000052_992' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000052
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000052_992: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO Executor: Finished task 52.0 in stage 68.0 (TID 992). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 65.0 in stage 68.0 (TID 1005) (10.0.0.43, executor driver, partition 65, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 65.0 in stage 68.0 (TID 1005)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 52.0 in stage 68.0 (TID 992) in 416 ms on 10.0.0.43 (executor driver) (56/200)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_64 stored as values in memory (estimated size 1254.2 KiB, free 71.5 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_64 locally
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000055_995' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000055
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000055_995: Committed. Elapsed time: 0 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO Executor: Finished task 55.0 in stage 68.0 (TID 995). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 66.0 in stage 68.0 (TID 1006) (10.0.0.43, executor driver, partition 66, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_65 stored as values in memory (estimated size 1448.7 KiB, free 58.1 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_65 locally
25/02/04 17:14:14 INFO Executor: Running task 66.0 in stage 68.0 (TID 1006)
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_63 stored as values in memory (estimated size 1263.8 KiB, free 54.9 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_63 locally
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000058_998' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000058
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000058_998: Committed. Elapsed time: 6 ms.
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO TaskSetManager: Finished task 55.0 in stage 68.0 (TID 995) in 428 ms on 10.0.0.43 (executor driver) (57/200)
25/02/04 17:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000057_997' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000057
25/02/04 17:14:14 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000057_997: Committed. Elapsed time: 1 ms.
25/02/04 17:14:14 INFO Executor: Finished task 57.0 in stage 68.0 (TID 997). 17954 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 67.0 in stage 68.0 (TID 1007) (10.0.0.43, executor driver, partition 67, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Finished task 58.0 in stage 68.0 (TID 998). 17997 bytes result sent to driver
25/02/04 17:14:14 INFO TaskSetManager: Starting task 68.0 in stage 68.0 (TID 1008) (10.0.0.43, executor driver, partition 68, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:14 INFO Executor: Running task 67.0 in stage 68.0 (TID 1007)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 57.0 in stage 68.0 (TID 997) in 285 ms on 10.0.0.43 (executor driver) (58/200)
25/02/04 17:14:14 INFO Executor: Running task 68.0 in stage 68.0 (TID 1008)
25/02/04 17:14:14 INFO TaskSetManager: Finished task 58.0 in stage 68.0 (TID 998) in 271 ms on 10.0.0.43 (executor driver) (59/200)
25/02/04 17:14:14 INFO MemoryStore: Block rdd_72_66 stored as values in memory (estimated size 1069.9 KiB, free 37.8 MiB)
25/02/04 17:14:14 INFO BlockManager: Found block rdd_72_66 locally
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_67 stored as values in memory (estimated size 1146.0 KiB, free 37.6 MiB)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_68 stored as values in memory (estimated size 1124.1 KiB, free 37.6 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_68 locally
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_67 locally
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000059_999' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000059
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000059_999: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO Executor: Finished task 59.0 in stage 68.0 (TID 999). 17997 bytes result sent to driver
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO TaskSetManager: Starting task 69.0 in stage 68.0 (TID 1009) (10.0.0.43, executor driver, partition 69, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO Executor: Running task 69.0 in stage 68.0 (TID 1009)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 59.0 in stage 68.0 (TID 999) in 417 ms on 10.0.0.43 (executor driver) (60/200)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_69 stored as values in memory (estimated size 981.1 KiB, free 4.6 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_69 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: 1 blocks selected for dropping (1066.1 KiB bytes)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_92 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_92 on disk on 10.0.0.43:62420 (current size: 1005.9 KiB, original size: 1005.9 KiB)
25/02/04 17:14:15 INFO MemoryStore: After dropping 1 blocks, free memory is 2.7 MiB
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000061_1001' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000061
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000061_1001: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000062_1002' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000062
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000062_1002: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO Executor: Finished task 61.0 in stage 68.0 (TID 1001). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO Executor: Finished task 62.0 in stage 68.0 (TID 1002). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000063_1003' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000063
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000063_1003: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO TaskSetManager: Starting task 70.0 in stage 68.0 (TID 1010) (10.0.0.43, executor driver, partition 70, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Finished task 63.0 in stage 68.0 (TID 1003). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO Executor: Running task 70.0 in stage 68.0 (TID 1010)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 61.0 in stage 68.0 (TID 1001) in 355 ms on 10.0.0.43 (executor driver) (61/200)
25/02/04 17:14:15 INFO TaskSetManager: Starting task 71.0 in stage 68.0 (TID 1011) (10.0.0.43, executor driver, partition 71, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Starting task 72.0 in stage 68.0 (TID 1012) (10.0.0.43, executor driver, partition 72, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 62.0 in stage 68.0 (TID 1002) in 355 ms on 10.0.0.43 (executor driver) (62/200)
25/02/04 17:14:15 INFO Executor: Running task 71.0 in stage 68.0 (TID 1011)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 63.0 in stage 68.0 (TID 1003) in 302 ms on 10.0.0.43 (executor driver) (63/200)
25/02/04 17:14:15 INFO Executor: Running task 72.0 in stage 68.0 (TID 1012)
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000065_1005' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000065
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000065_1005: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 65.0 in stage 68.0 (TID 1005). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 73.0 in stage 68.0 (TID 1013) (10.0.0.43, executor driver, partition 73, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 65.0 in stage 68.0 (TID 1005) in 287 ms on 10.0.0.43 (executor driver) (64/200)
25/02/04 17:14:15 INFO Executor: Running task 73.0 in stage 68.0 (TID 1013)
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000060_1000' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000060
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000060_1000: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO Executor: Finished task 60.0 in stage 68.0 (TID 1000). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 74.0 in stage 68.0 (TID 1014) (10.0.0.43, executor driver, partition 74, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 74.0 in stage 68.0 (TID 1014)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 60.0 in stage 68.0 (TID 1000) in 376 ms on 10.0.0.43 (executor driver) (65/200)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_71 stored as values in memory (estimated size 1153.0 KiB, free 75.5 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_71 locally
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_72 stored as values in memory (estimated size 1253.6 KiB, free 74.3 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_72 locally
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_70 stored as values in memory (estimated size 1056.1 KiB, free 74.3 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_70 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_73 stored as values in memory (estimated size 1243.1 KiB, free 29.1 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_73 locally
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_74 stored as values in memory (estimated size 1337.1 KiB, free 27.8 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_74 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_93 from memory
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_93 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 1137.0 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_94 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_94 on disk on 10.0.0.43:62420 (current size: 1355.6 KiB, original size: 1355.6 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_98 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_98 on disk on 10.0.0.43:62420 (current size: 1385.8 KiB, original size: 1385.8 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_99 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_99 on disk on 10.0.0.43:62420 (current size: 880.3 KiB, original size: 880.3 KiB)
25/02/04 17:14:15 INFO MemoryStore: After dropping 4 blocks, free memory is 8.7 MiB
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000064_1004' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000064
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000064_1004: Committed. Elapsed time: 5 ms.
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO Executor: Finished task 64.0 in stage 68.0 (TID 1004). 17997 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 75.0 in stage 68.0 (TID 1015) (10.0.0.43, executor driver, partition 75, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 75.0 in stage 68.0 (TID 1015)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 64.0 in stage 68.0 (TID 1004) in 454 ms on 10.0.0.43 (executor driver) (66/200)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_75 stored as values in memory (estimated size 1068.8 KiB, free 7.7 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_75 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO MemoryStore: 3 blocks selected for dropping (3.3 MiB bytes)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_95 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_95 on disk on 10.0.0.43:62420 (current size: 940.1 KiB, original size: 940.1 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_96 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_96 on disk on 10.0.0.43:62420 (current size: 977.5 KiB, original size: 977.5 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_97 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_97 on disk on 10.0.0.43:62420 (current size: 1303.1 KiB, original size: 1303.1 KiB)
25/02/04 17:14:15 INFO MemoryStore: After dropping 3 blocks, free memory is 5.0 MiB
25/02/04 17:14:15 INFO MemoryStore: 7 blocks selected for dropping (8.2 MiB bytes)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_101 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_101 on disk on 10.0.0.43:62420 (current size: 897.5 KiB, original size: 897.5 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_100 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_100 on disk on 10.0.0.43:62420 (current size: 1141.2 KiB, original size: 1141.2 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_102 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_102 on disk on 10.0.0.43:62420 (current size: 1296.9 KiB, original size: 1296.9 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_105 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_105 on disk on 10.0.0.43:62420 (current size: 1137.0 KiB, original size: 1137.0 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_103 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_103 on disk on 10.0.0.43:62420 (current size: 1003.8 KiB, original size: 1003.8 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_104 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_104 on disk on 10.0.0.43:62420 (current size: 1116.1 KiB, original size: 1116.1 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_106 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_106 on disk on 10.0.0.43:62420 (current size: 1350.0 KiB, original size: 1350.0 KiB)
25/02/04 17:14:15 INFO MemoryStore: After dropping 7 blocks, free memory is 9.2 MiB
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000066_1006' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000066
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000066_1006: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 66.0 in stage 68.0 (TID 1006). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 76.0 in stage 68.0 (TID 1016) (10.0.0.43, executor driver, partition 76, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 76.0 in stage 68.0 (TID 1016)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 66.0 in stage 68.0 (TID 1006) in 499 ms on 10.0.0.43 (executor driver) (67/200)
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000068_1008' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000068
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000068_1008: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 68.0 in stage 68.0 (TID 1008). 17997 bytes result sent to driver
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_76 stored as values in memory (estimated size 1148.0 KiB, free 50.1 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_76 locally
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000070_1010' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000070
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000070_1010: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO Executor: Finished task 70.0 in stage 68.0 (TID 1010). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000069_1009' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000069
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000069_1009: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO Executor: Finished task 69.0 in stage 68.0 (TID 1009). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO TaskSetManager: Starting task 77.0 in stage 68.0 (TID 1017) (10.0.0.43, executor driver, partition 77, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000067_1007' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000067
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000067_1007: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Running task 77.0 in stage 68.0 (TID 1017)
25/02/04 17:14:15 INFO Executor: Finished task 67.0 in stage 68.0 (TID 1007). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 78.0 in stage 68.0 (TID 1018) (10.0.0.43, executor driver, partition 78, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 78.0 in stage 68.0 (TID 1018)
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO TaskSetManager: Starting task 79.0 in stage 68.0 (TID 1019) (10.0.0.43, executor driver, partition 79, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO TaskSetManager: Starting task 80.0 in stage 68.0 (TID 1020) (10.0.0.43, executor driver, partition 80, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 79.0 in stage 68.0 (TID 1019)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 70.0 in stage 68.0 (TID 1010) in 276 ms on 10.0.0.43 (executor driver) (68/200)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 68.0 in stage 68.0 (TID 1008) in 497 ms on 10.0.0.43 (executor driver) (69/200)
25/02/04 17:14:15 INFO Executor: Running task 80.0 in stage 68.0 (TID 1020)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 69.0 in stage 68.0 (TID 1009) in 355 ms on 10.0.0.43 (executor driver) (70/200)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 67.0 in stage 68.0 (TID 1007) in 508 ms on 10.0.0.43 (executor driver) (71/200)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_77 stored as values in memory (estimated size 934.4 KiB, free 71.2 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_77 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_78 stored as values in memory (estimated size 1105.7 KiB, free 48.1 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_78 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_79 stored as values in memory (estimated size 1046.6 KiB, free 44.1 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_79 locally
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_80 stored as values in memory (estimated size 1093.8 KiB, free 41.9 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_80 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000071_1011' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000071
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000071_1011: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000072_1012' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000072
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000072_1012: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO Executor: Finished task 71.0 in stage 68.0 (TID 1011). 17997 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 81.0 in stage 68.0 (TID 1021) (10.0.0.43, executor driver, partition 81, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 81.0 in stage 68.0 (TID 1021)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 71.0 in stage 68.0 (TID 1011) in 360 ms on 10.0.0.43 (executor driver) (72/200)
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000073_1013' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000073
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000073_1013: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 73.0 in stage 68.0 (TID 1013). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 82.0 in stage 68.0 (TID 1022) (10.0.0.43, executor driver, partition 82, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 73.0 in stage 68.0 (TID 1013) in 361 ms on 10.0.0.43 (executor driver) (73/200)
25/02/04 17:14:15 INFO Executor: Running task 82.0 in stage 68.0 (TID 1022)
25/02/04 17:14:15 INFO Executor: Finished task 72.0 in stage 68.0 (TID 1012). 17997 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 83.0 in stage 68.0 (TID 1023) (10.0.0.43, executor driver, partition 83, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 72.0 in stage 68.0 (TID 1012) in 382 ms on 10.0.0.43 (executor driver) (74/200)
25/02/04 17:14:15 INFO Executor: Running task 83.0 in stage 68.0 (TID 1023)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_81 stored as values in memory (estimated size 1309.1 KiB, free 48.7 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_81 locally
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_82 stored as values in memory (estimated size 1281.3 KiB, free 47.4 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_82 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000074_1014' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000074
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000074_1014: Committed. Elapsed time: 4 ms.
25/02/04 17:14:15 INFO Executor: Finished task 74.0 in stage 68.0 (TID 1014). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_83 stored as values in memory (estimated size 1017.8 KiB, free 28.5 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_83 locally
25/02/04 17:14:15 INFO TaskSetManager: Starting task 84.0 in stage 68.0 (TID 1024) (10.0.0.43, executor driver, partition 84, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 74.0 in stage 68.0 (TID 1014) in 411 ms on 10.0.0.43 (executor driver) (75/200)
25/02/04 17:14:15 INFO Executor: Running task 84.0 in stage 68.0 (TID 1024)
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000075_1015' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000075
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000075_1015: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO Executor: Finished task 75.0 in stage 68.0 (TID 1015). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 85.0 in stage 68.0 (TID 1025) (10.0.0.43, executor driver, partition 85, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 85.0 in stage 68.0 (TID 1025)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 75.0 in stage 68.0 (TID 1015) in 283 ms on 10.0.0.43 (executor driver) (76/200)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000076_1016' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000076
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000076_1016: Committed. Elapsed time: 2 ms.
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000079_1019' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000079
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000079_1019: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 79.0 in stage 68.0 (TID 1019). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO Executor: Finished task 76.0 in stage 68.0 (TID 1016). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 86.0 in stage 68.0 (TID 1026) (10.0.0.43, executor driver, partition 86, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000080_1020' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000080
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000080_1020: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Finished task 80.0 in stage 68.0 (TID 1020). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000077_1017' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000077
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000077_1017: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Running task 86.0 in stage 68.0 (TID 1026)
25/02/04 17:14:15 INFO TaskSetManager: Starting task 87.0 in stage 68.0 (TID 1027) (10.0.0.43, executor driver, partition 87, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Starting task 88.0 in stage 68.0 (TID 1028) (10.0.0.43, executor driver, partition 88, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Finished task 77.0 in stage 68.0 (TID 1017). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO Executor: Running task 87.0 in stage 68.0 (TID 1027)
25/02/04 17:14:15 INFO TaskSetManager: Starting task 89.0 in stage 68.0 (TID 1029) (10.0.0.43, executor driver, partition 89, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 88.0 in stage 68.0 (TID 1028)
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000078_1018' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000078
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000078_1018: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO Executor: Running task 89.0 in stage 68.0 (TID 1029)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 80.0 in stage 68.0 (TID 1020) in 250 ms on 10.0.0.43 (executor driver) (77/200)
25/02/04 17:14:15 INFO Executor: Finished task 78.0 in stage 68.0 (TID 1018). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Finished task 79.0 in stage 68.0 (TID 1019) in 250 ms on 10.0.0.43 (executor driver) (78/200)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_85 stored as values in memory (estimated size 1035.6 KiB, free 107.5 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_85 locally
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_84 stored as values in memory (estimated size 1123.3 KiB, free 106.4 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_84 locally
25/02/04 17:14:15 INFO TaskSetManager: Starting task 90.0 in stage 68.0 (TID 1030) (10.0.0.43, executor driver, partition 90, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO TaskSetManager: Finished task 77.0 in stage 68.0 (TID 1017) in 269 ms on 10.0.0.43 (executor driver) (79/200)
25/02/04 17:14:15 INFO Executor: Running task 90.0 in stage 68.0 (TID 1030)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 76.0 in stage 68.0 (TID 1016) in 297 ms on 10.0.0.43 (executor driver) (80/200)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO TaskSetManager: Finished task 78.0 in stage 68.0 (TID 1018) in 255 ms on 10.0.0.43 (executor driver) (81/200)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_90 stored as values in memory (estimated size 1025.4 KiB, free 81.4 MiB)
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_87 stored as values in memory (estimated size 1050.2 KiB, free 80.4 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_87 locally
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_90 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_88 stored as values in memory (estimated size 1331.9 KiB, free 68.1 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_88 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_89 stored as values in memory (estimated size 1436.1 KiB, free 57.6 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_89 locally
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000082_1022' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000082
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000082_1022: Committed. Elapsed time: 1 ms.
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_86 stored as values in memory (estimated size 1128.6 KiB, free 54.5 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_86 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO Executor: Finished task 82.0 in stage 68.0 (TID 1022). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000081_1021' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000081
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000081_1021: Committed. Elapsed time: 4 ms.
25/02/04 17:14:15 INFO Executor: Finished task 81.0 in stage 68.0 (TID 1021). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO TaskSetManager: Starting task 91.0 in stage 68.0 (TID 1031) (10.0.0.43, executor driver, partition 91, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO Executor: Running task 91.0 in stage 68.0 (TID 1031)
25/02/04 17:14:15 INFO TaskSetManager: Starting task 92.0 in stage 68.0 (TID 1032) (10.0.0.43, executor driver, partition 92, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 92.0 in stage 68.0 (TID 1032)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 81.0 in stage 68.0 (TID 1021) in 271 ms on 10.0.0.43 (executor driver) (82/200)
25/02/04 17:14:15 INFO TaskSetManager: Finished task 82.0 in stage 68.0 (TID 1022) in 269 ms on 10.0.0.43 (executor driver) (83/200)
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000083_1023' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000083
25/02/04 17:14:15 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000083_1023: Committed. Elapsed time: 0 ms.
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_91 stored as values in memory (estimated size 1209.1 KiB, free 35.4 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_91 locally
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:15 INFO Executor: Finished task 83.0 in stage 68.0 (TID 1023). 17954 bytes result sent to driver
25/02/04 17:14:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: Block rdd_72_92 stored as values in memory (estimated size 1066.1 KiB, free 32.3 MiB)
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_92 locally
25/02/04 17:14:15 INFO TaskSetManager: Starting task 93.0 in stage 68.0 (TID 1033) (10.0.0.43, executor driver, partition 93, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:15 INFO Executor: Running task 93.0 in stage 68.0 (TID 1033)
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO TaskSetManager: Finished task 83.0 in stage 68.0 (TID 1023) in 289 ms on 10.0.0.43 (executor driver) (84/200)
25/02/04 17:14:15 INFO MemoryStore: Will not store rdd_72_93
25/02/04 17:14:15 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_72_93 in memory.
25/02/04 17:14:15 WARN MemoryStore: Not enough space to cache rdd_72_93 in memory! (computed 384.0 B so far)
25/02/04 17:14:15 INFO MemoryStore: Memory use = 216.0 MiB (blocks) + 0.0 B (scratch space shared across 0 tasks(s)) = 216.0 MiB. Storage limit = 216.3 MiB.
25/02/04 17:14:15 INFO BlockManager: Found block rdd_72_93 locally
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:15 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_107 from memory
25/02/04 17:14:15 INFO BlockManagerInfo: Updated rdd_72_107 on disk on 10.0.0.43:62420 (current size: 1159.8 KiB, original size: 1159.8 KiB)
25/02/04 17:14:15 INFO BlockManager: Dropping block rdd_72_108 from memory
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_108 on disk on 10.0.0.43:62420 (current size: 959.4 KiB, original size: 959.4 KiB)
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO MemoryStore: After dropping 2 blocks, free memory is 2.5 MiB
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000090_1030' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000090
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000086_1026' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000086
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000084_1024' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000084
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000087_1027' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000087
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000086_1026: Committed. Elapsed time: 3 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000087_1027: Committed. Elapsed time: 2 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000090_1030: Committed. Elapsed time: 2 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000084_1024: Committed. Elapsed time: 2 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000085_1025' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000085
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000085_1025: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000088_1028' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000088
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000088_1028: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO Executor: Finished task 86.0 in stage 68.0 (TID 1026). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 90.0 in stage 68.0 (TID 1030). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 84.0 in stage 68.0 (TID 1024). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 88.0 in stage 68.0 (TID 1028). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 85.0 in stage 68.0 (TID 1025). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 87.0 in stage 68.0 (TID 1027). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000089_1029' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000089
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000089_1029: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000092_1032' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000092
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000092_1032: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000091_1031' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000091
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000091_1031: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO Executor: Finished task 91.0 in stage 68.0 (TID 1031). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 92.0 in stage 68.0 (TID 1032). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 89.0 in stage 68.0 (TID 1029). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 94.0 in stage 68.0 (TID 1034) (10.0.0.43, executor driver, partition 94, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 94.0 in stage 68.0 (TID 1034)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 95.0 in stage 68.0 (TID 1035) (10.0.0.43, executor driver, partition 95, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 95.0 in stage 68.0 (TID 1035)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 90.0 in stage 68.0 (TID 1030) in 740 ms on 10.0.0.43 (executor driver) (85/200)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 96.0 in stage 68.0 (TID 1036) (10.0.0.43, executor driver, partition 96, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 84.0 in stage 68.0 (TID 1024) in 862 ms on 10.0.0.43 (executor driver) (86/200)
25/02/04 17:14:16 INFO Executor: Running task 96.0 in stage 68.0 (TID 1036)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 97.0 in stage 68.0 (TID 1037) (10.0.0.43, executor driver, partition 97, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 97.0 in stage 68.0 (TID 1037)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 98.0 in stage 68.0 (TID 1038) (10.0.0.43, executor driver, partition 98, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 98.0 in stage 68.0 (TID 1038)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 87.0 in stage 68.0 (TID 1027) in 765 ms on 10.0.0.43 (executor driver) (87/200)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 99.0 in stage 68.0 (TID 1039) (10.0.0.43, executor driver, partition 99, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 86.0 in stage 68.0 (TID 1026) in 775 ms on 10.0.0.43 (executor driver) (88/200)
25/02/04 17:14:16 INFO Executor: Running task 99.0 in stage 68.0 (TID 1039)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 100.0 in stage 68.0 (TID 1040) (10.0.0.43, executor driver, partition 100, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 100.0 in stage 68.0 (TID 1040)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 101.0 in stage 68.0 (TID 1041) (10.0.0.43, executor driver, partition 101, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 88.0 in stage 68.0 (TID 1028) in 772 ms on 10.0.0.43 (executor driver) (89/200)
25/02/04 17:14:16 INFO Executor: Running task 101.0 in stage 68.0 (TID 1041)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 85.0 in stage 68.0 (TID 1025) in 848 ms on 10.0.0.43 (executor driver) (90/200)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 102.0 in stage 68.0 (TID 1042) (10.0.0.43, executor driver, partition 102, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 102.0 in stage 68.0 (TID 1042)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 91.0 in stage 68.0 (TID 1031) in 712 ms on 10.0.0.43 (executor driver) (91/200)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 92.0 in stage 68.0 (TID 1032) in 711 ms on 10.0.0.43 (executor driver) (92/200)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 89.0 in stage 68.0 (TID 1029) in 774 ms on 10.0.0.43 (executor driver) (93/200)
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000093_1033' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000093
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000093_1033: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO Executor: Finished task 93.0 in stage 68.0 (TID 1033). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 103.0 in stage 68.0 (TID 1043) (10.0.0.43, executor driver, partition 103, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 103.0 in stage 68.0 (TID 1043)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 93.0 in stage 68.0 (TID 1033) in 649 ms on 10.0.0.43 (executor driver) (94/200)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_99 stored as values in memory (estimated size 934.9 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_96 stored as values in memory (estimated size 1038.0 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_101 stored as values in memory (estimated size 956.2 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_103 stored as values in memory (estimated size 1066.7 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_94 stored as values in memory (estimated size 1436.0 KiB, free 143.5 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_102 stored as values in memory (estimated size 1372.4 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_95 stored as values in memory (estimated size 998.9 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_96 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_103 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_101 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_98 stored as values in memory (estimated size 1466.2 KiB, free 144.9 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_94 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_99 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_95 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_97 stored as values in memory (estimated size 1377.5 KiB, free 140.9 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_97 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_98 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_100 stored as values in memory (estimated size 1207.1 KiB, free 140.9 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_100 locally
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_102 locally
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO MemoryStore: 4 blocks selected for dropping (4.1 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_109 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_109 on disk on 10.0.0.43:62420 (current size: 981.0 KiB, original size: 981.0 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_110 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_110 on disk on 10.0.0.43:62420 (current size: 920.0 KiB, original size: 920.0 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_111 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_111 on disk on 10.0.0.43:62420 (current size: 978.0 KiB, original size: 978.0 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_112 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_112 on disk on 10.0.0.43:62420 (current size: 1062.2 KiB, original size: 1062.2 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 4 blocks, free memory is 9.0 MiB
25/02/04 17:14:16 INFO MemoryStore: 1 blocks selected for dropping (1391.4 KiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_114 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_114 on disk on 10.0.0.43:62420 (current size: 1318.6 KiB, original size: 1318.6 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 1 blocks, free memory is 2.4 MiB
25/02/04 17:14:16 INFO MemoryStore: 2 blocks selected for dropping (2.0 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_115 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_115 on disk on 10.0.0.43:62420 (current size: 826.4 KiB, original size: 826.4 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_113 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_113 on disk on 10.0.0.43:62420 (current size: 1133.4 KiB, original size: 1133.4 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:16 INFO MemoryStore: 2 blocks selected for dropping (3.0 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_116 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_116 on disk on 10.0.0.43:62420 (current size: 1464.6 KiB, original size: 1464.6 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_117 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_117 on disk on 10.0.0.43:62420 (current size: 1476.3 KiB, original size: 1476.3 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 2 blocks, free memory is 5.4 MiB
25/02/04 17:14:16 INFO MemoryStore: 3 blocks selected for dropping (3.5 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_118 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_118 on disk on 10.0.0.43:62420 (current size: 1235.9 KiB, original size: 1235.9 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_120 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_120 on disk on 10.0.0.43:62420 (current size: 1062.9 KiB, original size: 1062.9 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_121 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_121 on disk on 10.0.0.43:62420 (current size: 1114.7 KiB, original size: 1114.7 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 3 blocks, free memory is 5.0 MiB
25/02/04 17:14:16 INFO MemoryStore: 1 blocks selected for dropping (1062.9 KiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_119 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_119 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 1002.4 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 1 blocks, free memory is 2.0 MiB
25/02/04 17:14:16 INFO MemoryStore: 2 blocks selected for dropping (2.6 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_122 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_122 on disk on 10.0.0.43:62420 (current size: 1302.6 KiB, original size: 1302.6 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_123 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_123 on disk on 10.0.0.43:62420 (current size: 1192.5 KiB, original size: 1192.5 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 2 blocks, free memory is 2.6 MiB
25/02/04 17:14:16 INFO MemoryStore: 5 blocks selected for dropping (6.4 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_124 from memory
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_124 on disk on 10.0.0.43:62420 (current size: 1116.4 KiB, original size: 1116.4 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_126 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_126 on disk on 10.0.0.43:62420 (current size: 1010.3 KiB, original size: 1010.3 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_125 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_125 on disk on 10.0.0.43:62420 (current size: 1138.8 KiB, original size: 1138.8 KiB)
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_127 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_127 on disk on 10.0.0.43:62420 (current size: 1582.0 KiB, original size: 1582.0 KiB)
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_129 from memory
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_129 on disk on 10.0.0.43:62420 (current size: 1334.1 KiB, original size: 1334.1 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 5 blocks, free memory is 8.7 MiB
25/02/04 17:14:16 INFO MemoryStore: 7 blocks selected for dropping (7.8 MiB bytes)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_130 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_130 on disk on 10.0.0.43:62420 (current size: 1100.2 KiB, original size: 1100.2 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_128 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_128 on disk on 10.0.0.43:62420 (current size: 1113.1 KiB, original size: 1113.1 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_131 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_131 on disk on 10.0.0.43:62420 (current size: 1276.0 KiB, original size: 1276.0 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_133 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_133 on disk on 10.0.0.43:62420 (current size: 865.8 KiB, original size: 865.8 KiB)
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_134 from memory
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_134 on disk on 10.0.0.43:62420 (current size: 1088.2 KiB, original size: 1088.2 KiB)
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_132 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_132 on disk on 10.0.0.43:62420 (current size: 1164.2 KiB, original size: 1164.2 KiB)
25/02/04 17:14:16 INFO BlockManager: Dropping block rdd_72_135 from memory
25/02/04 17:14:16 INFO BlockManagerInfo: Updated rdd_72_135 on disk on 10.0.0.43:62420 (current size: 966.4 KiB, original size: 966.4 KiB)
25/02/04 17:14:16 INFO MemoryStore: After dropping 7 blocks, free memory is 8.5 MiB
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000103_1043' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000103
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000097_1037' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000097
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000096_1036' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000096
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000100_1040' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000100
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000103_1043: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000100_1040: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000095_1035' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000095
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000095_1035: Committed. Elapsed time: 2 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000097_1037: Committed. Elapsed time: 2 ms.
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000096_1036: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000101_1041' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000101
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000101_1041: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000102_1042' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000102
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000102_1042: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO Executor: Finished task 101.0 in stage 68.0 (TID 1041). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 97.0 in stage 68.0 (TID 1037). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 95.0 in stage 68.0 (TID 1035). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 100.0 in stage 68.0 (TID 1040). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 103.0 in stage 68.0 (TID 1043). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO Executor: Finished task 96.0 in stage 68.0 (TID 1036). 17997 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 104.0 in stage 68.0 (TID 1044) (10.0.0.43, executor driver, partition 104, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000099_1039' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000099
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000099_1039: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO Executor: Running task 104.0 in stage 68.0 (TID 1044)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 101.0 in stage 68.0 (TID 1041) in 431 ms on 10.0.0.43 (executor driver) (95/200)
25/02/04 17:14:16 INFO Executor: Finished task 102.0 in stage 68.0 (TID 1042). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 105.0 in stage 68.0 (TID 1045) (10.0.0.43, executor driver, partition 105, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 97.0 in stage 68.0 (TID 1037) in 439 ms on 10.0.0.43 (executor driver) (96/200)
25/02/04 17:14:16 INFO Executor: Running task 105.0 in stage 68.0 (TID 1045)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 106.0 in stage 68.0 (TID 1046) (10.0.0.43, executor driver, partition 106, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 106.0 in stage 68.0 (TID 1046)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 107.0 in stage 68.0 (TID 1047) (10.0.0.43, executor driver, partition 107, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 107.0 in stage 68.0 (TID 1047)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 108.0 in stage 68.0 (TID 1048) (10.0.0.43, executor driver, partition 108, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 108.0 in stage 68.0 (TID 1048)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 109.0 in stage 68.0 (TID 1049) (10.0.0.43, executor driver, partition 109, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 109.0 in stage 68.0 (TID 1049)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 100.0 in stage 68.0 (TID 1040) in 434 ms on 10.0.0.43 (executor driver) (97/200)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 103.0 in stage 68.0 (TID 1043) in 414 ms on 10.0.0.43 (executor driver) (98/200)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 96.0 in stage 68.0 (TID 1036) in 458 ms on 10.0.0.43 (executor driver) (99/200)
25/02/04 17:14:16 INFO TaskSetManager: Starting task 110.0 in stage 68.0 (TID 1050) (10.0.0.43, executor driver, partition 110, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 95.0 in stage 68.0 (TID 1035) in 462 ms on 10.0.0.43 (executor driver) (100/200)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 102.0 in stage 68.0 (TID 1042) in 431 ms on 10.0.0.43 (executor driver) (101/200)
25/02/04 17:14:16 INFO Executor: Running task 110.0 in stage 68.0 (TID 1050)
25/02/04 17:14:16 INFO Executor: Finished task 99.0 in stage 68.0 (TID 1039). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 111.0 in stage 68.0 (TID 1051) (10.0.0.43, executor driver, partition 111, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 111.0 in stage 68.0 (TID 1051)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 99.0 in stage 68.0 (TID 1039) in 440 ms on 10.0.0.43 (executor driver) (102/200)
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000094_1034' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000094
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000094_1034: Committed. Elapsed time: 1 ms.
25/02/04 17:14:16 INFO Executor: Finished task 94.0 in stage 68.0 (TID 1034). 17954 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 112.0 in stage 68.0 (TID 1052) (10.0.0.43, executor driver, partition 112, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO Executor: Running task 112.0 in stage 68.0 (TID 1052)
25/02/04 17:14:16 INFO TaskSetManager: Finished task 94.0 in stage 68.0 (TID 1034) in 498 ms on 10.0.0.43 (executor driver) (103/200)
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_109 stored as values in memory (estimated size 1040.2 KiB, free 169.7 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_109 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_111 stored as values in memory (estimated size 1035.3 KiB, free 167.7 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_111 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_106 stored as values in memory (estimated size 1425.5 KiB, free 166.3 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_106 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_110 stored as values in memory (estimated size 975.1 KiB, free 168.7 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_110 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_108 stored as values in memory (estimated size 1017.1 KiB, free 165.3 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_108 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_107 stored as values in memory (estimated size 1226.5 KiB, free 164.1 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_107 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_105 stored as values in memory (estimated size 1205.0 KiB, free 161.8 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_105 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_104 stored as values in memory (estimated size 1184.6 KiB, free 161.8 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_104 locally
25/02/04 17:14:16 INFO MemoryStore: Block rdd_72_112 stored as values in memory (estimated size 1125.1 KiB, free 160.7 MiB)
25/02/04 17:14:16 INFO BlockManager: Found block rdd_72_112 locally
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000098_1038' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000098
25/02/04 17:14:16 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000098_1038: Committed. Elapsed time: 0 ms.
25/02/04 17:14:16 INFO Executor: Finished task 98.0 in stage 68.0 (TID 1038). 18040 bytes result sent to driver
25/02/04 17:14:16 INFO TaskSetManager: Starting task 113.0 in stage 68.0 (TID 1053) (10.0.0.43, executor driver, partition 113, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:16 INFO TaskSetManager: Finished task 98.0 in stage 68.0 (TID 1038) in 587 ms on 10.0.0.43 (executor driver) (104/200)
25/02/04 17:14:16 INFO Executor: Running task 113.0 in stage 68.0 (TID 1053)
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_113 stored as values in memory (estimated size 1203.2 KiB, free 25.6 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_113 locally
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO MemoryStore: 2 blocks selected for dropping (2.5 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_136 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_136 on disk on 10.0.0.43:62420 (current size: 1351.4 KiB, original size: 1351.4 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_139 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_139 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 1080.3 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 2 blocks, free memory is 8.2 MiB
25/02/04 17:14:17 INFO MemoryStore: 7 blocks selected for dropping (8.0 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_137 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_137 on disk on 10.0.0.43:62420 (current size: 970.1 KiB, original size: 970.1 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_140 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_140 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 1134.0 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_138 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_138 on disk on 10.0.0.43:62420 (current size: 1111.5 KiB, original size: 1111.5 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_142 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_142 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 1105.0 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_145 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_145 on disk on 10.0.0.43:62420 (current size: 1250.7 KiB, original size: 1250.7 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_141 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_141 on disk on 10.0.0.43:62420 (current size: 1197.5 KiB, original size: 1197.5 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_144 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_144 on disk on 10.0.0.43:62420 (current size: 966.7 KiB, original size: 966.7 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 7 blocks, free memory is 8.2 MiB
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000111_1051' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000111
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000109_1049' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000109
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000107_1047' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000107
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000104_1044' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000104
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000112_1052' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000112
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000107_1047: Committed. Elapsed time: 2 ms.
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000109_1049: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000110_1050' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000110
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000110_1050: Committed. Elapsed time: 3 ms.
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000111_1051: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000112_1052: Committed. Elapsed time: 2 ms.
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000104_1044: Committed. Elapsed time: 2 ms.
25/02/04 17:14:17 INFO Executor: Finished task 112.0 in stage 68.0 (TID 1052). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 104.0 in stage 68.0 (TID 1044). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 109.0 in stage 68.0 (TID 1049). 17997 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 107.0 in stage 68.0 (TID 1047). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 110.0 in stage 68.0 (TID 1050). 17997 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 111.0 in stage 68.0 (TID 1051). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 114.0 in stage 68.0 (TID 1054) (10.0.0.43, executor driver, partition 114, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000105_1045' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000105
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000105_1045: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 105.0 in stage 68.0 (TID 1045). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Running task 114.0 in stage 68.0 (TID 1054)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 115.0 in stage 68.0 (TID 1055) (10.0.0.43, executor driver, partition 115, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Starting task 116.0 in stage 68.0 (TID 1056) (10.0.0.43, executor driver, partition 116, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 115.0 in stage 68.0 (TID 1055)
25/02/04 17:14:17 INFO Executor: Running task 116.0 in stage 68.0 (TID 1056)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 117.0 in stage 68.0 (TID 1057) (10.0.0.43, executor driver, partition 117, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 110.0 in stage 68.0 (TID 1050) in 318 ms on 10.0.0.43 (executor driver) (105/200)
25/02/04 17:14:17 INFO Executor: Running task 117.0 in stage 68.0 (TID 1057)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 109.0 in stage 68.0 (TID 1049) in 319 ms on 10.0.0.43 (executor driver) (106/200)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 118.0 in stage 68.0 (TID 1058) (10.0.0.43, executor driver, partition 118, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Starting task 119.0 in stage 68.0 (TID 1059) (10.0.0.43, executor driver, partition 119, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 118.0 in stage 68.0 (TID 1058)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 120.0 in stage 68.0 (TID 1060) (10.0.0.43, executor driver, partition 120, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 112.0 in stage 68.0 (TID 1052) in 302 ms on 10.0.0.43 (executor driver) (107/200)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 105.0 in stage 68.0 (TID 1045) in 324 ms on 10.0.0.43 (executor driver) (108/200)
25/02/04 17:14:17 INFO Executor: Running task 119.0 in stage 68.0 (TID 1059)
25/02/04 17:14:17 INFO Executor: Running task 120.0 in stage 68.0 (TID 1060)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 107.0 in stage 68.0 (TID 1047) in 322 ms on 10.0.0.43 (executor driver) (109/200)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 104.0 in stage 68.0 (TID 1044) in 336 ms on 10.0.0.43 (executor driver) (110/200)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 111.0 in stage 68.0 (TID 1051) in 323 ms on 10.0.0.43 (executor driver) (111/200)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000106_1046' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000106
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000106_1046: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO Executor: Finished task 106.0 in stage 68.0 (TID 1046). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 121.0 in stage 68.0 (TID 1061) (10.0.0.43, executor driver, partition 121, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000113_1053' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000113
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000113_1053: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000108_1048' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000108
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000108_1048: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Running task 121.0 in stage 68.0 (TID 1061)
25/02/04 17:14:17 INFO Executor: Finished task 108.0 in stage 68.0 (TID 1048). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 113.0 in stage 68.0 (TID 1053). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 122.0 in stage 68.0 (TID 1062) (10.0.0.43, executor driver, partition 122, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 106.0 in stage 68.0 (TID 1046) in 378 ms on 10.0.0.43 (executor driver) (112/200)
25/02/04 17:14:17 INFO Executor: Running task 122.0 in stage 68.0 (TID 1062)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 108.0 in stage 68.0 (TID 1048) in 378 ms on 10.0.0.43 (executor driver) (113/200)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 123.0 in stage 68.0 (TID 1063) (10.0.0.43, executor driver, partition 123, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 123.0 in stage 68.0 (TID 1063)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 113.0 in stage 68.0 (TID 1053) in 235 ms on 10.0.0.43 (executor driver) (114/200)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_115 stored as values in memory (estimated size 879.4 KiB, free 171.3 MiB)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_118 stored as values in memory (estimated size 1312.1 KiB, free 170.0 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_118 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_119 stored as values in memory (estimated size 1062.9 KiB, free 169.0 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_119 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_120 stored as values in memory (estimated size 1129.3 KiB, free 167.9 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_120 locally
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_115 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_114 stored as values in memory (estimated size 1391.4 KiB, free 166.5 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_114 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_117 stored as values in memory (estimated size 1560.3 KiB, free 165.0 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_117 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_116 stored as values in memory (estimated size 1543.8 KiB, free 163.5 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_116 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_123 stored as values in memory (estimated size 1264.0 KiB, free 162.3 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_123 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_121 stored as values in memory (estimated size 1182.1 KiB, free 161.1 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_121 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_122 stored as values in memory (estimated size 1375.8 KiB, free 159.8 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_122 locally
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO MemoryStore: 3 blocks selected for dropping (3.3 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_143 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_143 on disk on 10.0.0.43:62420 (current size: 1131.3 KiB, original size: 1131.3 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_153 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_153 on disk on 10.0.0.43:62420 (current size: 939.3 KiB, original size: 939.3 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_151 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_151 on disk on 10.0.0.43:62420 (current size: 1149.0 KiB, original size: 1149.0 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 3 blocks, free memory is 9.1 MiB
25/02/04 17:14:17 INFO MemoryStore: 1 blocks selected for dropping (1152.4 KiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_150 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_150 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 1086.5 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:14:17 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_149 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_149 on disk on 10.0.0.43:62420 (current size: 1102.0 KiB, original size: 1102.0 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_154 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_154 on disk on 10.0.0.43:62420 (current size: 1008.9 KiB, original size: 1008.9 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:17 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:17 INFO MemoryStore: 7 blocks selected for dropping (8.4 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_146 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_146 on disk on 10.0.0.43:62420 (current size: 1156.8 KiB, original size: 1156.8 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_147 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_147 on disk on 10.0.0.43:62420 (current size: 1044.9 KiB, original size: 1044.9 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_148 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_148 on disk on 10.0.0.43:62420 (current size: 1192.4 KiB, original size: 1192.4 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_152 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_152 on disk on 10.0.0.43:62420 (current size: 1331.2 KiB, original size: 1331.2 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_155 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_155 on disk on 10.0.0.43:62420 (current size: 1075.9 KiB, original size: 1075.9 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_158 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_158 on disk on 10.0.0.43:62420 (current size: 1322.5 KiB, original size: 1322.5 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_156 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_156 on disk on 10.0.0.43:62420 (current size: 1002.4 KiB, original size: 1002.4 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 7 blocks, free memory is 8.5 MiB
25/02/04 17:14:17 INFO MemoryStore: 2 blocks selected for dropping (2.7 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_159 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_159 on disk on 10.0.0.43:62420 (current size: 1457.3 KiB, original size: 1457.3 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_157 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_157 on disk on 10.0.0.43:62420 (current size: 1134.0 KiB, original size: 1134.0 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 2 blocks, free memory is 3.2 MiB
25/02/04 17:14:17 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000115_1055' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000115
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000115_1055: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 115.0 in stage 68.0 (TID 1055). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000119_1059' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000119
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000119_1059: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 119.0 in stage 68.0 (TID 1059). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 124.0 in stage 68.0 (TID 1064) (10.0.0.43, executor driver, partition 124, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000120_1060' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000120
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000120_1060: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Running task 124.0 in stage 68.0 (TID 1064)
25/02/04 17:14:17 INFO Executor: Finished task 120.0 in stage 68.0 (TID 1060). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Finished task 115.0 in stage 68.0 (TID 1055) in 280 ms on 10.0.0.43 (executor driver) (115/200)
25/02/04 17:14:17 INFO TaskSetManager: Starting task 125.0 in stage 68.0 (TID 1065) (10.0.0.43, executor driver, partition 125, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Starting task 126.0 in stage 68.0 (TID 1066) (10.0.0.43, executor driver, partition 126, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 126.0 in stage 68.0 (TID 1066)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 120.0 in stage 68.0 (TID 1060) in 278 ms on 10.0.0.43 (executor driver) (116/200)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 119.0 in stage 68.0 (TID 1059) in 279 ms on 10.0.0.43 (executor driver) (117/200)
25/02/04 17:14:17 INFO Executor: Running task 125.0 in stage 68.0 (TID 1065)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000121_1061' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000121
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000121_1061: Committed. Elapsed time: 5 ms.
25/02/04 17:14:17 INFO Executor: Finished task 121.0 in stage 68.0 (TID 1061). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 127.0 in stage 68.0 (TID 1067) (10.0.0.43, executor driver, partition 127, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 121.0 in stage 68.0 (TID 1061) in 253 ms on 10.0.0.43 (executor driver) (118/200)
25/02/04 17:14:17 INFO Executor: Running task 127.0 in stage 68.0 (TID 1067)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_126 stored as values in memory (estimated size 1073.8 KiB, free 99.3 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_126 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_124 stored as values in memory (estimated size 1178.8 KiB, free 98.2 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_124 locally
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_125 stored as values in memory (estimated size 1204.4 KiB, free 96.5 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_125 locally
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_127 stored as values in memory (estimated size 1660.8 KiB, free 92.2 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_127 locally
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000123_1063' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000123
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000123_1063: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO Executor: Finished task 123.0 in stage 68.0 (TID 1063). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO TaskSetManager: Starting task 128.0 in stage 68.0 (TID 1068) (10.0.0.43, executor driver, partition 128, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO TaskSetManager: Finished task 123.0 in stage 68.0 (TID 1063) in 267 ms on 10.0.0.43 (executor driver) (119/200)
25/02/04 17:14:17 INFO Executor: Running task 128.0 in stage 68.0 (TID 1068)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000114_1054' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000114
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000114_1054: Committed. Elapsed time: 2 ms.
25/02/04 17:14:17 INFO Executor: Finished task 114.0 in stage 68.0 (TID 1054). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 129.0 in stage 68.0 (TID 1069) (10.0.0.43, executor driver, partition 129, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 129.0 in stage 68.0 (TID 1069)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 114.0 in stage 68.0 (TID 1054) in 344 ms on 10.0.0.43 (executor driver) (120/200)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_128 stored as values in memory (estimated size 1177.6 KiB, free 75.8 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_128 locally
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000122_1062' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000122
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000122_1062: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 122.0 in stage 68.0 (TID 1062). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 130.0 in stage 68.0 (TID 1070) (10.0.0.43, executor driver, partition 130, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 130.0 in stage 68.0 (TID 1070)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 122.0 in stage 68.0 (TID 1062) in 294 ms on 10.0.0.43 (executor driver) (121/200)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_129 stored as values in memory (estimated size 1408.3 KiB, free 74.4 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_129 locally
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_130 stored as values in memory (estimated size 1167.7 KiB, free 77.3 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_130 locally
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000118_1058' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000118
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000118_1058: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO Executor: Finished task 118.0 in stage 68.0 (TID 1058). 17997 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 131.0 in stage 68.0 (TID 1071) (10.0.0.43, executor driver, partition 131, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 131.0 in stage 68.0 (TID 1071)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 118.0 in stage 68.0 (TID 1058) in 379 ms on 10.0.0.43 (executor driver) (122/200)
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_131 stored as values in memory (estimated size 1353.8 KiB, free 36.0 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_131 locally
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000116_1056' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000116
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000116_1056: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO Executor: Finished task 116.0 in stage 68.0 (TID 1056). 18040 bytes result sent to driver
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO TaskSetManager: Starting task 132.0 in stage 68.0 (TID 1072) (10.0.0.43, executor driver, partition 132, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 132.0 in stage 68.0 (TID 1072)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000117_1057' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000117
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000117_1057: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 117.0 in stage 68.0 (TID 1057). 18040 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 133.0 in stage 68.0 (TID 1073) (10.0.0.43, executor driver, partition 133, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 133.0 in stage 68.0 (TID 1073)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 117.0 in stage 68.0 (TID 1057) in 521 ms on 10.0.0.43 (executor driver) (123/200)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 116.0 in stage 68.0 (TID 1056) in 525 ms on 10.0.0.43 (executor driver) (124/200)
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_133 stored as values in memory (estimated size 919.7 KiB, free 22.6 MiB)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_132 stored as values in memory (estimated size 1234.5 KiB, free 21.4 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_132 locally
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_133 locally
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO MemoryStore: 6 blocks selected for dropping (7.1 MiB bytes)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_164 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_164 on disk on 10.0.0.43:62420 (current size: 1357.3 KiB, original size: 1357.3 KiB)
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_162 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_162 on disk on 10.0.0.43:62420 (current size: 1171.5 KiB, original size: 1171.5 KiB)
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_160 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_160 on disk on 10.0.0.43:62420 (current size: 1140.9 KiB, original size: 1140.9 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_163 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_163 on disk on 10.0.0.43:62420 (current size: 1255.9 KiB, original size: 1255.9 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_161 from memory
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_161 on disk on 10.0.0.43:62420 (current size: 1075.6 KiB, original size: 1075.6 KiB)
25/02/04 17:14:17 INFO BlockManager: Dropping block rdd_72_172 from memory
25/02/04 17:14:17 INFO BlockManagerInfo: Updated rdd_72_172 on disk on 10.0.0.43:62420 (current size: 882.2 KiB, original size: 882.2 KiB)
25/02/04 17:14:17 INFO MemoryStore: After dropping 6 blocks, free memory is 8.5 MiB
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000126_1066' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000126
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000126_1066: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 126.0 in stage 68.0 (TID 1066). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 134.0 in stage 68.0 (TID 1074) (10.0.0.43, executor driver, partition 134, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 134.0 in stage 68.0 (TID 1074)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 126.0 in stage 68.0 (TID 1066) in 426 ms on 10.0.0.43 (executor driver) (125/200)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000124_1064' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000124
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000124_1064: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO Executor: Finished task 124.0 in stage 68.0 (TID 1064). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 135.0 in stage 68.0 (TID 1075) (10.0.0.43, executor driver, partition 135, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 124.0 in stage 68.0 (TID 1064) in 435 ms on 10.0.0.43 (executor driver) (126/200)
25/02/04 17:14:17 INFO Executor: Running task 135.0 in stage 68.0 (TID 1075)
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000125_1065' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000125
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000125_1065: Committed. Elapsed time: 0 ms.
25/02/04 17:14:17 INFO Executor: Finished task 125.0 in stage 68.0 (TID 1065). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 136.0 in stage 68.0 (TID 1076) (10.0.0.43, executor driver, partition 136, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Finished task 125.0 in stage 68.0 (TID 1065) in 442 ms on 10.0.0.43 (executor driver) (127/200)
25/02/04 17:14:17 INFO Executor: Running task 136.0 in stage 68.0 (TID 1076)
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_134 stored as values in memory (estimated size 1147.5 KiB, free 44.4 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_134 locally
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_135 stored as values in memory (estimated size 1025.8 KiB, free 44.4 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_135 locally
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO MemoryStore: Block rdd_72_136 stored as values in memory (estimated size 1429.3 KiB, free 42.9 MiB)
25/02/04 17:14:17 INFO BlockManager: Found block rdd_72_136 locally
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000130_1070' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000130
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000130_1070: Committed. Elapsed time: 7 ms.
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000128_1068' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000128
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000128_1068: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO Executor: Finished task 128.0 in stage 68.0 (TID 1068). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO Executor: Finished task 130.0 in stage 68.0 (TID 1070). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 137.0 in stage 68.0 (TID 1077) (10.0.0.43, executor driver, partition 137, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000129_1069' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000129
25/02/04 17:14:17 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000129_1069: Committed. Elapsed time: 1 ms.
25/02/04 17:14:17 INFO TaskSetManager: Finished task 128.0 in stage 68.0 (TID 1068) in 492 ms on 10.0.0.43 (executor driver) (128/200)
25/02/04 17:14:17 INFO Executor: Finished task 129.0 in stage 68.0 (TID 1069). 17954 bytes result sent to driver
25/02/04 17:14:17 INFO TaskSetManager: Starting task 138.0 in stage 68.0 (TID 1078) (10.0.0.43, executor driver, partition 138, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO TaskSetManager: Starting task 139.0 in stage 68.0 (TID 1079) (10.0.0.43, executor driver, partition 139, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:17 INFO Executor: Running task 137.0 in stage 68.0 (TID 1077)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 129.0 in stage 68.0 (TID 1069) in 484 ms on 10.0.0.43 (executor driver) (129/200)
25/02/04 17:14:17 INFO Executor: Running task 138.0 in stage 68.0 (TID 1078)
25/02/04 17:14:17 INFO Executor: Running task 139.0 in stage 68.0 (TID 1079)
25/02/04 17:14:17 INFO TaskSetManager: Finished task 130.0 in stage 68.0 (TID 1070) in 480 ms on 10.0.0.43 (executor driver) (130/200)
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:17 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000127_1067' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000127
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000127_1067: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO Executor: Finished task 127.0 in stage 68.0 (TID 1067). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 140.0 in stage 68.0 (TID 1080) (10.0.0.43, executor driver, partition 140, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_139 stored as values in memory (estimated size 1149.9 KiB, free 83.9 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_139 locally
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_137 stored as values in memory (estimated size 1027.9 KiB, free 82.9 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_137 locally
25/02/04 17:14:18 INFO TaskSetManager: Finished task 127.0 in stage 68.0 (TID 1067) in 564 ms on 10.0.0.43 (executor driver) (131/200)
25/02/04 17:14:18 INFO Executor: Running task 140.0 in stage 68.0 (TID 1080)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000131_1071' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000131
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000131_1071: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO Executor: Finished task 131.0 in stage 68.0 (TID 1071). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 141.0 in stage 68.0 (TID 1081) (10.0.0.43, executor driver, partition 141, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_138 stored as values in memory (estimated size 1174.8 KiB, free 81.7 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_138 locally
25/02/04 17:14:18 INFO TaskSetManager: Finished task 131.0 in stage 68.0 (TID 1071) in 481 ms on 10.0.0.43 (executor driver) (132/200)
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO Executor: Running task 141.0 in stage 68.0 (TID 1081)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_140 stored as values in memory (estimated size 1202.8 KiB, free 52.5 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_140 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_141 stored as values in memory (estimated size 1268.3 KiB, free 13.3 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_141 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO MemoryStore: 6 blocks selected for dropping (7.2 MiB bytes)
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_167 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_167 on disk on 10.0.0.43:62420 (current size: 994.1 KiB, original size: 994.1 KiB)
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_173 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_173 on disk on 10.0.0.43:62420 (current size: 1039.3 KiB, original size: 1039.3 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_169 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_169 on disk on 10.0.0.43:62420 (current size: 1051.8 KiB, original size: 1051.8 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_166 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_166 on disk on 10.0.0.43:62420 (current size: 1469.1 KiB, original size: 1469.1 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_170 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_170 on disk on 10.0.0.43:62420 (current size: 1180.1 KiB, original size: 1180.1 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_171 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_171 on disk on 10.0.0.43:62420 (current size: 1224.6 KiB, original size: 1224.6 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 6 blocks, free memory is 8.5 MiB
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000133_1073' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000133
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000133_1073: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO Executor: Finished task 133.0 in stage 68.0 (TID 1073). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO TaskSetManager: Starting task 142.0 in stage 68.0 (TID 1082) (10.0.0.43, executor driver, partition 142, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 142.0 in stage 68.0 (TID 1082)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 133.0 in stage 68.0 (TID 1073) in 435 ms on 10.0.0.43 (executor driver) (133/200)
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_142 stored as values in memory (estimated size 1171.1 KiB, free 15.4 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_142 locally
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000132_1072' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000132
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000132_1072: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO Executor: Finished task 132.0 in stage 68.0 (TID 1072). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 143.0 in stage 68.0 (TID 1083) (10.0.0.43, executor driver, partition 143, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 132.0 in stage 68.0 (TID 1072) in 485 ms on 10.0.0.43 (executor driver) (134/200)
25/02/04 17:14:18 INFO Executor: Running task 143.0 in stage 68.0 (TID 1083)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000135_1075' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000135
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000135_1075: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 135.0 in stage 68.0 (TID 1075). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 144.0 in stage 68.0 (TID 1084) (10.0.0.43, executor driver, partition 144, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 144.0 in stage 68.0 (TID 1084)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 135.0 in stage 68.0 (TID 1075) in 285 ms on 10.0.0.43 (executor driver) (135/200)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_143 stored as values in memory (estimated size 1200.3 KiB, free 30.2 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_143 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000134_1074' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000134
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000134_1074: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 134.0 in stage 68.0 (TID 1074). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO TaskSetManager: Starting task 145.0 in stage 68.0 (TID 1085) (10.0.0.43, executor driver, partition 145, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO Executor: Running task 145.0 in stage 68.0 (TID 1085)
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO TaskSetManager: Finished task 134.0 in stage 68.0 (TID 1074) in 311 ms on 10.0.0.43 (executor driver) (136/200)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_144 stored as values in memory (estimated size 1027.6 KiB, free 27.2 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_144 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_145 stored as values in memory (estimated size 1331.0 KiB, free 38.9 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_145 locally
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000136_1076' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000136
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000136_1076: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO Executor: Finished task 136.0 in stage 68.0 (TID 1076). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO TaskSetManager: Starting task 146.0 in stage 68.0 (TID 1086) (10.0.0.43, executor driver, partition 146, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 146.0 in stage 68.0 (TID 1086)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 136.0 in stage 68.0 (TID 1076) in 370 ms on 10.0.0.43 (executor driver) (137/200)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000137_1077' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000137
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000137_1077: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_146 stored as values in memory (estimated size 1225.4 KiB, free 24.7 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_146 locally
25/02/04 17:14:18 INFO Executor: Finished task 137.0 in stage 68.0 (TID 1077). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 147.0 in stage 68.0 (TID 1087) (10.0.0.43, executor driver, partition 147, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 147.0 in stage 68.0 (TID 1087)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 137.0 in stage 68.0 (TID 1077) in 299 ms on 10.0.0.43 (executor driver) (138/200)
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000139_1079' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000139
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000139_1079: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 139.0 in stage 68.0 (TID 1079). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO TaskSetManager: Starting task 148.0 in stage 68.0 (TID 1088) (10.0.0.43, executor driver, partition 148, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 148.0 in stage 68.0 (TID 1088)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 139.0 in stage 68.0 (TID 1079) in 306 ms on 10.0.0.43 (executor driver) (139/200)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_147 stored as values in memory (estimated size 1105.9 KiB, free 29.6 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_147 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000140_1080' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000140
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000140_1080: Committed. Elapsed time: 3 ms.
25/02/04 17:14:18 INFO Executor: Finished task 140.0 in stage 68.0 (TID 1080). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 149.0 in stage 68.0 (TID 1089) (10.0.0.43, executor driver, partition 149, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 149.0 in stage 68.0 (TID 1089)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 140.0 in stage 68.0 (TID 1080) in 283 ms on 10.0.0.43 (executor driver) (140/200)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000138_1078' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000138
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000138_1078: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 138.0 in stage 68.0 (TID 1078). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 150.0 in stage 68.0 (TID 1090) (10.0.0.43, executor driver, partition 150, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_148 stored as values in memory (estimated size 1260.4 KiB, free 40.4 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_148 locally
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO TaskSetManager: Finished task 138.0 in stage 68.0 (TID 1078) in 325 ms on 10.0.0.43 (executor driver) (141/200)
25/02/04 17:14:18 INFO Executor: Running task 150.0 in stage 68.0 (TID 1090)
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_149 stored as values in memory (estimated size 1166.6 KiB, free 36.2 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_149 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_150 stored as values in memory (estimated size 1152.4 KiB, free 20.1 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_150 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO MemoryStore: 2 blocks selected for dropping (2.1 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_168 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_168 on disk on 10.0.0.43:62420 (current size: 1014.6 KiB, original size: 1014.6 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_175 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_175 on disk on 10.0.0.43:62420 (current size: 1032.3 KiB, original size: 1032.3 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 2 blocks, free memory is 2.2 MiB
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000141_1081' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000141
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000141_1081: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 141.0 in stage 68.0 (TID 1081). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO TaskSetManager: Starting task 151.0 in stage 68.0 (TID 1091) (10.0.0.43, executor driver, partition 151, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO Executor: Running task 151.0 in stage 68.0 (TID 1091)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 141.0 in stage 68.0 (TID 1081) in 338 ms on 10.0.0.43 (executor driver) (142/200)
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_151 stored as values in memory (estimated size 1217.8 KiB, free 5.0 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_151 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO MemoryStore: 1 blocks selected for dropping (1020.3 KiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_176 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_176 on disk on 10.0.0.43:62420 (current size: 959.7 KiB, original size: 959.7 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 1 blocks, free memory is 2.0 MiB
25/02/04 17:14:18 INFO MemoryStore: 4 blocks selected for dropping (4.9 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_179 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_179 on disk on 10.0.0.43:62420 (current size: 1388.5 KiB, original size: 1388.5 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_178 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_178 on disk on 10.0.0.43:62420 (current size: 1282.9 KiB, original size: 1282.9 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_181 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_181 on disk on 10.0.0.43:62420 (current size: 1105.0 KiB, original size: 1105.0 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_180 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_180 on disk on 10.0.0.43:62420 (current size: 1018.4 KiB, original size: 1018.4 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 4 blocks, free memory is 5.0 MiB
25/02/04 17:14:18 INFO MemoryStore: 6 blocks selected for dropping (7.3 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_177 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_177 on disk on 10.0.0.43:62420 (current size: 1310.4 KiB, original size: 1310.4 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_182 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_182 on disk on 10.0.0.43:62420 (current size: 1110.7 KiB, original size: 1110.7 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_183 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_183 on disk on 10.0.0.43:62420 (current size: 1032.0 KiB, original size: 1032.0 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_185 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_185 on disk on 10.0.0.43:62420 (current size: 1088.7 KiB, original size: 1088.7 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_189 from memory
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_189 on disk on 10.0.0.43:62420 (current size: 1400.9 KiB, original size: 1400.9 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_188 from memory
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_188 on disk on 10.0.0.43:62420 (current size: 1143.5 KiB, original size: 1143.5 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 6 blocks, free memory is 8.3 MiB
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000143_1083' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000143
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000143_1083: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000142_1082' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000142
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000142_1082: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000144_1084' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000144
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000144_1084: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000146_1086' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000146
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000146_1086: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000150_1090' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000150
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000150_1090: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000147_1087' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000147
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000147_1087: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 143.0 in stage 68.0 (TID 1083). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 150.0 in stage 68.0 (TID 1090). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 142.0 in stage 68.0 (TID 1082). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 144.0 in stage 68.0 (TID 1084). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 147.0 in stage 68.0 (TID 1087). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 152.0 in stage 68.0 (TID 1092) (10.0.0.43, executor driver, partition 152, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000145_1085' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000145
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000145_1085: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO TaskSetManager: Finished task 143.0 in stage 68.0 (TID 1083) in 462 ms on 10.0.0.43 (executor driver) (143/200)
25/02/04 17:14:18 INFO Executor: Finished task 146.0 in stage 68.0 (TID 1086). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Running task 152.0 in stage 68.0 (TID 1092)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 153.0 in stage 68.0 (TID 1093) (10.0.0.43, executor driver, partition 153, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 153.0 in stage 68.0 (TID 1093)
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000149_1089' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000149
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000149_1089: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO TaskSetManager: Starting task 154.0 in stage 68.0 (TID 1094) (10.0.0.43, executor driver, partition 154, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO Executor: Running task 154.0 in stage 68.0 (TID 1094)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 155.0 in stage 68.0 (TID 1095) (10.0.0.43, executor driver, partition 155, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 155.0 in stage 68.0 (TID 1095)
25/02/04 17:14:18 INFO Executor: Finished task 149.0 in stage 68.0 (TID 1089). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 156.0 in stage 68.0 (TID 1096) (10.0.0.43, executor driver, partition 156, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 156.0 in stage 68.0 (TID 1096)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 157.0 in stage 68.0 (TID 1097) (10.0.0.43, executor driver, partition 157, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 157.0 in stage 68.0 (TID 1097)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 158.0 in stage 68.0 (TID 1098) (10.0.0.43, executor driver, partition 158, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 142.0 in stage 68.0 (TID 1082) in 513 ms on 10.0.0.43 (executor driver) (144/200)
25/02/04 17:14:18 INFO Executor: Running task 158.0 in stage 68.0 (TID 1098)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 150.0 in stage 68.0 (TID 1090) in 317 ms on 10.0.0.43 (executor driver) (145/200)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 144.0 in stage 68.0 (TID 1084) in 465 ms on 10.0.0.43 (executor driver) (146/200)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 149.0 in stage 68.0 (TID 1089) in 328 ms on 10.0.0.43 (executor driver) (147/200)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 147.0 in stage 68.0 (TID 1087) in 347 ms on 10.0.0.43 (executor driver) (148/200)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 146.0 in stage 68.0 (TID 1086) in 377 ms on 10.0.0.43 (executor driver) (149/200)
25/02/04 17:14:18 INFO Executor: Finished task 145.0 in stage 68.0 (TID 1085). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 159.0 in stage 68.0 (TID 1099) (10.0.0.43, executor driver, partition 159, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 145.0 in stage 68.0 (TID 1085) in 456 ms on 10.0.0.43 (executor driver) (150/200)
25/02/04 17:14:18 INFO Executor: Running task 159.0 in stage 68.0 (TID 1099)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000148_1088' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000148
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000148_1088: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 148.0 in stage 68.0 (TID 1088). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 160.0 in stage 68.0 (TID 1100) (10.0.0.43, executor driver, partition 160, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 148.0 in stage 68.0 (TID 1088) in 365 ms on 10.0.0.43 (executor driver) (151/200)
25/02/04 17:14:18 INFO Executor: Running task 160.0 in stage 68.0 (TID 1100)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_157 stored as values in memory (estimated size 1199.3 KiB, free 150.6 MiB)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_152 stored as values in memory (estimated size 1410.1 KiB, free 149.2 MiB)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_154 stored as values in memory (estimated size 1069.8 KiB, free 150.6 MiB)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_158 stored as values in memory (estimated size 1398.2 KiB, free 148.2 MiB)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_153 stored as values in memory (estimated size 994.4 KiB, free 148.2 MiB)
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_156 stored as values in memory (estimated size 1061.6 KiB, free 150.6 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_154 locally
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_155 stored as values in memory (estimated size 1139.9 KiB, free 148.2 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_155 locally
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_156 locally
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_152 locally
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_153 locally
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_158 locally
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_157 locally
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_159 stored as values in memory (estimated size 1537.9 KiB, free 146.7 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_159 locally
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_160 stored as values in memory (estimated size 1206.5 KiB, free 145.2 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_160 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO MemoryStore: 2 blocks selected for dropping (2.5 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_191 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_191 on disk on 10.0.0.43:62420 (current size: 1355.3 KiB, original size: 1355.3 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_186 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_186 on disk on 10.0.0.43:62420 (current size: 1048.2 KiB, original size: 1048.2 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 2 blocks, free memory is 8.0 MiB
25/02/04 17:14:18 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_184 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_184 on disk on 10.0.0.43:62420 (current size: 962.8 KiB, original size: 962.8 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_190 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_190 on disk on 10.0.0.43:62420 (current size: 1253.6 KiB, original size: 1253.6 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 2 blocks, free memory is 2.3 MiB
25/02/04 17:14:18 INFO MemoryStore: 1 blocks selected for dropping (1826.0 KiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_187 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_187 on disk on 10.0.0.43:62420 (current size: 1739.0 KiB, original size: 1739.0 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 1 blocks, free memory is 2.1 MiB
25/02/04 17:14:18 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_192 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_192 on disk on 10.0.0.43:62420 (current size: 1012.3 KiB, original size: 1012.3 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_193 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_193 on disk on 10.0.0.43:62420 (current size: 1194.9 KiB, original size: 1194.9 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:18 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_197 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_197 on disk on 10.0.0.43:62420 (current size: 1086.5 KiB, original size: 1086.5 KiB)
25/02/04 17:14:18 INFO BlockManager: Dropping block rdd_72_199 from memory
25/02/04 17:14:18 INFO BlockManagerInfo: Updated rdd_72_199 on disk on 10.0.0.43:62420 (current size: 1179.4 KiB, original size: 1179.4 KiB)
25/02/04 17:14:18 INFO MemoryStore: After dropping 2 blocks, free memory is 2.7 MiB
25/02/04 17:14:18 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000151_1091' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000151
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000151_1091: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO Executor: Finished task 151.0 in stage 68.0 (TID 1091). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 161.0 in stage 68.0 (TID 1101) (10.0.0.43, executor driver, partition 161, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 151.0 in stage 68.0 (TID 1091) in 399 ms on 10.0.0.43 (executor driver) (152/200)
25/02/04 17:14:18 INFO Executor: Running task 161.0 in stage 68.0 (TID 1101)
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO MemoryStore: Block rdd_72_161 stored as values in memory (estimated size 1138.7 KiB, free 19.3 MiB)
25/02/04 17:14:18 INFO BlockManager: Found block rdd_72_161 locally
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000153_1093' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000153
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000157_1097' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000157
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000155_1095' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000155
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000155_1095: Committed. Elapsed time: 2 ms.
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000157_1097: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000153_1093: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000154_1094' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000154
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000154_1094: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000156_1096' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000156
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000156_1096: Committed. Elapsed time: 2 ms.
25/02/04 17:14:18 INFO Executor: Finished task 154.0 in stage 68.0 (TID 1094). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 156.0 in stage 68.0 (TID 1096). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 155.0 in stage 68.0 (TID 1095). 17997 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 157.0 in stage 68.0 (TID 1097). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO Executor: Finished task 153.0 in stage 68.0 (TID 1093). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 162.0 in stage 68.0 (TID 1102) (10.0.0.43, executor driver, partition 162, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Finished task 156.0 in stage 68.0 (TID 1096) in 303 ms on 10.0.0.43 (executor driver) (153/200)
25/02/04 17:14:18 INFO Executor: Running task 162.0 in stage 68.0 (TID 1102)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 163.0 in stage 68.0 (TID 1103) (10.0.0.43, executor driver, partition 163, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 163.0 in stage 68.0 (TID 1103)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 164.0 in stage 68.0 (TID 1104) (10.0.0.43, executor driver, partition 164, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000160_1100' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000160
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000160_1100: Committed. Elapsed time: 0 ms.
25/02/04 17:14:18 INFO TaskSetManager: Finished task 155.0 in stage 68.0 (TID 1095) in 305 ms on 10.0.0.43 (executor driver) (154/200)
25/02/04 17:14:18 INFO Executor: Running task 164.0 in stage 68.0 (TID 1104)
25/02/04 17:14:18 INFO Executor: Finished task 160.0 in stage 68.0 (TID 1100). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 165.0 in stage 68.0 (TID 1105) (10.0.0.43, executor driver, partition 165, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO TaskSetManager: Starting task 166.0 in stage 68.0 (TID 1106) (10.0.0.43, executor driver, partition 166, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 165.0 in stage 68.0 (TID 1105)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 157.0 in stage 68.0 (TID 1097) in 305 ms on 10.0.0.43 (executor driver) (155/200)
25/02/04 17:14:18 INFO Executor: Running task 166.0 in stage 68.0 (TID 1106)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 154.0 in stage 68.0 (TID 1094) in 308 ms on 10.0.0.43 (executor driver) (156/200)
25/02/04 17:14:18 INFO TaskSetManager: Starting task 167.0 in stage 68.0 (TID 1107) (10.0.0.43, executor driver, partition 167, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO Executor: Running task 167.0 in stage 68.0 (TID 1107)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 153.0 in stage 68.0 (TID 1093) in 312 ms on 10.0.0.43 (executor driver) (157/200)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 160.0 in stage 68.0 (TID 1100) in 281 ms on 10.0.0.43 (executor driver) (158/200)
25/02/04 17:14:18 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000158_1098' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000158
25/02/04 17:14:18 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000158_1098: Committed. Elapsed time: 1 ms.
25/02/04 17:14:18 INFO Executor: Finished task 158.0 in stage 68.0 (TID 1098). 17954 bytes result sent to driver
25/02/04 17:14:18 INFO TaskSetManager: Starting task 168.0 in stage 68.0 (TID 1108) (10.0.0.43, executor driver, partition 168, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:18 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:18 INFO Executor: Running task 168.0 in stage 68.0 (TID 1108)
25/02/04 17:14:18 INFO TaskSetManager: Finished task 158.0 in stage 68.0 (TID 1098) in 312 ms on 10.0.0.43 (executor driver) (159/200)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_166 stored as values in memory (estimated size 1547.2 KiB, free 150.9 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_163 stored as values in memory (estimated size 1328.4 KiB, free 152.4 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_164 stored as values in memory (estimated size 1434.8 KiB, free 152.4 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_166 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_163 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_164 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_167 stored as values in memory (estimated size 1054.2 KiB, free 149.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_167 locally
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000152_1092' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000152
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000152_1092: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_168 stored as values in memory (estimated size 1077.6 KiB, free 148.8 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_168 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_162 stored as values in memory (estimated size 1247.5 KiB, free 147.6 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_162 locally
25/02/04 17:14:19 INFO Executor: Finished task 152.0 in stage 68.0 (TID 1092). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 169.0 in stage 68.0 (TID 1109) (10.0.0.43, executor driver, partition 169, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 169.0 in stage 68.0 (TID 1109)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 152.0 in stage 68.0 (TID 1092) in 497 ms on 10.0.0.43 (executor driver) (160/200)
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_165 stored as values in memory (estimated size 1185.7 KiB, free 94.4 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_165 locally
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_169 stored as values in memory (estimated size 1113.0 KiB, free 74.3 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_169 locally
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000161_1101' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000161
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000161_1101: Committed. Elapsed time: 1 ms.
25/02/04 17:14:19 INFO Executor: Finished task 161.0 in stage 68.0 (TID 1101). 17997 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Finished task 161.0 in stage 68.0 (TID 1101) in 542 ms on 10.0.0.43 (executor driver) (161/200)
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000167_1107' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000167
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000167_1107: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 167.0 in stage 68.0 (TID 1107). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000163_1103' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000163
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000163_1103: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 163.0 in stage 68.0 (TID 1103). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000159_1099' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000159
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000159_1099: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000168_1108' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000168
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000168_1108: Committed. Elapsed time: 3 ms.
25/02/04 17:14:19 INFO Executor: Finished task 168.0 in stage 68.0 (TID 1108). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 159.0 in stage 68.0 (TID 1099). 18040 bytes result sent to driver
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000169_1109' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000169
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000169_1109: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 169.0 in stage 68.0 (TID 1109). 17911 bytes result sent to driver
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO TaskSetManager: Starting task 170.0 in stage 68.0 (TID 1110) (10.0.0.43, executor driver, partition 170, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000164_1104' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000164
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000164_1104: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 164.0 in stage 68.0 (TID 1104). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Running task 170.0 in stage 68.0 (TID 1110)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 167.0 in stage 68.0 (TID 1107) in 408 ms on 10.0.0.43 (executor driver) (162/200)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 171.0 in stage 68.0 (TID 1111) (10.0.0.43, executor driver, partition 171, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 171.0 in stage 68.0 (TID 1111)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 172.0 in stage 68.0 (TID 1112) (10.0.0.43, executor driver, partition 172, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 172.0 in stage 68.0 (TID 1112)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 163.0 in stage 68.0 (TID 1103) in 417 ms on 10.0.0.43 (executor driver) (163/200)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 168.0 in stage 68.0 (TID 1108) in 409 ms on 10.0.0.43 (executor driver) (164/200)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 173.0 in stage 68.0 (TID 1113) (10.0.0.43, executor driver, partition 173, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 173.0 in stage 68.0 (TID 1113)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 174.0 in stage 68.0 (TID 1114) (10.0.0.43, executor driver, partition 174, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 174.0 in stage 68.0 (TID 1114)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 175.0 in stage 68.0 (TID 1115) (10.0.0.43, executor driver, partition 175, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 175.0 in stage 68.0 (TID 1115)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 176.0 in stage 68.0 (TID 1116) (10.0.0.43, executor driver, partition 176, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO TaskSetManager: Finished task 169.0 in stage 68.0 (TID 1109) in 248 ms on 10.0.0.43 (executor driver) (165/200)
25/02/04 17:14:19 INFO Executor: Running task 176.0 in stage 68.0 (TID 1116)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 159.0 in stage 68.0 (TID 1099) in 719 ms on 10.0.0.43 (executor driver) (166/200)
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000162_1102' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000162
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000162_1102: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000165_1105' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000165
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000165_1105: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 165.0 in stage 68.0 (TID 1105). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 162.0 in stage 68.0 (TID 1102). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Finished task 164.0 in stage 68.0 (TID 1104) in 457 ms on 10.0.0.43 (executor driver) (167/200)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 177.0 in stage 68.0 (TID 1117) (10.0.0.43, executor driver, partition 177, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO TaskSetManager: Starting task 178.0 in stage 68.0 (TID 1118) (10.0.0.43, executor driver, partition 178, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 177.0 in stage 68.0 (TID 1117)
25/02/04 17:14:19 INFO Executor: Running task 178.0 in stage 68.0 (TID 1118)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 165.0 in stage 68.0 (TID 1105) in 471 ms on 10.0.0.43 (executor driver) (168/200)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 162.0 in stage 68.0 (TID 1102) in 478 ms on 10.0.0.43 (executor driver) (169/200)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_173 stored as values in memory (estimated size 1103.4 KiB, free 159.0 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_173 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_171 stored as values in memory (estimated size 1299.1 KiB, free 159.0 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_171 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_177 stored as values in memory (estimated size 1384.6 KiB, free 157.7 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_178 stored as values in memory (estimated size 1351.0 KiB, free 156.3 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_178 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_177 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_174 stored as values in memory (estimated size 1313.1 KiB, free 155.0 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_174 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_176 stored as values in memory (estimated size 1020.3 KiB, free 154.1 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_176 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_170 stored as values in memory (estimated size 1245.6 KiB, free 152.8 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_170 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_172 stored as values in memory (estimated size 936.9 KiB, free 151.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_172 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_175 stored as values in memory (estimated size 1094.3 KiB, free 150.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_175 locally
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000166_1106' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000166
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000166_1106: Committed. Elapsed time: 1 ms.
25/02/04 17:14:19 INFO Executor: Finished task 166.0 in stage 68.0 (TID 1106). 18040 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 179.0 in stage 68.0 (TID 1119) (10.0.0.43, executor driver, partition 179, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 179.0 in stage 68.0 (TID 1119)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 166.0 in stage 68.0 (TID 1106) in 525 ms on 10.0.0.43 (executor driver) (170/200)
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_179 stored as values in memory (estimated size 1459.9 KiB, free 10.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_179 locally
25/02/04 17:14:19 INFO MemoryStore: 4 blocks selected for dropping (4.5 MiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_198 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_198 on disk on 10.0.0.43:62420 (current size: 947.7 KiB, original size: 947.7 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_195 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_195 on disk on 10.0.0.43:62420 (current size: 910.4 KiB, original size: 910.4 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_194 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_194 on disk on 10.0.0.43:62420 (current size: 952.6 KiB, original size: 952.6 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_196 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_196 on disk on 10.0.0.43:62420 (current size: 1587.2 KiB, original size: 1587.2 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 4 blocks, free memory is 8.5 MiB
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO MemoryStore: 2 blocks selected for dropping (413.1 KiB bytes)
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO BlockManager: Dropping block broadcast_27_piece0 from memory
25/02/04 17:14:19 INFO BlockManager: Writing block broadcast_27_piece0 to disk
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO BlockManagerInfo: Updated broadcast_27_piece0 on disk on 10.0.0.43:62420 (current size: 113.3 KiB, original size: 0.0 B)
25/02/04 17:14:19 INFO BlockManager: Dropping block broadcast_27 from memory
25/02/04 17:14:19 INFO BlockManager: Writing block broadcast_27 to disk
25/02/04 17:14:19 INFO MemoryStore: After dropping 2 blocks, free memory is 629.3 KiB
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO MemoryStore: 1 blocks selected for dropping (1104.4 KiB bytes)
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_0 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_0 on disk on 10.0.0.43:62420 (current size: 1043.3 KiB, original size: 1043.3 KiB)
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO MemoryStore: After dropping 1 blocks, free memory is 1477.7 KiB
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO MemoryStore: 1 blocks selected for dropping (1252.8 KiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_4 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_4 on disk on 10.0.0.43:62420 (current size: 1183.4 KiB, original size: 1183.4 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 1 blocks, free memory is 2.2 MiB
25/02/04 17:14:19 INFO MemoryStore: 1 blocks selected for dropping (1150.5 KiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_9 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_9 on disk on 10.0.0.43:62420 (current size: 1084.9 KiB, original size: 1084.9 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 1 blocks, free memory is 2.3 MiB
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO MemoryStore: 3 blocks selected for dropping (3.7 MiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_1 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_1 on disk on 10.0.0.43:62420 (current size: 1494.1 KiB, original size: 1494.1 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_7 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_7 on disk on 10.0.0.43:62420 (current size: 895.3 KiB, original size: 895.3 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_8 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_8 on disk on 10.0.0.43:62420 (current size: 1237.7 KiB, original size: 1237.7 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 3 blocks, free memory is 4.0 MiB
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO MemoryStore: 8 blocks selected for dropping (9.3 MiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_5 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_5 on disk on 10.0.0.43:62420 (current size: 1031.0 KiB, original size: 1031.0 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_6 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_6 on disk on 10.0.0.43:62420 (current size: 1175.2 KiB, original size: 1175.2 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_3 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_3 on disk on 10.0.0.43:62420 (current size: 987.2 KiB, original size: 987.2 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_2 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_2 on disk on 10.0.0.43:62420 (current size: 1110.3 KiB, original size: 1110.3 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_11 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_11 on disk on 10.0.0.43:62420 (current size: 1090.0 KiB, original size: 1090.0 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_12 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_12 on disk on 10.0.0.43:62420 (current size: 1138.3 KiB, original size: 1138.3 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_10 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_10 on disk on 10.0.0.43:62420 (current size: 1093.3 KiB, original size: 1093.3 KiB)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_13 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_13 on disk on 10.0.0.43:62420 (current size: 1373.4 KiB, original size: 1373.4 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 8 blocks, free memory is 9.4 MiB
25/02/04 17:14:19 INFO MemoryStore: 1 blocks selected for dropping (1175.6 KiB bytes)
25/02/04 17:14:19 INFO BlockManager: Dropping block rdd_72_16 from memory
25/02/04 17:14:19 INFO BlockManagerInfo: Updated rdd_72_16 on disk on 10.0.0.43:62420 (current size: 1109.4 KiB, original size: 1109.4 KiB)
25/02/04 17:14:19 INFO MemoryStore: After dropping 1 blocks, free memory is 2.5 MiB
25/02/04 17:14:19 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000172_1112' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000172
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000176_1116' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000176
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000175_1115' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000175
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000176_1116: Committed. Elapsed time: 3 ms.
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000172_1112: Committed. Elapsed time: 4 ms.
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000175_1115: Committed. Elapsed time: 2 ms.
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000174_1114' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000174
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000174_1114: Committed. Elapsed time: 4 ms.
25/02/04 17:14:19 INFO Executor: Finished task 175.0 in stage 68.0 (TID 1115). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 174.0 in stage 68.0 (TID 1114). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 172.0 in stage 68.0 (TID 1112). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 176.0 in stage 68.0 (TID 1116). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 180.0 in stage 68.0 (TID 1120) (10.0.0.43, executor driver, partition 180, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000170_1110' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000170
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000170_1110: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 170.0 in stage 68.0 (TID 1110). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Running task 180.0 in stage 68.0 (TID 1120)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 172.0 in stage 68.0 (TID 1112) in 365 ms on 10.0.0.43 (executor driver) (171/200)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 181.0 in stage 68.0 (TID 1121) (10.0.0.43, executor driver, partition 181, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 181.0 in stage 68.0 (TID 1121)
25/02/04 17:14:19 INFO TaskSetManager: Starting task 182.0 in stage 68.0 (TID 1122) (10.0.0.43, executor driver, partition 182, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO TaskSetManager: Starting task 183.0 in stage 68.0 (TID 1123) (10.0.0.43, executor driver, partition 183, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO TaskSetManager: Starting task 184.0 in stage 68.0 (TID 1124) (10.0.0.43, executor driver, partition 184, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 182.0 in stage 68.0 (TID 1122)
25/02/04 17:14:19 INFO Executor: Running task 183.0 in stage 68.0 (TID 1123)
25/02/04 17:14:19 INFO Executor: Running task 184.0 in stage 68.0 (TID 1124)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 176.0 in stage 68.0 (TID 1116) in 360 ms on 10.0.0.43 (executor driver) (172/200)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 175.0 in stage 68.0 (TID 1115) in 361 ms on 10.0.0.43 (executor driver) (173/200)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 174.0 in stage 68.0 (TID 1114) in 362 ms on 10.0.0.43 (executor driver) (174/200)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 170.0 in stage 68.0 (TID 1110) in 380 ms on 10.0.0.43 (executor driver) (175/200)
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000178_1118' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000178
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000178_1118: Committed. Elapsed time: 1 ms.
25/02/04 17:14:19 INFO Executor: Finished task 178.0 in stage 68.0 (TID 1118). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 185.0 in stage 68.0 (TID 1125) (10.0.0.43, executor driver, partition 185, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 185.0 in stage 68.0 (TID 1125)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 178.0 in stage 68.0 (TID 1118) in 335 ms on 10.0.0.43 (executor driver) (176/200)
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000173_1113' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000173
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000173_1113: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 173.0 in stage 68.0 (TID 1113). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 186.0 in stage 68.0 (TID 1126) (10.0.0.43, executor driver, partition 186, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 186.0 in stage 68.0 (TID 1126)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 173.0 in stage 68.0 (TID 1113) in 398 ms on 10.0.0.43 (executor driver) (177/200)
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000171_1111' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000171
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000171_1111: Committed. Elapsed time: 1 ms.
25/02/04 17:14:19 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000177_1117' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000177
25/02/04 17:14:19 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000177_1117: Committed. Elapsed time: 0 ms.
25/02/04 17:14:19 INFO Executor: Finished task 171.0 in stage 68.0 (TID 1111). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO Executor: Finished task 177.0 in stage 68.0 (TID 1117). 17954 bytes result sent to driver
25/02/04 17:14:19 INFO TaskSetManager: Starting task 187.0 in stage 68.0 (TID 1127) (10.0.0.43, executor driver, partition 187, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO TaskSetManager: Starting task 188.0 in stage 68.0 (TID 1128) (10.0.0.43, executor driver, partition 188, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:19 INFO Executor: Running task 187.0 in stage 68.0 (TID 1127)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 171.0 in stage 68.0 (TID 1111) in 405 ms on 10.0.0.43 (executor driver) (178/200)
25/02/04 17:14:19 INFO Executor: Running task 188.0 in stage 68.0 (TID 1128)
25/02/04 17:14:19 INFO TaskSetManager: Finished task 177.0 in stage 68.0 (TID 1117) in 349 ms on 10.0.0.43 (executor driver) (179/200)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_184 stored as values in memory (estimated size 1023.9 KiB, free 170.3 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_180 stored as values in memory (estimated size 1080.7 KiB, free 167.0 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_181 stored as values in memory (estimated size 1168.3 KiB, free 167.0 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_182 stored as values in memory (estimated size 1175.7 KiB, free 167.0 MiB)
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_183 stored as values in memory (estimated size 1091.3 KiB, free 167.0 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_183 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_180 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_184 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_182 locally
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_181 locally
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_185 stored as values in memory (estimated size 1151.8 KiB, free 165.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_185 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_186 stored as values in memory (estimated size 1115.1 KiB, free 164.8 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_186 locally
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_188 stored as values in memory (estimated size 1209.4 KiB, free 163.6 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_188 locally
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO MemoryStore: Block rdd_72_187 stored as values in memory (estimated size 1826.0 KiB, free 161.9 MiB)
25/02/04 17:14:19 INFO BlockManager: Found block rdd_72_187 locally
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:19 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:19 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:19 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:14:20 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000180_1120' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000180
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000180_1120: Committed. Elapsed time: 1 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000182_1122' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000182
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000182_1122: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000186_1126' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000186
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000186_1126: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000185_1125' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000185
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000185_1125: Committed. Elapsed time: 2 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000181_1121' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000181
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000181_1121: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000188_1128' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000188
25/02/04 17:14:20 INFO Executor: Finished task 180.0 in stage 68.0 (TID 1120). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000188_1128: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 182.0 in stage 68.0 (TID 1122). 17997 bytes result sent to driver
25/02/04 17:14:20 INFO Executor: Finished task 186.0 in stage 68.0 (TID 1126). 17997 bytes result sent to driver
25/02/04 17:14:20 INFO Executor: Finished task 188.0 in stage 68.0 (TID 1128). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO Executor: Finished task 181.0 in stage 68.0 (TID 1121). 17997 bytes result sent to driver
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000183_1123' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000183
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000183_1123: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 185.0 in stage 68.0 (TID 1125). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO Executor: Finished task 183.0 in stage 68.0 (TID 1123). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO TaskSetManager: Starting task 189.0 in stage 68.0 (TID 1129) (10.0.0.43, executor driver, partition 189, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO Executor: Running task 189.0 in stage 68.0 (TID 1129)
25/02/04 17:14:20 INFO TaskSetManager: Starting task 190.0 in stage 68.0 (TID 1130) (10.0.0.43, executor driver, partition 190, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Finished task 182.0 in stage 68.0 (TID 1122) in 347 ms on 10.0.0.43 (executor driver) (180/200)
25/02/04 17:14:20 INFO Executor: Running task 190.0 in stage 68.0 (TID 1130)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 186.0 in stage 68.0 (TID 1126) in 315 ms on 10.0.0.43 (executor driver) (181/200)
25/02/04 17:14:20 INFO TaskSetManager: Starting task 191.0 in stage 68.0 (TID 1131) (10.0.0.43, executor driver, partition 191, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO Executor: Running task 191.0 in stage 68.0 (TID 1131)
25/02/04 17:14:20 INFO TaskSetManager: Starting task 192.0 in stage 68.0 (TID 1132) (10.0.0.43, executor driver, partition 192, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Starting task 193.0 in stage 68.0 (TID 1133) (10.0.0.43, executor driver, partition 193, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Starting task 194.0 in stage 68.0 (TID 1134) (10.0.0.43, executor driver, partition 194, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Starting task 195.0 in stage 68.0 (TID 1135) (10.0.0.43, executor driver, partition 195, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Finished task 180.0 in stage 68.0 (TID 1120) in 356 ms on 10.0.0.43 (executor driver) (182/200)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 188.0 in stage 68.0 (TID 1128) in 314 ms on 10.0.0.43 (executor driver) (183/200)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 185.0 in stage 68.0 (TID 1125) in 328 ms on 10.0.0.43 (executor driver) (184/200)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 181.0 in stage 68.0 (TID 1121) in 352 ms on 10.0.0.43 (executor driver) (185/200)
25/02/04 17:14:20 INFO Executor: Running task 192.0 in stage 68.0 (TID 1132)
25/02/04 17:14:20 INFO Executor: Running task 193.0 in stage 68.0 (TID 1133)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 183.0 in stage 68.0 (TID 1123) in 352 ms on 10.0.0.43 (executor driver) (186/200)
25/02/04 17:14:20 INFO Executor: Running task 194.0 in stage 68.0 (TID 1134)
25/02/04 17:14:20 INFO Executor: Running task 195.0 in stage 68.0 (TID 1135)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000184_1124' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000184
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000184_1124: Committed. Elapsed time: 2 ms.
25/02/04 17:14:20 INFO Executor: Finished task 184.0 in stage 68.0 (TID 1124). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Starting task 196.0 in stage 68.0 (TID 1136) (10.0.0.43, executor driver, partition 196, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO Executor: Running task 196.0 in stage 68.0 (TID 1136)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 184.0 in stage 68.0 (TID 1124) in 373 ms on 10.0.0.43 (executor driver) (187/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000179_1119' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000179
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000179_1119: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 179.0 in stage 68.0 (TID 1119). 18040 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Starting task 197.0 in stage 68.0 (TID 1137) (10.0.0.43, executor driver, partition 197, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO Executor: Running task 197.0 in stage 68.0 (TID 1137)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 179.0 in stage 68.0 (TID 1119) in 636 ms on 10.0.0.43 (executor driver) (188/200)
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_192 stored as values in memory (estimated size 1074.5 KiB, free 155.6 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_192 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_190 stored as values in memory (estimated size 1326.0 KiB, free 155.6 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_190 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_194 stored as values in memory (estimated size 1006.5 KiB, free 154.6 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_194 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_189 stored as values in memory (estimated size 1483.9 KiB, free 153.1 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_189 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_191 stored as values in memory (estimated size 1429.8 KiB, free 151.7 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_191 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_193 stored as values in memory (estimated size 1261.6 KiB, free 150.5 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_193 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_196 stored as values in memory (estimated size 1663.1 KiB, free 148.9 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_196 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_197 stored as values in memory (estimated size 1149.1 KiB, free 147.4 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_197 locally
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_195 stored as values in memory (estimated size 968.9 KiB, free 146.4 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_195 locally
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:20 INFO MemoryStore: 4 blocks selected for dropping (5.6 MiB bytes)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_15 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_15 on disk on 10.0.0.43:62420 (current size: 1246.0 KiB, original size: 1246.0 KiB)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_14 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_14 on disk on 10.0.0.43:62420 (current size: 1827.2 KiB, original size: 1827.2 KiB)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_17 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_17 on disk on 10.0.0.43:62420 (current size: 1455.6 KiB, original size: 1455.6 KiB)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_18 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_18 on disk on 10.0.0.43:62420 (current size: 918.0 KiB, original size: 918.0 KiB)
25/02/04 17:14:20 INFO MemoryStore: After dropping 4 blocks, free memory is 8.1 MiB
25/02/04 17:14:20 INFO MemoryStore: 2 blocks selected for dropping (2.3 MiB bytes)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_19 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_19 on disk on 10.0.0.43:62420 (current size: 1310.5 KiB, original size: 1310.5 KiB)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_21 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_21 on disk on 10.0.0.43:62420 (current size: 911.0 KiB, original size: 911.0 KiB)
25/02/04 17:14:20 INFO MemoryStore: After dropping 2 blocks, free memory is 2.4 MiB
25/02/04 17:14:20 INFO MemoryStore: 2 blocks selected for dropping (2.2 MiB bytes)
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_24 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_24 on disk on 10.0.0.43:62420 (current size: 1032.1 KiB, original size: 1032.1 KiB)
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO BlockManager: Dropping block rdd_72_23 from memory
25/02/04 17:14:20 INFO BlockManagerInfo: Updated rdd_72_23 on disk on 10.0.0.43:62420 (current size: 1091.7 KiB, original size: 1091.7 KiB)
25/02/04 17:14:20 INFO MemoryStore: After dropping 2 blocks, free memory is 2.6 MiB
25/02/04 17:14:20 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 18.0 MiB to disk (0  time so far)
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000187_1127' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000187
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000187_1127: Committed. Elapsed time: 1 ms.
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO Executor: Finished task 187.0 in stage 68.0 (TID 1127). 18040 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Starting task 198.0 in stage 68.0 (TID 1138) (10.0.0.43, executor driver, partition 198, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO TaskSetManager: Finished task 187.0 in stage 68.0 (TID 1127) in 577 ms on 10.0.0.43 (executor driver) (189/200)
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO Executor: Running task 198.0 in stage 68.0 (TID 1138)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000192_1132' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000192
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000192_1132: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000194_1134' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000194
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000194_1134: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 194.0 in stage 68.0 (TID 1134). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO Executor: Finished task 192.0 in stage 68.0 (TID 1132). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Starting task 199.0 in stage 68.0 (TID 1139) (10.0.0.43, executor driver, partition 199, PROCESS_LOCAL, 9281 bytes) 
25/02/04 17:14:20 INFO Executor: Running task 199.0 in stage 68.0 (TID 1139)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 194.0 in stage 68.0 (TID 1134) in 273 ms on 10.0.0.43 (executor driver) (190/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000195_1135' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000195
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000195_1135: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 195.0 in stage 68.0 (TID 1135). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 192.0 in stage 68.0 (TID 1132) in 281 ms on 10.0.0.43 (executor driver) (191/200)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 195.0 in stage 68.0 (TID 1135) in 280 ms on 10.0.0.43 (executor driver) (192/200)
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_198 stored as values in memory (estimated size 1005.0 KiB, free 70.6 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_198 locally
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO MemoryStore: Block rdd_72_199 stored as values in memory (estimated size 1240.6 KiB, free 83.9 MiB)
25/02/04 17:14:20 INFO BlockManager: Found block rdd_72_199 locally
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000193_1133' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000193
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000193_1133: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:20 INFO Executor: Finished task 193.0 in stage 68.0 (TID 1133). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 193.0 in stage 68.0 (TID 1133) in 298 ms on 10.0.0.43 (executor driver) (193/200)
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000197_1137' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000197
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000197_1137: Committed. Elapsed time: 1 ms.
25/02/04 17:14:20 INFO Executor: Finished task 197.0 in stage 68.0 (TID 1137). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 197.0 in stage 68.0 (TID 1137) in 291 ms on 10.0.0.43 (executor driver) (194/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000191_1131' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000191
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000191_1131: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 191.0 in stage 68.0 (TID 1131). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000190_1130' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000190
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000190_1130: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 190.0 in stage 68.0 (TID 1130). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 191.0 in stage 68.0 (TID 1131) in 327 ms on 10.0.0.43 (executor driver) (195/200)
25/02/04 17:14:20 INFO TaskSetManager: Finished task 190.0 in stage 68.0 (TID 1130) in 329 ms on 10.0.0.43 (executor driver) (196/200)
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "Plays",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 new_userId;
  required int32 new_songId;
  optional int32 Plays;
}

       
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000196_1136' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000196
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000196_1136: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 196.0 in stage 68.0 (TID 1136). 18040 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 196.0 in stage 68.0 (TID 1136) in 362 ms on 10.0.0.43 (executor driver) (197/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000189_1129' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000189
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000189_1129: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 189.0 in stage 68.0 (TID 1129). 18040 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 189.0 in stage 68.0 (TID 1129) in 439 ms on 10.0.0.43 (executor driver) (198/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000198_1138' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000198
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000198_1138: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 198.0 in stage 68.0 (TID 1138). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 198.0 in stage 68.0 (TID 1138) in 174 ms on 10.0.0.43 (executor driver) (199/200)
25/02/04 17:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714118896838600511385937_0068_m_000199_1139' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/test/_temporary/0/task_202502041714118896838600511385937_0068_m_000199
25/02/04 17:14:20 INFO SparkHadoopMapRedUtil: attempt_202502041714118896838600511385937_0068_m_000199_1139: Committed. Elapsed time: 0 ms.
25/02/04 17:14:20 INFO Executor: Finished task 199.0 in stage 68.0 (TID 1139). 17954 bytes result sent to driver
25/02/04 17:14:20 INFO TaskSetManager: Finished task 199.0 in stage 68.0 (TID 1139) in 181 ms on 10.0.0.43 (executor driver) (200/200)
25/02/04 17:14:20 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
25/02/04 17:14:20 INFO DAGScheduler: ResultStage 68 (parquet at NativeMethodAccessorImpl.java:0) finished in 9.264 s
25/02/04 17:14:20 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:14:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
25/02/04 17:14:20 INFO DAGScheduler: Job 18 finished: parquet at NativeMethodAccessorImpl.java:0, took 9.325912 s
25/02/04 17:14:20 INFO FileFormatWriter: Start to commit write Job 90f4e9fa-3f19-4cc9-99c9-8953d2f8ee57.
25/02/04 17:14:20 INFO FileFormatWriter: Write Job 90f4e9fa-3f19-4cc9-99c9-8953d2f8ee57 committed. Elapsed time: 194 ms.
25/02/04 17:14:20 INFO FileFormatWriter: Finished processing stats for write job 90f4e9fa-3f19-4cc9-99c9-8953d2f8ee57.
25/02/04 17:14:20 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:14:20 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:14:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:21 INFO CodeGenerator: Code generated in 146.74675 ms
25/02/04 17:14:21 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 350.3 KiB, free 160.4 MiB)
25/02/04 17:14:21 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 160.4 MiB)
25/02/04 17:14:21 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.3 MiB)
25/02/04 17:14:21 INFO SparkContext: Created broadcast 28 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:14:21 INFO DAGScheduler: Registering RDD 95 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 8
25/02/04 17:14:21 INFO DAGScheduler: Got map stage job 19 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:14:21 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:21 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:14:21 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:21 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[95] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:21 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 37.1 KiB, free 160.3 MiB)
25/02/04 17:14:21 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 160.3 MiB)
25/02/04 17:14:21 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.2 MiB)
25/02/04 17:14:21 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:21 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[95] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:14:21 INFO TaskSchedulerImpl: Adding task set 69.0 with 23 tasks resource profile 0
25/02/04 17:14:21 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 1140) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 1141) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 1142) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 1143) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 1144) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 1145) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 1146) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 1147) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 1148) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 1149) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:21 INFO Executor: Running task 2.0 in stage 69.0 (TID 1142)
25/02/04 17:14:21 INFO Executor: Running task 6.0 in stage 69.0 (TID 1146)
25/02/04 17:14:21 INFO Executor: Running task 5.0 in stage 69.0 (TID 1145)
25/02/04 17:14:21 INFO Executor: Running task 4.0 in stage 69.0 (TID 1144)
25/02/04 17:14:21 INFO Executor: Running task 1.0 in stage 69.0 (TID 1141)
25/02/04 17:14:21 INFO Executor: Running task 0.0 in stage 69.0 (TID 1140)
25/02/04 17:14:21 INFO Executor: Running task 3.0 in stage 69.0 (TID 1143)
25/02/04 17:14:21 INFO Executor: Running task 9.0 in stage 69.0 (TID 1149)
25/02/04 17:14:21 INFO Executor: Running task 7.0 in stage 69.0 (TID 1147)
25/02/04 17:14:21 INFO Executor: Running task 8.0 in stage 69.0 (TID 1148)
25/02/04 17:14:21 INFO CodeGenerator: Code generated in 49.578333 ms
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:14:21 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:14:22 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.0.43:62420 on disk (size: 113.3 KiB)
25/02/04 17:14:28 INFO Executor: Finished task 8.0 in stage 69.0 (TID 1148). 2805 bytes result sent to driver
25/02/04 17:14:28 INFO Executor: Finished task 9.0 in stage 69.0 (TID 1149). 2805 bytes result sent to driver
25/02/04 17:14:28 INFO Executor: Finished task 0.0 in stage 69.0 (TID 1140). 2805 bytes result sent to driver
25/02/04 17:14:28 INFO Executor: Finished task 3.0 in stage 69.0 (TID 1143). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO Executor: Finished task 5.0 in stage 69.0 (TID 1145). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Starting task 10.0 in stage 69.0 (TID 1150) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO TaskSetManager: Starting task 11.0 in stage 69.0 (TID 1151) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO Executor: Running task 10.0 in stage 69.0 (TID 1150)
25/02/04 17:14:28 INFO TaskSetManager: Starting task 12.0 in stage 69.0 (TID 1152) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO TaskSetManager: Starting task 13.0 in stage 69.0 (TID 1153) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO TaskSetManager: Starting task 14.0 in stage 69.0 (TID 1154) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO Executor: Running task 13.0 in stage 69.0 (TID 1153)
25/02/04 17:14:28 INFO Executor: Running task 12.0 in stage 69.0 (TID 1152)
25/02/04 17:14:28 INFO Executor: Running task 14.0 in stage 69.0 (TID 1154)
25/02/04 17:14:28 INFO Executor: Running task 11.0 in stage 69.0 (TID 1151)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 1148) in 7210 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 1143) in 7211 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 1149) in 7210 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 1140) in 7213 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:14:28 INFO Executor: Finished task 1.0 in stage 69.0 (TID 1141). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 1145) in 7212 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:14:28 INFO TaskSetManager: Starting task 15.0 in stage 69.0 (TID 1155) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO Executor: Running task 15.0 in stage 69.0 (TID 1155)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 1141) in 7215 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:14:28 INFO Executor: Finished task 6.0 in stage 69.0 (TID 1146). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Starting task 16.0 in stage 69.0 (TID 1156) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 1146) in 7214 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:14:28 INFO Executor: Running task 16.0 in stage 69.0 (TID 1156)
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:14:28 INFO Executor: Finished task 2.0 in stage 69.0 (TID 1142). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Starting task 17.0 in stage 69.0 (TID 1157) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO Executor: Running task 17.0 in stage 69.0 (TID 1157)
25/02/04 17:14:28 INFO Executor: Finished task 7.0 in stage 69.0 (TID 1147). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Starting task 18.0 in stage 69.0 (TID 1158) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 1142) in 7245 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:14:28 INFO Executor: Running task 18.0 in stage 69.0 (TID 1158)
25/02/04 17:14:28 INFO Executor: Finished task 4.0 in stage 69.0 (TID 1144). 2762 bytes result sent to driver
25/02/04 17:14:28 INFO TaskSetManager: Starting task 19.0 in stage 69.0 (TID 1159) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:28 INFO Executor: Running task 19.0 in stage 69.0 (TID 1159)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 1147) in 7244 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:14:28 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 1144) in 7244 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:14:28 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:14:32 INFO Executor: Finished task 16.0 in stage 69.0 (TID 1156). 2719 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 11.0 in stage 69.0 (TID 1151). 2805 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 18.0 in stage 69.0 (TID 1158). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 17.0 in stage 69.0 (TID 1157). 2805 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 14.0 in stage 69.0 (TID 1154). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 19.0 in stage 69.0 (TID 1159). 2719 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 15.0 in stage 69.0 (TID 1155). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 12.0 in stage 69.0 (TID 1152). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 10.0 in stage 69.0 (TID 1150). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO Executor: Finished task 13.0 in stage 69.0 (TID 1153). 2762 bytes result sent to driver
25/02/04 17:14:32 INFO TaskSetManager: Starting task 20.0 in stage 69.0 (TID 1160) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:32 INFO Executor: Running task 20.0 in stage 69.0 (TID 1160)
25/02/04 17:14:32 INFO TaskSetManager: Starting task 21.0 in stage 69.0 (TID 1161) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:32 INFO Executor: Running task 21.0 in stage 69.0 (TID 1161)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 18.0 in stage 69.0 (TID 1158) in 4278 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:14:32 INFO TaskSetManager: Starting task 22.0 in stage 69.0 (TID 1162) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:32 INFO TaskSetManager: Finished task 16.0 in stage 69.0 (TID 1156) in 4311 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:14:32 INFO Executor: Running task 22.0 in stage 69.0 (TID 1162)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 19.0 in stage 69.0 (TID 1159) in 4286 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 11.0 in stage 69.0 (TID 1151) in 4431 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 14.0 in stage 69.0 (TID 1154) in 4426 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 15.0 in stage 69.0 (TID 1155) in 4318 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 10.0 in stage 69.0 (TID 1150) in 4453 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 17.0 in stage 69.0 (TID 1157) in 4288 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 13.0 in stage 69.0 (TID 1153) in 4429 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:14:32 INFO TaskSetManager: Finished task 12.0 in stage 69.0 (TID 1152) in 4431 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:14:32 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:14:32 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:14:32 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:14:33 INFO Executor: Finished task 22.0 in stage 69.0 (TID 1162). 2805 bytes result sent to driver
25/02/04 17:14:33 INFO TaskSetManager: Finished task 22.0 in stage 69.0 (TID 1162) in 993 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:14:35 INFO Executor: Finished task 21.0 in stage 69.0 (TID 1161). 2762 bytes result sent to driver
25/02/04 17:14:35 INFO TaskSetManager: Finished task 21.0 in stage 69.0 (TID 1161) in 2411 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:14:35 INFO Executor: Finished task 20.0 in stage 69.0 (TID 1160). 2762 bytes result sent to driver
25/02/04 17:14:35 INFO TaskSetManager: Finished task 20.0 in stage 69.0 (TID 1160) in 2426 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
25/02/04 17:14:35 INFO DAGScheduler: ShuffleMapStage 69 (parquet at NativeMethodAccessorImpl.java:0) finished in 13.952 s
25/02/04 17:14:35 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:14:35 INFO DAGScheduler: running: Set()
25/02/04 17:14:35 INFO DAGScheduler: waiting: Set()
25/02/04 17:14:35 INFO DAGScheduler: failed: Set()
25/02/04 17:14:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:35 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 4576237, minimum partition size: 1048576
25/02/04 17:14:35 INFO CodeGenerator: Code generated in 147.968625 ms
25/02/04 17:14:35 INFO DAGScheduler: Registering RDD 98 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 9
25/02/04 17:14:35 INFO DAGScheduler: Got map stage job 20 (parquet at NativeMethodAccessorImpl.java:0) with 10 output partitions
25/02/04 17:14:35 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
25/02/04 17:14:35 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:35 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[98] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:35 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 43.4 KiB, free 160.3 MiB)
25/02/04 17:14:35 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 160.3 MiB)
25/02/04 17:14:35 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:14:35 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[98] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/02/04 17:14:35 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
25/02/04 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 1163) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 1164) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 1165) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 1166) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 1167) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 1168) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 1169) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 1170) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 1171) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 1172) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:35 INFO Executor: Running task 5.0 in stage 71.0 (TID 1168)
25/02/04 17:14:35 INFO Executor: Running task 2.0 in stage 71.0 (TID 1165)
25/02/04 17:14:35 INFO Executor: Running task 4.0 in stage 71.0 (TID 1167)
25/02/04 17:14:35 INFO Executor: Running task 1.0 in stage 71.0 (TID 1164)
25/02/04 17:14:35 INFO Executor: Running task 7.0 in stage 71.0 (TID 1170)
25/02/04 17:14:35 INFO Executor: Running task 9.0 in stage 71.0 (TID 1172)
25/02/04 17:14:35 INFO Executor: Running task 8.0 in stage 71.0 (TID 1171)
25/02/04 17:14:35 INFO Executor: Running task 0.0 in stage 71.0 (TID 1163)
25/02/04 17:14:35 INFO Executor: Running task 3.0 in stage 71.0 (TID 1166)
25/02/04 17:14:35 INFO Executor: Running task 6.0 in stage 71.0 (TID 1169)
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.3 MiB) non-empty blocks including 23 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.2 MiB) non-empty blocks including 23 (4.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.4 MiB) non-empty blocks including 23 (4.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (5.2 MiB) non-empty blocks including 23 (5.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 23 (4.3 MiB) non-empty blocks including 23 (4.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:14:35 INFO CodeGenerator: Code generated in 44.347458 ms
25/02/04 17:14:36 INFO Executor: Finished task 2.0 in stage 71.0 (TID 1165). 5342 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 5.0 in stage 71.0 (TID 1168). 5342 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 8.0 in stage 71.0 (TID 1171). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 0.0 in stage 71.0 (TID 1163). 5342 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 7.0 in stage 71.0 (TID 1170). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 1.0 in stage 71.0 (TID 1164). 5342 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 4.0 in stage 71.0 (TID 1167). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 6.0 in stage 71.0 (TID 1169). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO Executor: Finished task 3.0 in stage 71.0 (TID 1166). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 1168) in 726 ms on 10.0.0.43 (executor driver) (1/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 1165) in 727 ms on 10.0.0.43 (executor driver) (2/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 1170) in 726 ms on 10.0.0.43 (executor driver) (3/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 1164) in 728 ms on 10.0.0.43 (executor driver) (4/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 1167) in 728 ms on 10.0.0.43 (executor driver) (5/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 1171) in 727 ms on 10.0.0.43 (executor driver) (6/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 1166) in 728 ms on 10.0.0.43 (executor driver) (7/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 1169) in 728 ms on 10.0.0.43 (executor driver) (8/10)
25/02/04 17:14:36 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 1163) in 735 ms on 10.0.0.43 (executor driver) (9/10)
25/02/04 17:14:36 INFO Executor: Finished task 9.0 in stage 71.0 (TID 1172). 5299 bytes result sent to driver
25/02/04 17:14:36 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 1172) in 732 ms on 10.0.0.43 (executor driver) (10/10)
25/02/04 17:14:36 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
25/02/04 17:14:36 INFO DAGScheduler: ShuffleMapStage 71 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.777 s
25/02/04 17:14:36 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:14:36 INFO DAGScheduler: running: Set()
25/02/04 17:14:36 INFO DAGScheduler: waiting: Set()
25/02/04 17:14:36 INFO DAGScheduler: failed: Set()
25/02/04 17:14:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:36 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:36 INFO CodeGenerator: Code generated in 38.219291 ms
25/02/04 17:14:36 INFO CodeGenerator: Code generated in 18.490917 ms
25/02/04 17:14:36 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:36 INFO DAGScheduler: Got job 21 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:14:36 INFO DAGScheduler: Final stage: ResultStage 74 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
25/02/04 17:14:36 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:36 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[103] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:36 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 246.1 KiB, free 160.0 MiB)
25/02/04 17:14:36 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 91.3 KiB, free 159.9 MiB)
25/02/04 17:14:36 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.0.43:62420 (size: 91.3 KiB, free: 366.1 MiB)
25/02/04 17:14:36 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[103] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:14:36 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
25/02/04 17:14:36 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 1173) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
25/02/04 17:14:36 INFO Executor: Running task 0.0 in stage 74.0 (TID 1173)
25/02/04 17:14:36 INFO ShuffleBlockFetcherIterator: Getting 10 (42.9 MiB) non-empty blocks including 10 (42.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:14:36 INFO CodeGenerator: Code generated in 19.448917 ms
25/02/04 17:14:37 INFO CodeGenerator: Code generated in 6.711209 ms
25/02/04 17:14:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:37 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "userId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_userId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary userId (STRING);
  required int32 new_userId;
}

       
25/02/04 17:14:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:14:37 INFO MemoryStore: 20 blocks selected for dropping (23.3 MiB bytes)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_20 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_20 on disk on 10.0.0.43:62420 (current size: 1080.3 KiB, original size: 1080.3 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_22 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_22 on disk on 10.0.0.43:62420 (current size: 1206.1 KiB, original size: 1206.1 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_26 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_26 on disk on 10.0.0.43:62420 (current size: 1185.0 KiB, original size: 1185.0 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_25 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_25 on disk on 10.0.0.43:62420 (current size: 930.4 KiB, original size: 930.4 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_30 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_30 on disk on 10.0.0.43:62420 (current size: 1269.9 KiB, original size: 1269.9 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_28 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_28 on disk on 10.0.0.43:62420 (current size: 1014.4 KiB, original size: 1014.4 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_29 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_29 on disk on 10.0.0.43:62420 (current size: 1303.4 KiB, original size: 1303.4 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_27 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_27 on disk on 10.0.0.43:62420 (current size: 811.7 KiB, original size: 811.7 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_33 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_33 on disk on 10.0.0.43:62420 (current size: 1002.7 KiB, original size: 1002.7 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_31 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_31 on disk on 10.0.0.43:62420 (current size: 1153.2 KiB, original size: 1153.2 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_32 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_32 on disk on 10.0.0.43:62420 (current size: 1224.7 KiB, original size: 1224.7 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_34 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_34 on disk on 10.0.0.43:62420 (current size: 1065.7 KiB, original size: 1065.7 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_36 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_36 on disk on 10.0.0.43:62420 (current size: 1002.0 KiB, original size: 1002.0 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_38 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_38 on disk on 10.0.0.43:62420 (current size: 1049.2 KiB, original size: 1049.2 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_37 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_37 on disk on 10.0.0.43:62420 (current size: 1156.5 KiB, original size: 1156.5 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_35 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_35 on disk on 10.0.0.43:62420 (current size: 1036.4 KiB, original size: 1036.4 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_39 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_39 on disk on 10.0.0.43:62420 (current size: 1210.6 KiB, original size: 1210.6 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_43 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_43 on disk on 10.0.0.43:62420 (current size: 1189.7 KiB, original size: 1189.7 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_41 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_41 on disk on 10.0.0.43:62420 (current size: 1165.3 KiB, original size: 1165.3 KiB)
25/02/04 17:14:37 INFO BlockManager: Dropping block rdd_72_42 from memory
25/02/04 17:14:37 INFO BlockManagerInfo: Updated rdd_72_42 on disk on 10.0.0.43:62420 (current size: 1453.8 KiB, original size: 1453.8 KiB)
25/02/04 17:14:37 INFO MemoryStore: After dropping 20 blocks, free memory is 33.2 MiB
25/02/04 17:14:37 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.0.43:62420 in memory (size: 17.4 KiB, free: 366.2 MiB)
25/02/04 17:14:37 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:14:38 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714362152333975692652797_0074_m_000000_1173' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/users/_temporary/0/task_202502041714362152333975692652797_0074_m_000000
25/02/04 17:14:38 INFO SparkHadoopMapRedUtil: attempt_202502041714362152333975692652797_0074_m_000000_1173: Committed. Elapsed time: 3 ms.
25/02/04 17:14:38 INFO Executor: Finished task 0.0 in stage 74.0 (TID 1173). 7847 bytes result sent to driver
25/02/04 17:14:38 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 1173) in 1879 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:14:38 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
25/02/04 17:14:38 INFO DAGScheduler: ResultStage 74 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.948 s
25/02/04 17:14:38 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:14:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
25/02/04 17:14:38 INFO DAGScheduler: Job 21 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.985197 s
25/02/04 17:14:38 INFO FileFormatWriter: Start to commit write Job 92f42309-c2cf-4961-9d5b-b5019c6e2249.
25/02/04 17:14:38 INFO FileFormatWriter: Write Job 92f42309-c2cf-4961-9d5b-b5019c6e2249 committed. Elapsed time: 37 ms.
25/02/04 17:14:38 INFO FileFormatWriter: Finished processing stats for write job 92f42309-c2cf-4961-9d5b-b5019c6e2249.
25/02/04 17:14:38 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:14:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:14:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:39 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 350.3 KiB, free 183.0 MiB)
25/02/04 17:14:39 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 183.0 MiB)
25/02/04 17:14:39 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:14:39 INFO SparkContext: Created broadcast 32 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:14:39 INFO DAGScheduler: Registering RDD 107 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 10
25/02/04 17:14:39 INFO DAGScheduler: Got map stage job 22 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:14:39 INFO DAGScheduler: Final stage: ShuffleMapStage 75 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:39 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:14:39 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:39 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[107] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:39 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 37.1 KiB, free 182.9 MiB)
25/02/04 17:14:39 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 182.9 MiB)
25/02/04 17:14:39 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:14:39 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:39 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[107] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:14:39 INFO TaskSchedulerImpl: Adding task set 75.0 with 23 tasks resource profile 0
25/02/04 17:14:39 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 1174) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 1175) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 1176) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 1177) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 1178) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 1179) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 1180) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 1181) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 8.0 in stage 75.0 (TID 1182) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO TaskSetManager: Starting task 9.0 in stage 75.0 (TID 1183) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:39 INFO Executor: Running task 6.0 in stage 75.0 (TID 1180)
25/02/04 17:14:39 INFO Executor: Running task 3.0 in stage 75.0 (TID 1177)
25/02/04 17:14:39 INFO Executor: Running task 9.0 in stage 75.0 (TID 1183)
25/02/04 17:14:39 INFO Executor: Running task 8.0 in stage 75.0 (TID 1182)
25/02/04 17:14:39 INFO Executor: Running task 4.0 in stage 75.0 (TID 1178)
25/02/04 17:14:39 INFO Executor: Running task 7.0 in stage 75.0 (TID 1181)
25/02/04 17:14:39 INFO Executor: Running task 1.0 in stage 75.0 (TID 1175)
25/02/04 17:14:39 INFO Executor: Running task 0.0 in stage 75.0 (TID 1174)
25/02/04 17:14:39 INFO Executor: Running task 5.0 in stage 75.0 (TID 1179)
25/02/04 17:14:39 INFO Executor: Running task 2.0 in stage 75.0 (TID 1176)
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:14:39 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1181
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@704026a9: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@91635bb: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1181 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1178
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@7cd32ec0: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@79f7db1c: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1178 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1182
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1179
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5348efb0: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@234e8545: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1179 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 155849850 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1180
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@184b6e9f: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@428ea6bb: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1180 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 151325245 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5268a958: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@1f7dda5f: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1182 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 151325245 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1174
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@488c1a8e: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@4c3de0e: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1174 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1177
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@73a9c728: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@2ad0d7ea: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1177 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1176
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4a4c7008: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@55198db5: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1176 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1175
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@c04a5e2: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@5244c7ba: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1175 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:42 INFO TaskMemoryManager: Memory used in task 1183
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@3eac345f: 2.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@4ebfae76: 12.0 MiB
25/02/04 17:14:42 INFO TaskMemoryManager: 0 bytes of memory were used by task 1183 but are not associated with specific consumers
25/02/04 17:14:42 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 192293158 bytes of memory are used for storage
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:42 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:44 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:45 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:45 INFO CodeGenerator: Code generated in 149.180459 ms
25/02/04 17:14:46 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:14:46 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.0.43:62420 in memory (size: 91.3 KiB, free: 366.2 MiB)
25/02/04 17:14:46 INFO Executor: Finished task 0.0 in stage 75.0 (TID 1174). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 3.0 in stage 75.0 (TID 1177). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 2.0 in stage 75.0 (TID 1176). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 1.0 in stage 75.0 (TID 1175). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 7.0 in stage 75.0 (TID 1181). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 8.0 in stage 75.0 (TID 1182). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 9.0 in stage 75.0 (TID 1183). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 4.0 in stage 75.0 (TID 1178). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 6.0 in stage 75.0 (TID 1180). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO Executor: Finished task 5.0 in stage 75.0 (TID 1179). 2891 bytes result sent to driver
25/02/04 17:14:46 INFO TaskSetManager: Starting task 10.0 in stage 75.0 (TID 1184) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 10.0 in stage 75.0 (TID 1184)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 11.0 in stage 75.0 (TID 1185) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 11.0 in stage 75.0 (TID 1185)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 12.0 in stage 75.0 (TID 1186) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 12.0 in stage 75.0 (TID 1186)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 13.0 in stage 75.0 (TID 1187) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO TaskSetManager: Starting task 14.0 in stage 75.0 (TID 1188) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 13.0 in stage 75.0 (TID 1187)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 15.0 in stage 75.0 (TID 1189) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 14.0 in stage 75.0 (TID 1188)
25/02/04 17:14:46 INFO Executor: Running task 15.0 in stage 75.0 (TID 1189)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 16.0 in stage 75.0 (TID 1190) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO TaskSetManager: Starting task 17.0 in stage 75.0 (TID 1191) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 16.0 in stage 75.0 (TID 1190)
25/02/04 17:14:46 INFO Executor: Running task 17.0 in stage 75.0 (TID 1191)
25/02/04 17:14:46 INFO TaskSetManager: Starting task 18.0 in stage 75.0 (TID 1192) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO TaskSetManager: Starting task 19.0 in stage 75.0 (TID 1193) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:46 INFO Executor: Running task 18.0 in stage 75.0 (TID 1192)
25/02/04 17:14:46 INFO Executor: Running task 19.0 in stage 75.0 (TID 1193)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 1175) in 7815 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 1176) in 7816 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 1181) in 7815 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 9.0 in stage 75.0 (TID 1183) in 7815 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 1177) in 7820 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 1174) in 7828 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 8.0 in stage 75.0 (TID 1182) in 7822 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 1180) in 7822 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 1178) in 7822 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:14:46 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 1179) in 7822 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:14:47 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1188
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@6b2d7cf9: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@317b7fe1: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1188 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1189
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4a1f46fb: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@3bc4f5ac: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1189 but are not associated with specific consumers
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1185
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4b7a312: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@6669fb36: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1185 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1187
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@5b45d753: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5a05fb33: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1187 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1193
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@cae808: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@3d1f4f75: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1193 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1186
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1191
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1192
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@6642ea2f: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@39be10c: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4caaf4f6: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@5033502c: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@37b648eb: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@10ebb995: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1186 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1192 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1191 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1190
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@43c51df1: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4cda3006: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1190 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:14:50 INFO TaskMemoryManager: Memory used in task 1184
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@1717ddf6: 12.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@32eadb67: 2.0 MiB
25/02/04 17:14:50 INFO TaskMemoryManager: 0 bytes of memory were used by task 1184 but are not associated with specific consumers
25/02/04 17:14:50 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191553753 bytes of memory are used for storage
25/02/04 17:14:50 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:52 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:14:53 INFO Executor: Finished task 16.0 in stage 75.0 (TID 1190). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 11.0 in stage 75.0 (TID 1185). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 19.0 in stage 75.0 (TID 1193). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 15.0 in stage 75.0 (TID 1189). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 12.0 in stage 75.0 (TID 1186). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 14.0 in stage 75.0 (TID 1188). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 17.0 in stage 75.0 (TID 1191). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 18.0 in stage 75.0 (TID 1192). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 10.0 in stage 75.0 (TID 1184). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO Executor: Finished task 13.0 in stage 75.0 (TID 1187). 2891 bytes result sent to driver
25/02/04 17:14:53 INFO TaskSetManager: Starting task 20.0 in stage 75.0 (TID 1194) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:53 INFO Executor: Running task 20.0 in stage 75.0 (TID 1194)
25/02/04 17:14:53 INFO TaskSetManager: Starting task 21.0 in stage 75.0 (TID 1195) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:53 INFO Executor: Running task 21.0 in stage 75.0 (TID 1195)
25/02/04 17:14:53 INFO TaskSetManager: Starting task 22.0 in stage 75.0 (TID 1196) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:53 INFO Executor: Running task 22.0 in stage 75.0 (TID 1196)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 16.0 in stage 75.0 (TID 1190) in 6526 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 11.0 in stage 75.0 (TID 1185) in 6540 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 19.0 in stage 75.0 (TID 1193) in 6528 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 15.0 in stage 75.0 (TID 1189) in 6530 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 10.0 in stage 75.0 (TID 1184) in 6584 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 12.0 in stage 75.0 (TID 1186) in 6557 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 13.0 in stage 75.0 (TID 1187) in 6554 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 14.0 in stage 75.0 (TID 1188) in 6551 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 17.0 in stage 75.0 (TID 1191) in 6551 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:14:53 INFO TaskSetManager: Finished task 18.0 in stage 75.0 (TID 1192) in 6551 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:14:53 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:14:53 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:14:53 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:14:54 INFO Executor: Finished task 22.0 in stage 75.0 (TID 1196). 2762 bytes result sent to driver
25/02/04 17:14:54 INFO TaskSetManager: Finished task 22.0 in stage 75.0 (TID 1196) in 1259 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:14:56 INFO Executor: Finished task 21.0 in stage 75.0 (TID 1195). 2762 bytes result sent to driver
25/02/04 17:14:56 INFO TaskSetManager: Finished task 21.0 in stage 75.0 (TID 1195) in 2825 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:14:56 INFO Executor: Finished task 20.0 in stage 75.0 (TID 1194). 2762 bytes result sent to driver
25/02/04 17:14:56 INFO TaskSetManager: Finished task 20.0 in stage 75.0 (TID 1194) in 2862 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:14:56 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
25/02/04 17:14:56 INFO DAGScheduler: ShuffleMapStage 75 (parquet at NativeMethodAccessorImpl.java:0) finished in 17.163 s
25/02/04 17:14:56 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:14:56 INFO DAGScheduler: running: Set()
25/02/04 17:14:56 INFO DAGScheduler: waiting: Set()
25/02/04 17:14:56 INFO DAGScheduler: failed: Set()
25/02/04 17:14:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:56 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 7390524, minimum partition size: 1048576
25/02/04 17:14:56 INFO DAGScheduler: Registering RDD 110 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 11
25/02/04 17:14:56 INFO DAGScheduler: Got map stage job 23 (parquet at NativeMethodAccessorImpl.java:0) with 11 output partitions
25/02/04 17:14:56 INFO DAGScheduler: Final stage: ShuffleMapStage 77 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
25/02/04 17:14:56 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:56 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[110] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:56 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 43.4 KiB, free 183.6 MiB)
25/02/04 17:14:56 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 183.6 MiB)
25/02/04 17:14:56 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:14:56 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:56 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[110] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/02/04 17:14:56 INFO TaskSchedulerImpl: Adding task set 77.0 with 11 tasks resource profile 0
25/02/04 17:14:56 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 1197) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 1198) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 1199) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 1200) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 1201) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 1202) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 1203) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 1204) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 1205) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 1206) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO Executor: Running task 1.0 in stage 77.0 (TID 1198)
25/02/04 17:14:56 INFO Executor: Running task 4.0 in stage 77.0 (TID 1201)
25/02/04 17:14:56 INFO Executor: Running task 9.0 in stage 77.0 (TID 1206)
25/02/04 17:14:56 INFO Executor: Running task 8.0 in stage 77.0 (TID 1205)
25/02/04 17:14:56 INFO Executor: Running task 0.0 in stage 77.0 (TID 1197)
25/02/04 17:14:56 INFO Executor: Running task 3.0 in stage 77.0 (TID 1200)
25/02/04 17:14:56 INFO Executor: Running task 5.0 in stage 77.0 (TID 1202)
25/02/04 17:14:56 INFO Executor: Running task 7.0 in stage 77.0 (TID 1204)
25/02/04 17:14:56 INFO Executor: Running task 2.0 in stage 77.0 (TID 1199)
25/02/04 17:14:56 INFO Executor: Running task 6.0 in stage 77.0 (TID 1203)
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:14:56 INFO Executor: Finished task 4.0 in stage 77.0 (TID 1201). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 5.0 in stage 77.0 (TID 1202). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 7.0 in stage 77.0 (TID 1204). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 3.0 in stage 77.0 (TID 1200). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 0.0 in stage 77.0 (TID 1197). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 9.0 in stage 77.0 (TID 1206). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 8.0 in stage 77.0 (TID 1205). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 1.0 in stage 77.0 (TID 1198). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 6.0 in stage 77.0 (TID 1203). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO Executor: Finished task 2.0 in stage 77.0 (TID 1199). 5299 bytes result sent to driver
25/02/04 17:14:56 INFO TaskSetManager: Starting task 10.0 in stage 77.0 (TID 1207) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 8988 bytes) 
25/02/04 17:14:56 INFO Executor: Running task 10.0 in stage 77.0 (TID 1207)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 1202) in 331 ms on 10.0.0.43 (executor driver) (1/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 1197) in 341 ms on 10.0.0.43 (executor driver) (2/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 1206) in 333 ms on 10.0.0.43 (executor driver) (3/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 1198) in 339 ms on 10.0.0.43 (executor driver) (4/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 1200) in 339 ms on 10.0.0.43 (executor driver) (5/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 1204) in 334 ms on 10.0.0.43 (executor driver) (6/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 1201) in 339 ms on 10.0.0.43 (executor driver) (7/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 1205) in 334 ms on 10.0.0.43 (executor driver) (8/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 1203) in 334 ms on 10.0.0.43 (executor driver) (9/11)
25/02/04 17:14:56 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 1199) in 339 ms on 10.0.0.43 (executor driver) (10/11)
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Getting 23 (1449.7 KiB) non-empty blocks including 23 (1449.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:14:56 INFO Executor: Finished task 10.0 in stage 77.0 (TID 1207). 5256 bytes result sent to driver
25/02/04 17:14:56 INFO TaskSetManager: Finished task 10.0 in stage 77.0 (TID 1207) in 41 ms on 10.0.0.43 (executor driver) (11/11)
25/02/04 17:14:56 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
25/02/04 17:14:56 INFO DAGScheduler: ShuffleMapStage 77 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.414 s
25/02/04 17:14:56 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:14:56 INFO DAGScheduler: running: Set()
25/02/04 17:14:56 INFO DAGScheduler: waiting: Set()
25/02/04 17:14:56 INFO DAGScheduler: failed: Set()
25/02/04 17:14:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:56 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:57 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:57 INFO DAGScheduler: Got job 24 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:14:57 INFO DAGScheduler: Final stage: ResultStage 80 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
25/02/04 17:14:57 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:57 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[115] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 246.2 KiB, free 183.3 MiB)
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 91.3 KiB, free 183.2 MiB)
25/02/04 17:14:57 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.0.43:62420 (size: 91.3 KiB, free: 366.1 MiB)
25/02/04 17:14:57 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[115] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:14:57 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
25/02/04 17:14:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:14:57 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 1208) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
25/02/04 17:14:57 INFO Executor: Running task 0.0 in stage 80.0 (TID 1208)
25/02/04 17:14:57 INFO ShuffleBlockFetcherIterator: Getting 11 (5.9 MiB) non-empty blocks including 11 (5.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:14:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:14:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:14:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:14:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:14:57 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:57 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:14:57 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:14:57 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  required int32 new_songId;
}

       
25/02/04 17:14:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:14:57 INFO FileOutputCommitter: Saved output of task 'attempt_202502041714571552038138910152008_0080_m_000000_1208' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/items/_temporary/0/task_202502041714571552038138910152008_0080_m_000000
25/02/04 17:14:57 INFO SparkHadoopMapRedUtil: attempt_202502041714571552038138910152008_0080_m_000000_1208: Committed. Elapsed time: 0 ms.
25/02/04 17:14:57 INFO Executor: Finished task 0.0 in stage 80.0 (TID 1208). 7675 bytes result sent to driver
25/02/04 17:14:57 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 1208) in 452 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:14:57 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
25/02/04 17:14:57 INFO DAGScheduler: ResultStage 80 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.501 s
25/02/04 17:14:57 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:14:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
25/02/04 17:14:57 INFO DAGScheduler: Job 24 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.504518 s
25/02/04 17:14:57 INFO FileFormatWriter: Start to commit write Job 7194f981-172b-4ce4-b398-b0679406313b.
25/02/04 17:14:57 INFO FileFormatWriter: Write Job 7194f981-172b-4ce4-b398-b0679406313b committed. Elapsed time: 25 ms.
25/02/04 17:14:57 INFO FileFormatWriter: Finished processing stats for write job 7194f981-172b-4ce4-b398-b0679406313b.
25/02/04 17:14:57 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:14:57 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:14:57 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:14:57 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:14:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:57 INFO CodeGenerator: Code generated in 121.362333 ms
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 350.3 KiB, free 182.9 MiB)
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 182.9 MiB)
25/02/04 17:14:57 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:14:57 INFO SparkContext: Created broadcast 36 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:14:57 INFO DAGScheduler: Registering RDD 119 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 12
25/02/04 17:14:57 INFO DAGScheduler: Got map stage job 25 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/02/04 17:14:57 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:57 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:14:57 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:57 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[119] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 17.3 KiB, free 182.9 MiB)
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 182.9 MiB)
25/02/04 17:14:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.0.43:62420 (size: 8.5 KiB, free: 366.1 MiB)
25/02/04 17:14:57 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[119] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/02/04 17:14:57 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks resource profile 0
25/02/04 17:14:57 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 1209) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9638 bytes) 
25/02/04 17:14:57 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 1210) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9638 bytes) 
25/02/04 17:14:57 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 1211) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9638 bytes) 
25/02/04 17:14:57 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 1212) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9638 bytes) 
25/02/04 17:14:57 INFO Executor: Running task 2.0 in stage 81.0 (TID 1211)
25/02/04 17:14:57 INFO Executor: Running task 1.0 in stage 81.0 (TID 1210)
25/02/04 17:14:57 INFO Executor: Running task 3.0 in stage 81.0 (TID 1212)
25/02/04 17:14:57 INFO Executor: Running task 0.0 in stage 81.0 (TID 1209)
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 350.3 KiB, free 182.5 MiB)
25/02/04 17:14:57 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 182.5 MiB)
25/02/04 17:14:57 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:14:57 INFO SparkContext: Created broadcast 38 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:14:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:14:57 INFO CodeGenerator: Code generated in 23.634 ms
25/02/04 17:14:57 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 0-4194304, partition values: [empty row]
25/02/04 17:14:57 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 8388608-12582912, partition values: [empty row]
25/02/04 17:14:57 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 12582912-14644326, partition values: [empty row]
25/02/04 17:14:57 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/taste_profile_song_to_tracks.txt, range: 4194304-8388608, partition values: [empty row]
25/02/04 17:14:58 INFO DAGScheduler: Registering RDD 123 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 13
25/02/04 17:14:58 INFO DAGScheduler: Got map stage job 26 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:14:58 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:14:58 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:14:58 INFO DAGScheduler: Missing parents: List()
25/02/04 17:14:58 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[123] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:14:58 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 37.1 KiB, free 182.5 MiB)
25/02/04 17:14:58 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 182.5 MiB)
25/02/04 17:14:58 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:14:58 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585
25/02/04 17:14:58 INFO CodeGenerator: Code generated in 20.960584 ms
25/02/04 17:14:58 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[123] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:14:58 INFO TaskSchedulerImpl: Adding task set 82.0 with 23 tasks resource profile 0
25/02/04 17:14:58 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 1213) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 1214) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 1215) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 1216) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 1217) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO TaskSetManager: Starting task 5.0 in stage 82.0 (TID 1218) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:58 INFO Executor: Running task 0.0 in stage 82.0 (TID 1213)
25/02/04 17:14:58 INFO Executor: Running task 1.0 in stage 82.0 (TID 1214)
25/02/04 17:14:58 INFO Executor: Running task 2.0 in stage 82.0 (TID 1215)
25/02/04 17:14:58 INFO Executor: Running task 4.0 in stage 82.0 (TID 1217)
25/02/04 17:14:58 INFO Executor: Running task 5.0 in stage 82.0 (TID 1218)
25/02/04 17:14:58 INFO Executor: Running task 3.0 in stage 82.0 (TID 1216)
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:14:58 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:14:58 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.0.43:62420 in memory (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:14:58 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:14:58 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.0.43:62420 in memory (size: 91.3 KiB, free: 366.2 MiB)
25/02/04 17:14:59 INFO Executor: Finished task 3.0 in stage 81.0 (TID 1212). 2072 bytes result sent to driver
25/02/04 17:14:59 INFO TaskSetManager: Starting task 6.0 in stage 82.0 (TID 1219) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:59 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 1212) in 1277 ms on 10.0.0.43 (executor driver) (1/4)
25/02/04 17:14:59 INFO Executor: Running task 6.0 in stage 82.0 (TID 1219)
25/02/04 17:14:59 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:14:59 INFO Executor: Finished task 0.0 in stage 81.0 (TID 1209). 2072 bytes result sent to driver
25/02/04 17:14:59 INFO TaskSetManager: Starting task 7.0 in stage 82.0 (TID 1220) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:59 INFO Executor: Running task 7.0 in stage 82.0 (TID 1220)
25/02/04 17:14:59 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 1209) in 1576 ms on 10.0.0.43 (executor driver) (2/4)
25/02/04 17:14:59 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:14:59 INFO Executor: Finished task 1.0 in stage 81.0 (TID 1210). 2029 bytes result sent to driver
25/02/04 17:14:59 INFO Executor: Finished task 2.0 in stage 81.0 (TID 1211). 2029 bytes result sent to driver
25/02/04 17:14:59 INFO TaskSetManager: Starting task 8.0 in stage 82.0 (TID 1221) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:59 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 1210) in 1707 ms on 10.0.0.43 (executor driver) (3/4)
25/02/04 17:14:59 INFO Executor: Running task 8.0 in stage 82.0 (TID 1221)
25/02/04 17:14:59 INFO TaskSetManager: Starting task 9.0 in stage 82.0 (TID 1222) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:14:59 INFO Executor: Running task 9.0 in stage 82.0 (TID 1222)
25/02/04 17:14:59 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 1211) in 1714 ms on 10.0.0.43 (executor driver) (4/4)
25/02/04 17:14:59 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
25/02/04 17:14:59 INFO DAGScheduler: ShuffleMapStage 81 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.743 s
25/02/04 17:14:59 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:14:59 INFO DAGScheduler: running: Set(ShuffleMapStage 82)
25/02/04 17:14:59 INFO DAGScheduler: waiting: Set()
25/02/04 17:14:59 INFO DAGScheduler: failed: Set()
25/02/04 17:14:59 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:14:59 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:14:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:14:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:01 INFO TaskMemoryManager: Memory used in task 1213
25/02/04 17:15:01 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4ea8f6ab: 2.0 MiB
25/02/04 17:15:01 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@4a8e13eb: 12.0 MiB
25/02/04 17:15:01 INFO TaskMemoryManager: 0 bytes of memory were used by task 1213 but are not associated with specific consumers
25/02/04 17:15:01 INFO TaskMemoryManager: 138412032 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1217
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@7e434898: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@27dce0a0: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1217 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 140509184 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1215
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@2b379976: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@45a66d91: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1215 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 142606336 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1216
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@3542d832: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@302264bd: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1216 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 138412032 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1214
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@692fdde6: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@55d1e72d: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1214 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 111935488 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1218
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@1b77a1b1: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@1d5a2fe2: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1218 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 90177536 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1219
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@48f6e968: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@18c1b3ee: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1219 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 109051904 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1220
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@7946217b: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@4745bf0a: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1220 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 109051904 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1222
25/02/04 17:15:02 INFO TaskMemoryManager: Memory used in task 1221
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@304c1898: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@1e22795: 2.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@7fc84dee: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@15e5fb4b: 12.0 MiB
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1221 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 0 bytes of memory were used by task 1222 but are not associated with specific consumers
25/02/04 17:15:02 INFO TaskMemoryManager: 98566144 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO TaskMemoryManager: 98566144 bytes of memory are used for execution and 191974053 bytes of memory are used for storage
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:02 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:03 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.0.43:62420 in memory (size: 8.5 KiB, free: 366.2 MiB)
25/02/04 17:15:03 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:04 INFO Executor: Finished task 0.0 in stage 82.0 (TID 1213). 2848 bytes result sent to driver
25/02/04 17:15:04 INFO Executor: Finished task 3.0 in stage 82.0 (TID 1216). 2848 bytes result sent to driver
25/02/04 17:15:04 INFO Executor: Finished task 1.0 in stage 82.0 (TID 1214). 2848 bytes result sent to driver
25/02/04 17:15:04 INFO Executor: Finished task 4.0 in stage 82.0 (TID 1217). 2891 bytes result sent to driver
25/02/04 17:15:04 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:04 INFO TaskSetManager: Starting task 10.0 in stage 82.0 (TID 1223) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Finished task 5.0 in stage 82.0 (TID 1218). 2848 bytes result sent to driver
25/02/04 17:15:04 INFO Executor: Running task 10.0 in stage 82.0 (TID 1223)
25/02/04 17:15:04 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:04 INFO Executor: Finished task 2.0 in stage 82.0 (TID 1215). 2848 bytes result sent to driver
25/02/04 17:15:04 INFO TaskSetManager: Starting task 11.0 in stage 82.0 (TID 1224) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Running task 11.0 in stage 82.0 (TID 1224)
25/02/04 17:15:04 INFO TaskSetManager: Starting task 12.0 in stage 82.0 (TID 1225) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Running task 12.0 in stage 82.0 (TID 1225)
25/02/04 17:15:04 INFO TaskSetManager: Starting task 13.0 in stage 82.0 (TID 1226) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Running task 13.0 in stage 82.0 (TID 1226)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 1213) in 6437 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:15:04 INFO TaskSetManager: Starting task 14.0 in stage 82.0 (TID 1227) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Running task 14.0 in stage 82.0 (TID 1227)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 1217) in 6439 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 1216) in 6439 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 1214) in 6440 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 5.0 in stage 82.0 (TID 1218) in 6440 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:15:04 INFO TaskSetManager: Starting task 15.0 in stage 82.0 (TID 1228) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:04 INFO Executor: Running task 15.0 in stage 82.0 (TID 1228)
25/02/04 17:15:04 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 1215) in 6460 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:15:04 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:15:04 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:04 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:04 INFO Executor: Finished task 7.0 in stage 82.0 (TID 1220). 2891 bytes result sent to driver
25/02/04 17:15:05 INFO Executor: Finished task 6.0 in stage 82.0 (TID 1219). 2891 bytes result sent to driver
25/02/04 17:15:05 INFO TaskSetManager: Starting task 16.0 in stage 82.0 (TID 1229) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:05 INFO Executor: Finished task 9.0 in stage 82.0 (TID 1222). 2891 bytes result sent to driver
25/02/04 17:15:05 INFO Executor: Finished task 8.0 in stage 82.0 (TID 1221). 2848 bytes result sent to driver
25/02/04 17:15:05 INFO Executor: Running task 16.0 in stage 82.0 (TID 1229)
25/02/04 17:15:05 INFO TaskSetManager: Starting task 17.0 in stage 82.0 (TID 1230) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:05 INFO Executor: Running task 17.0 in stage 82.0 (TID 1230)
25/02/04 17:15:05 INFO TaskSetManager: Finished task 6.0 in stage 82.0 (TID 1219) in 5878 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:15:05 INFO TaskSetManager: Starting task 18.0 in stage 82.0 (TID 1231) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:05 INFO TaskSetManager: Finished task 7.0 in stage 82.0 (TID 1220) in 5571 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:15:05 INFO TaskSetManager: Finished task 9.0 in stage 82.0 (TID 1222) in 5432 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:15:05 INFO Executor: Running task 18.0 in stage 82.0 (TID 1231)
25/02/04 17:15:05 INFO TaskSetManager: Starting task 19.0 in stage 82.0 (TID 1232) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:05 INFO Executor: Running task 19.0 in stage 82.0 (TID 1232)
25/02/04 17:15:05 INFO TaskSetManager: Finished task 8.0 in stage 82.0 (TID 1221) in 5440 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:15:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:15:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:15:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:15:05 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:15:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:07 INFO TaskMemoryManager: Memory used in task 1224
25/02/04 17:15:07 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5ef3f862: 12.0 MiB
25/02/04 17:15:07 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@6246a6c0: 2.0 MiB
25/02/04 17:15:07 INFO TaskMemoryManager: 0 bytes of memory were used by task 1224 but are not associated with specific consumers
25/02/04 17:15:07 INFO TaskMemoryManager: 138412032 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:07 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1227
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@2411978: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@dfe7702: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1227 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 136839168 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1228
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@20a7ee8: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@2a06af8d: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1228 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 136839168 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1225
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1223
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@28e5b7d7: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@66e9fe8e: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@ab8c211: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@55010d1b: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1225 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 116916224 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1223 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 116916224 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1226
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@1145c7c5: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@31635490: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1226 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 117440512 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1230
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@42f04017: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@1f2d70e2: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1230 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 111149056 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1232
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@7cc6269c: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@2a62cc4e: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1232 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 111149056 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1231
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@29537803: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@62013018: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1231 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 90963968 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:08 INFO TaskMemoryManager: Memory used in task 1229
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@53a31ebf: 2.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@217a3454: 12.0 MiB
25/02/04 17:15:08 INFO TaskMemoryManager: 0 bytes of memory were used by task 1229 but are not associated with specific consumers
25/02/04 17:15:08 INFO TaskMemoryManager: 90963968 bytes of memory are used for execution and 191947612 bytes of memory are used for storage
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:08 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:09 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:09 INFO Executor: Finished task 11.0 in stage 82.0 (TID 1224). 2891 bytes result sent to driver
25/02/04 17:15:09 INFO TaskSetManager: Starting task 20.0 in stage 82.0 (TID 1233) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:09 INFO Executor: Running task 20.0 in stage 82.0 (TID 1233)
25/02/04 17:15:09 INFO TaskSetManager: Finished task 11.0 in stage 82.0 (TID 1224) in 5523 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:15:09 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:15:10 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO Executor: Finished task 15.0 in stage 82.0 (TID 1228). 2891 bytes result sent to driver
25/02/04 17:15:10 INFO TaskSetManager: Starting task 21.0 in stage 82.0 (TID 1234) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:10 INFO Executor: Running task 21.0 in stage 82.0 (TID 1234)
25/02/04 17:15:10 INFO TaskSetManager: Finished task 15.0 in stage 82.0 (TID 1228) in 6196 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:15:10 INFO Executor: Finished task 10.0 in stage 82.0 (TID 1223). 2891 bytes result sent to driver
25/02/04 17:15:10 INFO TaskSetManager: Starting task 22.0 in stage 82.0 (TID 1235) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:10 INFO Executor: Finished task 12.0 in stage 82.0 (TID 1225). 2848 bytes result sent to driver
25/02/04 17:15:10 INFO Executor: Running task 22.0 in stage 82.0 (TID 1235)
25/02/04 17:15:10 INFO TaskSetManager: Finished task 10.0 in stage 82.0 (TID 1223) in 6311 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:15:10 INFO TaskSetManager: Finished task 12.0 in stage 82.0 (TID 1225) in 6289 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:15:10 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:15:10 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:15:10 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:10 INFO Executor: Finished task 14.0 in stage 82.0 (TID 1227). 2848 bytes result sent to driver
25/02/04 17:15:10 INFO TaskSetManager: Finished task 14.0 in stage 82.0 (TID 1227) in 6398 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:15:10 INFO Executor: Finished task 13.0 in stage 82.0 (TID 1226). 2848 bytes result sent to driver
25/02/04 17:15:10 INFO TaskSetManager: Finished task 13.0 in stage 82.0 (TID 1226) in 6407 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:15:11 INFO UnsafeExternalSorter: Thread 1876 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:11 INFO Executor: Finished task 17.0 in stage 82.0 (TID 1230). 2891 bytes result sent to driver
25/02/04 17:15:11 INFO TaskSetManager: Finished task 17.0 in stage 82.0 (TID 1230) in 5960 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:15:11 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:11 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:11 INFO Executor: Finished task 19.0 in stage 82.0 (TID 1232). 2848 bytes result sent to driver
25/02/04 17:15:11 INFO TaskSetManager: Finished task 19.0 in stage 82.0 (TID 1232) in 6130 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:15:11 INFO Executor: Finished task 16.0 in stage 82.0 (TID 1229). 2848 bytes result sent to driver
25/02/04 17:15:11 INFO Executor: Finished task 18.0 in stage 82.0 (TID 1231). 2848 bytes result sent to driver
25/02/04 17:15:11 INFO TaskSetManager: Finished task 16.0 in stage 82.0 (TID 1229) in 6238 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:15:11 INFO TaskSetManager: Finished task 18.0 in stage 82.0 (TID 1231) in 6178 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:15:11 INFO Executor: Finished task 22.0 in stage 82.0 (TID 1235). 2762 bytes result sent to driver
25/02/04 17:15:11 INFO TaskSetManager: Finished task 22.0 in stage 82.0 (TID 1235) in 1248 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:15:13 INFO Executor: Finished task 20.0 in stage 82.0 (TID 1233). 2762 bytes result sent to driver
25/02/04 17:15:13 INFO TaskSetManager: Finished task 20.0 in stage 82.0 (TID 1233) in 3321 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:15:13 INFO Executor: Finished task 21.0 in stage 82.0 (TID 1234). 2762 bytes result sent to driver
25/02/04 17:15:13 INFO TaskSetManager: Finished task 21.0 in stage 82.0 (TID 1234) in 2865 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:15:13 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
25/02/04 17:15:13 INFO DAGScheduler: ShuffleMapStage 82 (parquet at NativeMethodAccessorImpl.java:0) finished in 15.499 s
25/02/04 17:15:13 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:13 INFO DAGScheduler: running: Set()
25/02/04 17:15:13 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:13 INFO DAGScheduler: failed: Set()
25/02/04 17:15:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:13 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 7390524, minimum partition size: 1048576
25/02/04 17:15:13 INFO CodeGenerator: Code generated in 142.850875 ms
25/02/04 17:15:13 INFO DAGScheduler: Registering RDD 126 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 14
25/02/04 17:15:13 INFO DAGScheduler: Got map stage job 27 (parquet at NativeMethodAccessorImpl.java:0) with 11 output partitions
25/02/04 17:15:13 INFO DAGScheduler: Final stage: ShuffleMapStage 84 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
25/02/04 17:15:13 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:13 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[126] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:13 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 43.4 KiB, free 183.2 MiB)
25/02/04 17:15:13 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 183.2 MiB)
25/02/04 17:15:13 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:15:13 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:13 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[126] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/02/04 17:15:13 INFO TaskSchedulerImpl: Adding task set 84.0 with 11 tasks resource profile 0
25/02/04 17:15:13 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 1236) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 1237) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 1238) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 1239) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 1240) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 1241) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 6.0 in stage 84.0 (TID 1242) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 7.0 in stage 84.0 (TID 1243) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 8.0 in stage 84.0 (TID 1244) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO TaskSetManager: Starting task 9.0 in stage 84.0 (TID 1245) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:13 INFO Executor: Running task 5.0 in stage 84.0 (TID 1241)
25/02/04 17:15:13 INFO Executor: Running task 8.0 in stage 84.0 (TID 1244)
25/02/04 17:15:13 INFO Executor: Running task 9.0 in stage 84.0 (TID 1245)
25/02/04 17:15:13 INFO Executor: Running task 4.0 in stage 84.0 (TID 1240)
25/02/04 17:15:13 INFO Executor: Running task 7.0 in stage 84.0 (TID 1243)
25/02/04 17:15:13 INFO Executor: Running task 6.0 in stage 84.0 (TID 1242)
25/02/04 17:15:13 INFO Executor: Running task 0.0 in stage 84.0 (TID 1236)
25/02/04 17:15:13 INFO Executor: Running task 3.0 in stage 84.0 (TID 1239)
25/02/04 17:15:13 INFO Executor: Running task 1.0 in stage 84.0 (TID 1237)
25/02/04 17:15:13 INFO Executor: Running task 2.0 in stage 84.0 (TID 1238)
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/02/04 17:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
25/02/04 17:15:13 INFO CodeGenerator: Code generated in 45.347167 ms
25/02/04 17:15:14 INFO Executor: Finished task 4.0 in stage 84.0 (TID 1240). 5342 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 5.0 in stage 84.0 (TID 1241). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 9.0 in stage 84.0 (TID 1245). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 0.0 in stage 84.0 (TID 1236). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 6.0 in stage 84.0 (TID 1242). 5342 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 7.0 in stage 84.0 (TID 1243). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 8.0 in stage 84.0 (TID 1244). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 3.0 in stage 84.0 (TID 1239). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 1.0 in stage 84.0 (TID 1237). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO Executor: Finished task 2.0 in stage 84.0 (TID 1238). 5299 bytes result sent to driver
25/02/04 17:15:14 INFO TaskSetManager: Starting task 10.0 in stage 84.0 (TID 1246) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:14 INFO Executor: Running task 10.0 in stage 84.0 (TID 1246)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 1236) in 847 ms on 10.0.0.43 (executor driver) (1/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 7.0 in stage 84.0 (TID 1243) in 843 ms on 10.0.0.43 (executor driver) (2/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 1241) in 843 ms on 10.0.0.43 (executor driver) (3/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 6.0 in stage 84.0 (TID 1242) in 843 ms on 10.0.0.43 (executor driver) (4/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 8.0 in stage 84.0 (TID 1244) in 843 ms on 10.0.0.43 (executor driver) (5/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 9.0 in stage 84.0 (TID 1245) in 843 ms on 10.0.0.43 (executor driver) (6/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 1240) in 843 ms on 10.0.0.43 (executor driver) (7/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 1238) in 844 ms on 10.0.0.43 (executor driver) (8/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 1237) in 844 ms on 10.0.0.43 (executor driver) (9/11)
25/02/04 17:15:14 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 1239) in 845 ms on 10.0.0.43 (executor driver) (10/11)
25/02/04 17:15:14 INFO ShuffleBlockFetcherIterator: Getting 23 (1449.7 KiB) non-empty blocks including 23 (1449.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:14 INFO Executor: Finished task 10.0 in stage 84.0 (TID 1246). 5256 bytes result sent to driver
25/02/04 17:15:14 INFO TaskSetManager: Finished task 10.0 in stage 84.0 (TID 1246) in 71 ms on 10.0.0.43 (executor driver) (11/11)
25/02/04 17:15:14 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
25/02/04 17:15:14 INFO DAGScheduler: ShuffleMapStage 84 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.944 s
25/02/04 17:15:14 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:14 INFO DAGScheduler: running: Set()
25/02/04 17:15:14 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:14 INFO DAGScheduler: failed: Set()
25/02/04 17:15:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:14 INFO CodeGenerator: Code generated in 19.076917 ms
25/02/04 17:15:14 INFO CodeGenerator: Code generated in 7.647084 ms
25/02/04 17:15:14 INFO DAGScheduler: Registering RDD 131 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 15
25/02/04 17:15:14 INFO DAGScheduler: Got map stage job 28 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:15:14 INFO DAGScheduler: Final stage: ShuffleMapStage 87 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
25/02/04 17:15:14 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:14 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[131] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:14 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 46.0 KiB, free 183.1 MiB)
25/02/04 17:15:14 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 21.3 KiB, free 183.1 MiB)
25/02/04 17:15:14 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.0.43:62420 (size: 21.3 KiB, free: 366.2 MiB)
25/02/04 17:15:14 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[131] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:15:14 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
25/02/04 17:15:14 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 1247) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:14 INFO Executor: Running task 0.0 in stage 87.0 (TID 1247)
25/02/04 17:15:14 INFO ShuffleBlockFetcherIterator: Getting 11 (5.9 MiB) non-empty blocks including 11 (5.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:14 INFO CodeGenerator: Code generated in 9.05 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 3.884875 ms
25/02/04 17:15:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:15:15 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:15:15 INFO Executor: Finished task 0.0 in stage 87.0 (TID 1247). 7138 bytes result sent to driver
25/02/04 17:15:15 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 1247) in 390 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:15:15 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
25/02/04 17:15:15 INFO DAGScheduler: ShuffleMapStage 87 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.407 s
25/02/04 17:15:15 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:15 INFO DAGScheduler: running: Set()
25/02/04 17:15:15 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:15 INFO DAGScheduler: failed: Set()
25/02/04 17:15:15 INFO ShufflePartitionsUtil: For shuffle(12, 15), advisory target size: 67108864, actual target size 2070980, minimum partition size: 1048576
25/02/04 17:15:15 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 21.122125 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 12.646375 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 5.606042 ms
25/02/04 17:15:15 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:15:15 INFO DAGScheduler: Got job 29 (parquet at NativeMethodAccessorImpl.java:0) with 10 output partitions
25/02/04 17:15:15 INFO DAGScheduler: Final stage: ResultStage 92 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88, ShuffleMapStage 91)
25/02/04 17:15:15 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:15 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[138] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:15 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 263.8 KiB, free 182.9 MiB)
25/02/04 17:15:15 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 98.6 KiB, free 182.8 MiB)
25/02/04 17:15:15 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.0.43:62420 (size: 98.6 KiB, free: 366.1 MiB)
25/02/04 17:15:15 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (MapPartitionsRDD[138] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/02/04 17:15:15 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
25/02/04 17:15:15 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 1248) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 1249) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 1250) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 1251) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 1252) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 1253) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 1254) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 1255) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 1256) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 1257) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:15 INFO Executor: Running task 6.0 in stage 92.0 (TID 1254)
25/02/04 17:15:15 INFO Executor: Running task 9.0 in stage 92.0 (TID 1257)
25/02/04 17:15:15 INFO Executor: Running task 8.0 in stage 92.0 (TID 1256)
25/02/04 17:15:15 INFO Executor: Running task 0.0 in stage 92.0 (TID 1248)
25/02/04 17:15:15 INFO Executor: Running task 3.0 in stage 92.0 (TID 1251)
25/02/04 17:15:15 INFO Executor: Running task 1.0 in stage 92.0 (TID 1249)
25/02/04 17:15:15 INFO Executor: Running task 7.0 in stage 92.0 (TID 1255)
25/02/04 17:15:15 INFO Executor: Running task 2.0 in stage 92.0 (TID 1250)
25/02/04 17:15:15 INFO Executor: Running task 4.0 in stage 92.0 (TID 1252)
25/02/04 17:15:15 INFO Executor: Running task 5.0 in stage 92.0 (TID 1253)
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1222.8 KiB) non-empty blocks including 4 (1222.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1519.6 KiB) non-empty blocks including 4 (1519.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1216.7 KiB) non-empty blocks including 4 (1216.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1261.8 KiB) non-empty blocks including 4 (1261.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1209.9 KiB) non-empty blocks including 4 (1209.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1221.9 KiB) non-empty blocks including 4 (1221.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1275.0 KiB) non-empty blocks including 4 (1275.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1266.4 KiB) non-empty blocks including 4 (1266.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1267.1 KiB) non-empty blocks including 4 (1267.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 4 (1262.1 KiB) non-empty blocks including 4 (1262.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 8.927375 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (719.0 KiB) non-empty blocks including 1 (719.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (750.5 KiB) non-empty blocks including 1 (750.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (719.0 KiB) non-empty blocks including 1 (719.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (747.0 KiB) non-empty blocks including 1 (747.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (740.0 KiB) non-empty blocks including 1 (740.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (743.5 KiB) non-empty blocks including 1 (743.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (897.1 KiB) non-empty blocks including 1 (897.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (715.6 KiB) non-empty blocks including 1 (715.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (719.0 KiB) non-empty blocks including 1 (719.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 (750.5 KiB) non-empty blocks including 1 (750.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 16.004375 ms
25/02/04 17:15:15 INFO CodeGenerator: Code generated in 17.711584 ms
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "trackId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary trackId (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:15 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:15:15 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:15:15 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 70.10% for 10 writers
25/02/04 17:15:15 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.0.43:62420 in memory (size: 21.3 KiB, free: 366.1 MiB)
25/02/04 17:15:16 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 77.89% for 9 writers
25/02/04 17:15:16 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000001_1249' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000001
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000006_1254' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000006
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000004_1252' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000004
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000000_1248' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000000
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000001_1249: Committed. Elapsed time: 2 ms.
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000003_1251' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000003
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000003_1251: Committed. Elapsed time: 1 ms.
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000008_1256' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000008
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000004_1252: Committed. Elapsed time: 2 ms.
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000008_1256: Committed. Elapsed time: 2 ms.
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000000_1248: Committed. Elapsed time: 2 ms.
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000006_1254: Committed. Elapsed time: 1 ms.
25/02/04 17:15:16 INFO Executor: Finished task 6.0 in stage 92.0 (TID 1254). 11177 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 3.0 in stage 92.0 (TID 1251). 11177 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 0.0 in stage 92.0 (TID 1248). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000005_1253' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000005
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000005_1253: Committed. Elapsed time: 0 ms.
25/02/04 17:15:16 INFO Executor: Finished task 8.0 in stage 92.0 (TID 1256). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 1.0 in stage 92.0 (TID 1249). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 4.0 in stage 92.0 (TID 1252). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 5.0 in stage 92.0 (TID 1253). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 1254) in 1206 ms on 10.0.0.43 (executor driver) (1/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 1251) in 1207 ms on 10.0.0.43 (executor driver) (2/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 1248) in 1209 ms on 10.0.0.43 (executor driver) (3/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 1256) in 1206 ms on 10.0.0.43 (executor driver) (4/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 1249) in 1208 ms on 10.0.0.43 (executor driver) (5/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 1252) in 1207 ms on 10.0.0.43 (executor driver) (6/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 1253) in 1208 ms on 10.0.0.43 (executor driver) (7/10)
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000009_1257' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000009
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000009_1257: Committed. Elapsed time: 0 ms.
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000007_1255' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000007
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000007_1255: Committed. Elapsed time: 0 ms.
25/02/04 17:15:16 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715151901154832066549837_0092_m_000002_1250' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/songs2tracks/_temporary/0/task_202502041715151901154832066549837_0092_m_000002
25/02/04 17:15:16 INFO SparkHadoopMapRedUtil: attempt_202502041715151901154832066549837_0092_m_000002_1250: Committed. Elapsed time: 1 ms.
25/02/04 17:15:16 INFO Executor: Finished task 9.0 in stage 92.0 (TID 1257). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 2.0 in stage 92.0 (TID 1250). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO Executor: Finished task 7.0 in stage 92.0 (TID 1255). 11134 bytes result sent to driver
25/02/04 17:15:16 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 1250) in 1214 ms on 10.0.0.43 (executor driver) (8/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 1257) in 1213 ms on 10.0.0.43 (executor driver) (9/10)
25/02/04 17:15:16 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 1255) in 1213 ms on 10.0.0.43 (executor driver) (10/10)
25/02/04 17:15:16 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
25/02/04 17:15:16 INFO DAGScheduler: ResultStage 92 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.261 s
25/02/04 17:15:16 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:15:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
25/02/04 17:15:16 INFO DAGScheduler: Job 29 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.274640 s
25/02/04 17:15:16 INFO FileFormatWriter: Start to commit write Job 17adffe7-ae7c-49e6-8c41-bf5df3ffa26f.
25/02/04 17:15:16 INFO FileFormatWriter: Write Job 17adffe7-ae7c-49e6-8c41-bf5df3ffa26f committed. Elapsed time: 75 ms.
25/02/04 17:15:16 INFO FileFormatWriter: Finished processing stats for write job 17adffe7-ae7c-49e6-8c41-bf5df3ffa26f.
25/02/04 17:15:17 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:15:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:15:17 INFO FileSourceStrategy: Pushed Filters: 
25/02/04 17:15:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/02/04 17:15:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:17 INFO CodeGenerator: Code generated in 69.379583 ms
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 350.3 KiB, free 182.5 MiB)
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 182.5 MiB)
25/02/04 17:15:17 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.1 MiB)
25/02/04 17:15:17 INFO SparkContext: Created broadcast 43 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:15:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:15:17 INFO DAGScheduler: Registering RDD 142 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 16
25/02/04 17:15:17 INFO DAGScheduler: Got map stage job 30 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:15:17 INFO DAGScheduler: Final stage: ShuffleMapStage 93 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:17 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:15:17 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:17 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[142] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 350.3 KiB, free 182.2 MiB)
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 21.2 KiB, free 182.2 MiB)
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 182.1 MiB)
25/02/04 17:15:17 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.0.43:62420 (size: 9.3 KiB, free: 366.1 MiB)
25/02/04 17:15:17 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[142] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:15:17 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 182.1 MiB)
25/02/04 17:15:17 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.0.43:62420 (size: 34.3 KiB, free: 366.0 MiB)
25/02/04 17:15:17 INFO SparkContext: Created broadcast 44 from parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:15:17 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 1258) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) 
25/02/04 17:15:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
25/02/04 17:15:17 INFO Executor: Running task 0.0 in stage 93.0 (TID 1258)
25/02/04 17:15:17 INFO DAGScheduler: Registering RDD 146 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 17
25/02/04 17:15:17 INFO DAGScheduler: Got map stage job 31 (parquet at NativeMethodAccessorImpl.java:0) with 23 output partitions
25/02/04 17:15:17 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:17 INFO DAGScheduler: Parents of final stage: List()
25/02/04 17:15:17 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:17 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[146] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 37.1 KiB, free 182.1 MiB)
25/02/04 17:15:17 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 182.1 MiB)
25/02/04 17:15:17 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.0.43:62420 (size: 17.4 KiB, free: 366.0 MiB)
25/02/04 17:15:17 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:17 INFO DAGScheduler: Submitting 23 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[146] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/02/04 17:15:17 INFO TaskSchedulerImpl: Adding task set 94.0 with 23 tasks resource profile 0
25/02/04 17:15:17 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 1259) (10.0.0.43, executor driver, partition 0, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 1260) (10.0.0.43, executor driver, partition 1, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 1261) (10.0.0.43, executor driver, partition 2, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 1262) (10.0.0.43, executor driver, partition 3, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 4.0 in stage 94.0 (TID 1263) (10.0.0.43, executor driver, partition 4, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 5.0 in stage 94.0 (TID 1264) (10.0.0.43, executor driver, partition 5, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 6.0 in stage 94.0 (TID 1265) (10.0.0.43, executor driver, partition 6, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 7.0 in stage 94.0 (TID 1266) (10.0.0.43, executor driver, partition 7, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO TaskSetManager: Starting task 8.0 in stage 94.0 (TID 1267) (10.0.0.43, executor driver, partition 8, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:17 INFO Executor: Running task 7.0 in stage 94.0 (TID 1266)
25/02/04 17:15:17 INFO Executor: Running task 0.0 in stage 94.0 (TID 1259)
25/02/04 17:15:17 INFO Executor: Running task 5.0 in stage 94.0 (TID 1264)
25/02/04 17:15:17 INFO Executor: Running task 8.0 in stage 94.0 (TID 1267)
25/02/04 17:15:17 INFO Executor: Running task 3.0 in stage 94.0 (TID 1262)
25/02/04 17:15:17 INFO Executor: Running task 2.0 in stage 94.0 (TID 1261)
25/02/04 17:15:17 INFO Executor: Running task 1.0 in stage 94.0 (TID 1260)
25/02/04 17:15:17 INFO Executor: Running task 4.0 in stage 94.0 (TID 1263)
25/02/04 17:15:17 INFO Executor: Running task 6.0 in stage 94.0 (TID 1265)
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1073741824-1207959552, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 671088640-805306368, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 134217728-268435456, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 536870912-671088640, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 402653184-536870912, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 805306368-939524096, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 939524096-1073741824, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 0-134217728, partition values: [empty row]
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 268435456-402653184, partition values: [empty row]
25/02/04 17:15:17 INFO CodeGenerator: Code generated in 140.167125 ms
25/02/04 17:15:17 INFO CodeGenerator: Code generated in 200.850583 ms
25/02/04 17:15:17 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/msd_subset.csv, range: 0-1155592, partition values: [empty row]
25/02/04 17:15:18 INFO CodeGenerator: Code generated in 41.243958 ms
25/02/04 17:15:18 INFO Executor: Finished task 0.0 in stage 93.0 (TID 1258). 2072 bytes result sent to driver
25/02/04 17:15:18 INFO TaskSetManager: Starting task 9.0 in stage 94.0 (TID 1268) (10.0.0.43, executor driver, partition 9, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:18 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 1258) in 1240 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:15:18 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
25/02/04 17:15:18 INFO DAGScheduler: ShuffleMapStage 93 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.301 s
25/02/04 17:15:18 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:18 INFO DAGScheduler: running: Set(ShuffleMapStage 94)
25/02/04 17:15:18 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:18 INFO DAGScheduler: failed: Set()
25/02/04 17:15:18 INFO Executor: Running task 9.0 in stage 94.0 (TID 1268)
25/02/04 17:15:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:18 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1207959552-1342177280, partition values: [empty row]
25/02/04 17:15:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.0.43:62420 in memory (size: 98.6 KiB, free: 366.1 MiB)
25/02/04 17:15:19 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.0.43:62420 in memory (size: 9.3 KiB, free: 366.1 MiB)
25/02/04 17:15:19 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.0.43:62420 in memory (size: 17.4 KiB, free: 366.1 MiB)
25/02/04 17:15:19 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:15:19 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.0.43:62420 in memory (size: 34.3 KiB, free: 366.2 MiB)
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1266
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@43cf0c7f: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4884422d: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1266 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1261
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@56f77041: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@2ffffc94: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1261 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1260
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@245beec8: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@2da8b524: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1260 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1259
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@32dd9f39: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@19cf1a56: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1259 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1264
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@51523be7: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@4ab39294: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1264 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1263
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@679e26b8: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@2c438ad8: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1263 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1265
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@14477673: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@fd2741f: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1265 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 144703488 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1267
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@35879d97: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@3ca3e930: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1267 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:21 INFO TaskMemoryManager: Memory used in task 1262
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@614feb7: 12.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@4ed6297f: 2.0 MiB
25/02/04 17:15:21 INFO TaskMemoryManager: 0 bytes of memory were used by task 1262 but are not associated with specific consumers
25/02/04 17:15:21 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:21 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:22 INFO TaskMemoryManager: Memory used in task 1268
25/02/04 17:15:22 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@d58c86c: 12.0 MiB
25/02/04 17:15:22 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@9674d98: 2.0 MiB
25/02/04 17:15:22 INFO TaskMemoryManager: 0 bytes of memory were used by task 1268 but are not associated with specific consumers
25/02/04 17:15:22 INFO TaskMemoryManager: 70254592 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:22 INFO UnsafeExternalSorter: Thread 3155 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:23 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:24 INFO UnsafeExternalSorter: Thread 3155 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:24 INFO Executor: Finished task 6.0 in stage 94.0 (TID 1265). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 5.0 in stage 94.0 (TID 1264). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 3.0 in stage 94.0 (TID 1262). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 8.0 in stage 94.0 (TID 1267). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 0.0 in stage 94.0 (TID 1259). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 7.0 in stage 94.0 (TID 1266). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 4.0 in stage 94.0 (TID 1263). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 1.0 in stage 94.0 (TID 1260). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO Executor: Finished task 2.0 in stage 94.0 (TID 1261). 2891 bytes result sent to driver
25/02/04 17:15:24 INFO TaskSetManager: Starting task 10.0 in stage 94.0 (TID 1269) (10.0.0.43, executor driver, partition 10, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO Executor: Running task 10.0 in stage 94.0 (TID 1269)
25/02/04 17:15:25 INFO TaskSetManager: Starting task 11.0 in stage 94.0 (TID 1270) (10.0.0.43, executor driver, partition 11, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO Executor: Running task 11.0 in stage 94.0 (TID 1270)
25/02/04 17:15:25 INFO TaskSetManager: Starting task 12.0 in stage 94.0 (TID 1271) (10.0.0.43, executor driver, partition 12, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Starting task 13.0 in stage 94.0 (TID 1272) (10.0.0.43, executor driver, partition 13, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Starting task 14.0 in stage 94.0 (TID 1273) (10.0.0.43, executor driver, partition 14, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Starting task 15.0 in stage 94.0 (TID 1274) (10.0.0.43, executor driver, partition 15, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Starting task 16.0 in stage 94.0 (TID 1275) (10.0.0.43, executor driver, partition 16, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Starting task 17.0 in stage 94.0 (TID 1276) (10.0.0.43, executor driver, partition 17, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO Executor: Running task 14.0 in stage 94.0 (TID 1273)
25/02/04 17:15:25 INFO Executor: Running task 15.0 in stage 94.0 (TID 1274)
25/02/04 17:15:25 INFO Executor: Running task 12.0 in stage 94.0 (TID 1271)
25/02/04 17:15:25 INFO TaskSetManager: Starting task 18.0 in stage 94.0 (TID 1277) (10.0.0.43, executor driver, partition 18, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO Executor: Running task 13.0 in stage 94.0 (TID 1272)
25/02/04 17:15:25 INFO Executor: Running task 17.0 in stage 94.0 (TID 1276)
25/02/04 17:15:25 INFO Executor: Running task 16.0 in stage 94.0 (TID 1275)
25/02/04 17:15:25 INFO Executor: Running task 18.0 in stage 94.0 (TID 1277)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 7.0 in stage 94.0 (TID 1266) in 7561 ms on 10.0.0.43 (executor driver) (1/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 1259) in 7566 ms on 10.0.0.43 (executor driver) (2/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 5.0 in stage 94.0 (TID 1264) in 7564 ms on 10.0.0.43 (executor driver) (3/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 4.0 in stage 94.0 (TID 1263) in 7566 ms on 10.0.0.43 (executor driver) (4/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 6.0 in stage 94.0 (TID 1265) in 7567 ms on 10.0.0.43 (executor driver) (5/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 1261) in 7569 ms on 10.0.0.43 (executor driver) (6/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 1262) in 7572 ms on 10.0.0.43 (executor driver) (7/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 8.0 in stage 94.0 (TID 1267) in 7572 ms on 10.0.0.43 (executor driver) (8/23)
25/02/04 17:15:25 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 1260) in 7575 ms on 10.0.0.43 (executor driver) (9/23)
25/02/04 17:15:25 INFO Executor: Finished task 9.0 in stage 94.0 (TID 1268). 2891 bytes result sent to driver
25/02/04 17:15:25 INFO TaskSetManager: Starting task 19.0 in stage 94.0 (TID 1278) (10.0.0.43, executor driver, partition 19, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:25 INFO TaskSetManager: Finished task 9.0 in stage 94.0 (TID 1268) in 6538 ms on 10.0.0.43 (executor driver) (10/23)
25/02/04 17:15:25 INFO Executor: Running task 19.0 in stage 94.0 (TID 1278)
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1744830464-1879048192, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2415919104-2550136832, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2013265920-2147483648, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1610612736-1744830464, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2147483648-2281701376, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1879048192-2013265920, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1476395008-1610612736, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 1342177280-1476395008, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2281701376-2415919104, partition values: [empty row]
25/02/04 17:15:25 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2550136832-2684354560, partition values: [empty row]
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1273
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@59777b64: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@217ccad0: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1273 but are not associated with specific consumers
25/02/04 17:15:28 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1274
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@56efaaf9: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@17694cd2: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1274 but are not associated with specific consumers
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1269
25/02/04 17:15:28 INFO TaskMemoryManager: 151335153 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@637cdb1f: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@21beefa0: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1269 but are not associated with specific consumers
25/02/04 17:15:28 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1270
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@19cf2b5f: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@7d0df592: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1270 but are not associated with specific consumers
25/02/04 17:15:28 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1271
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@31445cef: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@3d21532e: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1271 but are not associated with specific consumers
25/02/04 17:15:28 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:28 INFO TaskMemoryManager: Memory used in task 1276
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@edcfdc6: 2.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@6b4078ee: 12.0 MiB
25/02/04 17:15:28 INFO TaskMemoryManager: 0 bytes of memory were used by task 1276 but are not associated with specific consumers
25/02/04 17:15:28 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO TaskMemoryManager: Memory used in task 1272
25/02/04 17:15:29 INFO TaskMemoryManager: Memory used in task 1277
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO TaskMemoryManager: Memory used in task 1278
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@74de00fc: 2.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5ad6394: 12.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@5ca8d2cc: 2.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@26d0acfc: 12.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@64acc1f9: 2.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@533531fe: 12.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: 0 bytes of memory were used by task 1277 but are not associated with specific consumers
25/02/04 17:15:29 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:29 INFO TaskMemoryManager: 0 bytes of memory were used by task 1272 but are not associated with specific consumers
25/02/04 17:15:29 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:29 INFO TaskMemoryManager: 0 bytes of memory were used by task 1278 but are not associated with specific consumers
25/02/04 17:15:29 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
25/02/04 17:15:29 INFO TaskMemoryManager: Memory used in task 1275
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.sql.catalyst.expressions.VariableLengthRowBasedKeyValueBatch@59cf5f93: 2.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@6f1234fd: 12.0 MiB
25/02/04 17:15:29 INFO TaskMemoryManager: 0 bytes of memory were used by task 1275 but are not associated with specific consumers
25/02/04 17:15:29 INFO TaskMemoryManager: 146800640 bytes of memory are used for execution and 191947609 bytes of memory are used for storage
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 3155 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:29 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 67 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 364 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 1871 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 68 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:30 INFO UnsafeExternalSorter: Thread 353 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:31 INFO UnsafeExternalSorter: Thread 3155 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:31 INFO UnsafeExternalSorter: Thread 70 spilling sort data of 4.0 MiB to disk (0  time so far)
25/02/04 17:15:31 INFO Executor: Finished task 10.0 in stage 94.0 (TID 1269). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 12.0 in stage 94.0 (TID 1271). 2891 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 15.0 in stage 94.0 (TID 1274). 2891 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 17.0 in stage 94.0 (TID 1276). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 16.0 in stage 94.0 (TID 1275). 2891 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 18.0 in stage 94.0 (TID 1277). 2891 bytes result sent to driver
25/02/04 17:15:31 INFO TaskSetManager: Starting task 20.0 in stage 94.0 (TID 1279) (10.0.0.43, executor driver, partition 20, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:31 INFO Executor: Finished task 13.0 in stage 94.0 (TID 1272). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Finished task 11.0 in stage 94.0 (TID 1270). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO Executor: Running task 20.0 in stage 94.0 (TID 1279)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 15.0 in stage 94.0 (TID 1274) in 6705 ms on 10.0.0.43 (executor driver) (11/23)
25/02/04 17:15:31 INFO TaskSetManager: Starting task 21.0 in stage 94.0 (TID 1280) (10.0.0.43, executor driver, partition 21, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:31 INFO Executor: Finished task 19.0 in stage 94.0 (TID 1278). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO TaskSetManager: Starting task 22.0 in stage 94.0 (TID 1281) (10.0.0.43, executor driver, partition 22, PROCESS_LOCAL, 9624 bytes) 
25/02/04 17:15:31 INFO Executor: Running task 22.0 in stage 94.0 (TID 1281)
25/02/04 17:15:31 INFO Executor: Running task 21.0 in stage 94.0 (TID 1280)
25/02/04 17:15:31 INFO Executor: Finished task 14.0 in stage 94.0 (TID 1273). 2848 bytes result sent to driver
25/02/04 17:15:31 INFO TaskSetManager: Finished task 12.0 in stage 94.0 (TID 1271) in 6792 ms on 10.0.0.43 (executor driver) (12/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 17.0 in stage 94.0 (TID 1276) in 6784 ms on 10.0.0.43 (executor driver) (13/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 10.0 in stage 94.0 (TID 1269) in 6906 ms on 10.0.0.43 (executor driver) (14/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 16.0 in stage 94.0 (TID 1275) in 6790 ms on 10.0.0.43 (executor driver) (15/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 13.0 in stage 94.0 (TID 1272) in 6795 ms on 10.0.0.43 (executor driver) (16/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 11.0 in stage 94.0 (TID 1270) in 6837 ms on 10.0.0.43 (executor driver) (17/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 18.0 in stage 94.0 (TID 1277) in 6798 ms on 10.0.0.43 (executor driver) (18/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 19.0 in stage 94.0 (TID 1278) in 6604 ms on 10.0.0.43 (executor driver) (19/23)
25/02/04 17:15:31 INFO TaskSetManager: Finished task 14.0 in stage 94.0 (TID 1273) in 6810 ms on 10.0.0.43 (executor driver) (20/23)
25/02/04 17:15:31 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2952790016-3001659271, partition values: [empty row]
25/02/04 17:15:31 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2684354560-2818572288, partition values: [empty row]
25/02/04 17:15:31 INFO FileScanRDD: Reading File path: file:///Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/raw/train_triplets.txt, range: 2818572288-2952790016, partition values: [empty row]
25/02/04 17:15:33 INFO Executor: Finished task 22.0 in stage 94.0 (TID 1281). 2805 bytes result sent to driver
25/02/04 17:15:33 INFO TaskSetManager: Finished task 22.0 in stage 94.0 (TID 1281) in 1425 ms on 10.0.0.43 (executor driver) (21/23)
25/02/04 17:15:34 INFO Executor: Finished task 21.0 in stage 94.0 (TID 1280). 2805 bytes result sent to driver
25/02/04 17:15:34 INFO TaskSetManager: Finished task 21.0 in stage 94.0 (TID 1280) in 2974 ms on 10.0.0.43 (executor driver) (22/23)
25/02/04 17:15:34 INFO Executor: Finished task 20.0 in stage 94.0 (TID 1279). 2762 bytes result sent to driver
25/02/04 17:15:34 INFO TaskSetManager: Finished task 20.0 in stage 94.0 (TID 1279) in 3010 ms on 10.0.0.43 (executor driver) (23/23)
25/02/04 17:15:34 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
25/02/04 17:15:34 INFO DAGScheduler: ShuffleMapStage 94 (parquet at NativeMethodAccessorImpl.java:0) finished in 17.230 s
25/02/04 17:15:34 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:34 INFO DAGScheduler: running: Set()
25/02/04 17:15:34 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:34 INFO DAGScheduler: failed: Set()
25/02/04 17:15:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:34 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 7390524, minimum partition size: 1048576
25/02/04 17:15:35 INFO DAGScheduler: Registering RDD 149 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 18
25/02/04 17:15:35 INFO DAGScheduler: Got map stage job 32 (parquet at NativeMethodAccessorImpl.java:0) with 11 output partitions
25/02/04 17:15:35 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
25/02/04 17:15:35 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:35 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[149] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:35 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 43.4 KiB, free 183.2 MiB)
25/02/04 17:15:35 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 183.2 MiB)
25/02/04 17:15:35 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.0.43:62420 (size: 20.2 KiB, free: 366.2 MiB)
25/02/04 17:15:35 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:35 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[149] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/02/04 17:15:35 INFO TaskSchedulerImpl: Adding task set 96.0 with 11 tasks resource profile 0
25/02/04 17:15:35 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 1282) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 1283) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 1284) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 1285) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 4.0 in stage 96.0 (TID 1286) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 5.0 in stage 96.0 (TID 1287) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 6.0 in stage 96.0 (TID 1288) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 7.0 in stage 96.0 (TID 1289) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 8.0 in stage 96.0 (TID 1290) (10.0.0.43, executor driver, partition 8, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Starting task 9.0 in stage 96.0 (TID 1291) (10.0.0.43, executor driver, partition 9, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO Executor: Running task 0.0 in stage 96.0 (TID 1282)
25/02/04 17:15:35 INFO Executor: Running task 2.0 in stage 96.0 (TID 1284)
25/02/04 17:15:35 INFO Executor: Running task 1.0 in stage 96.0 (TID 1283)
25/02/04 17:15:35 INFO Executor: Running task 3.0 in stage 96.0 (TID 1285)
25/02/04 17:15:35 INFO Executor: Running task 5.0 in stage 96.0 (TID 1287)
25/02/04 17:15:35 INFO Executor: Running task 8.0 in stage 96.0 (TID 1290)
25/02/04 17:15:35 INFO Executor: Running task 7.0 in stage 96.0 (TID 1289)
25/02/04 17:15:35 INFO Executor: Running task 6.0 in stage 96.0 (TID 1288)
25/02/04 17:15:35 INFO Executor: Running task 9.0 in stage 96.0 (TID 1291)
25/02/04 17:15:35 INFO Executor: Running task 4.0 in stage 96.0 (TID 1286)
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (6.8 MiB) non-empty blocks including 23 (6.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (6.7 MiB) non-empty blocks including 23 (6.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (7.0 MiB) non-empty blocks including 23 (7.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
25/02/04 17:15:35 INFO Executor: Finished task 9.0 in stage 96.0 (TID 1291). 5342 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 8.0 in stage 96.0 (TID 1290). 5342 bytes result sent to driver
25/02/04 17:15:35 INFO TaskSetManager: Starting task 10.0 in stage 96.0 (TID 1292) (10.0.0.43, executor driver, partition 10, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO TaskSetManager: Finished task 8.0 in stage 96.0 (TID 1290) in 373 ms on 10.0.0.43 (executor driver) (1/11)
25/02/04 17:15:35 INFO Executor: Running task 10.0 in stage 96.0 (TID 1292)
25/02/04 17:15:35 INFO Executor: Finished task 2.0 in stage 96.0 (TID 1284). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 3.0 in stage 96.0 (TID 1285). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 1.0 in stage 96.0 (TID 1283). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 0.0 in stage 96.0 (TID 1282). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 6.0 in stage 96.0 (TID 1288). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 7.0 in stage 96.0 (TID 1289). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 5.0 in stage 96.0 (TID 1287). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO Executor: Finished task 4.0 in stage 96.0 (TID 1286). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 1283) in 396 ms on 10.0.0.43 (executor driver) (2/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 1285) in 395 ms on 10.0.0.43 (executor driver) (3/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 1282) in 402 ms on 10.0.0.43 (executor driver) (4/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 6.0 in stage 96.0 (TID 1288) in 396 ms on 10.0.0.43 (executor driver) (5/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 5.0 in stage 96.0 (TID 1287) in 396 ms on 10.0.0.43 (executor driver) (6/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 7.0 in stage 96.0 (TID 1289) in 396 ms on 10.0.0.43 (executor driver) (7/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 4.0 in stage 96.0 (TID 1286) in 396 ms on 10.0.0.43 (executor driver) (8/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 9.0 in stage 96.0 (TID 1291) in 397 ms on 10.0.0.43 (executor driver) (9/11)
25/02/04 17:15:35 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 1284) in 398 ms on 10.0.0.43 (executor driver) (10/11)
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 23 (1449.7 KiB) non-empty blocks including 23 (1449.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:35 INFO Executor: Finished task 10.0 in stage 96.0 (TID 1292). 5299 bytes result sent to driver
25/02/04 17:15:35 INFO TaskSetManager: Finished task 10.0 in stage 96.0 (TID 1292) in 92 ms on 10.0.0.43 (executor driver) (11/11)
25/02/04 17:15:35 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
25/02/04 17:15:35 INFO DAGScheduler: ShuffleMapStage 96 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.506 s
25/02/04 17:15:35 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:35 INFO DAGScheduler: running: Set()
25/02/04 17:15:35 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:35 INFO DAGScheduler: failed: Set()
25/02/04 17:15:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
25/02/04 17:15:35 INFO DAGScheduler: Registering RDD 154 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 19
25/02/04 17:15:35 INFO DAGScheduler: Got map stage job 33 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/02/04 17:15:35 INFO DAGScheduler: Final stage: ShuffleMapStage 99 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
25/02/04 17:15:35 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:35 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[154] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:35 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 46.0 KiB, free 183.1 MiB)
25/02/04 17:15:35 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 21.3 KiB, free 183.1 MiB)
25/02/04 17:15:35 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.0.43:62420 (size: 21.3 KiB, free: 366.2 MiB)
25/02/04 17:15:35 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[154] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/02/04 17:15:35 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
25/02/04 17:15:35 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 1293) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
25/02/04 17:15:35 INFO Executor: Running task 0.0 in stage 99.0 (TID 1293)
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Getting 11 (5.9 MiB) non-empty blocks including 11 (5.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
25/02/04 17:15:36 INFO Executor: Finished task 0.0 in stage 99.0 (TID 1293). 7095 bytes result sent to driver
25/02/04 17:15:36 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 1293) in 419 ms on 10.0.0.43 (executor driver) (1/1)
25/02/04 17:15:36 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
25/02/04 17:15:36 INFO DAGScheduler: ShuffleMapStage 99 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.443 s
25/02/04 17:15:36 INFO DAGScheduler: looking for newly runnable stages
25/02/04 17:15:36 INFO DAGScheduler: running: Set()
25/02/04 17:15:36 INFO DAGScheduler: waiting: Set()
25/02/04 17:15:36 INFO DAGScheduler: failed: Set()
25/02/04 17:15:36 INFO ShufflePartitionsUtil: For shuffle(16, 19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/02/04 17:15:36 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO CodeGenerator: Code generated in 145.668542 ms
25/02/04 17:15:36 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/02/04 17:15:36 INFO DAGScheduler: Got job 34 (parquet at NativeMethodAccessorImpl.java:0) with 8 output partitions
25/02/04 17:15:36 INFO DAGScheduler: Final stage: ResultStage 104 (parquet at NativeMethodAccessorImpl.java:0)
25/02/04 17:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 100)
25/02/04 17:15:36 INFO DAGScheduler: Missing parents: List()
25/02/04 17:15:36 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[161] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/02/04 17:15:36 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 271.9 KiB, free 182.9 MiB)
25/02/04 17:15:36 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 101.0 KiB, free 182.8 MiB)
25/02/04 17:15:36 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.0.43:62420 (size: 101.0 KiB, free: 366.1 MiB)
25/02/04 17:15:36 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
25/02/04 17:15:36 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 104 (MapPartitionsRDD[161] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/02/04 17:15:36 INFO TaskSchedulerImpl: Adding task set 104.0 with 8 tasks resource profile 0
25/02/04 17:15:36 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 1294) (10.0.0.43, executor driver, partition 0, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 1295) (10.0.0.43, executor driver, partition 1, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 1296) (10.0.0.43, executor driver, partition 2, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 1297) (10.0.0.43, executor driver, partition 3, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 1298) (10.0.0.43, executor driver, partition 4, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 1299) (10.0.0.43, executor driver, partition 5, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 1300) (10.0.0.43, executor driver, partition 6, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 1301) (10.0.0.43, executor driver, partition 7, NODE_LOCAL, 9281 bytes) 
25/02/04 17:15:36 INFO Executor: Running task 6.0 in stage 104.0 (TID 1300)
25/02/04 17:15:36 INFO Executor: Running task 4.0 in stage 104.0 (TID 1298)
25/02/04 17:15:36 INFO Executor: Running task 5.0 in stage 104.0 (TID 1299)
25/02/04 17:15:36 INFO Executor: Running task 3.0 in stage 104.0 (TID 1297)
25/02/04 17:15:36 INFO Executor: Running task 0.0 in stage 104.0 (TID 1294)
25/02/04 17:15:36 INFO Executor: Running task 1.0 in stage 104.0 (TID 1295)
25/02/04 17:15:36 INFO Executor: Running task 2.0 in stage 104.0 (TID 1296)
25/02/04 17:15:36 INFO Executor: Running task 7.0 in stage 104.0 (TID 1301)
25/02/04 17:15:36 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.0.43:62420 in memory (size: 20.2 KiB, free: 366.1 MiB)
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (176.9 KiB) non-empty blocks including 1 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (176.2 KiB) non-empty blocks including 1 (176.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (305.6 KiB) non-empty blocks including 1 (305.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (172.4 KiB) non-empty blocks including 1 (172.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (176.8 KiB) non-empty blocks including 1 (176.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (173.5 KiB) non-empty blocks including 1 (173.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (176.6 KiB) non-empty blocks including 1 (176.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (168.3 KiB) non-empty blocks including 1 (168.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.0.43:62420 in memory (size: 21.3 KiB, free: 366.1 MiB)
25/02/04 17:15:36 INFO CodeGenerator: Code generated in 29.192958 ms
25/02/04 17:15:36 INFO CodeGenerator: Code generated in 21.999625 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (862.2 KiB) non-empty blocks including 1 (862.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (1466.0 KiB) non-empty blocks including 1 (1466.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (862.2 KiB) non-empty blocks including 1 (862.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (862.2 KiB) non-empty blocks including 1 (862.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (855.2 KiB) non-empty blocks including 1 (855.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (862.2 KiB) non-empty blocks including 1 (862.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (872.6 KiB) non-empty blocks including 1 (872.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (858.7 KiB) non-empty blocks including 1 (858.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/02/04 17:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/02/04 17:15:36 INFO CodeGenerator: Code generated in 24.773833 ms
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/02/04 17:15:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/02/04 17:15:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO CodecConfig: Compression: SNAPPY
25/02/04 17:15:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/02/04 17:15:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "songId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_familiarity",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_hotttness",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "artist_terms_freq",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "release_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duration",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "new_songId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary songId (STRING);
  optional binary artist_familiarity (STRING);
  optional binary artist_hotttness (STRING);
  optional binary artist_id (STRING);
  optional binary artist_name (STRING);
  optional binary artist_terms (STRING);
  optional binary artist_terms_freq (STRING);
  optional binary release_id (STRING);
  optional binary duration (STRING);
  optional binary year (STRING);
  optional int32 new_songId;
}

       
25/02/04 17:15:36 WARN MemoryManager: Total allocation exceeds 95.00% (940,861,019 bytes) of heap memory
Scaling row group sizes to 87.62% for 8 writers
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000000_1294' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000000
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000003_1297' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000003
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000001_1295' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000001
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000007_1301' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000007
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000004_1298' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000004
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000002_1296' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000002
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000001_1295: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000005_1299' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000005
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000005_1299: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000000_1294: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000007_1301: Committed. Elapsed time: 1 ms.
25/02/04 17:15:37 INFO FileOutputCommitter: Saved output of task 'attempt_202502041715364596342140631485161_0104_m_000006_1300' to file:/Users/Kexin/Desktop/MSU/Fifthyear/MSD/data/processed/metadata/_temporary/0/task_202502041715364596342140631485161_0104_m_000006
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000003_1297: Committed. Elapsed time: 1 ms.
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000006_1300: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000002_1296: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO SparkHadoopMapRedUtil: attempt_202502041715364596342140631485161_0104_m_000004_1298: Committed. Elapsed time: 2 ms.
25/02/04 17:15:37 INFO Executor: Finished task 5.0 in stage 104.0 (TID 1299). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 0.0 in stage 104.0 (TID 1294). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 4.0 in stage 104.0 (TID 1298). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 6.0 in stage 104.0 (TID 1300). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 7.0 in stage 104.0 (TID 1301). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 3.0 in stage 104.0 (TID 1297). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 1.0 in stage 104.0 (TID 1295). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO Executor: Finished task 2.0 in stage 104.0 (TID 1296). 11177 bytes result sent to driver
25/02/04 17:15:37 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 1300) in 646 ms on 10.0.0.43 (executor driver) (1/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 1294) in 649 ms on 10.0.0.43 (executor driver) (2/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 1298) in 647 ms on 10.0.0.43 (executor driver) (3/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 1299) in 647 ms on 10.0.0.43 (executor driver) (4/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 1301) in 647 ms on 10.0.0.43 (executor driver) (5/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 1295) in 648 ms on 10.0.0.43 (executor driver) (6/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 1297) in 647 ms on 10.0.0.43 (executor driver) (7/8)
25/02/04 17:15:37 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 1296) in 647 ms on 10.0.0.43 (executor driver) (8/8)
25/02/04 17:15:37 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
25/02/04 17:15:37 INFO DAGScheduler: ResultStage 104 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.713 s
25/02/04 17:15:37 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
25/02/04 17:15:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished
25/02/04 17:15:37 INFO DAGScheduler: Job 34 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.724008 s
25/02/04 17:15:37 INFO FileFormatWriter: Start to commit write Job 735747f6-e560-4284-ad50-4a5388827b1a.
25/02/04 17:15:37 INFO FileFormatWriter: Write Job 735747f6-e560-4284-ad50-4a5388827b1a committed. Elapsed time: 35 ms.
25/02/04 17:15:37 INFO FileFormatWriter: Finished processing stats for write job 735747f6-e560-4284-ad50-4a5388827b1a.
 Data processing complete. Files saved to data/processed
25/02/04 17:15:37 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/02/04 17:15:37 INFO SparkUI: Stopped Spark web UI at http://10.0.0.43:4040
25/02/04 17:15:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/02/04 17:15:37 INFO MemoryStore: MemoryStore cleared
25/02/04 17:15:37 INFO BlockManager: BlockManager stopped
25/02/04 17:15:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/02/04 17:15:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/02/04 17:15:37 INFO SparkContext: Successfully stopped SparkContext
25/02/04 17:15:37 INFO ShutdownHookManager: Shutdown hook called
25/02/04 17:15:37 INFO ShutdownHookManager: Deleting directory /private/var/folders/fp/rrfgkk216j93ycpskxsyphnw0000gn/T/spark-10d65f27-4a56-4084-8ffc-b40b3d5b3fc1/pyspark-497aa88c-7213-4398-abf4-9a6dda460708
25/02/04 17:15:37 INFO ShutdownHookManager: Deleting directory /private/var/folders/fp/rrfgkk216j93ycpskxsyphnw0000gn/T/spark-02e94c37-26ee-44ad-a6ac-52f125996100
25/02/04 17:15:37 INFO ShutdownHookManager: Deleting directory /private/var/folders/fp/rrfgkk216j93ycpskxsyphnw0000gn/T/spark-10d65f27-4a56-4084-8ffc-b40b3d5b3fc1
